{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "use newpycaret env\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# packages\n",
    "import snowflake.connector\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from autots import AutoTS\n",
    "from sklearn.impute import SimpleImputer\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime, timedelta\n",
    "from dateutil import relativedelta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Load Data\n",
    "\n",
    "---\n",
    "\n",
    "### To Do: copy and paste in to a new chunk, enter credentials and run to save in environment. Then delete chunk\n",
    "\n",
    "%env snowflakeuser=<your_snowflake_username> <br>\n",
    "%env snowflakepass=<your_snowflake_password>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\crudek\\AppData\\Local\\Temp\\ipykernel_24392\\2623517584.py:19: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_initial = pd.read_sql_query(query.read(), conn)\n"
     ]
    }
   ],
   "source": [
    "# Query Snowflake\n",
    "\n",
    "# Snowflake connection parameters\n",
    "connection_params = {\n",
    "    \"user\": os.environ['snowflakeuser'],\n",
    "    \"password\": os.environ['snowflakepass'],\n",
    "    \"account\": \"zib52348.us-east-1\",\n",
    "    \"role\": \"ACCOUNTADMIN\",\n",
    "    \"warehouse\": \"REPORTING\",\n",
    "    \"database\": \"ANALYTICS\",\n",
    "    \"schema\": \"FORECASTING\",\n",
    "}\n",
    "\n",
    "# Establish a connection to Snowflake\n",
    "conn = snowflake.connector.connect(**connection_params)\n",
    "\n",
    "with open('net_sales_query.sql', 'r') as query:\n",
    "    # connection == the connection to your database, in your case prob_db\n",
    "    df_initial = pd.read_sql_query(query.read(), conn)\n",
    "\n",
    "# Close the connection\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/14 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\crudek\\AppData\\Local\\Temp\\ipykernel_24392\\927946470.py:101: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_subset_all = df_subset_all.append(df_merged)\n",
      "C:\\Users\\crudek\\AppData\\Local\\Temp\\ipykernel_24392\\927946470.py:101: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_subset_all = df_subset_all.append(df_merged)\n",
      "C:\\Users\\crudek\\AppData\\Local\\Temp\\ipykernel_24392\\927946470.py:101: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_subset_all = df_subset_all.append(df_merged)\n",
      "C:\\Users\\crudek\\AppData\\Local\\Temp\\ipykernel_24392\\927946470.py:101: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_subset_all = df_subset_all.append(df_merged)\n",
      "C:\\Users\\crudek\\AppData\\Local\\Temp\\ipykernel_24392\\927946470.py:101: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_subset_all = df_subset_all.append(df_merged)\n",
      "C:\\Users\\crudek\\AppData\\Local\\Temp\\ipykernel_24392\\927946470.py:101: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_subset_all = df_subset_all.append(df_merged)\n",
      "C:\\Users\\crudek\\AppData\\Local\\Temp\\ipykernel_24392\\927946470.py:101: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_subset_all = df_subset_all.append(df_merged)\n",
      "C:\\Users\\crudek\\AppData\\Local\\Temp\\ipykernel_24392\\927946470.py:101: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_subset_all = df_subset_all.append(df_merged)\n",
      "C:\\Users\\crudek\\AppData\\Local\\Temp\\ipykernel_24392\\927946470.py:101: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_subset_all = df_subset_all.append(df_merged)\n",
      "C:\\Users\\crudek\\AppData\\Local\\Temp\\ipykernel_24392\\927946470.py:101: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_subset_all = df_subset_all.append(df_merged)\n",
      "C:\\Users\\crudek\\AppData\\Local\\Temp\\ipykernel_24392\\927946470.py:101: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_subset_all = df_subset_all.append(df_merged)\n",
      "C:\\Users\\crudek\\AppData\\Local\\Temp\\ipykernel_24392\\927946470.py:101: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_subset_all = df_subset_all.append(df_merged)\n",
      "C:\\Users\\crudek\\AppData\\Local\\Temp\\ipykernel_24392\\927946470.py:101: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_subset_all = df_subset_all.append(df_merged)\n",
      "C:\\Users\\crudek\\AppData\\Local\\Temp\\ipykernel_24392\\927946470.py:101: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_subset_all = df_subset_all.append(df_merged)\n",
      "100%|██████████| 14/14 [00:00<00:00, 248.60it/s]\n",
      "  0%|          | 0/14 [00:00<?, ?it/s]C:\\Users\\crudek\\AppData\\Local\\Temp\\ipykernel_24392\\927946470.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_subset_all2 = df_subset_all2.append(temp_result2)\n",
      "C:\\Users\\crudek\\AppData\\Local\\Temp\\ipykernel_24392\\927946470.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_subset_all2 = df_subset_all2.append(temp_result2)\n",
      "C:\\Users\\crudek\\AppData\\Local\\Temp\\ipykernel_24392\\927946470.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_subset_all2 = df_subset_all2.append(temp_result2)\n",
      "C:\\Users\\crudek\\AppData\\Local\\Temp\\ipykernel_24392\\927946470.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_subset_all2 = df_subset_all2.append(temp_result2)\n",
      "C:\\Users\\crudek\\AppData\\Local\\Temp\\ipykernel_24392\\927946470.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_subset_all2 = df_subset_all2.append(temp_result2)\n",
      "C:\\Users\\crudek\\AppData\\Local\\Temp\\ipykernel_24392\\927946470.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_subset_all2 = df_subset_all2.append(temp_result2)\n",
      "C:\\Users\\crudek\\AppData\\Local\\Temp\\ipykernel_24392\\927946470.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_subset_all2 = df_subset_all2.append(temp_result2)\n",
      "C:\\Users\\crudek\\AppData\\Local\\Temp\\ipykernel_24392\\927946470.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_subset_all2 = df_subset_all2.append(temp_result2)\n",
      "C:\\Users\\crudek\\AppData\\Local\\Temp\\ipykernel_24392\\927946470.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_subset_all2 = df_subset_all2.append(temp_result2)\n",
      "C:\\Users\\crudek\\AppData\\Local\\Temp\\ipykernel_24392\\927946470.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_subset_all2 = df_subset_all2.append(temp_result2)\n",
      "C:\\Users\\crudek\\AppData\\Local\\Temp\\ipykernel_24392\\927946470.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_subset_all2 = df_subset_all2.append(temp_result2)\n",
      "C:\\Users\\crudek\\AppData\\Local\\Temp\\ipykernel_24392\\927946470.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_subset_all2 = df_subset_all2.append(temp_result2)\n",
      "C:\\Users\\crudek\\AppData\\Local\\Temp\\ipykernel_24392\\927946470.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_subset_all2 = df_subset_all2.append(temp_result2)\n",
      "C:\\Users\\crudek\\AppData\\Local\\Temp\\ipykernel_24392\\927946470.py:119: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_subset_all2 = df_subset_all2.append(temp_result2)\n",
      "100%|██████████| 14/14 [00:00<00:00, 540.03it/s]\n"
     ]
    }
   ],
   "source": [
    "##### INITIAL VARIABLE DECLARATION #####\n",
    "\n",
    "# Get the current date\n",
    "current_date = datetime.today()\n",
    "\n",
    "# Calculate the first day of the current month\n",
    "first_day_of_current_month = pd.to_datetime(current_date.replace(day=1))\n",
    "\n",
    "# Calculate the first day of the next month\n",
    "first_day_of_next_month = datetime(current_date.year, current_date.month + 1, 1)\n",
    "\n",
    "# Calculate the first day of the last month\n",
    "last_day_of_last_month = first_day_of_current_month - timedelta(days=1)\n",
    "first_day_of_last_month = last_day_of_last_month.replace(day=1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### MANUAL INPUTS ###\n",
    "\n",
    "# how much data do you want to keep to train models. \n",
    "#end_of_data = first_day_of_last_month # the default which is the max date this should ever be because it would include all months that have full data\n",
    "end_of_data = pd.to_datetime('2022-12-01')\n",
    "\n",
    "# forecast horizon = how many months in to the future you want to forecast. So, we will forecast this many months past the above end_of_data\n",
    "fh = 12\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### FORECAST HORIZON (FH) DATAFRAME ###\n",
    "\n",
    "end_of_data_next_month = end_of_data + relativedelta.relativedelta(months=1, day=1)\n",
    "end_of_data_df = pd.DataFrame({'end_of_data': [end_of_data_next_month]})\n",
    "end_of_data_df['end_of_data'] = pd.to_datetime(end_of_data_df['end_of_data'])\n",
    "\n",
    "# Create a date range for the next 12 months\n",
    "next_12_months = pd.date_range(start=end_of_data_df['end_of_data'].iloc[0], periods=fh, freq='MS')\n",
    "\n",
    "fh_dates_df = pd.DataFrame({'MONTH': next_12_months})\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### INITIAL DATA PREPARATION ###\n",
    "\n",
    "# create copy of df_d\n",
    "df = df_initial.copy(deep=True)\n",
    "\n",
    "# convert month field to date\n",
    "df[\"MONTH\"] = pd.to_datetime(df[\"MONTH\"])\n",
    "\n",
    "# Some random months will have data that we want to remove (* Want to test without July though)\n",
    "df = df[[\"DEP_ENT\", \"MONTH\", \"NET_SALES\"]]  # select fields of interest\n",
    "df = df.sort_values(['DEP_ENT', 'MONTH'])  # reorder dataframe\n",
    "\n",
    "# remove data after the 'end of data' setting above\n",
    "df_sub = df[df['MONTH'] <= end_of_data]\n",
    "\n",
    "# create series\n",
    "df_s = df_sub.set_index(['DEP_ENT','MONTH'])['NET_SALES']\n",
    "# convert back to dataframe\n",
    "df_d = df_s.to_frame()\n",
    "#reset index\n",
    "df_d.reset_index(inplace=True)\n",
    "\n",
    "\n",
    "# list of each dep-ent\n",
    "all_dep_ent = df_d['DEP_ENT'].unique()\n",
    "\n",
    "\n",
    "### IMPUTE MISSIG VALUES WITH MONTH AND MEAN ###\n",
    "\n",
    "# Create empty dataframe\n",
    "df_subset_all = pd.DataFrame()\n",
    "\n",
    "for i in tqdm(all_dep_ent):\n",
    "    \n",
    "    temp_subset = df_d[df_d['DEP_ENT'] == i]\n",
    "    \n",
    "    # Define the minimum and maximum dates\n",
    "    min_date = min(temp_subset['MONTH'])\n",
    "    max_date = max(temp_subset['MONTH'])\n",
    "\n",
    "    # Generate a list of dates for each month in between\n",
    "    date_range = []\n",
    "    current_month = min_date.replace(day=1)\n",
    "    while current_month <= max_date:\n",
    "        date_range.append(current_month)\n",
    "        current_month = current_month + timedelta(days=32)\n",
    "        current_month = current_month.replace(day=1)\n",
    "\n",
    "    # Create a DataFrame from the list of dates\n",
    "    date_range_df = pd.DataFrame({'MONTH': date_range})\n",
    "\n",
    "    df_merged = pd.merge(date_range_df, temp_subset, on='MONTH', how='left')\n",
    "\n",
    "    #Finding the mean of the column having NaN\n",
    "    mean_value = df_merged['NET_SALES'].mean()\n",
    "    \n",
    "    # Replace NaNs in column S2 with the\n",
    "    # mean of values in the same column\n",
    "    df_merged['NET_SALES'].fillna(value=mean_value, inplace=True)\n",
    "    \n",
    "    df_merged['DEP_ENT'] = i\n",
    "\n",
    "    df_subset_all = df_subset_all.append(df_merged)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### FILL DATES THROUGH END OF FORECAST HORIZON ###\n",
    "\n",
    "# Create empty dataframe\n",
    "df_subset_all2 = pd.DataFrame()\n",
    "\n",
    "for i in tqdm(all_dep_ent):\n",
    "    # filter to one dep_ent\n",
    "    temp_subset2 = df_subset_all[df_subset_all['DEP_ENT'] == i]\n",
    "    # temp result\n",
    "    temp_result2 = pd.merge(temp_subset2, fh_dates_df, on='MONTH', how='outer')\n",
    "    temp_result2['DEP_ENT'] = i\n",
    "    \n",
    "    # combine for all dep_ents\n",
    "    df_subset_all2 = df_subset_all2.append(temp_result2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### REGRESSOR DATA PREPARATION ###\n",
    "\n",
    "# create copy of df_d\n",
    "df_d_regress = df_d.copy(deep=True)\n",
    "\n",
    "# Prepare regressors\n",
    "\n",
    "# Define the prime COVID period\n",
    "cov_start_date = pd.Timestamp(2020, 1, 1)\n",
    "cov_end_date = pd.Timestamp(2021, 12, 1)\n",
    "\n",
    "# Create the binary dummy variable\n",
    "df_d_regress['COVID'] = df_d_regress['MONTH'].apply(lambda date: '1' if cov_start_date <= date <= cov_end_date else '0')\n",
    "\n",
    "# Amazon prime day shipments\n",
    "\n",
    "# Define the dictionary\n",
    "amzn_ship_dict = {\n",
    "    'MONTH': [pd.Timestamp(2016, 7, 1), pd.Timestamp(2017, 5, 1), pd.Timestamp(2018, 6, 1), pd.Timestamp(2019, 6, 1), pd.Timestamp(2020, 6, 1),\n",
    "              pd.Timestamp(2020, 10, 1), pd.Timestamp(2021, 5, 1), pd.Timestamp(2022, 5, 1), pd.Timestamp(2023, 5, 1), pd.Timestamp(2023, 6, 1), pd.Timestamp(2023, 7, 1)],\n",
    "    'AMZN': ['1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1']\n",
    "}\n",
    "\n",
    "# Create a DataFrame from the dictionary\n",
    "amzn_ship_df = pd.DataFrame(amzn_ship_dict)\n",
    "# add Amazon department\n",
    "amzn_ship_df['DEP_ENT'] = '250_155'\n",
    "\n",
    "# combine in to single table\n",
    "df_d_regress1 = df_d_regress.merge(\n",
    "    amzn_ship_df, on=['DEP_ENT', 'MONTH'], how='left')\n",
    "\n",
    "df_d_regress1['AMZN'] = df_d_regress1['AMZN'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MONTH</th>\n",
       "      <th>DEP_ENT</th>\n",
       "      <th>NET_SALES</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>160_155</td>\n",
       "      <td>1076855.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-02-01</td>\n",
       "      <td>160_155</td>\n",
       "      <td>1305615.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-03-01</td>\n",
       "      <td>160_155</td>\n",
       "      <td>1774890.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-04-01</td>\n",
       "      <td>160_155</td>\n",
       "      <td>852505.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-05-01</td>\n",
       "      <td>160_155</td>\n",
       "      <td>3399714.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>2022-08-01</td>\n",
       "      <td>260_155</td>\n",
       "      <td>3398.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>2022-09-01</td>\n",
       "      <td>260_155</td>\n",
       "      <td>5377.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>2022-10-01</td>\n",
       "      <td>260_155</td>\n",
       "      <td>2673.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>2022-11-01</td>\n",
       "      <td>260_155</td>\n",
       "      <td>2998.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>2022-12-01</td>\n",
       "      <td>260_155</td>\n",
       "      <td>10435.32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1101 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        MONTH  DEP_ENT   NET_SALES\n",
       "0  2016-01-01  160_155  1076855.07\n",
       "1  2016-02-01  160_155  1305615.57\n",
       "2  2016-03-01  160_155  1774890.87\n",
       "3  2016-04-01  160_155   852505.23\n",
       "4  2016-05-01  160_155  3399714.50\n",
       "..        ...      ...         ...\n",
       "42 2022-08-01  260_155     3398.93\n",
       "43 2022-09-01  260_155     5377.52\n",
       "44 2022-10-01  260_155     2673.52\n",
       "45 2022-11-01  260_155     2998.44\n",
       "46 2022-12-01  260_155    10435.32\n",
       "\n",
       "[1101 rows x 3 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_subset_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/14 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 6 cpus for n_jobs.\n",
      "Data frequency is: MS, used frequency is: MS\n",
      "Model Number: 1 with model ARIMA in generation 0 of 3\n",
      "Model Number: 2 with model AverageValueNaive in generation 0 of 3\n",
      "Model Number: 3 with model AverageValueNaive in generation 0 of 3\n",
      "Model Number: 4 with model AverageValueNaive in generation 0 of 3\n",
      "Model Number: 5 with model DatepartRegression in generation 0 of 3\n",
      "Model Number: 6 with model DatepartRegression in generation 0 of 3\n",
      "Model Number: 7 with model DatepartRegression in generation 0 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 8 with model DatepartRegression in generation 0 of 3\n",
      "Template Eval Error: ImportError('Tensorflow not available, install with pip install tensorflow.') in model 8 in generation 0: DatepartRegression\n",
      "Model Number: 9 with model ETS in generation 0 of 3\n",
      "Model Number: 10 with model ETS in generation 0 of 3\n",
      "Model Number: 11 with model GLM in generation 0 of 3\n",
      "Model Number: 12 with model GLM in generation 0 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:541: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 13 with model GLS in generation 0 of 3\n",
      "Model Number: 14 with model GLS in generation 0 of 3\n",
      "Model Number: 15 with model GluonTS in generation 0 of 3\n",
      "Template Eval Error: ImportError('GluonTS installation is incompatible with AutoTS. The numpy version is sometimes the issue, try 1.23.1 {as of 06-2023}') in model 15 in generation 0: GluonTS\n",
      "Model Number: 16 with model GluonTS in generation 0 of 3\n",
      "Template Eval Error: ImportError('GluonTS installation is incompatible with AutoTS. The numpy version is sometimes the issue, try 1.23.1 {as of 06-2023}') in model 16 in generation 0: GluonTS\n",
      "Model Number: 17 with model GluonTS in generation 0 of 3\n",
      "Template Eval Error: ImportError('GluonTS installation is incompatible with AutoTS. The numpy version is sometimes the issue, try 1.23.1 {as of 06-2023}') in model 17 in generation 0: GluonTS\n",
      "Model Number: 18 with model GluonTS in generation 0 of 3\n",
      "Template Eval Error: ImportError('GluonTS installation is incompatible with AutoTS. The numpy version is sometimes the issue, try 1.23.1 {as of 06-2023}') in model 18 in generation 0: GluonTS\n",
      "Model Number: 19 with model GluonTS in generation 0 of 3\n",
      "Template Eval Error: ImportError('GluonTS installation is incompatible with AutoTS. The numpy version is sometimes the issue, try 1.23.1 {as of 06-2023}') in model 19 in generation 0: GluonTS\n",
      "Model Number: 20 with model LastValueNaive in generation 0 of 3\n",
      "Model Number: 21 with model LastValueNaive in generation 0 of 3\n",
      "Model Number: 22 with model LastValueNaive in generation 0 of 3\n",
      "Model Number: 23 with model LastValueNaive in generation 0 of 3\n",
      "Model Number: 24 with model SeasonalNaive in generation 0 of 3\n",
      "Model Number: 25 with model SeasonalNaive in generation 0 of 3\n",
      "Model Number: 26 with model SeasonalNaive in generation 0 of 3\n",
      "Model Number: 27 with model UnobservedComponents in generation 0 of 3\n",
      "Model Number: 28 with model UnobservedComponents in generation 0 of 3\n",
      "Model Number: 29 with model UnobservedComponents in generation 0 of 3\n",
      "Model Number: 30 with model VAR in generation 0 of 3\n",
      "Template Eval Error: ValueError('Only gave one variable to VAR') in model 30 in generation 0: VAR\n",
      "Model Number: 31 with model VAR in generation 0 of 3\n",
      "Template Eval Error: ValueError('Only gave one variable to VAR') in model 31 in generation 0: VAR\n",
      "Model Number: 32 with model VECM in generation 0 of 3\n",
      "Template Eval Error: ValueError('Only gave one variable to VECM') in model 32 in generation 0: VECM\n",
      "Model Number: 33 with model VECM in generation 0 of 3\n",
      "Template Eval Error: ValueError('Only gave one variable to VECM') in model 33 in generation 0: VECM\n",
      "Model Number: 34 with model WindowRegression in generation 0 of 3\n",
      "Model Number: 35 with model ConstantNaive in generation 0 of 3\n",
      "Model Number: 36 with model FBProphet in generation 0 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16:08:22 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:08:22 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 37 with model GluonTS in generation 0 of 3\n",
      "Template Eval Error: ImportError('GluonTS installation is incompatible with AutoTS. The numpy version is sometimes the issue, try 1.23.1 {as of 06-2023}') in model 37 in generation 0: GluonTS\n",
      "Model Number: 38 with model MultivariateRegression in generation 0 of 3\n",
      "Model Number: 39 with model MultivariateRegression in generation 0 of 3\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000027 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Model Number: 40 with model DatepartRegression in generation 0 of 3\n",
      "Model Number: 41 with model SeasonalNaive in generation 0 of 3\n",
      "Model Number: 42 with model DatepartRegression in generation 0 of 3\n",
      "Model Number: 43 with model UnobservedComponents in generation 0 of 3\n",
      "Model Number: 44 with model UnobservedComponents in generation 0 of 3\n",
      "Model Number: 45 with model ETS in generation 0 of 3\n",
      "Model Number: 46 with model VECM in generation 0 of 3\n",
      "Template Eval Error: ValueError('Only gave one variable to VECM') in model 46 in generation 0: VECM\n",
      "Model Number: 47 with model ARDL in generation 0 of 3\n",
      "Model Number: 48 with model MultivariateMotif in generation 0 of 3\n",
      "Model Number: 49 with model MultivariateMotif in generation 0 of 3\n",
      "Model Number: 50 with model UnivariateMotif in generation 0 of 3\n",
      "Template Eval Error: ValueError('kth(=10) out of bounds (1)') in model 50 in generation 0: UnivariateMotif\n",
      "Model Number: 51 with model UnivariateMotif in generation 0 of 3\n",
      "Model Number: 52 with model SectionalMotif in generation 0 of 3\n",
      "Model Number: 53 with model SectionalMotif in generation 0 of 3\n",
      "Model Number: 54 with model MultivariateRegression in generation 0 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16:08:25 - cmdstanpy - INFO - Chain [1] start processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 55 with model FBProphet in generation 0 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16:08:43 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 56 with model SeasonalNaive in generation 0 of 3\n",
      "Model Number: 57 with model DatepartRegression in generation 0 of 3\n",
      "Model Number: 58 with model NVAR in generation 0 of 3\n",
      "Model Number: 59 with model Theta in generation 0 of 3\n",
      "Model Number: 60 with model UnivariateRegression in generation 0 of 3\n",
      "Template Eval Error: ValueError('Input X contains NaN.\\nDecisionTreeRegressor does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values') in model 60 in generation 0: UnivariateRegression\n",
      "Model Number: 61 with model ARCH in generation 0 of 3\n",
      "Template Eval Error: ImportError('`arch` package must be installed from pip') in model 61 in generation 0: ARCH\n",
      "Model Number: 62 with model ConstantNaive in generation 0 of 3\n",
      "Model Number: 63 with model LastValueNaive in generation 0 of 3\n",
      "Model Number: 64 with model AverageValueNaive in generation 0 of 3\n",
      "Model Number: 65 with model GLS in generation 0 of 3\n",
      "Model Number: 66 with model SeasonalNaive in generation 0 of 3\n",
      "Model Number: 67 with model GLM in generation 0 of 3\n",
      "Template Eval Error: ValueError('The first guess on the deviance function returned a nan.  This could be a boundary  problem and should be reported.') in model 67 in generation 0: GLM\n",
      "Model Number: 68 with model ETS in generation 0 of 3\n",
      "Model Number: 69 with model FBProphet in generation 0 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\statsmodels\\genmod\\families\\family.py:1367: ValueWarning: Negative binomial dispersion parameter alpha not set. Using default value alpha=1.0.\n",
      "  warnings.warn(\"Negative binomial dispersion parameter alpha not \"\n",
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\statsmodels\\genmod\\families\\family.py:1406: RuntimeWarning: invalid value encountered in log\n",
      "  resid_dev -= endog_alpha * np.log(endog_alpha / mu_alpha)\n",
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.336e+12, tolerance: 2.160e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "16:08:43 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:08:44 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 70 with model GluonTS in generation 0 of 3\n",
      "Template Eval Error: ImportError('GluonTS installation is incompatible with AutoTS. The numpy version is sometimes the issue, try 1.23.1 {as of 06-2023}') in model 70 in generation 0: GluonTS\n",
      "Model Number: 71 with model UnobservedComponents in generation 0 of 3\n",
      "Model Number: 72 with model VAR in generation 0 of 3\n",
      "Template Eval Error: ValueError('Only gave one variable to VAR') in model 72 in generation 0: VAR\n",
      "Model Number: 73 with model VECM in generation 0 of 3\n",
      "Template Eval Error: ValueError('Only gave one variable to VECM') in model 73 in generation 0: VECM\n",
      "Model Number: 74 with model ARIMA in generation 0 of 3\n",
      "Model Number: 75 with model WindowRegression in generation 0 of 3\n",
      "Model Number: 76 with model DatepartRegression in generation 0 of 3\n",
      "Model Number: 77 with model UnivariateRegression in generation 0 of 3\n",
      "Model Number: 78 with model MultivariateRegression in generation 0 of 3\n",
      "Model Number: 79 with model UnivariateMotif in generation 0 of 3\n",
      "Model Number: 80 with model MultivariateMotif in generation 0 of 3\n",
      "Template Eval Error: ValueError('kth(=100) out of bounds (51)') in model 80 in generation 0: MultivariateMotif\n",
      "Model Number: 81 with model SectionalMotif in generation 0 of 3\n",
      "Template Eval Error: ValueError(\"Model returned NaN due to a preprocessing transformer {'fillna': 'rolling_mean', 'transformations': {'0': 'SeasonalDifference', '1': 'AlignLastValue', '2': 'AlignLastValue', '3': 'EWMAFilter'}, 'transformation_params': {'0': {'lag_1': 7, 'method': 'LastValue'}, '1': {'rows': 1, 'lag': 1, 'method': 'multiplicative', 'strength': 1.0, 'first_value_only': False}, '2': {'rows': 1, 'lag': 1, 'method': 'additive', 'strength': 1.0, 'first_value_only': False}, '3': {'span': 12}}}. fail_on_forecast_nan=True\") in model 81 in generation 0: SectionalMotif\n",
      "Model Number: 82 with model NVAR in generation 0 of 3\n",
      "Model Number: 83 with model Theta in generation 0 of 3\n",
      "Model Number: 84 with model ARDL in generation 0 of 3\n",
      "Model Number: 85 with model ARCH in generation 0 of 3\n",
      "Template Eval Error: ImportError('`arch` package must be installed from pip') in model 85 in generation 0: ARCH\n",
      "Model Number: 86 with model MetricMotif in generation 0 of 3\n",
      "Model Number: 87 with model AverageValueNaive in generation 0 of 3\n",
      "Model Number: 88 with model UnobservedComponents in generation 0 of 3\n",
      "Model Number: 89 with model AverageValueNaive in generation 0 of 3\n",
      "Model Number: 90 with model LastValueNaive in generation 0 of 3\n",
      "Model Number: 91 with model ARDL in generation 0 of 3\n",
      "Model Number: 92 with model WindowRegression in generation 0 of 3\n",
      "Model Number: 93 with model ConstantNaive in generation 0 of 3\n",
      "Model Number: 94 with model SeasonalNaive in generation 0 of 3\n",
      "Model Number: 95 with model ARDL in generation 0 of 3\n",
      "Template Eval Error: ValueError(\"ARDL series NET_SALES failed with error ValueError('The number of regressors (178) including deterministics, lags of the endog, lags of the exogenous, and fixed regressors is larger than the sample available for estimation (69).') exog train             weekend  quarter      epoch  month_1  month_2  month_3  month_4  \\\\\\nMONTH                                                                         \\n2016-01-01        0        1  2457388.5      1.0      0.0      0.0      0.0   \\n2016-02-01        0        1  2457419.5      0.0      1.0      0.0      0.0   \\n2016-03-01        0        1  2457448.5      0.0      0.0      1.0      0.0   \\n2016-04-01        0        2  2457479.5      0.0      0.0      0.0      1.0   \\n2016-05-01        1        2  2457509.5      0.0      0.0      0.0      0.0   \\n...             ...      ...        ...      ...      ...      ...      ...   \\n2021-08-01        1        3  2459427.5      0.0      0.0      0.0      0.0   \\n2021-09-01        0        3  2459458.5      0.0      0.0      0.0      0.0   \\n2021-10-01        0        4  2459488.5      0.0      0.0      0.0      0.0   \\n2021-11-01        0        4  2459519.5      0.0      0.0      0.0      0.0   \\n2021-12-01        0        4  2459549.5      0.0      0.0      0.0      0.0   \\n\\n            month_5  month_6  month_7  ...  day_27  day_28  day_29  day_30  \\\\\\nMONTH                                  ...                                   \\n2016-01-01      0.0      0.0      0.0  ...     0.0     0.0     0.0     0.0   \\n2016-02-01      0.0      0.0      0.0  ...     0.0     0.0     0.0     0.0   \\n2016-03-01      0.0      0.0      0.0  ...     0.0     0.0     0.0     0.0   \\n2016-04-01      0.0      0.0      0.0  ...     0.0     0.0     0.0     0.0   \\n2016-05-01      1.0      0.0      0.0  ...     0.0     0.0     0.0     0.0   \\n...             ...      ...      ...  ...     ...     ...     ...     ...   \\n2021-08-01      0.0      0.0      0.0  ...     0.0     0.0     0.0     0.0   \\n2021-09-01      0.0      0.0      0.0  ...     0.0     0.0     0.0     0.0   \\n2021-10-01      0.0      0.0      0.0  ...     0.0     0.0     0.0     0.0   \\n2021-11-01      0.0      0.0      0.0  ...     0.0     0.0     0.0     0.0   \\n2021-12-01      0.0      0.0      0.0  ...     0.0     0.0     0.0     0.0   \\n\\n            day_31  weekdayofmonth_1  weekdayofmonth_2  weekdayofmonth_3  \\\\\\nMONTH                                                                      \\n2016-01-01     0.0               1.0               0.0               0.0   \\n2016-02-01     0.0               1.0               0.0               0.0   \\n2016-03-01     0.0               1.0               0.0               0.0   \\n2016-04-01     0.0               1.0               0.0               0.0   \\n2016-05-01     0.0               1.0               0.0               0.0   \\n...            ...               ...               ...               ...   \\n2021-08-01     0.0               1.0               0.0               0.0   \\n2021-09-01     0.0               1.0               0.0               0.0   \\n2021-10-01     0.0               1.0               0.0               0.0   \\n2021-11-01     0.0               1.0               0.0               0.0   \\n2021-12-01     0.0               1.0               0.0               0.0   \\n\\n            weekdayofmonth_4  weekdayofmonth_5  \\nMONTH                                           \\n2016-01-01               0.0               0.0  \\n2016-02-01               0.0               0.0  \\n2016-03-01               0.0               0.0  \\n2016-04-01               0.0               0.0  \\n2016-05-01               0.0               0.0  \\n...                      ...               ...  \\n2021-08-01               0.0               0.0  \\n2021-09-01               0.0               0.0  \\n2021-10-01               0.0               0.0  \\n2021-11-01               0.0               0.0  \\n2021-12-01               0.0               0.0  \\n\\n[72 rows x 58 columns] and predict             weekend  quarter      epoch  month_1  month_2  month_3  month_4  \\\\\\n2022-01-01        1        1  2459580.5      1.0      0.0      0.0      0.0   \\n2022-02-01        0        1  2459611.5      0.0      1.0      0.0      0.0   \\n2022-03-01        0        1  2459639.5      0.0      0.0      1.0      0.0   \\n2022-04-01        0        2  2459670.5      0.0      0.0      0.0      1.0   \\n2022-05-01        1        2  2459700.5      0.0      0.0      0.0      0.0   \\n2022-06-01        0        2  2459731.5      0.0      0.0      0.0      0.0   \\n2022-07-01        0        3  2459761.5      0.0      0.0      0.0      0.0   \\n2022-08-01        0        3  2459792.5      0.0      0.0      0.0      0.0   \\n2022-09-01        0        3  2459823.5      0.0      0.0      0.0      0.0   \\n2022-10-01        1        4  2459853.5      0.0      0.0      0.0      0.0   \\n2022-11-01        0        4  2459884.5      0.0      0.0      0.0      0.0   \\n2022-12-01        0        4  2459914.5      0.0      0.0      0.0      0.0   \\n\\n            month_5  month_6  month_7  ...  day_27  day_28  day_29  day_30  \\\\\\n2022-01-01      0.0      0.0      0.0  ...     0.0     0.0     0.0     0.0   \\n2022-02-01      0.0      0.0      0.0  ...     0.0     0.0     0.0     0.0   \\n2022-03-01      0.0      0.0      0.0  ...     0.0     0.0     0.0     0.0   \\n2022-04-01      0.0      0.0      0.0  ...     0.0     0.0     0.0     0.0   \\n2022-05-01      1.0      0.0      0.0  ...     0.0     0.0     0.0     0.0   \\n2022-06-01      0.0      1.0      0.0  ...     0.0     0.0     0.0     0.0   \\n2022-07-01      0.0      0.0      1.0  ...     0.0     0.0     0.0     0.0   \\n2022-08-01      0.0      0.0      0.0  ...     0.0     0.0     0.0     0.0   \\n2022-09-01      0.0      0.0      0.0  ...     0.0     0.0     0.0     0.0   \\n2022-10-01      0.0      0.0      0.0  ...     0.0     0.0     0.0     0.0   \\n2022-11-01      0.0      0.0      0.0  ...     0.0     0.0     0.0     0.0   \\n2022-12-01      0.0      0.0      0.0  ...     0.0     0.0     0.0     0.0   \\n\\n            day_31  weekdayofmonth_1  weekdayofmonth_2  weekdayofmonth_3  \\\\\\n2022-01-01     0.0               1.0               0.0               0.0   \\n2022-02-01     0.0               1.0               0.0               0.0   \\n2022-03-01     0.0               1.0               0.0               0.0   \\n2022-04-01     0.0               1.0               0.0               0.0   \\n2022-05-01     0.0               1.0               0.0               0.0   \\n2022-06-01     0.0               1.0               0.0               0.0   \\n2022-07-01     0.0               1.0               0.0               0.0   \\n2022-08-01     0.0               1.0               0.0               0.0   \\n2022-09-01     0.0               1.0               0.0               0.0   \\n2022-10-01     0.0               1.0               0.0               0.0   \\n2022-11-01     0.0               1.0               0.0               0.0   \\n2022-12-01     0.0               1.0               0.0               0.0   \\n\\n            weekdayofmonth_4  weekdayofmonth_5  \\n2022-01-01               0.0               0.0  \\n2022-02-01               0.0               0.0  \\n2022-03-01               0.0               0.0  \\n2022-04-01               0.0               0.0  \\n2022-05-01               0.0               0.0  \\n2022-06-01               0.0               0.0  \\n2022-07-01               0.0               0.0  \\n2022-08-01               0.0               0.0  \\n2022-09-01               0.0               0.0  \\n2022-10-01               0.0               0.0  \\n2022-11-01               0.0               0.0  \\n2022-12-01               0.0               0.0  \\n\\n[12 rows x 58 columns]\") in model 95 in generation 0: ARDL\n",
      "Model Number: 96 with model FBProphet in generation 0 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16:08:45 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:08:45 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 97 with model ConstantNaive in generation 0 of 3\n",
      "Model Number: 98 with model ConstantNaive in generation 0 of 3\n",
      "Model Number: 99 with model UnobservedComponents in generation 0 of 3\n",
      "Model Number: 100 with model ConstantNaive in generation 0 of 3\n",
      "Model Number: 101 with model VAR in generation 0 of 3\n",
      "Template Eval Error: ValueError('Only gave one variable to VAR') in model 101 in generation 0: VAR\n",
      "Model Number: 102 with model ETS in generation 0 of 3\n",
      "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
      "ETS failed on NET_SALES with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
      "Model Number: 103 with model Theta in generation 0 of 3\n",
      "Model Number: 104 with model DatepartRegression in generation 0 of 3\n",
      "Template Eval Error: ValueError('Model DatepartRegression returned NaN for one or more series. fail_on_forecast_nan=True') in model 104 in generation 0: DatepartRegression\n",
      "Model Number: 105 with model GLM in generation 0 of 3\n",
      "Model Number: 106 with model ARCH in generation 0 of 3\n",
      "Template Eval Error: Exception('Transformer Detrend failed on fit') in model 106 in generation 0: ARCH\n",
      "Model Number: 107 with model AverageValueNaive in generation 0 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\neighbors\\_regression.py:494: UserWarning: One or more samples have no neighbors within specified radius; predicting NaN.\n",
      "  warnings.warn(empty_warning_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 108 with model MetricMotif in generation 0 of 3\n",
      "Model Number: 109 with model ETS in generation 0 of 3\n",
      "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
      "ETS failed on NET_SALES with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
      "Template Eval Error: Exception('Transformer DifferencedTransformer failed on inverse') in model 109 in generation 0: ETS\n",
      "Model Number: 110 with model ETS in generation 0 of 3\n",
      "ETS error ValueError('Cannot compute initial seasonals using heuristic method with less than two full seasonal cycles in the data.')\n",
      "ETS failed on NET_SALES with ValueError('Cannot compute initial seasonals using heuristic method with less than two full seasonal cycles in the data.')\n",
      "Template Eval Error: Exception('Transformer AlignLastValue failed on inverse') in model 110 in generation 0: ETS\n",
      "Model Number: 111 with model SeasonalNaive in generation 0 of 3\n",
      "Model Number: 112 with model ARCH in generation 0 of 3\n",
      "Template Eval Error: ImportError('`arch` package must be installed from pip') in model 112 in generation 0: ARCH\n",
      "Model Number: 113 with model SectionalMotif in generation 0 of 3\n",
      "Model Number: 114 with model SeasonalNaive in generation 0 of 3\n",
      "Model Number: 115 with model UnivariateRegression in generation 0 of 3\n",
      "Model Number: 116 with model VAR in generation 0 of 3\n",
      "Template Eval Error: ValueError('Only gave one variable to VAR') in model 116 in generation 0: VAR\n",
      "Model Number: 117 with model GluonTS in generation 0 of 3\n",
      "Template Eval Error: ImportError('GluonTS installation is incompatible with AutoTS. The numpy version is sometimes the issue, try 1.23.1 {as of 06-2023}') in model 117 in generation 0: GluonTS\n",
      "Model Number: 118 with model GLM in generation 0 of 3\n",
      "Template Eval Error: ValueError('NaN, inf or invalid value detected in weights, estimation infeasible.') in model 118 in generation 0: GLM\n",
      "Model Number: 119 with model MultivariateMotif in generation 0 of 3\n",
      "Model Number: 120 with model AverageValueNaive in generation 0 of 3\n",
      "Model Number: 121 with model ConstantNaive in generation 0 of 3\n",
      "Model Number: 122 with model ARCH in generation 0 of 3\n",
      "Template Eval Error: ImportError('`arch` package must be installed from pip') in model 122 in generation 0: ARCH\n",
      "Model Number: 123 with model GLS in generation 0 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\statsmodels\\genmod\\families\\family.py:1367: ValueWarning: Negative binomial dispersion parameter alpha not set. Using default value alpha=1.0.\n",
      "  warnings.warn(\"Negative binomial dispersion parameter alpha not \"\n",
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\statsmodels\\genmod\\families\\links.py:527: RuntimeWarning: overflow encountered in exp\n",
      "  return np.exp(z)\n",
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\statsmodels\\genmod\\families\\family.py:1402: RuntimeWarning: divide by zero encountered in divide\n",
      "  endog_mu = self._clean(endog / mu)\n",
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\statsmodels\\genmod\\families\\family.py:1406: RuntimeWarning: divide by zero encountered in log\n",
      "  resid_dev -= endog_alpha * np.log(endog_alpha / mu_alpha)\n",
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\statsmodels\\genmod\\families\\family.py:1406: RuntimeWarning: invalid value encountered in log\n",
      "  resid_dev -= endog_alpha * np.log(endog_alpha / mu_alpha)\n",
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\numpy\\core\\fromnumeric.py:86: RuntimeWarning: invalid value encountered in reduce\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n",
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\statsmodels\\genmod\\families\\family.py:143: RuntimeWarning: invalid value encountered in multiply\n",
      "  return 1. / (self.link.deriv(mu)**2 * self.variance(mu))\n",
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\statsmodels\\genmod\\generalized_linear_model.py:1243: RuntimeWarning: invalid value encountered in multiply\n",
      "  wlsendog = (lin_pred + self.family.link.deriv(mu) * (self.endog-mu)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 124 with model LastValueNaive in generation 0 of 3\n",
      "Template Eval Error: Exception('Transformer RegressionFilter failed on fit') in model 124 in generation 0: LastValueNaive\n",
      "Model Number: 125 with model UnobservedComponents in generation 0 of 3\n",
      "Model Number: 126 with model LastValueNaive in generation 0 of 3\n",
      "Model Number: 127 with model SectionalMotif in generation 0 of 3\n",
      "Template Eval Error: ValueError('Unknown Distance Metric: kulsinski') in model 127 in generation 0: SectionalMotif\n",
      "Model Number: 128 with model GLS in generation 0 of 3\n",
      "Model Number: 129 with model Theta in generation 0 of 3\n",
      "Model Number: 130 with model UnobservedComponents in generation 0 of 3\n",
      "Model Number: 131 with model WindowRegression in generation 0 of 3\n",
      "Template Eval Error: ValueError('Input X contains NaN.\\nBayesianRidge does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values') in model 131 in generation 0: WindowRegression\n",
      "Model Number: 132 with model NVAR in generation 0 of 3\n",
      "Model Number: 133 with model SeasonalNaive in generation 0 of 3\n",
      "Model Number: 134 with model UnobservedComponents in generation 0 of 3\n",
      "Template Eval Error: Exception('Transformer Detrend failed on fit') in model 134 in generation 0: UnobservedComponents\n",
      "Model Number: 135 with model GLS in generation 0 of 3\n",
      "Model Number: 136 with model MetricMotif in generation 0 of 3\n",
      "Model Number: 137 with model VAR in generation 0 of 3\n",
      "Template Eval Error: ValueError('Only gave one variable to VAR') in model 137 in generation 0: VAR\n",
      "Model Number: 138 with model WindowRegression in generation 0 of 3\n",
      "Template Eval Error: ImportError('Tensorflow not available, install with pip install tensorflow.') in model 138 in generation 0: WindowRegression\n",
      "Model Number: 139 with model GLM in generation 0 of 3\n",
      "Model Number: 140 with model NVAR in generation 0 of 3\n",
      "Model Number: 141 with model VAR in generation 0 of 3\n",
      "Template Eval Error: ValueError('Only gave one variable to VAR') in model 141 in generation 0: VAR\n",
      "Model Number: 142 with model DatepartRegression in generation 0 of 3\n",
      "Model Number: 143 with model GLS in generation 0 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\statsmodels\\genmod\\families\\links.py:198: RuntimeWarning: overflow encountered in exp\n",
      "  t = np.exp(-z)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 144 with model DatepartRegression in generation 0 of 3\n",
      "Template Eval Error: ValueError('Input X contains NaN.\\nExtraTreesRegressor does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values') in model 144 in generation 0: DatepartRegression\n",
      "Model Number: 145 with model VAR in generation 0 of 3\n",
      "Template Eval Error: ValueError('Only gave one variable to VAR') in model 145 in generation 0: VAR\n",
      "Model Number: 146 with model Theta in generation 0 of 3\n",
      "Model Number: 147 with model ETS in generation 0 of 3\n",
      "ETS error ValueError('Cannot compute initial seasonals using heuristic method with less than two full seasonal cycles in the data.')\n",
      "ETS failed on NET_SALES with ValueError('Cannot compute initial seasonals using heuristic method with less than two full seasonal cycles in the data.')\n",
      "Model Number: 148 with model ConstantNaive in generation 0 of 3\n",
      "Model Number: 149 with model ARDL in generation 0 of 3\n",
      "Model Number: 150 with model SectionalMotif in generation 0 of 3\n",
      "Model Number: 151 with model VAR in generation 0 of 3\n",
      "Model Number: 152 with model DatepartRegression in generation 0 of 3\n",
      "Model Number: 153 with model Theta in generation 0 of 3\n",
      "Model Number: 154 with model MetricMotif in generation 0 of 3\n",
      "Model Number: 155 with model DatepartRegression in generation 0 of 3\n",
      "Model Number: 156 with model GLM in generation 0 of 3\n",
      "Model Number: 157 with model GluonTS in generation 0 of 3\n",
      "Template Eval Error: ImportError('GluonTS installation is incompatible with AutoTS. The numpy version is sometimes the issue, try 1.23.1 {as of 06-2023}') in model 157 in generation 0: GluonTS\n",
      "Model Number: 158 with model DatepartRegression in generation 0 of 3\n",
      "Template Eval Error: Exception('Transformer AlignLastValue failed on inverse') in model 158 in generation 0: DatepartRegression\n",
      "Model Number: 159 with model NVAR in generation 0 of 3\n",
      "Model Number: 160 with model GLS in generation 0 of 3\n",
      "Model Number: 161 with model SectionalMotif in generation 0 of 3\n",
      "Model Number: 162 with model FBProphet in generation 0 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16:08:48 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:08:48 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 163 with model ETS in generation 0 of 3\n",
      "Model Number: 164 with model VAR in generation 0 of 3\n",
      "Template Eval Error: ValueError('Only gave one variable to VAR') in model 164 in generation 0: VAR\n",
      "Model Number: 165 with model MultivariateMotif in generation 0 of 3\n",
      "Model Number: 166 with model VAR in generation 0 of 3\n",
      "Template Eval Error: ValueError('Only gave one variable to VAR') in model 166 in generation 0: VAR\n",
      "Model Number: 167 with model ARIMA in generation 0 of 3\n",
      "Model Number: 168 with model UnobservedComponents in generation 0 of 3\n",
      "Model Number: 169 with model UnivariateMotif in generation 0 of 3\n",
      "Template Eval Error: ValueError('kth(=100) out of bounds (51)') in model 169 in generation 0: UnivariateMotif\n",
      "Model Number: 170 with model VAR in generation 0 of 3\n",
      "Template Eval Error: ValueError('Only gave one variable to VAR') in model 170 in generation 0: VAR\n",
      "Model Number: 171 with model Theta in generation 0 of 3\n",
      "Model Number: 172 with model MultivariateMotif in generation 0 of 3\n",
      "Model Number: 173 with model UnobservedComponents in generation 0 of 3\n",
      "Model Number: 174 with model WindowRegression in generation 0 of 3\n",
      "Model Number: 175 with model SeasonalNaive in generation 0 of 3\n",
      "Model Number: 176 with model ARDL in generation 0 of 3\n",
      "Model Number: 177 with model GLS in generation 0 of 3\n",
      "Model Number: 178 with model SectionalMotif in generation 0 of 3\n",
      "Model Number: 179 with model ARDL in generation 0 of 3\n",
      "Model Number: 180 with model MultivariateMotif in generation 0 of 3\n",
      "Model Number: 181 with model ARCH in generation 0 of 3\n",
      "Template Eval Error: ImportError('`arch` package must be installed from pip') in model 181 in generation 0: ARCH\n",
      "Model Number: 182 with model SectionalMotif in generation 0 of 3\n",
      "Model Number: 183 with model ARIMA in generation 0 of 3\n",
      "Model Number: 184 with model DatepartRegression in generation 0 of 3\n",
      "Model Number: 185 with model ETS in generation 0 of 3\n",
      "ETS error ValueError('Cannot compute initial seasonals using heuristic method with less than two full seasonal cycles in the data.')\n",
      "ETS failed on NET_SALES with ValueError('Cannot compute initial seasonals using heuristic method with less than two full seasonal cycles in the data.')\n",
      "Model Number: 186 with model VECM in generation 0 of 3\n",
      "Template Eval Error: ValueError('Only gave one variable to VECM') in model 186 in generation 0: VECM\n",
      "New Generation: 1 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.097e-01, tolerance: 5.909e-04\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 187 with model DatepartRegression in generation 1 of 3\n",
      "Model Number: 188 with model ETS in generation 1 of 3\n",
      "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
      "ETS failed on NET_SALES with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
      "Model Number: 189 with model SectionalMotif in generation 1 of 3\n",
      "Model Number: 190 with model MetricMotif in generation 1 of 3\n",
      "Template Eval Error: Exception('Transformer Cointegration failed on fit') in model 190 in generation 1: MetricMotif\n",
      "Model Number: 191 with model DatepartRegression in generation 1 of 3\n",
      "Template Eval Error: ImportError('Tensorflow not available, install with pip install tensorflow.') in model 191 in generation 1: DatepartRegression\n",
      "Model Number: 192 with model DatepartRegression in generation 1 of 3\n",
      "Model Number: 193 with model AverageValueNaive in generation 1 of 3\n",
      "Model Number: 194 with model WindowRegression in generation 1 of 3\n",
      "Template Eval Error: LightGBMError('[tweedie]: at least one target label is negative') in model 194 in generation 1: WindowRegression\n",
      "Model Number: 195 with model SeasonalNaive in generation 1 of 3\n",
      "Model Number: 196 with model SectionalMotif in generation 1 of 3\n",
      "Model Number: 197 with model GLM in generation 1 of 3\n",
      "Model Number: 198 with model ARDL in generation 1 of 3\n",
      "Model Number: 199 with model UnobservedComponents in generation 1 of 3\n",
      "Model Number: 200 with model UnobservedComponents in generation 1 of 3\n",
      "Model Number: 201 with model MetricMotif in generation 1 of 3\n",
      "Model Number: 202 with model ETS in generation 1 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\statsmodels\\genmod\\families\\links.py:198: RuntimeWarning: overflow encountered in exp\n",
      "  t = np.exp(-z)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 203 with model MetricMotif in generation 1 of 3\n",
      "Model Number: 204 with model MultivariateRegression in generation 1 of 3\n",
      "Template Eval Error: Exception('Transformer Cointegration failed on fit') in model 204 in generation 1: MultivariateRegression\n",
      "Model Number: 205 with model ARIMA in generation 1 of 3\n",
      "Model Number: 206 with model ETS in generation 1 of 3\n",
      "Model Number: 207 with model Theta in generation 1 of 3\n",
      "Model Number: 208 with model AverageValueNaive in generation 1 of 3\n",
      "Model Number: 209 with model DatepartRegression in generation 1 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.572e+13, tolerance: 6.130e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 210 with model MultivariateRegression in generation 1 of 3\n",
      "Model Number: 211 with model DatepartRegression in generation 1 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 212 with model ConstantNaive in generation 1 of 3\n",
      "Model Number: 213 with model MetricMotif in generation 1 of 3\n",
      "Model Number: 214 with model DatepartRegression in generation 1 of 3\n",
      "Model Number: 215 with model MultivariateRegression in generation 1 of 3\n",
      "Model Number: 216 with model ARDL in generation 1 of 3\n",
      "Model Number: 217 with model ARIMA in generation 1 of 3\n",
      "Model Number: 218 with model ETS in generation 1 of 3\n",
      "Model Number: 219 with model LastValueNaive in generation 1 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 220 with model LastValueNaive in generation 1 of 3\n",
      "Model Number: 221 with model UnivariateMotif in generation 1 of 3\n",
      "Model Number: 222 with model MultivariateMotif in generation 1 of 3\n",
      "Template Eval Error: ValueError('kth(=100) out of bounds (51)') in model 222 in generation 1: MultivariateMotif\n",
      "Model Number: 223 with model GLM in generation 1 of 3\n",
      "Model Number: 224 with model SectionalMotif in generation 1 of 3\n",
      "Template Eval Error: Exception('Transformer AlignLastValue failed on inverse') in model 224 in generation 1: SectionalMotif\n",
      "Model Number: 225 with model UnobservedComponents in generation 1 of 3\n",
      "Model Number: 226 with model SectionalMotif in generation 1 of 3\n",
      "Model Number: 227 with model AverageValueNaive in generation 1 of 3\n",
      "Model Number: 228 with model SeasonalNaive in generation 1 of 3\n",
      "Model Number: 229 with model DatepartRegression in generation 1 of 3\n",
      "Model Number: 230 with model WindowRegression in generation 1 of 3\n",
      "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "Model Number: 231 with model Theta in generation 1 of 3\n",
      "Model Number: 232 with model UnobservedComponents in generation 1 of 3\n",
      "Model Number: 233 with model ETS in generation 1 of 3\n",
      "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
      "ETS failed on NET_SALES with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
      "Model Number: 234 with model DatepartRegression in generation 1 of 3\n",
      "Template Eval Error: ValueError('Model DatepartRegression returned NaN for one or more series. fail_on_forecast_nan=True') in model 234 in generation 1: DatepartRegression\n",
      "Model Number: 235 with model GLS in generation 1 of 3\n",
      "Model Number: 236 with model ARIMA in generation 1 of 3\n",
      "Model Number: 237 with model SeasonalNaive in generation 1 of 3\n",
      "Model Number: 238 with model MetricMotif in generation 1 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\neighbors\\_regression.py:494: UserWarning: One or more samples have no neighbors within specified radius; predicting NaN.\n",
      "  warnings.warn(empty_warning_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 239 with model MetricMotif in generation 1 of 3\n",
      "Model Number: 240 with model FBProphet in generation 1 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.749e+12, tolerance: 2.219e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "16:08:57 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:08:57 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 241 with model MultivariateRegression in generation 1 of 3\n",
      "Template Eval Error: Exception('Transformer Cointegration failed on fit') in model 241 in generation 1: MultivariateRegression\n",
      "Model Number: 242 with model DatepartRegression in generation 1 of 3\n",
      "Model Number: 243 with model SeasonalNaive in generation 1 of 3\n",
      "Model Number: 244 with model SectionalMotif in generation 1 of 3\n",
      "Model Number: 245 with model GLS in generation 1 of 3\n",
      "Model Number: 246 with model ETS in generation 1 of 3\n",
      "Model Number: 247 with model UnobservedComponents in generation 1 of 3\n",
      "Model Number: 248 with model NVAR in generation 1 of 3\n",
      "Model Number: 249 with model ConstantNaive in generation 1 of 3\n",
      "Model Number: 250 with model NVAR in generation 1 of 3\n",
      "Model Number: 251 with model AverageValueNaive in generation 1 of 3\n",
      "Model Number: 252 with model NVAR in generation 1 of 3\n",
      "Model Number: 253 with model GLS in generation 1 of 3\n",
      "Model Number: 254 with model MultivariateMotif in generation 1 of 3\n",
      "Model Number: 255 with model UnivariateRegression in generation 1 of 3\n",
      "Model Number: 256 with model FBProphet in generation 1 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16:08:58 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:08:59 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 257 with model ARDL in generation 1 of 3\n",
      "Model Number: 258 with model DatepartRegression in generation 1 of 3\n",
      "Model Number: 259 with model GLS in generation 1 of 3\n",
      "Model Number: 260 with model ETS in generation 1 of 3\n",
      "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
      "ETS failed on NET_SALES with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
      "Model Number: 261 with model UnobservedComponents in generation 1 of 3\n",
      "Model Number: 262 with model MultivariateMotif in generation 1 of 3\n",
      "Model Number: 263 with model ETS in generation 1 of 3\n",
      "Model Number: 264 with model DatepartRegression in generation 1 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\autots\\tools\\probabilistic.py:67: RuntimeWarning: invalid value encountered in divide\n",
      "  (prior_mu / prior_sigma**2) + ((n * data_mu) / prior_sigma**2)\n",
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\autots\\tools\\probabilistic.py:68: RuntimeWarning: divide by zero encountered in divide\n",
      "  ) / ((1 / prior_sigma**2) + (n / prior_sigma**2))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 265 with model MultivariateMotif in generation 1 of 3\n",
      "Model Number: 266 with model SeasonalNaive in generation 1 of 3\n",
      "Template Eval Error: Exception('Transformer BTCD failed on fit') in model 266 in generation 1: SeasonalNaive\n",
      "Model Number: 267 with model ARIMA in generation 1 of 3\n",
      "Model Number: 268 with model WindowRegression in generation 1 of 3\n",
      "Template Eval Error: ValueError('Input X contains NaN.\\nRadiusNeighborsRegressor does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values') in model 268 in generation 1: WindowRegression\n",
      "Model Number: 269 with model GLS in generation 1 of 3\n",
      "Model Number: 270 with model AverageValueNaive in generation 1 of 3\n",
      "Model Number: 271 with model ConstantNaive in generation 1 of 3\n",
      "Model Number: 272 with model GLS in generation 1 of 3\n",
      "Model Number: 273 with model NVAR in generation 1 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\neighbors\\_regression.py:494: UserWarning: One or more samples have no neighbors within specified radius; predicting NaN.\n",
      "  warnings.warn(empty_warning_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 274 with model ARIMA in generation 1 of 3\n",
      "Model Number: 275 with model UnobservedComponents in generation 1 of 3\n",
      "Model Number: 276 with model SeasonalNaive in generation 1 of 3\n",
      "Model Number: 277 with model AverageValueNaive in generation 1 of 3\n",
      "Model Number: 278 with model MultivariateMotif in generation 1 of 3\n",
      "Model Number: 279 with model LastValueNaive in generation 1 of 3\n",
      "Template Eval Error: Exception('Transformer Detrend failed on fit') in model 279 in generation 1: LastValueNaive\n",
      "Model Number: 280 with model UnivariateRegression in generation 1 of 3\n",
      "Template Eval Error: ValueError('Input X contains NaN.\\nDecisionTreeRegressor does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values') in model 280 in generation 1: UnivariateRegression\n",
      "Model Number: 281 with model GLM in generation 1 of 3\n",
      "Model Number: 282 with model ARDL in generation 1 of 3\n",
      "Model Number: 283 with model ETS in generation 1 of 3\n",
      "Model Number: 284 with model Theta in generation 1 of 3\n",
      "Model Number: 285 with model NVAR in generation 1 of 3\n",
      "Model Number: 286 with model AverageValueNaive in generation 1 of 3\n",
      "Model Number: 287 with model WindowRegression in generation 1 of 3\n",
      "Model Number: 288 with model ARDL in generation 1 of 3\n",
      "Model Number: 289 with model GLS in generation 1 of 3\n",
      "Model Number: 290 with model MultivariateMotif in generation 1 of 3\n",
      "Model Number: 291 with model MultivariateRegression in generation 1 of 3\n",
      "Model Number: 292 with model SectionalMotif in generation 1 of 3\n",
      "Model Number: 293 with model LastValueNaive in generation 1 of 3\n",
      "Model Number: 294 with model GLS in generation 1 of 3\n",
      "Model Number: 295 with model AverageValueNaive in generation 1 of 3\n",
      "Model Number: 296 with model NVAR in generation 1 of 3\n",
      "Model Number: 297 with model NVAR in generation 1 of 3\n",
      "Model Number: 298 with model NVAR in generation 1 of 3\n",
      "Model Number: 299 with model GLS in generation 1 of 3\n",
      "Model Number: 300 with model NVAR in generation 1 of 3\n",
      "Model Number: 301 with model ConstantNaive in generation 1 of 3\n",
      "Model Number: 302 with model SeasonalNaive in generation 1 of 3\n",
      "Template Eval Error: Exception('Transformer AlignLastValue failed on inverse') in model 302 in generation 1: SeasonalNaive\n",
      "Model Number: 303 with model LastValueNaive in generation 1 of 3\n",
      "Model Number: 304 with model ETS in generation 1 of 3\n",
      "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
      "ETS failed on NET_SALES with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
      "Model Number: 305 with model ConstantNaive in generation 1 of 3\n",
      "Template Eval Error: Exception('Transformer Cointegration failed on fit') in model 305 in generation 1: ConstantNaive\n",
      "Model Number: 306 with model MetricMotif in generation 1 of 3\n",
      "Model Number: 307 with model SectionalMotif in generation 1 of 3\n",
      "Model Number: 308 with model AverageValueNaive in generation 1 of 3\n",
      "Model Number: 309 with model UnobservedComponents in generation 1 of 3\n",
      "Model Number: 310 with model MultivariateRegression in generation 1 of 3\n",
      "Model Number: 311 with model GLM in generation 1 of 3\n",
      "New Generation: 2 of 3\n",
      "Model Number: 312 with model ARDL in generation 2 of 3\n",
      "Template Eval Error: Exception('Transformer LocalLinearTrend failed on fit') in model 312 in generation 2: ARDL\n",
      "Model Number: 313 with model GLS in generation 2 of 3\n",
      "Model Number: 314 with model ARDL in generation 2 of 3\n",
      "Model Number: 315 with model ARDL in generation 2 of 3\n",
      "Template Eval Error: ValueError(\"ARDL series NET_SALES failed with error IndexError('tuple index out of range') exog train None and predict                    MONTH  COVID  AMZN\\nMONTH                                \\n2022-01-01  1.640995e+18    0.0   0.0\\n2022-02-01  1.643674e+18    0.0   0.0\\n2022-03-01  1.646093e+18    0.0   0.0\\n2022-04-01  1.648771e+18    0.0   0.0\\n2022-05-01  1.651363e+18    0.0   0.0\\n2022-06-01  1.654042e+18    0.0   0.0\\n2022-07-01  1.656634e+18    0.0   0.0\\n2022-08-01  1.659312e+18    0.0   0.0\\n2022-09-01  1.661990e+18    0.0   0.0\\n2022-10-01  1.664582e+18    0.0   0.0\\n2022-11-01  1.667261e+18    0.0   0.0\\n2022-12-01  1.669853e+18    0.0   0.0\") in model 315 in generation 2: ARDL\n",
      "Model Number: 316 with model ARDL in generation 2 of 3\n",
      "Template Eval Error: ValueError(\"ARDL series NET_SALES failed with error IndexError('tuple index out of range') exog train None and predict                    MONTH  COVID  AMZN\\nMONTH                                \\n2022-01-01  1.640995e+18    0.0   0.0\\n2022-02-01  1.643674e+18    0.0   0.0\\n2022-03-01  1.646093e+18    0.0   0.0\\n2022-04-01  1.648771e+18    0.0   0.0\\n2022-05-01  1.651363e+18    0.0   0.0\\n2022-06-01  1.654042e+18    0.0   0.0\\n2022-07-01  1.656634e+18    0.0   0.0\\n2022-08-01  1.659312e+18    0.0   0.0\\n2022-09-01  1.661990e+18    0.0   0.0\\n2022-10-01  1.664582e+18    0.0   0.0\\n2022-11-01  1.667261e+18    0.0   0.0\\n2022-12-01  1.669853e+18    0.0   0.0\") in model 316 in generation 2: ARDL\n",
      "Model Number: 317 with model ARDL in generation 2 of 3\n",
      "Model Number: 318 with model SeasonalNaive in generation 2 of 3\n",
      "Model Number: 319 with model DatepartRegression in generation 2 of 3\n",
      "Model Number: 320 with model MetricMotif in generation 2 of 3\n",
      "Model Number: 321 with model UnobservedComponents in generation 2 of 3\n",
      "Model Number: 322 with model WindowRegression in generation 2 of 3\n",
      "Model Number: 323 with model GLS in generation 2 of 3\n",
      "Template Eval Error: Exception('Transformer LocalLinearTrend failed on fit') in model 323 in generation 2: GLS\n",
      "Model Number: 324 with model ARDL in generation 2 of 3\n",
      "Model Number: 325 with model AverageValueNaive in generation 2 of 3\n",
      "Model Number: 326 with model GLS in generation 2 of 3\n",
      "Model Number: 327 with model GLS in generation 2 of 3\n",
      "Model Number: 328 with model AverageValueNaive in generation 2 of 3\n",
      "Model Number: 329 with model ETS in generation 2 of 3\n",
      "Model Number: 330 with model AverageValueNaive in generation 2 of 3\n",
      "Model Number: 331 with model NVAR in generation 2 of 3\n",
      "Model Number: 332 with model GLM in generation 2 of 3\n",
      "Model Number: 333 with model MultivariateRegression in generation 2 of 3\n",
      "Model Number: 334 with model SectionalMotif in generation 2 of 3\n",
      "Model Number: 335 with model AverageValueNaive in generation 2 of 3\n",
      "Model Number: 336 with model LastValueNaive in generation 2 of 3\n",
      "Model Number: 337 with model MetricMotif in generation 2 of 3\n",
      "Model Number: 338 with model LastValueNaive in generation 2 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 339 with model WindowRegression in generation 2 of 3\n",
      "Model Number: 340 with model ARIMA in generation 2 of 3\n",
      "Model Number: 341 with model GLS in generation 2 of 3\n",
      "Model Number: 342 with model Theta in generation 2 of 3\n",
      "Model Number: 343 with model MultivariateRegression in generation 2 of 3\n",
      "Model Number: 344 with model SeasonalNaive in generation 2 of 3\n",
      "Template Eval Error: Exception('Transformer RegressionFilter failed on fit') in model 344 in generation 2: SeasonalNaive\n",
      "Model Number: 345 with model ARIMA in generation 2 of 3\n",
      "Model Number: 346 with model DatepartRegression in generation 2 of 3\n",
      "Model Number: 347 with model DatepartRegression in generation 2 of 3\n",
      "Model Number: 348 with model AverageValueNaive in generation 2 of 3\n",
      "Model Number: 349 with model NVAR in generation 2 of 3\n",
      "Model Number: 350 with model SectionalMotif in generation 2 of 3\n",
      "Model Number: 351 with model GLS in generation 2 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 352 with model AverageValueNaive in generation 2 of 3\n",
      "Model Number: 353 with model GLS in generation 2 of 3\n",
      "Template Eval Error: Exception('Transformer LocalLinearTrend failed on fit') in model 353 in generation 2: GLS\n",
      "Model Number: 354 with model MetricMotif in generation 2 of 3\n",
      "Model Number: 355 with model AverageValueNaive in generation 2 of 3\n",
      "Model Number: 356 with model ARIMA in generation 2 of 3\n",
      "Model Number: 357 with model AverageValueNaive in generation 2 of 3\n",
      "Model Number: 358 with model LastValueNaive in generation 2 of 3\n",
      "Model Number: 359 with model AverageValueNaive in generation 2 of 3\n",
      "Model Number: 360 with model DatepartRegression in generation 2 of 3\n",
      "Model Number: 361 with model AverageValueNaive in generation 2 of 3\n",
      "Model Number: 362 with model GLS in generation 2 of 3\n",
      "Model Number: 363 with model MetricMotif in generation 2 of 3\n",
      "Model Number: 364 with model UnobservedComponents in generation 2 of 3\n",
      "Model Number: 365 with model WindowRegression in generation 2 of 3\n",
      "Model Number: 366 with model MetricMotif in generation 2 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 367 with model GLS in generation 2 of 3\n",
      "Model Number: 368 with model SectionalMotif in generation 2 of 3\n",
      "Model Number: 369 with model NVAR in generation 2 of 3\n",
      "Model Number: 370 with model GLM in generation 2 of 3\n",
      "Model Number: 371 with model DatepartRegression in generation 2 of 3\n",
      "Model Number: 372 with model GLS in generation 2 of 3\n",
      "Template Eval Error: Exception('Transformer Detrend failed on fit') in model 372 in generation 2: GLS\n",
      "Model Number: 373 with model NVAR in generation 2 of 3\n",
      "Model Number: 374 with model SeasonalNaive in generation 2 of 3\n",
      "Model Number: 375 with model MetricMotif in generation 2 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\statsmodels\\genmod\\families\\links.py:198: RuntimeWarning: overflow encountered in exp\n",
      "  t = np.exp(-z)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 376 with model ARDL in generation 2 of 3\n",
      "Model Number: 377 with model DatepartRegression in generation 2 of 3\n",
      "Model Number: 378 with model UnobservedComponents in generation 2 of 3\n",
      "Model Number: 379 with model DatepartRegression in generation 2 of 3\n",
      "Template Eval Error: Exception('Transformer Cointegration failed on fit') in model 379 in generation 2: DatepartRegression\n",
      "Model Number: 380 with model DatepartRegression in generation 2 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Template Eval Error: Exception('Transformer DatepartRegression failed on fit') in model 380 in generation 2: DatepartRegression\n",
      "Model Number: 381 with model ARIMA in generation 2 of 3\n",
      "Model Number: 382 with model ARDL in generation 2 of 3\n",
      "Template Eval Error: ValueError(\"ARDL series NET_SALES failed with error IndexError('tuple index out of range') exog train None and predict                    MONTH  COVID  AMZN\\nMONTH                                \\n2022-01-01  1.640995e+18    0.0   0.0\\n2022-02-01  1.643674e+18    0.0   0.0\\n2022-03-01  1.646093e+18    0.0   0.0\\n2022-04-01  1.648771e+18    0.0   0.0\\n2022-05-01  1.651363e+18    0.0   0.0\\n2022-06-01  1.654042e+18    0.0   0.0\\n2022-07-01  1.656634e+18    0.0   0.0\\n2022-08-01  1.659312e+18    0.0   0.0\\n2022-09-01  1.661990e+18    0.0   0.0\\n2022-10-01  1.664582e+18    0.0   0.0\\n2022-11-01  1.667261e+18    0.0   0.0\\n2022-12-01  1.669853e+18    0.0   0.0\") in model 382 in generation 2: ARDL\n",
      "Model Number: 383 with model GLS in generation 2 of 3\n",
      "Model Number: 384 with model Theta in generation 2 of 3\n",
      "Model Number: 385 with model LastValueNaive in generation 2 of 3\n",
      "Model Number: 386 with model ETS in generation 2 of 3\n",
      "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
      "ETS failed on NET_SALES with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
      "Model Number: 387 with model ARDL in generation 2 of 3\n",
      "Model Number: 388 with model ConstantNaive in generation 2 of 3\n",
      "Model Number: 389 with model NVAR in generation 2 of 3\n",
      "Model Number: 390 with model UnobservedComponents in generation 2 of 3\n",
      "Model Number: 391 with model UnobservedComponents in generation 2 of 3\n",
      "Model Number: 392 with model MultivariateMotif in generation 2 of 3\n",
      "Model Number: 393 with model UnobservedComponents in generation 2 of 3\n",
      "Model Number: 394 with model MultivariateMotif in generation 2 of 3\n",
      "Model Number: 395 with model UnobservedComponents in generation 2 of 3\n",
      "Model Number: 396 with model MetricMotif in generation 2 of 3\n",
      "Model Number: 397 with model WindowRegression in generation 2 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\decomposition\\_fastica.py:708: FutureWarning: Starting in v1.3, whiten=True should be specified as whiten='arbitrary-variance' (its current behaviour). This behavior is deprecated in 1.1 and will raise ValueError in 1.3.\n",
      "  return self._fit_transform(X, compute_sources=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 398 with model DatepartRegression in generation 2 of 3\n",
      "Model Number: 399 with model ETS in generation 2 of 3\n",
      "Model Number: 400 with model AverageValueNaive in generation 2 of 3\n",
      "Model Number: 401 with model DatepartRegression in generation 2 of 3\n",
      "Template Eval Error: Exception('Transformer DatepartRegression failed on fit') in model 401 in generation 2: DatepartRegression\n",
      "Model Number: 402 with model SectionalMotif in generation 2 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\decomposition\\_fastica.py:708: FutureWarning: Starting in v1.3, whiten=True should be specified as whiten='arbitrary-variance' (its current behaviour). This behavior is deprecated in 1.1 and will raise ValueError in 1.3.\n",
      "  return self._fit_transform(X, compute_sources=True)\n",
      "16:09:14 - cmdstanpy - INFO - Chain [1] start processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 403 with model FBProphet in generation 2 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16:09:14 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 404 with model SectionalMotif in generation 2 of 3\n",
      "Model Number: 405 with model ETS in generation 2 of 3\n",
      "Model Number: 406 with model ETS in generation 2 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\linear_model\\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.48343e-24): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 407 with model NVAR in generation 2 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (250) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 408 with model AverageValueNaive in generation 2 of 3\n",
      "Model Number: 409 with model WindowRegression in generation 2 of 3\n",
      "Model Number: 410 with model UnobservedComponents in generation 2 of 3\n",
      "Model Number: 411 with model ETS in generation 2 of 3\n",
      "Model Number: 412 with model ETS in generation 2 of 3\n",
      "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
      "ETS failed on NET_SALES with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
      "Model Number: 413 with model DatepartRegression in generation 2 of 3\n",
      "Template Eval Error: Exception('Transformer Cointegration failed on fit') in model 413 in generation 2: DatepartRegression\n",
      "Model Number: 414 with model NVAR in generation 2 of 3\n",
      "Model Number: 415 with model ARDL in generation 2 of 3\n",
      "Model Number: 416 with model Theta in generation 2 of 3\n",
      "Model Number: 417 with model GLS in generation 2 of 3\n",
      "Model Number: 418 with model WindowRegression in generation 2 of 3\n",
      "Model Number: 419 with model MultivariateRegression in generation 2 of 3\n",
      "Model Number: 420 with model MultivariateMotif in generation 2 of 3\n",
      "Model Number: 421 with model ETS in generation 2 of 3\n",
      "Model Number: 422 with model SectionalMotif in generation 2 of 3\n",
      "Model Number: 423 with model UnivariateMotif in generation 2 of 3\n",
      "Model Number: 424 with model UnivariateRegression in generation 2 of 3\n",
      "Model Number: 425 with model ARIMA in generation 2 of 3\n",
      "Model Number: 426 with model AverageValueNaive in generation 2 of 3\n",
      "Model Number: 427 with model NVAR in generation 2 of 3\n",
      "Model Number: 428 with model AverageValueNaive in generation 2 of 3\n",
      "Model Number: 429 with model UnivariateRegression in generation 2 of 3\n",
      "Model Number: 430 with model SectionalMotif in generation 2 of 3\n",
      "Model Number: 431 with model SeasonalNaive in generation 2 of 3\n",
      "Model Number: 432 with model SeasonalNaive in generation 2 of 3\n",
      "Model Number: 433 with model NVAR in generation 2 of 3\n",
      "Model Number: 434 with model WindowRegression in generation 2 of 3\n",
      "Model Number: 435 with model MetricMotif in generation 2 of 3\n",
      "Model Number: 436 with model NVAR in generation 2 of 3\n",
      "New Generation: 3 of 3\n",
      "Model Number: 437 with model WindowRegression in generation 3 of 3\n",
      "Model Number: 438 with model Theta in generation 3 of 3\n",
      "Model Number: 439 with model GLS in generation 3 of 3\n",
      "Model Number: 440 with model SeasonalNaive in generation 3 of 3\n",
      "Model Number: 441 with model WindowRegression in generation 3 of 3\n",
      "Model Number: 442 with model UnobservedComponents in generation 3 of 3\n",
      "Model Number: 443 with model GLS in generation 3 of 3\n",
      "Model Number: 444 with model SeasonalNaive in generation 3 of 3\n",
      "Model Number: 445 with model MultivariateRegression in generation 3 of 3\n",
      "Model Number: 446 with model UnobservedComponents in generation 3 of 3\n",
      "Model Number: 447 with model MetricMotif in generation 3 of 3\n",
      "Model Number: 448 with model NVAR in generation 3 of 3\n",
      "Model Number: 449 with model LastValueNaive in generation 3 of 3\n",
      "Model Number: 450 with model SectionalMotif in generation 3 of 3\n",
      "Model Number: 451 with model LastValueNaive in generation 3 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 452 with model ConstantNaive in generation 3 of 3\n",
      "Template Eval Error: ValueError(\"Model returned NaN due to a preprocessing transformer {'fillna': 'ffill', 'transformations': {'0': 'AlignLastValue', '1': 'Detrend', '2': 'AlignLastValue', '3': 'KalmanSmoothing'}, 'transformation_params': {'0': {'rows': 1, 'lag': 1, 'method': 'additive', 'strength': 1.0, 'first_value_only': False}, '1': {'model': 'Linear', 'phi': 1, 'window': 365, 'transform_dict': None}, '2': {'rows': 1, 'lag': 1, 'method': 'multiplicative', 'strength': 0.2, 'first_value_only': False}, '3': {'model_name': 'local_linear_trend_ets_aan', 'state_transition': [[1, 1], [0, 1]], 'process_noise': [[1.3, 0.0], [0.0, 0.3]], 'observation_model': [[1, 0]], 'observation_noise': 0.25, 'em_iter': None}}}. fail_on_forecast_nan=True\") in model 452 in generation 3: ConstantNaive\n",
      "Model Number: 453 with model GLM in generation 3 of 3\n",
      "Model Number: 454 with model AverageValueNaive in generation 3 of 3\n",
      "Model Number: 455 with model NVAR in generation 3 of 3\n",
      "Model Number: 456 with model UnivariateRegression in generation 3 of 3\n",
      "Model Number: 457 with model ConstantNaive in generation 3 of 3\n",
      "Model Number: 458 with model ETS in generation 3 of 3\n",
      "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
      "ETS failed on NET_SALES with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
      "Model Number: 459 with model ARIMA in generation 3 of 3\n",
      "Template Eval Error: Exception('Transformer AlignLastValue failed on inverse') in model 459 in generation 3: ARIMA\n",
      "Model Number: 460 with model LastValueNaive in generation 3 of 3\n",
      "Model Number: 461 with model GLM in generation 3 of 3\n",
      "Model Number: 462 with model NVAR in generation 3 of 3\n",
      "Model Number: 463 with model MetricMotif in generation 3 of 3\n",
      "Model Number: 464 with model WindowRegression in generation 3 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\decomposition\\_fastica.py:708: FutureWarning: Starting in v1.3, whiten=True should be specified as whiten='arbitrary-variance' (its current behaviour). This behavior is deprecated in 1.1 and will raise ValueError in 1.3.\n",
      "  return self._fit_transform(X, compute_sources=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 465 with model NVAR in generation 3 of 3\n",
      "Model Number: 466 with model UnobservedComponents in generation 3 of 3\n",
      "Model Number: 467 with model MultivariateRegression in generation 3 of 3\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000030 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Model Number: 468 with model ARIMA in generation 3 of 3\n",
      "Model Number: 469 with model MetricMotif in generation 3 of 3\n",
      "Model Number: 470 with model UnivariateMotif in generation 3 of 3\n",
      "Model Number: 471 with model LastValueNaive in generation 3 of 3\n",
      "Model Number: 472 with model WindowRegression in generation 3 of 3\n",
      "Model Number: 473 with model DatepartRegression in generation 3 of 3\n",
      "Model Number: 474 with model ETS in generation 3 of 3\n",
      "Model Number: 475 with model LastValueNaive in generation 3 of 3\n",
      "Model Number: 476 with model AverageValueNaive in generation 3 of 3\n",
      "Model Number: 477 with model ARDL in generation 3 of 3\n",
      "Model Number: 478 with model NVAR in generation 3 of 3\n",
      "Model Number: 479 with model WindowRegression in generation 3 of 3\n",
      "Model Number: 480 with model AverageValueNaive in generation 3 of 3\n",
      "Model Number: 481 with model MultivariateMotif in generation 3 of 3\n",
      "Template Eval Error: Exception('Transformer BTCD failed on fit') in model 481 in generation 3: MultivariateMotif\n",
      "Model Number: 482 with model ARIMA in generation 3 of 3\n",
      "Model Number: 483 with model SeasonalNaive in generation 3 of 3\n",
      "Model Number: 484 with model ARDL in generation 3 of 3\n",
      "Model Number: 485 with model AverageValueNaive in generation 3 of 3\n",
      "Model Number: 486 with model ARDL in generation 3 of 3\n",
      "Model Number: 487 with model LastValueNaive in generation 3 of 3\n",
      "Model Number: 488 with model MetricMotif in generation 3 of 3\n",
      "Model Number: 489 with model UnobservedComponents in generation 3 of 3\n",
      "Template Eval Error: ValueError(\"'shape' elements cannot be negative\") in model 489 in generation 3: UnobservedComponents\n",
      "Model Number: 490 with model UnobservedComponents in generation 3 of 3\n",
      "Model Number: 491 with model DatepartRegression in generation 3 of 3\n",
      "Model Number: 492 with model ETS in generation 3 of 3\n",
      "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
      "ETS failed on NET_SALES with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
      "Model Number: 493 with model LastValueNaive in generation 3 of 3\n",
      "Model Number: 494 with model LastValueNaive in generation 3 of 3\n",
      "Model Number: 495 with model ARDL in generation 3 of 3\n",
      "Model Number: 496 with model DatepartRegression in generation 3 of 3\n",
      "Model Number: 497 with model MetricMotif in generation 3 of 3\n",
      "Model Number: 498 with model DatepartRegression in generation 3 of 3\n",
      "Model Number: 499 with model SeasonalNaive in generation 3 of 3\n",
      "Model Number: 500 with model DatepartRegression in generation 3 of 3\n",
      "Model Number: 501 with model ARDL in generation 3 of 3\n",
      "Model Number: 502 with model AverageValueNaive in generation 3 of 3\n",
      "Model Number: 503 with model MultivariateMotif in generation 3 of 3\n",
      "Model Number: 504 with model DatepartRegression in generation 3 of 3\n",
      "Template Eval Error: Exception('Transformer Cointegration failed on fit') in model 504 in generation 3: DatepartRegression\n",
      "Model Number: 505 with model GLM in generation 3 of 3\n",
      "Model Number: 506 with model MultivariateRegression in generation 3 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 507 with model GLM in generation 3 of 3\n",
      "Model Number: 508 with model ETS in generation 3 of 3\n",
      "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
      "ETS failed on NET_SALES with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
      "Model Number: 509 with model VAR in generation 3 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\statsmodels\\genmod\\generalized_linear_model.py:307: DomainWarning: The InversePower link function does not respect the domain of the Gamma family.\n",
      "  warnings.warn((f\"The {type(family.link).__name__} link function \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 510 with model MultivariateRegression in generation 3 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\decomposition\\_fastica.py:708: FutureWarning: Starting in v1.3, whiten=True should be specified as whiten='arbitrary-variance' (its current behaviour). This behavior is deprecated in 1.1 and will raise ValueError in 1.3.\n",
      "  return self._fit_transform(X, compute_sources=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 511 with model ETS in generation 3 of 3\n",
      "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
      "ETS failed on NET_SALES with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
      "Model Number: 512 with model UnobservedComponents in generation 3 of 3\n",
      "Model Number: 513 with model WindowRegression in generation 3 of 3\n",
      "Model Number: 514 with model DatepartRegression in generation 3 of 3\n",
      "Model Number: 515 with model UnivariateRegression in generation 3 of 3\n",
      "Model Number: 516 with model ARDL in generation 3 of 3\n",
      "Model Number: 517 with model UnivariateMotif in generation 3 of 3\n",
      "Model Number: 518 with model WindowRegression in generation 3 of 3\n",
      "Model Number: 519 with model GLS in generation 3 of 3\n",
      "Template Eval Error: Exception('Transformer BTCD failed on fit') in model 519 in generation 3: GLS\n",
      "Model Number: 520 with model MultivariateRegression in generation 3 of 3\n",
      "Model Number: 521 with model SeasonalNaive in generation 3 of 3\n",
      "Model Number: 522 with model SectionalMotif in generation 3 of 3\n",
      "Model Number: 523 with model SectionalMotif in generation 3 of 3\n",
      "Template Eval Error: ValueError('kth(=20) out of bounds (11)') in model 523 in generation 3: SectionalMotif\n",
      "Model Number: 524 with model ETS in generation 3 of 3\n",
      "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
      "ETS failed on NET_SALES with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
      "Model Number: 525 with model ARIMA in generation 3 of 3\n",
      "Model Number: 526 with model Theta in generation 3 of 3\n",
      "Model Number: 527 with model SectionalMotif in generation 3 of 3\n",
      "Model Number: 528 with model AverageValueNaive in generation 3 of 3\n",
      "Model Number: 529 with model ARDL in generation 3 of 3\n",
      "Model Number: 530 with model AverageValueNaive in generation 3 of 3\n",
      "Template Eval Error: Exception('Transformer AlignLastValue failed on inverse') in model 530 in generation 3: AverageValueNaive\n",
      "Model Number: 531 with model Theta in generation 3 of 3\n",
      "Template Eval Error: Exception('Transformer AlignLastValue failed on inverse') in model 531 in generation 3: Theta\n",
      "Model Number: 532 with model UnivariateMotif in generation 3 of 3\n",
      "Model Number: 533 with model MultivariateMotif in generation 3 of 3\n",
      "Model Number: 534 with model DatepartRegression in generation 3 of 3\n",
      "Model Number: 535 with model WindowRegression in generation 3 of 3\n",
      "Model Number: 536 with model ARDL in generation 3 of 3\n",
      "Model Number: 537 with model SectionalMotif in generation 3 of 3\n",
      "Model Number: 538 with model ConstantNaive in generation 3 of 3\n",
      "Template Eval Error: ValueError(\"Model returned NaN due to a preprocessing transformer {'fillna': 'rolling_mean_24', 'transformations': {'0': 'LevelShiftTransformer', '1': 'SinTrend', '2': 'EWMAFilter', '3': 'AlignLastValue'}, 'transformation_params': {'0': {'window_size': 90, 'alpha': 3.0, 'grouping_forward_limit': 4, 'max_level_shifts': 5, 'alignment': 'average'}, '1': {}, '2': {'span': 4}, '3': {'rows': 1, 'lag': 7, 'method': 'multiplicative', 'strength': 1.0, 'first_value_only': False}}}. fail_on_forecast_nan=True\") in model 538 in generation 3: ConstantNaive\n",
      "Model Number: 539 with model ARIMA in generation 3 of 3\n",
      "Model Number: 540 with model GLS in generation 3 of 3\n",
      "Model Number: 541 with model NVAR in generation 3 of 3\n",
      "Model Number: 542 with model ETS in generation 3 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (250) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 543 with model UnivariateRegression in generation 3 of 3\n",
      "Model Number: 544 with model UnobservedComponents in generation 3 of 3\n",
      "Model Number: 545 with model GLS in generation 3 of 3\n",
      "Model Number: 546 with model DatepartRegression in generation 3 of 3\n",
      "Template Eval Error: ImportError('Tensorflow not available, install with pip install tensorflow.') in model 546 in generation 3: DatepartRegression\n",
      "Model Number: 547 with model ARIMA in generation 3 of 3\n",
      "Model Number: 548 with model GLM in generation 3 of 3\n",
      "Model Number: 549 with model MetricMotif in generation 3 of 3\n",
      "Template Eval Error: Exception('Transformer ScipyFilter failed on fit') in model 549 in generation 3: MetricMotif\n",
      "Model Number: 550 with model GLM in generation 3 of 3\n",
      "Model Number: 551 with model MetricMotif in generation 3 of 3\n",
      "Model Number: 552 with model MultivariateMotif in generation 3 of 3\n",
      "Model Number: 553 with model GLS in generation 3 of 3\n",
      "Model Number: 554 with model ARDL in generation 3 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\statsmodels\\genmod\\families\\links.py:198: RuntimeWarning: overflow encountered in exp\n",
      "  t = np.exp(-z)\n",
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\decomposition\\_fastica.py:708: FutureWarning: Starting in v1.3, whiten=True should be specified as whiten='arbitrary-variance' (its current behaviour). This behavior is deprecated in 1.1 and will raise ValueError in 1.3.\n",
      "  return self._fit_transform(X, compute_sources=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 555 with model GLS in generation 3 of 3\n",
      "Template Eval Error: Exception('Transformer Cointegration failed on fit') in model 555 in generation 3: GLS\n",
      "Model Number: 556 with model AverageValueNaive in generation 3 of 3\n",
      "Template Eval Error: Exception('Transformer AlignLastValue failed on inverse') in model 556 in generation 3: AverageValueNaive\n",
      "Model Number: 557 with model SeasonalNaive in generation 3 of 3\n",
      "Model Number: 558 with model AverageValueNaive in generation 3 of 3\n",
      "Model Number: 559 with model NVAR in generation 3 of 3\n",
      "Model Number: 560 with model AverageValueNaive in generation 3 of 3\n",
      "Model Number: 561 with model GLS in generation 3 of 3\n",
      "TotalRuntime missing in 4!\n",
      "Validation Round: 1\n",
      "Model Number: 1 of 84 with model AverageValueNaive for Validation 1\n",
      "📈 1 - AverageValueNaive with avg smape 47.02: \n",
      "Model Number: 2 of 84 with model DatepartRegression for Validation 1\n",
      "2 - DatepartRegression with avg smape 49.17: \n",
      "Model Number: 3 of 84 with model LastValueNaive for Validation 1\n",
      "📈 3 - LastValueNaive with avg smape 43.52: \n",
      "Model Number: 4 of 84 with model UnobservedComponents for Validation 1\n",
      "4 - UnobservedComponents with avg smape 46.94: \n",
      "Model Number: 5 of 84 with model LastValueNaive for Validation 1\n",
      "📈 5 - LastValueNaive with avg smape 42.7: \n",
      "Model Number: 6 of 84 with model ARDL for Validation 1\n",
      "6 - ARDL with avg smape 56.4: \n",
      "Model Number: 7 of 84 with model LastValueNaive for Validation 1\n",
      "7 - LastValueNaive with avg smape 42.76: \n",
      "Model Number: 8 of 84 with model UnobservedComponents for Validation 1\n",
      "8 - UnobservedComponents with avg smape 56.61: \n",
      "Model Number: 9 of 84 with model LastValueNaive for Validation 1\n",
      "9 - LastValueNaive with avg smape 45.51: \n",
      "Model Number: 10 of 84 with model AverageValueNaive for Validation 1\n",
      "10 - AverageValueNaive with avg smape 49.02: \n",
      "Model Number: 11 of 84 with model UnobservedComponents for Validation 1\n",
      "11 - UnobservedComponents with avg smape 45.9: \n",
      "Model Number: 12 of 84 with model ETS for Validation 1\n",
      "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
      "ETS failed on NET_SALES with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
      "12 - ETS with avg smape 48.19: \n",
      "Model Number: 13 of 84 with model AverageValueNaive for Validation 1\n",
      "13 - AverageValueNaive with avg smape 45.11: \n",
      "Model Number: 14 of 84 with model ARDL for Validation 1\n",
      "14 - ARDL with avg smape 55.66: \n",
      "Model Number: 15 of 84 with model UnobservedComponents for Validation 1\n",
      "15 - UnobservedComponents with avg smape 48.46: \n",
      "Model Number: 16 of 84 with model SeasonalNaive for Validation 1\n",
      "16 - SeasonalNaive with avg smape 42.7: \n",
      "Model Number: 17 of 84 with model GLS for Validation 1\n",
      "17 - GLS with avg smape 45.24: \n",
      "Model Number: 18 of 84 with model DatepartRegression for Validation 1\n",
      "18 - DatepartRegression with avg smape 43.95: \n",
      "Model Number: 19 of 84 with model DatepartRegression for Validation 1\n",
      "19 - DatepartRegression with avg smape 44.11: \n",
      "Model Number: 20 of 84 with model NVAR for Validation 1\n",
      "20 - NVAR with avg smape 42.85: \n",
      "Model Number: 21 of 84 with model GLS for Validation 1\n",
      "21 - GLS with avg smape 52.05: \n",
      "Model Number: 22 of 84 with model WindowRegression for Validation 1\n",
      "22 - WindowRegression with avg smape 72.49: \n",
      "Model Number: 23 of 84 with model ARIMA for Validation 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23 - ARIMA with avg smape 49.51: \n",
      "Model Number: 24 of 84 with model ARDL for Validation 1\n",
      "24 - ARDL with avg smape 61.58: \n",
      "Model Number: 25 of 84 with model NVAR for Validation 1\n",
      "25 - NVAR with avg smape 47.35: \n",
      "Model Number: 26 of 84 with model ARDL for Validation 1\n",
      "26 - ARDL with avg smape 49.42: \n",
      "Model Number: 27 of 84 with model WindowRegression for Validation 1\n",
      "27 - WindowRegression with avg smape 47.22: \n",
      "Model Number: 28 of 84 with model UnobservedComponents for Validation 1\n",
      "28 - UnobservedComponents with avg smape 47.4: \n",
      "Model Number: 29 of 84 with model UnivariateMotif for Validation 1\n",
      "29 - UnivariateMotif with avg smape 53.39: \n",
      "Model Number: 30 of 84 with model AverageValueNaive for Validation 1\n",
      "30 - AverageValueNaive with avg smape 43.65: \n",
      "Model Number: 31 of 84 with model AverageValueNaive for Validation 1\n",
      "31 - AverageValueNaive with avg smape 43.86: \n",
      "Model Number: 32 of 84 with model GLM for Validation 1\n",
      "32 - GLM with avg smape 43.67: \n",
      "Model Number: 33 of 84 with model DatepartRegression for Validation 1\n",
      "33 - DatepartRegression with avg smape 44.25: \n",
      "Model Number: 34 of 84 with model WindowRegression for Validation 1\n",
      "34 - WindowRegression with avg smape 48.82: \n",
      "Model Number: 35 of 84 with model GLS for Validation 1\n",
      "35 - GLS with avg smape 44.23: \n",
      "Model Number: 36 of 84 with model GLS for Validation 1\n",
      "36 - GLS with avg smape 43.54: \n",
      "Model Number: 37 of 84 with model NVAR for Validation 1\n",
      "📈 37 - NVAR with avg smape 41.74: \n",
      "Model Number: 38 of 84 with model UnivariateRegression for Validation 1\n",
      "38 - UnivariateRegression with avg smape 69.82: \n",
      "Model Number: 39 of 84 with model DatepartRegression for Validation 1\n",
      "39 - DatepartRegression with avg smape 48.69: \n",
      "Model Number: 40 of 84 with model GLS for Validation 1\n",
      "40 - GLS with avg smape 47.12: \n",
      "Model Number: 41 of 84 with model ETS for Validation 1\n",
      "41 - ETS with avg smape 49.46: \n",
      "Model Number: 42 of 84 with model ETS for Validation 1\n",
      "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
      "ETS failed on NET_SALES with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
      "42 - ETS with avg smape 47.15: \n",
      "Model Number: 43 of 84 with model WindowRegression for Validation 1\n",
      "43 - WindowRegression with avg smape 43.51: \n",
      "Model Number: 44 of 84 with model ARDL for Validation 1\n",
      "44 - ARDL with avg smape 58.8: \n",
      "Model Number: 45 of 84 with model ETS for Validation 1\n",
      "45 - ETS with avg smape 43.02: \n",
      "Model Number: 46 of 84 with model MetricMotif for Validation 1\n",
      "46 - MetricMotif with avg smape 43.77: \n",
      "Model Number: 47 of 84 with model LastValueNaive for Validation 1\n",
      "47 - LastValueNaive with avg smape 43.05: \n",
      "Model Number: 48 of 84 with model ETS for Validation 1\n",
      "48 - ETS with avg smape 43.52: \n",
      "Model Number: 49 of 84 with model ARIMA for Validation 1\n",
      "49 - ARIMA with avg smape 47.39: \n",
      "Model Number: 50 of 84 with model WindowRegression for Validation 1\n",
      "50 - WindowRegression with avg smape 43.16: \n",
      "Model Number: 51 of 84 with model MetricMotif for Validation 1\n",
      "51 - MetricMotif with avg smape 45.3: \n",
      "Model Number: 52 of 84 with model NVAR for Validation 1\n",
      "52 - NVAR with avg smape 43.72: \n",
      "Model Number: 53 of 84 with model NVAR for Validation 1\n",
      "53 - NVAR with avg smape 47.52: \n",
      "Model Number: 54 of 84 with model MultivariateMotif for Validation 1\n",
      "54 - MultivariateMotif with avg smape 43.84: \n",
      "Model Number: 55 of 84 with model ARIMA for Validation 1\n",
      "55 - ARIMA with avg smape 68.77: \n",
      "Model Number: 56 of 84 with model GLM for Validation 1\n",
      "56 - GLM with avg smape 43.34: \n",
      "Model Number: 57 of 84 with model GLM for Validation 1\n",
      "57 - GLM with avg smape 47.47: \n",
      "Model Number: 58 of 84 with model ARIMA for Validation 1\n",
      "58 - ARIMA with avg smape 44.27: \n",
      "Model Number: 59 of 84 with model MultivariateRegression for Validation 1\n",
      "59 - MultivariateRegression with avg smape 45.84: \n",
      "Model Number: 60 of 84 with model MetricMotif for Validation 1\n",
      "60 - MetricMotif with avg smape 54.34: \n",
      "Model Number: 61 of 84 with model MetricMotif for Validation 1\n",
      "61 - MetricMotif with avg smape 43.63: \n",
      "Model Number: 62 of 84 with model SectionalMotif for Validation 1\n",
      "62 - SectionalMotif with avg smape 46.79: \n",
      "Model Number: 63 of 84 with model ConstantNaive for Validation 1\n",
      "63 - ConstantNaive with avg smape 44.54: \n",
      "Model Number: 64 of 84 with model SectionalMotif for Validation 1\n",
      "64 - SectionalMotif with avg smape 47.59: \n",
      "Model Number: 65 of 84 with model MetricMotif for Validation 1\n",
      "65 - MetricMotif with avg smape 47.12: \n",
      "Model Number: 66 of 84 with model ARIMA for Validation 1\n",
      "66 - ARIMA with avg smape 46.68: \n",
      "Model Number: 67 of 84 with model MultivariateMotif for Validation 1\n",
      "67 - MultivariateMotif with avg smape 48.79: \n",
      "Model Number: 68 of 84 with model GLM for Validation 1\n",
      "68 - GLM with avg smape 46.86: \n",
      "Model Number: 69 of 84 with model UnivariateRegression for Validation 1\n",
      "69 - UnivariateRegression with avg smape 82.53: \n",
      "Model Number: 70 of 84 with model VAR for Validation 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\statsmodels\\genmod\\families\\links.py:198: RuntimeWarning: overflow encountered in exp\n",
      "  t = np.exp(-z)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70 - VAR with avg smape 82.44: \n",
      "Model Number: 71 of 84 with model MultivariateRegression for Validation 1\n",
      "71 - MultivariateRegression with avg smape 42.97: \n",
      "Model Number: 72 of 84 with model SectionalMotif for Validation 1\n",
      "Template Eval Error: ValueError('kth(=10) out of bounds (8)') in model 72 in generation 0: SectionalMotif\n",
      "Model Number: 73 of 84 with model UnivariateMotif for Validation 1\n",
      "73 - UnivariateMotif with avg smape 47.81: \n",
      "Model Number: 74 of 84 with model SectionalMotif for Validation 1\n",
      "74 - SectionalMotif with avg smape 48.34: \n",
      "Model Number: 75 of 84 with model SectionalMotif for Validation 1\n",
      "75 - SectionalMotif with avg smape 48.34: \n",
      "Model Number: 76 of 84 with model MultivariateRegression for Validation 1\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000024 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "76 - MultivariateRegression with avg smape 41.96: \n",
      "Model Number: 77 of 84 with model SeasonalNaive for Validation 1\n",
      "77 - SeasonalNaive with avg smape 45.19: \n",
      "Model Number: 78 of 84 with model SeasonalNaive for Validation 1\n",
      "78 - SeasonalNaive with avg smape 45.19: \n",
      "Model Number: 79 of 84 with model Theta for Validation 1\n",
      "79 - Theta with avg smape 44.54: \n",
      "Model Number: 80 of 84 with model UnivariateRegression for Validation 1\n",
      "80 - UnivariateRegression with avg smape 129.62: \n",
      "Model Number: 81 of 84 with model GLM for Validation 1\n",
      "81 - GLM with avg smape 44.17: \n",
      "Model Number: 82 of 84 with model MultivariateMotif for Validation 1\n",
      "82 - MultivariateMotif with avg smape 49.67: \n",
      "Model Number: 83 of 84 with model MultivariateRegression for Validation 1\n",
      "83 - MultivariateRegression with avg smape 42.9: \n",
      "Model Number: 84 of 84 with model Theta for Validation 1\n",
      "84 - Theta with avg smape 44.04: \n",
      "Validation Round: 2\n",
      "Model Number: 1 of 84 with model AverageValueNaive for Validation 2\n",
      "📈 1 - AverageValueNaive with avg smape 30.18: \n",
      "Model Number: 2 of 84 with model DatepartRegression for Validation 2\n",
      "2 - DatepartRegression with avg smape 33.2: \n",
      "Model Number: 3 of 84 with model LastValueNaive for Validation 2\n",
      "3 - LastValueNaive with avg smape 35.27: \n",
      "Model Number: 4 of 84 with model UnobservedComponents for Validation 2\n",
      "4 - UnobservedComponents with avg smape 32.29: \n",
      "Model Number: 5 of 84 with model LastValueNaive for Validation 2\n",
      "5 - LastValueNaive with avg smape 37.91: \n",
      "Model Number: 6 of 84 with model ARDL for Validation 2\n",
      "📈 6 - ARDL with avg smape 27.31: \n",
      "Model Number: 7 of 84 with model LastValueNaive for Validation 2\n",
      "7 - LastValueNaive with avg smape 37.91: \n",
      "Model Number: 8 of 84 with model UnobservedComponents for Validation 2\n",
      "Template Eval Error: LinAlgError('Singular matrix') in model 8 in generation 0: UnobservedComponents\n",
      "Model Number: 9 of 84 with model LastValueNaive for Validation 2\n",
      "9 - LastValueNaive with avg smape 35.29: \n",
      "Model Number: 10 of 84 with model AverageValueNaive for Validation 2\n",
      "10 - AverageValueNaive with avg smape 31.82: \n",
      "Model Number: 11 of 84 with model UnobservedComponents for Validation 2\n",
      "11 - UnobservedComponents with avg smape 31.69: \n",
      "Model Number: 12 of 84 with model ETS for Validation 2\n",
      "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
      "ETS failed on NET_SALES with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
      "12 - ETS with avg smape 28.74: \n",
      "Model Number: 13 of 84 with model AverageValueNaive for Validation 2\n",
      "13 - AverageValueNaive with avg smape 35.15: \n",
      "Model Number: 14 of 84 with model ARDL for Validation 2\n",
      "14 - ARDL with avg smape 29.22: \n",
      "Model Number: 15 of 84 with model UnobservedComponents for Validation 2\n",
      "15 - UnobservedComponents with avg smape 36.17: \n",
      "Model Number: 16 of 84 with model SeasonalNaive for Validation 2\n",
      "16 - SeasonalNaive with avg smape 37.91: \n",
      "Model Number: 17 of 84 with model GLS for Validation 2\n",
      "17 - GLS with avg smape 32.78: \n",
      "Model Number: 18 of 84 with model DatepartRegression for Validation 2\n",
      "18 - DatepartRegression with avg smape 33.28: \n",
      "Model Number: 19 of 84 with model DatepartRegression for Validation 2\n",
      "19 - DatepartRegression with avg smape 32.88: \n",
      "Model Number: 20 of 84 with model NVAR for Validation 2\n",
      "20 - NVAR with avg smape 38.31: \n",
      "Model Number: 21 of 84 with model GLS for Validation 2\n",
      "21 - GLS with avg smape 35.81: \n",
      "Model Number: 22 of 84 with model WindowRegression for Validation 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22 - WindowRegression with avg smape 28.76: \n",
      "Model Number: 23 of 84 with model ARIMA for Validation 2\n",
      "23 - ARIMA with avg smape 30.56: \n",
      "Model Number: 24 of 84 with model ARDL for Validation 2\n",
      "24 - ARDL with avg smape 33.04: \n",
      "Model Number: 25 of 84 with model NVAR for Validation 2\n",
      "25 - NVAR with avg smape 31.1: \n",
      "Model Number: 26 of 84 with model ARDL for Validation 2\n",
      "26 - ARDL with avg smape 33.07: \n",
      "Model Number: 27 of 84 with model WindowRegression for Validation 2\n",
      "27 - WindowRegression with avg smape 31.7: \n",
      "Model Number: 28 of 84 with model UnobservedComponents for Validation 2\n",
      "28 - UnobservedComponents with avg smape 30.2: \n",
      "Model Number: 29 of 84 with model UnivariateMotif for Validation 2\n",
      "29 - UnivariateMotif with avg smape 37.62: \n",
      "Model Number: 30 of 84 with model AverageValueNaive for Validation 2\n",
      "30 - AverageValueNaive with avg smape 30.31: \n",
      "Model Number: 31 of 84 with model AverageValueNaive for Validation 2\n",
      "31 - AverageValueNaive with avg smape 29.53: \n",
      "Model Number: 32 of 84 with model GLM for Validation 2\n",
      "32 - GLM with avg smape 29.86: \n",
      "Model Number: 33 of 84 with model DatepartRegression for Validation 2\n",
      "33 - DatepartRegression with avg smape 30.04: \n",
      "Model Number: 34 of 84 with model WindowRegression for Validation 2\n",
      "34 - WindowRegression with avg smape 33.97: \n",
      "Model Number: 35 of 84 with model GLS for Validation 2\n",
      "35 - GLS with avg smape 29.64: \n",
      "Model Number: 36 of 84 with model GLS for Validation 2\n",
      "36 - GLS with avg smape 29.64: \n",
      "Model Number: 37 of 84 with model NVAR for Validation 2\n",
      "37 - NVAR with avg smape 40.47: \n",
      "Model Number: 38 of 84 with model UnivariateRegression for Validation 2\n",
      "38 - UnivariateRegression with avg smape 29.82: \n",
      "Model Number: 39 of 84 with model DatepartRegression for Validation 2\n",
      "39 - DatepartRegression with avg smape 32.41: \n",
      "Model Number: 40 of 84 with model GLS for Validation 2\n",
      "40 - GLS with avg smape 30.71: \n",
      "Model Number: 41 of 84 with model ETS for Validation 2\n",
      "41 - ETS with avg smape 30.12: \n",
      "Model Number: 42 of 84 with model ETS for Validation 2\n",
      "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
      "ETS failed on NET_SALES with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
      "42 - ETS with avg smape 30.67: \n",
      "Model Number: 43 of 84 with model WindowRegression for Validation 2\n",
      "43 - WindowRegression with avg smape 29.97: \n",
      "Model Number: 44 of 84 with model ARDL for Validation 2\n",
      "44 - ARDL with avg smape 31.8: \n",
      "Model Number: 45 of 84 with model ETS for Validation 2\n",
      "45 - ETS with avg smape 29.48: \n",
      "Model Number: 46 of 84 with model MetricMotif for Validation 2\n",
      "46 - MetricMotif with avg smape 35.01: \n",
      "Model Number: 47 of 84 with model LastValueNaive for Validation 2\n",
      "47 - LastValueNaive with avg smape 29.47: \n",
      "Model Number: 48 of 84 with model ETS for Validation 2\n",
      "48 - ETS with avg smape 30.18: \n",
      "Model Number: 49 of 84 with model ARIMA for Validation 2\n",
      "49 - ARIMA with avg smape 29.94: \n",
      "Model Number: 50 of 84 with model WindowRegression for Validation 2\n",
      "50 - WindowRegression with avg smape 28.9: \n",
      "Model Number: 51 of 84 with model MetricMotif for Validation 2\n",
      "51 - MetricMotif with avg smape 33.66: \n",
      "Model Number: 52 of 84 with model NVAR for Validation 2\n",
      "52 - NVAR with avg smape 40.52: \n",
      "Model Number: 53 of 84 with model NVAR for Validation 2\n",
      "53 - NVAR with avg smape 29.39: \n",
      "Model Number: 54 of 84 with model MultivariateMotif for Validation 2\n",
      "54 - MultivariateMotif with avg smape 40.17: \n",
      "Model Number: 55 of 84 with model ARIMA for Validation 2\n",
      "55 - ARIMA with avg smape 31.73: \n",
      "Model Number: 56 of 84 with model GLM for Validation 2\n",
      "56 - GLM with avg smape 29.9: \n",
      "Model Number: 57 of 84 with model GLM for Validation 2\n",
      "57 - GLM with avg smape 30.55: \n",
      "Model Number: 58 of 84 with model ARIMA for Validation 2\n",
      "58 - ARIMA with avg smape 32.14: \n",
      "Model Number: 59 of 84 with model MultivariateRegression for Validation 2\n",
      "59 - MultivariateRegression with avg smape 32.01: \n",
      "Model Number: 60 of 84 with model MetricMotif for Validation 2\n",
      "60 - MetricMotif with avg smape 37.0: \n",
      "Model Number: 61 of 84 with model MetricMotif for Validation 2\n",
      "61 - MetricMotif with avg smape 31.2: \n",
      "Model Number: 62 of 84 with model SectionalMotif for Validation 2\n",
      "62 - SectionalMotif with avg smape 32.06: \n",
      "Model Number: 63 of 84 with model ConstantNaive for Validation 2\n",
      "63 - ConstantNaive with avg smape 29.75: \n",
      "Model Number: 64 of 84 with model SectionalMotif for Validation 2\n",
      "64 - SectionalMotif with avg smape 33.07: \n",
      "Model Number: 65 of 84 with model MetricMotif for Validation 2\n",
      "65 - MetricMotif with avg smape 38.02: \n",
      "Model Number: 66 of 84 with model ARIMA for Validation 2\n",
      "66 - ARIMA with avg smape 53.46: \n",
      "Model Number: 67 of 84 with model MultivariateMotif for Validation 2\n",
      "67 - MultivariateMotif with avg smape 36.58: \n",
      "Model Number: 68 of 84 with model GLM for Validation 2\n",
      "68 - GLM with avg smape 31.57: \n",
      "Model Number: 69 of 84 with model UnivariateRegression for Validation 2\n",
      "69 - UnivariateRegression with avg smape 60.97: \n",
      "Model Number: 70 of 84 with model VAR for Validation 2\n",
      "Template Eval Error: ValueError('array must not contain infs or NaNs') in model 70 in generation 0: VAR\n",
      "Model Number: 71 of 84 with model MultivariateRegression for Validation 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\statsmodels\\genmod\\families\\links.py:198: RuntimeWarning: overflow encountered in exp\n",
      "  t = np.exp(-z)\n",
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\autots\\tools\\window_functions.py:468: RuntimeWarning: invalid value encountered in divide\n",
      "  slope = (sxy - sx * sy) / (sx2 - sx**2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71 - MultivariateRegression with avg smape 34.04: \n",
      "Model Number: 72 of 84 with model SectionalMotif for Validation 2\n",
      "Template Eval Error: ValueError('kth(=10) out of bounds (6)') in model 72 in generation 0: SectionalMotif\n",
      "Model Number: 73 of 84 with model UnivariateMotif for Validation 2\n",
      "73 - UnivariateMotif with avg smape 35.66: \n",
      "Model Number: 74 of 84 with model SectionalMotif for Validation 2\n",
      "74 - SectionalMotif with avg smape 33.05: \n",
      "Model Number: 75 of 84 with model SectionalMotif for Validation 2\n",
      "75 - SectionalMotif with avg smape 33.05: \n",
      "Model Number: 76 of 84 with model MultivariateRegression for Validation 2\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000030 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "76 - MultivariateRegression with avg smape 28.26: \n",
      "Model Number: 77 of 84 with model SeasonalNaive for Validation 2\n",
      "77 - SeasonalNaive with avg smape 33.84: \n",
      "Model Number: 78 of 84 with model SeasonalNaive for Validation 2\n",
      "78 - SeasonalNaive with avg smape 33.84: \n",
      "Model Number: 79 of 84 with model Theta for Validation 2\n",
      "79 - Theta with avg smape 33.15: \n",
      "Model Number: 80 of 84 with model UnivariateRegression for Validation 2\n",
      "80 - UnivariateRegression with avg smape 47.8: \n",
      "Model Number: 81 of 84 with model GLM for Validation 2\n",
      "81 - GLM with avg smape 29.46: \n",
      "Model Number: 82 of 84 with model MultivariateMotif for Validation 2\n",
      "82 - MultivariateMotif with avg smape 46.58: \n",
      "Model Number: 83 of 84 with model MultivariateRegression for Validation 2\n",
      "83 - MultivariateRegression with avg smape 32.34: \n",
      "Model Number: 84 of 84 with model Theta for Validation 2\n",
      "84 - Theta with avg smape 32.56: \n",
      "Validation Round: 3\n",
      "Model Number: 1 of 84 with model AverageValueNaive for Validation 3\n",
      "📈 1 - AverageValueNaive with avg smape 79.85: \n",
      "Model Number: 2 of 84 with model DatepartRegression for Validation 3\n",
      "2 - DatepartRegression with avg smape 96.35: \n",
      "Model Number: 3 of 84 with model LastValueNaive for Validation 3\n",
      "3 - LastValueNaive with avg smape 80.86: \n",
      "Model Number: 4 of 84 with model UnobservedComponents for Validation 3\n",
      "📈 4 - UnobservedComponents with avg smape 72.43: \n",
      "Model Number: 5 of 84 with model LastValueNaive for Validation 3\n",
      "5 - LastValueNaive with avg smape 77.91: \n",
      "Model Number: 6 of 84 with model ARDL for Validation 3\n",
      "📈 6 - ARDL with avg smape 70.27: \n",
      "Model Number: 7 of 84 with model LastValueNaive for Validation 3\n",
      "7 - LastValueNaive with avg smape 77.91: \n",
      "Model Number: 8 of 84 with model UnobservedComponents for Validation 3\n",
      "8 - UnobservedComponents with avg smape 102.87: \n",
      "Model Number: 9 of 84 with model LastValueNaive for Validation 3\n",
      "9 - LastValueNaive with avg smape 93.58: \n",
      "Model Number: 10 of 84 with model AverageValueNaive for Validation 3\n",
      "10 - AverageValueNaive with avg smape 71.75: \n",
      "Model Number: 11 of 84 with model UnobservedComponents for Validation 3\n",
      "11 - UnobservedComponents with avg smape 71.97: \n",
      "Model Number: 12 of 84 with model ETS for Validation 3\n",
      "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
      "ETS failed on NET_SALES with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
      "12 - ETS with avg smape 78.44: \n",
      "Model Number: 13 of 84 with model AverageValueNaive for Validation 3\n",
      "13 - AverageValueNaive with avg smape 87.84: \n",
      "Model Number: 14 of 84 with model ARDL for Validation 3\n",
      "📈 14 - ARDL with avg smape 70.14: \n",
      "Model Number: 15 of 84 with model UnobservedComponents for Validation 3\n",
      "15 - UnobservedComponents with avg smape 71.36: \n",
      "Model Number: 16 of 84 with model SeasonalNaive for Validation 3\n",
      "16 - SeasonalNaive with avg smape 77.91: \n",
      "Model Number: 17 of 84 with model GLS for Validation 3\n",
      "17 - GLS with avg smape 70.5: \n",
      "Model Number: 18 of 84 with model DatepartRegression for Validation 3\n",
      "18 - DatepartRegression with avg smape 76.09: \n",
      "Model Number: 19 of 84 with model DatepartRegression for Validation 3\n",
      "19 - DatepartRegression with avg smape 77.59: \n",
      "Model Number: 20 of 84 with model NVAR for Validation 3\n",
      "📈 20 - NVAR with avg smape 70.11: \n",
      "Model Number: 21 of 84 with model GLS for Validation 3\n",
      "📈 21 - GLS with avg smape 69.38: \n",
      "Model Number: 22 of 84 with model WindowRegression for Validation 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22 - WindowRegression with avg smape 90.13: \n",
      "Model Number: 23 of 84 with model ARIMA for Validation 3\n",
      "23 - ARIMA with avg smape 70.57: \n",
      "Model Number: 24 of 84 with model ARDL for Validation 3\n",
      "24 - ARDL with avg smape 74.36: \n",
      "Model Number: 25 of 84 with model NVAR for Validation 3\n",
      "25 - NVAR with avg smape 80.82: \n",
      "Model Number: 26 of 84 with model ARDL for Validation 3\n",
      "26 - ARDL with avg smape 75.94: \n",
      "Model Number: 27 of 84 with model WindowRegression for Validation 3\n",
      "27 - WindowRegression with avg smape 73.51: \n",
      "Model Number: 28 of 84 with model UnobservedComponents for Validation 3\n",
      "28 - UnobservedComponents with avg smape 70.13: \n",
      "Model Number: 29 of 84 with model UnivariateMotif for Validation 3\n",
      "29 - UnivariateMotif with avg smape 76.78: \n",
      "Model Number: 30 of 84 with model AverageValueNaive for Validation 3\n",
      "30 - AverageValueNaive with avg smape 80.73: \n",
      "Model Number: 31 of 84 with model AverageValueNaive for Validation 3\n",
      "31 - AverageValueNaive with avg smape 79.39: \n",
      "Model Number: 32 of 84 with model GLM for Validation 3\n",
      "📈 32 - GLM with avg smape 67.33: \n",
      "Model Number: 33 of 84 with model DatepartRegression for Validation 3\n",
      "33 - DatepartRegression with avg smape 90.15: \n",
      "Model Number: 34 of 84 with model WindowRegression for Validation 3\n",
      "34 - WindowRegression with avg smape 82.17: \n",
      "Model Number: 35 of 84 with model GLS for Validation 3\n",
      "35 - GLS with avg smape 74.75: \n",
      "Model Number: 36 of 84 with model GLS for Validation 3\n",
      "36 - GLS with avg smape 72.97: \n",
      "Model Number: 37 of 84 with model NVAR for Validation 3\n",
      "37 - NVAR with avg smape 71.21: \n",
      "Model Number: 38 of 84 with model UnivariateRegression for Validation 3\n",
      "Template Eval Error: Exception('Transformer RegressionFilter failed on fit') in model 38 in generation 0: UnivariateRegression\n",
      "Model Number: 39 of 84 with model DatepartRegression for Validation 3\n",
      "📈 39 - DatepartRegression with avg smape 65.22: \n",
      "Model Number: 40 of 84 with model GLS for Validation 3\n",
      "40 - GLS with avg smape 70.19: \n",
      "Model Number: 41 of 84 with model ETS for Validation 3\n",
      "41 - ETS with avg smape 81.83: \n",
      "Model Number: 42 of 84 with model ETS for Validation 3\n",
      "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
      "ETS failed on NET_SALES with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
      "42 - ETS with avg smape 70.19: \n",
      "Model Number: 43 of 84 with model WindowRegression for Validation 3\n",
      "43 - WindowRegression with avg smape 68.15: \n",
      "Model Number: 44 of 84 with model ARDL for Validation 3\n",
      "44 - ARDL with avg smape 80.29: \n",
      "Model Number: 45 of 84 with model ETS for Validation 3\n",
      "45 - ETS with avg smape 84.18: \n",
      "Model Number: 46 of 84 with model MetricMotif for Validation 3\n",
      "Template Eval Error: Exception('Transformer RegressionFilter failed on fit') in model 46 in generation 0: MetricMotif\n",
      "Model Number: 47 of 84 with model LastValueNaive for Validation 3\n",
      "📈 47 - LastValueNaive with avg smape 58.98: \n",
      "Model Number: 48 of 84 with model ETS for Validation 3\n",
      "48 - ETS with avg smape 73.95: \n",
      "Model Number: 49 of 84 with model ARIMA for Validation 3\n",
      "49 - ARIMA with avg smape 70.14: \n",
      "Model Number: 50 of 84 with model WindowRegression for Validation 3\n",
      "50 - WindowRegression with avg smape 62.64: \n",
      "Model Number: 51 of 84 with model MetricMotif for Validation 3\n",
      "51 - MetricMotif with avg smape 59.35: \n",
      "Model Number: 52 of 84 with model NVAR for Validation 3\n",
      "52 - NVAR with avg smape 65.72: \n",
      "Model Number: 53 of 84 with model NVAR for Validation 3\n",
      "53 - NVAR with avg smape 63.32: \n",
      "Model Number: 54 of 84 with model MultivariateMotif for Validation 3\n",
      "54 - MultivariateMotif with avg smape 73.92: \n",
      "Model Number: 55 of 84 with model ARIMA for Validation 3\n",
      "55 - ARIMA with avg smape 78.15: \n",
      "Model Number: 56 of 84 with model GLM for Validation 3\n",
      "Template Eval Error: Exception('Transformer RegressionFilter failed on fit') in model 56 in generation 0: GLM\n",
      "Model Number: 57 of 84 with model GLM for Validation 3\n",
      "📈 57 - GLM with avg smape 55.53: \n",
      "Model Number: 58 of 84 with model ARIMA for Validation 3\n",
      "58 - ARIMA with avg smape 64.5: \n",
      "Model Number: 59 of 84 with model MultivariateRegression for Validation 3\n",
      "59 - MultivariateRegression with avg smape 84.18: \n",
      "Model Number: 60 of 84 with model MetricMotif for Validation 3\n",
      "Template Eval Error: Exception('Transformer RegressionFilter failed on fit') in model 60 in generation 0: MetricMotif\n",
      "Model Number: 61 of 84 with model MetricMotif for Validation 3\n",
      "Template Eval Error: Exception('Transformer RegressionFilter failed on fit') in model 61 in generation 0: MetricMotif\n",
      "Model Number: 62 of 84 with model SectionalMotif for Validation 3\n",
      "Template Eval Error: ValueError('kth(=20) out of bounds (15)') in model 62 in generation 0: SectionalMotif\n",
      "Model Number: 63 of 84 with model ConstantNaive for Validation 3\n",
      "63 - ConstantNaive with avg smape 82.95: \n",
      "Model Number: 64 of 84 with model SectionalMotif for Validation 3\n",
      "64 - SectionalMotif with avg smape 63.38: \n",
      "Model Number: 65 of 84 with model MetricMotif for Validation 3\n",
      "65 - MetricMotif with avg smape 61.93: \n",
      "Model Number: 66 of 84 with model ARIMA for Validation 3\n",
      "66 - ARIMA with avg smape 77.21: \n",
      "Model Number: 67 of 84 with model MultivariateMotif for Validation 3\n",
      "Template Eval Error: ValueError('kth(=20) out of bounds (15)') in model 67 in generation 0: MultivariateMotif\n",
      "Model Number: 68 of 84 with model GLM for Validation 3\n",
      "68 - GLM with avg smape 114.38: \n",
      "Model Number: 69 of 84 with model UnivariateRegression for Validation 3\n",
      "69 - UnivariateRegression with avg smape 143.98: \n",
      "Model Number: 70 of 84 with model VAR for Validation 3\n",
      "Template Eval Error: ValueError('array must not contain infs or NaNs') in model 70 in generation 0: VAR\n",
      "Model Number: 71 of 84 with model MultivariateRegression for Validation 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\statsmodels\\genmod\\families\\links.py:198: RuntimeWarning: overflow encountered in exp\n",
      "  t = np.exp(-z)\n",
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\autots\\tools\\window_functions.py:468: RuntimeWarning: invalid value encountered in divide\n",
      "  slope = (sxy - sx * sy) / (sx2 - sx**2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71 - MultivariateRegression with avg smape 59.22: \n",
      "Model Number: 72 of 84 with model SectionalMotif for Validation 3\n",
      "Template Eval Error: ValueError('kth(=10) out of bounds (3)') in model 72 in generation 0: SectionalMotif\n",
      "Model Number: 73 of 84 with model UnivariateMotif for Validation 3\n",
      "Template Eval Error: Exception('Transformer RegressionFilter failed on fit') in model 73 in generation 0: UnivariateMotif\n",
      "Model Number: 74 of 84 with model SectionalMotif for Validation 3\n",
      "Template Eval Error: ValueError('kth(=20) out of bounds (15)') in model 74 in generation 0: SectionalMotif\n",
      "Model Number: 75 of 84 with model SectionalMotif for Validation 3\n",
      "Template Eval Error: ValueError('kth(=20) out of bounds (15)') in model 75 in generation 0: SectionalMotif\n",
      "Model Number: 76 of 84 with model MultivariateRegression for Validation 3\n",
      "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "76 - MultivariateRegression with avg smape 79.45: \n",
      "Model Number: 77 of 84 with model SeasonalNaive for Validation 3\n",
      "77 - SeasonalNaive with avg smape 122.11: \n",
      "Model Number: 78 of 84 with model SeasonalNaive for Validation 3\n",
      "78 - SeasonalNaive with avg smape 122.11: \n",
      "Model Number: 79 of 84 with model Theta for Validation 3\n",
      "79 - Theta with avg smape 87.59: \n",
      "Model Number: 80 of 84 with model UnivariateRegression for Validation 3\n",
      "80 - UnivariateRegression with avg smape 140.71: \n",
      "Model Number: 81 of 84 with model GLM for Validation 3\n",
      "Template Eval Error: Exception('Transformer RegressionFilter failed on fit') in model 81 in generation 0: GLM\n",
      "Model Number: 82 of 84 with model MultivariateMotif for Validation 3\n",
      "82 - MultivariateMotif with avg smape 58.3: \n",
      "Model Number: 83 of 84 with model MultivariateRegression for Validation 3\n",
      "83 - MultivariateRegression with avg smape 69.29: \n",
      "Model Number: 84 of 84 with model Theta for Validation 3\n",
      "84 - Theta with avg smape 91.11: \n",
      "TotalRuntime missing in 5!\n",
      "Validation Round: 1\n",
      "TotalRuntime missing in 0!\n",
      "Validation Round: 2\n",
      "TotalRuntime missing in 0!\n",
      "Validation Round: 3\n",
      "TotalRuntime missing in 0!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\crudek\\AppData\\Local\\Temp\\ipykernel_24392\\2714734623.py:60: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  all_predictions = all_predictions.append(temp_fcasts)\n",
      "  7%|▋         | 1/14 [01:45<22:45, 105.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 6 cpus for n_jobs.\n",
      "Data frequency is: MS, used frequency is: MS\n",
      "Model Number: 1 with model ARIMA in generation 0 of 3\n",
      "Model Number: 2 with model AverageValueNaive in generation 0 of 3\n",
      "Model Number: 3 with model AverageValueNaive in generation 0 of 3\n",
      "Model Number: 4 with model AverageValueNaive in generation 0 of 3\n",
      "Model Number: 5 with model DatepartRegression in generation 0 of 3\n",
      "Model Number: 6 with model DatepartRegression in generation 0 of 3\n",
      "Model Number: 7 with model DatepartRegression in generation 0 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 8 with model DatepartRegression in generation 0 of 3\n",
      "Template Eval Error: ImportError('Tensorflow not available, install with pip install tensorflow.') in model 8 in generation 0: DatepartRegression\n",
      "Model Number: 9 with model ETS in generation 0 of 3\n",
      "Model Number: 10 with model ETS in generation 0 of 3\n",
      "Model Number: 11 with model GLM in generation 0 of 3\n",
      "Model Number: 12 with model GLM in generation 0 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:541: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 13 with model GLS in generation 0 of 3\n",
      "Model Number: 14 with model GLS in generation 0 of 3\n",
      "Model Number: 15 with model GluonTS in generation 0 of 3\n",
      "Template Eval Error: ImportError('GluonTS installation is incompatible with AutoTS. The numpy version is sometimes the issue, try 1.23.1 {as of 06-2023}') in model 15 in generation 0: GluonTS\n",
      "Model Number: 16 with model GluonTS in generation 0 of 3\n",
      "Template Eval Error: ImportError('GluonTS installation is incompatible with AutoTS. The numpy version is sometimes the issue, try 1.23.1 {as of 06-2023}') in model 16 in generation 0: GluonTS\n",
      "Model Number: 17 with model GluonTS in generation 0 of 3\n",
      "Template Eval Error: ImportError('GluonTS installation is incompatible with AutoTS. The numpy version is sometimes the issue, try 1.23.1 {as of 06-2023}') in model 17 in generation 0: GluonTS\n",
      "Model Number: 18 with model GluonTS in generation 0 of 3\n",
      "Template Eval Error: ImportError('GluonTS installation is incompatible with AutoTS. The numpy version is sometimes the issue, try 1.23.1 {as of 06-2023}') in model 18 in generation 0: GluonTS\n",
      "Model Number: 19 with model GluonTS in generation 0 of 3\n",
      "Template Eval Error: ImportError('GluonTS installation is incompatible with AutoTS. The numpy version is sometimes the issue, try 1.23.1 {as of 06-2023}') in model 19 in generation 0: GluonTS\n",
      "Model Number: 20 with model LastValueNaive in generation 0 of 3\n",
      "Model Number: 21 with model LastValueNaive in generation 0 of 3\n",
      "Model Number: 22 with model LastValueNaive in generation 0 of 3\n",
      "Model Number: 23 with model LastValueNaive in generation 0 of 3\n",
      "Model Number: 24 with model SeasonalNaive in generation 0 of 3\n",
      "Model Number: 25 with model SeasonalNaive in generation 0 of 3\n",
      "Model Number: 26 with model SeasonalNaive in generation 0 of 3\n",
      "Model Number: 27 with model UnobservedComponents in generation 0 of 3\n",
      "Model Number: 28 with model UnobservedComponents in generation 0 of 3\n",
      "Model Number: 29 with model UnobservedComponents in generation 0 of 3\n",
      "Model Number: 30 with model VAR in generation 0 of 3\n",
      "Template Eval Error: ValueError('Only gave one variable to VAR') in model 30 in generation 0: VAR\n",
      "Model Number: 31 with model VAR in generation 0 of 3\n",
      "Template Eval Error: ValueError('Only gave one variable to VAR') in model 31 in generation 0: VAR\n",
      "Model Number: 32 with model VECM in generation 0 of 3\n",
      "Template Eval Error: ValueError('Only gave one variable to VECM') in model 32 in generation 0: VECM\n",
      "Model Number: 33 with model VECM in generation 0 of 3\n",
      "Template Eval Error: ValueError('Only gave one variable to VECM') in model 33 in generation 0: VECM\n",
      "Model Number: 34 with model WindowRegression in generation 0 of 3\n",
      "Model Number: 35 with model ConstantNaive in generation 0 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16:10:07 - cmdstanpy - INFO - Chain [1] start processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 36 with model FBProphet in generation 0 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16:10:07 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 37 with model GluonTS in generation 0 of 3\n",
      "Template Eval Error: ImportError('GluonTS installation is incompatible with AutoTS. The numpy version is sometimes the issue, try 1.23.1 {as of 06-2023}') in model 37 in generation 0: GluonTS\n",
      "Model Number: 38 with model MultivariateRegression in generation 0 of 3\n",
      "Model Number: 39 with model MultivariateRegression in generation 0 of 3\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000025 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Model Number: 40 with model DatepartRegression in generation 0 of 3\n",
      "Model Number: 41 with model SeasonalNaive in generation 0 of 3\n",
      "Model Number: 42 with model DatepartRegression in generation 0 of 3\n",
      "Model Number: 43 with model UnobservedComponents in generation 0 of 3\n",
      "Model Number: 44 with model UnobservedComponents in generation 0 of 3\n",
      "Model Number: 45 with model ETS in generation 0 of 3\n",
      "Model Number: 46 with model VECM in generation 0 of 3\n",
      "Template Eval Error: ValueError('Only gave one variable to VECM') in model 46 in generation 0: VECM\n",
      "Model Number: 47 with model ARDL in generation 0 of 3\n",
      "Model Number: 48 with model MultivariateMotif in generation 0 of 3\n",
      "Model Number: 49 with model MultivariateMotif in generation 0 of 3\n",
      "Model Number: 50 with model UnivariateMotif in generation 0 of 3\n",
      "Template Eval Error: ValueError('kth(=10) out of bounds (1)') in model 50 in generation 0: UnivariateMotif\n",
      "Model Number: 51 with model UnivariateMotif in generation 0 of 3\n",
      "Model Number: 52 with model SectionalMotif in generation 0 of 3\n",
      "Model Number: 53 with model SectionalMotif in generation 0 of 3\n",
      "Model Number: 54 with model MultivariateRegression in generation 0 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16:10:10 - cmdstanpy - INFO - Chain [1] start processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 55 with model FBProphet in generation 0 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16:10:29 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 56 with model SeasonalNaive in generation 0 of 3\n",
      "Model Number: 57 with model DatepartRegression in generation 0 of 3\n",
      "Model Number: 58 with model NVAR in generation 0 of 3\n",
      "Model Number: 59 with model Theta in generation 0 of 3\n",
      "Model Number: 60 with model UnivariateRegression in generation 0 of 3\n",
      "Template Eval Error: ValueError('Input X contains NaN.\\nDecisionTreeRegressor does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values') in model 60 in generation 0: UnivariateRegression\n",
      "Model Number: 61 with model ARCH in generation 0 of 3\n",
      "Template Eval Error: ImportError('`arch` package must be installed from pip') in model 61 in generation 0: ARCH\n",
      "Model Number: 62 with model ConstantNaive in generation 0 of 3\n",
      "Model Number: 63 with model LastValueNaive in generation 0 of 3\n",
      "Model Number: 64 with model AverageValueNaive in generation 0 of 3\n",
      "Model Number: 65 with model GLS in generation 0 of 3\n",
      "Model Number: 66 with model SeasonalNaive in generation 0 of 3\n",
      "Model Number: 67 with model GLM in generation 0 of 3\n",
      "Template Eval Error: ValueError('The first guess on the deviance function returned a nan.  This could be a boundary  problem and should be reported.') in model 67 in generation 0: GLM\n",
      "Model Number: 68 with model ETS in generation 0 of 3\n",
      "Model Number: 69 with model FBProphet in generation 0 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\statsmodels\\genmod\\families\\family.py:1367: ValueWarning: Negative binomial dispersion parameter alpha not set. Using default value alpha=1.0.\n",
      "  warnings.warn(\"Negative binomial dispersion parameter alpha not \"\n",
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\statsmodels\\genmod\\families\\family.py:1406: RuntimeWarning: invalid value encountered in log\n",
      "  resid_dev -= endog_alpha * np.log(endog_alpha / mu_alpha)\n",
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.380e+12, tolerance: 7.414e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "16:10:30 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:10:30 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 70 with model GluonTS in generation 0 of 3\n",
      "Template Eval Error: ImportError('GluonTS installation is incompatible with AutoTS. The numpy version is sometimes the issue, try 1.23.1 {as of 06-2023}') in model 70 in generation 0: GluonTS\n",
      "Model Number: 71 with model UnobservedComponents in generation 0 of 3\n",
      "Model Number: 72 with model VAR in generation 0 of 3\n",
      "Template Eval Error: ValueError('Only gave one variable to VAR') in model 72 in generation 0: VAR\n",
      "Model Number: 73 with model VECM in generation 0 of 3\n",
      "Template Eval Error: ValueError('Only gave one variable to VECM') in model 73 in generation 0: VECM\n",
      "Model Number: 74 with model ARIMA in generation 0 of 3\n",
      "Model Number: 75 with model WindowRegression in generation 0 of 3\n",
      "Model Number: 76 with model DatepartRegression in generation 0 of 3\n",
      "Model Number: 77 with model UnivariateRegression in generation 0 of 3\n",
      "Model Number: 78 with model MultivariateRegression in generation 0 of 3\n",
      "Model Number: 79 with model UnivariateMotif in generation 0 of 3\n",
      "Model Number: 80 with model MultivariateMotif in generation 0 of 3\n",
      "Template Eval Error: ValueError('kth(=100) out of bounds (51)') in model 80 in generation 0: MultivariateMotif\n",
      "Model Number: 81 with model SectionalMotif in generation 0 of 3\n",
      "Template Eval Error: ValueError(\"Model returned NaN due to a preprocessing transformer {'fillna': 'rolling_mean', 'transformations': {'0': 'SeasonalDifference', '1': 'AlignLastValue', '2': 'AlignLastValue', '3': 'EWMAFilter'}, 'transformation_params': {'0': {'lag_1': 7, 'method': 'LastValue'}, '1': {'rows': 1, 'lag': 1, 'method': 'multiplicative', 'strength': 1.0, 'first_value_only': False}, '2': {'rows': 1, 'lag': 1, 'method': 'additive', 'strength': 1.0, 'first_value_only': False}, '3': {'span': 12}}}. fail_on_forecast_nan=True\") in model 81 in generation 0: SectionalMotif\n",
      "Model Number: 82 with model NVAR in generation 0 of 3\n",
      "Model Number: 83 with model Theta in generation 0 of 3\n",
      "Model Number: 84 with model ARDL in generation 0 of 3\n",
      "Model Number: 85 with model ARCH in generation 0 of 3\n",
      "Template Eval Error: ImportError('`arch` package must be installed from pip') in model 85 in generation 0: ARCH\n",
      "Model Number: 86 with model MetricMotif in generation 0 of 3\n",
      "Model Number: 87 with model AverageValueNaive in generation 0 of 3\n",
      "Model Number: 88 with model UnobservedComponents in generation 0 of 3\n",
      "Model Number: 89 with model AverageValueNaive in generation 0 of 3\n",
      "Model Number: 90 with model LastValueNaive in generation 0 of 3\n",
      "Model Number: 91 with model ARDL in generation 0 of 3\n",
      "Model Number: 92 with model WindowRegression in generation 0 of 3\n",
      "Model Number: 93 with model ConstantNaive in generation 0 of 3\n",
      "Model Number: 94 with model SeasonalNaive in generation 0 of 3\n",
      "Model Number: 95 with model ARDL in generation 0 of 3\n",
      "Template Eval Error: ValueError(\"ARDL series NET_SALES failed with error ValueError('The number of regressors (178) including deterministics, lags of the endog, lags of the exogenous, and fixed regressors is larger than the sample available for estimation (69).') exog train             weekend  quarter      epoch  month_1  month_2  month_3  month_4  \\\\\\nMONTH                                                                         \\n2016-01-01        0        1  2457388.5      1.0      0.0      0.0      0.0   \\n2016-02-01        0        1  2457419.5      0.0      1.0      0.0      0.0   \\n2016-03-01        0        1  2457448.5      0.0      0.0      1.0      0.0   \\n2016-04-01        0        2  2457479.5      0.0      0.0      0.0      1.0   \\n2016-05-01        1        2  2457509.5      0.0      0.0      0.0      0.0   \\n...             ...      ...        ...      ...      ...      ...      ...   \\n2021-08-01        1        3  2459427.5      0.0      0.0      0.0      0.0   \\n2021-09-01        0        3  2459458.5      0.0      0.0      0.0      0.0   \\n2021-10-01        0        4  2459488.5      0.0      0.0      0.0      0.0   \\n2021-11-01        0        4  2459519.5      0.0      0.0      0.0      0.0   \\n2021-12-01        0        4  2459549.5      0.0      0.0      0.0      0.0   \\n\\n            month_5  month_6  month_7  ...  day_27  day_28  day_29  day_30  \\\\\\nMONTH                                  ...                                   \\n2016-01-01      0.0      0.0      0.0  ...     0.0     0.0     0.0     0.0   \\n2016-02-01      0.0      0.0      0.0  ...     0.0     0.0     0.0     0.0   \\n2016-03-01      0.0      0.0      0.0  ...     0.0     0.0     0.0     0.0   \\n2016-04-01      0.0      0.0      0.0  ...     0.0     0.0     0.0     0.0   \\n2016-05-01      1.0      0.0      0.0  ...     0.0     0.0     0.0     0.0   \\n...             ...      ...      ...  ...     ...     ...     ...     ...   \\n2021-08-01      0.0      0.0      0.0  ...     0.0     0.0     0.0     0.0   \\n2021-09-01      0.0      0.0      0.0  ...     0.0     0.0     0.0     0.0   \\n2021-10-01      0.0      0.0      0.0  ...     0.0     0.0     0.0     0.0   \\n2021-11-01      0.0      0.0      0.0  ...     0.0     0.0     0.0     0.0   \\n2021-12-01      0.0      0.0      0.0  ...     0.0     0.0     0.0     0.0   \\n\\n            day_31  weekdayofmonth_1  weekdayofmonth_2  weekdayofmonth_3  \\\\\\nMONTH                                                                      \\n2016-01-01     0.0               1.0               0.0               0.0   \\n2016-02-01     0.0               1.0               0.0               0.0   \\n2016-03-01     0.0               1.0               0.0               0.0   \\n2016-04-01     0.0               1.0               0.0               0.0   \\n2016-05-01     0.0               1.0               0.0               0.0   \\n...            ...               ...               ...               ...   \\n2021-08-01     0.0               1.0               0.0               0.0   \\n2021-09-01     0.0               1.0               0.0               0.0   \\n2021-10-01     0.0               1.0               0.0               0.0   \\n2021-11-01     0.0               1.0               0.0               0.0   \\n2021-12-01     0.0               1.0               0.0               0.0   \\n\\n            weekdayofmonth_4  weekdayofmonth_5  \\nMONTH                                           \\n2016-01-01               0.0               0.0  \\n2016-02-01               0.0               0.0  \\n2016-03-01               0.0               0.0  \\n2016-04-01               0.0               0.0  \\n2016-05-01               0.0               0.0  \\n...                      ...               ...  \\n2021-08-01               0.0               0.0  \\n2021-09-01               0.0               0.0  \\n2021-10-01               0.0               0.0  \\n2021-11-01               0.0               0.0  \\n2021-12-01               0.0               0.0  \\n\\n[72 rows x 58 columns] and predict             weekend  quarter      epoch  month_1  month_2  month_3  month_4  \\\\\\n2022-01-01        1        1  2459580.5      1.0      0.0      0.0      0.0   \\n2022-02-01        0        1  2459611.5      0.0      1.0      0.0      0.0   \\n2022-03-01        0        1  2459639.5      0.0      0.0      1.0      0.0   \\n2022-04-01        0        2  2459670.5      0.0      0.0      0.0      1.0   \\n2022-05-01        1        2  2459700.5      0.0      0.0      0.0      0.0   \\n2022-06-01        0        2  2459731.5      0.0      0.0      0.0      0.0   \\n2022-07-01        0        3  2459761.5      0.0      0.0      0.0      0.0   \\n2022-08-01        0        3  2459792.5      0.0      0.0      0.0      0.0   \\n2022-09-01        0        3  2459823.5      0.0      0.0      0.0      0.0   \\n2022-10-01        1        4  2459853.5      0.0      0.0      0.0      0.0   \\n2022-11-01        0        4  2459884.5      0.0      0.0      0.0      0.0   \\n2022-12-01        0        4  2459914.5      0.0      0.0      0.0      0.0   \\n\\n            month_5  month_6  month_7  ...  day_27  day_28  day_29  day_30  \\\\\\n2022-01-01      0.0      0.0      0.0  ...     0.0     0.0     0.0     0.0   \\n2022-02-01      0.0      0.0      0.0  ...     0.0     0.0     0.0     0.0   \\n2022-03-01      0.0      0.0      0.0  ...     0.0     0.0     0.0     0.0   \\n2022-04-01      0.0      0.0      0.0  ...     0.0     0.0     0.0     0.0   \\n2022-05-01      1.0      0.0      0.0  ...     0.0     0.0     0.0     0.0   \\n2022-06-01      0.0      1.0      0.0  ...     0.0     0.0     0.0     0.0   \\n2022-07-01      0.0      0.0      1.0  ...     0.0     0.0     0.0     0.0   \\n2022-08-01      0.0      0.0      0.0  ...     0.0     0.0     0.0     0.0   \\n2022-09-01      0.0      0.0      0.0  ...     0.0     0.0     0.0     0.0   \\n2022-10-01      0.0      0.0      0.0  ...     0.0     0.0     0.0     0.0   \\n2022-11-01      0.0      0.0      0.0  ...     0.0     0.0     0.0     0.0   \\n2022-12-01      0.0      0.0      0.0  ...     0.0     0.0     0.0     0.0   \\n\\n            day_31  weekdayofmonth_1  weekdayofmonth_2  weekdayofmonth_3  \\\\\\n2022-01-01     0.0               1.0               0.0               0.0   \\n2022-02-01     0.0               1.0               0.0               0.0   \\n2022-03-01     0.0               1.0               0.0               0.0   \\n2022-04-01     0.0               1.0               0.0               0.0   \\n2022-05-01     0.0               1.0               0.0               0.0   \\n2022-06-01     0.0               1.0               0.0               0.0   \\n2022-07-01     0.0               1.0               0.0               0.0   \\n2022-08-01     0.0               1.0               0.0               0.0   \\n2022-09-01     0.0               1.0               0.0               0.0   \\n2022-10-01     0.0               1.0               0.0               0.0   \\n2022-11-01     0.0               1.0               0.0               0.0   \\n2022-12-01     0.0               1.0               0.0               0.0   \\n\\n            weekdayofmonth_4  weekdayofmonth_5  \\n2022-01-01               0.0               0.0  \\n2022-02-01               0.0               0.0  \\n2022-03-01               0.0               0.0  \\n2022-04-01               0.0               0.0  \\n2022-05-01               0.0               0.0  \\n2022-06-01               0.0               0.0  \\n2022-07-01               0.0               0.0  \\n2022-08-01               0.0               0.0  \\n2022-09-01               0.0               0.0  \\n2022-10-01               0.0               0.0  \\n2022-11-01               0.0               0.0  \\n2022-12-01               0.0               0.0  \\n\\n[12 rows x 58 columns]\") in model 95 in generation 0: ARDL\n",
      "Model Number: 96 with model FBProphet in generation 0 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16:10:32 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:10:32 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 97 with model ConstantNaive in generation 0 of 3\n",
      "Model Number: 98 with model ConstantNaive in generation 0 of 3\n",
      "Model Number: 99 with model UnobservedComponents in generation 0 of 3\n",
      "Model Number: 100 with model ConstantNaive in generation 0 of 3\n",
      "Model Number: 101 with model VAR in generation 0 of 3\n",
      "Template Eval Error: ValueError('Only gave one variable to VAR') in model 101 in generation 0: VAR\n",
      "Model Number: 102 with model ETS in generation 0 of 3\n",
      "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
      "ETS failed on NET_SALES with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
      "Model Number: 103 with model Theta in generation 0 of 3\n",
      "Model Number: 104 with model DatepartRegression in generation 0 of 3\n",
      "Template Eval Error: ValueError('Model DatepartRegression returned NaN for one or more series. fail_on_forecast_nan=True') in model 104 in generation 0: DatepartRegression\n",
      "Model Number: 105 with model GLM in generation 0 of 3\n",
      "Model Number: 106 with model ARCH in generation 0 of 3\n",
      "Template Eval Error: Exception('Transformer Detrend failed on fit') in model 106 in generation 0: ARCH\n",
      "Model Number: 107 with model AverageValueNaive in generation 0 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\neighbors\\_regression.py:494: UserWarning: One or more samples have no neighbors within specified radius; predicting NaN.\n",
      "  warnings.warn(empty_warning_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 108 with model MetricMotif in generation 0 of 3\n",
      "Model Number: 109 with model ETS in generation 0 of 3\n",
      "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
      "ETS failed on NET_SALES with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
      "Template Eval Error: Exception('Transformer DifferencedTransformer failed on inverse') in model 109 in generation 0: ETS\n",
      "Model Number: 110 with model ETS in generation 0 of 3\n",
      "ETS error ValueError('Cannot compute initial seasonals using heuristic method with less than two full seasonal cycles in the data.')\n",
      "ETS failed on NET_SALES with ValueError('Cannot compute initial seasonals using heuristic method with less than two full seasonal cycles in the data.')\n",
      "Template Eval Error: Exception('Transformer AlignLastValue failed on inverse') in model 110 in generation 0: ETS\n",
      "Model Number: 111 with model SeasonalNaive in generation 0 of 3\n",
      "Model Number: 112 with model ARCH in generation 0 of 3\n",
      "Template Eval Error: ImportError('`arch` package must be installed from pip') in model 112 in generation 0: ARCH\n",
      "Model Number: 113 with model SectionalMotif in generation 0 of 3\n",
      "Model Number: 114 with model SeasonalNaive in generation 0 of 3\n",
      "Model Number: 115 with model UnivariateRegression in generation 0 of 3\n",
      "Model Number: 116 with model VAR in generation 0 of 3\n",
      "Template Eval Error: ValueError('Only gave one variable to VAR') in model 116 in generation 0: VAR\n",
      "Model Number: 117 with model GluonTS in generation 0 of 3\n",
      "Template Eval Error: ImportError('GluonTS installation is incompatible with AutoTS. The numpy version is sometimes the issue, try 1.23.1 {as of 06-2023}') in model 117 in generation 0: GluonTS\n",
      "Model Number: 118 with model GLM in generation 0 of 3\n",
      "Template Eval Error: ValueError('NaN, inf or invalid value detected in weights, estimation infeasible.') in model 118 in generation 0: GLM\n",
      "Model Number: 119 with model MultivariateMotif in generation 0 of 3\n",
      "Model Number: 120 with model AverageValueNaive in generation 0 of 3\n",
      "Model Number: 121 with model ConstantNaive in generation 0 of 3\n",
      "Model Number: 122 with model ARCH in generation 0 of 3\n",
      "Template Eval Error: ImportError('`arch` package must be installed from pip') in model 122 in generation 0: ARCH\n",
      "Model Number: 123 with model GLS in generation 0 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\statsmodels\\genmod\\families\\family.py:1367: ValueWarning: Negative binomial dispersion parameter alpha not set. Using default value alpha=1.0.\n",
      "  warnings.warn(\"Negative binomial dispersion parameter alpha not \"\n",
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\statsmodels\\genmod\\families\\links.py:527: RuntimeWarning: overflow encountered in exp\n",
      "  return np.exp(z)\n",
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\statsmodels\\genmod\\families\\family.py:1402: RuntimeWarning: divide by zero encountered in divide\n",
      "  endog_mu = self._clean(endog / mu)\n",
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\statsmodels\\genmod\\families\\family.py:1406: RuntimeWarning: divide by zero encountered in log\n",
      "  resid_dev -= endog_alpha * np.log(endog_alpha / mu_alpha)\n",
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\statsmodels\\genmod\\families\\family.py:1406: RuntimeWarning: invalid value encountered in log\n",
      "  resid_dev -= endog_alpha * np.log(endog_alpha / mu_alpha)\n",
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\numpy\\core\\fromnumeric.py:86: RuntimeWarning: invalid value encountered in reduce\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n",
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\statsmodels\\genmod\\families\\family.py:143: RuntimeWarning: invalid value encountered in multiply\n",
      "  return 1. / (self.link.deriv(mu)**2 * self.variance(mu))\n",
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\statsmodels\\genmod\\generalized_linear_model.py:1243: RuntimeWarning: invalid value encountered in multiply\n",
      "  wlsendog = (lin_pred + self.family.link.deriv(mu) * (self.endog-mu)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 124 with model LastValueNaive in generation 0 of 3\n",
      "Template Eval Error: Exception('Transformer RegressionFilter failed on fit') in model 124 in generation 0: LastValueNaive\n",
      "Model Number: 125 with model UnobservedComponents in generation 0 of 3\n",
      "Model Number: 126 with model LastValueNaive in generation 0 of 3\n",
      "Model Number: 127 with model SectionalMotif in generation 0 of 3\n",
      "Template Eval Error: ValueError('Unknown Distance Metric: kulsinski') in model 127 in generation 0: SectionalMotif\n",
      "Model Number: 128 with model GLS in generation 0 of 3\n",
      "Model Number: 129 with model Theta in generation 0 of 3\n",
      "Model Number: 130 with model UnobservedComponents in generation 0 of 3\n",
      "Model Number: 131 with model WindowRegression in generation 0 of 3\n",
      "Template Eval Error: ValueError('Input X contains NaN.\\nBayesianRidge does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values') in model 131 in generation 0: WindowRegression\n",
      "Model Number: 132 with model NVAR in generation 0 of 3\n",
      "Model Number: 133 with model SeasonalNaive in generation 0 of 3\n",
      "Model Number: 134 with model UnobservedComponents in generation 0 of 3\n",
      "Template Eval Error: Exception('Transformer Detrend failed on fit') in model 134 in generation 0: UnobservedComponents\n",
      "Model Number: 135 with model GLS in generation 0 of 3\n",
      "Model Number: 136 with model MetricMotif in generation 0 of 3\n",
      "Model Number: 137 with model VAR in generation 0 of 3\n",
      "Template Eval Error: ValueError('Only gave one variable to VAR') in model 137 in generation 0: VAR\n",
      "Model Number: 138 with model WindowRegression in generation 0 of 3\n",
      "Template Eval Error: ImportError('Tensorflow not available, install with pip install tensorflow.') in model 138 in generation 0: WindowRegression\n",
      "Model Number: 139 with model GLM in generation 0 of 3\n",
      "Model Number: 140 with model NVAR in generation 0 of 3\n",
      "Model Number: 141 with model VAR in generation 0 of 3\n",
      "Template Eval Error: ValueError('Only gave one variable to VAR') in model 141 in generation 0: VAR\n",
      "Model Number: 142 with model DatepartRegression in generation 0 of 3\n",
      "Model Number: 143 with model GLS in generation 0 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\statsmodels\\genmod\\families\\links.py:198: RuntimeWarning: overflow encountered in exp\n",
      "  t = np.exp(-z)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 144 with model DatepartRegression in generation 0 of 3\n",
      "Template Eval Error: ValueError('Input X contains NaN.\\nExtraTreesRegressor does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values') in model 144 in generation 0: DatepartRegression\n",
      "Model Number: 145 with model VAR in generation 0 of 3\n",
      "Template Eval Error: ValueError('Only gave one variable to VAR') in model 145 in generation 0: VAR\n",
      "Model Number: 146 with model Theta in generation 0 of 3\n",
      "Model Number: 147 with model ETS in generation 0 of 3\n",
      "ETS error ValueError('Cannot compute initial seasonals using heuristic method with less than two full seasonal cycles in the data.')\n",
      "ETS failed on NET_SALES with ValueError('Cannot compute initial seasonals using heuristic method with less than two full seasonal cycles in the data.')\n",
      "Model Number: 148 with model ConstantNaive in generation 0 of 3\n",
      "Model Number: 149 with model ARDL in generation 0 of 3\n",
      "Model Number: 150 with model SectionalMotif in generation 0 of 3\n",
      "Model Number: 151 with model VAR in generation 0 of 3\n",
      "Model Number: 152 with model DatepartRegression in generation 0 of 3\n",
      "Model Number: 153 with model Theta in generation 0 of 3\n",
      "Model Number: 154 with model MetricMotif in generation 0 of 3\n",
      "Model Number: 155 with model DatepartRegression in generation 0 of 3\n",
      "Model Number: 156 with model GLM in generation 0 of 3\n",
      "Model Number: 157 with model GluonTS in generation 0 of 3\n",
      "Template Eval Error: ImportError('GluonTS installation is incompatible with AutoTS. The numpy version is sometimes the issue, try 1.23.1 {as of 06-2023}') in model 157 in generation 0: GluonTS\n",
      "Model Number: 158 with model DatepartRegression in generation 0 of 3\n",
      "Template Eval Error: Exception('Transformer AlignLastValue failed on inverse') in model 158 in generation 0: DatepartRegression\n",
      "Model Number: 159 with model NVAR in generation 0 of 3\n",
      "Model Number: 160 with model GLS in generation 0 of 3\n",
      "Model Number: 161 with model SectionalMotif in generation 0 of 3\n",
      "Model Number: 162 with model FBProphet in generation 0 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\statsmodels\\genmod\\families\\links.py:198: RuntimeWarning: overflow encountered in exp\n",
      "  t = np.exp(-z)\n",
      "16:10:35 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:10:35 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 163 with model ETS in generation 0 of 3\n",
      "Model Number: 164 with model VAR in generation 0 of 3\n",
      "Template Eval Error: ValueError('Only gave one variable to VAR') in model 164 in generation 0: VAR\n",
      "Model Number: 165 with model MultivariateMotif in generation 0 of 3\n",
      "Model Number: 166 with model VAR in generation 0 of 3\n",
      "Template Eval Error: ValueError('Only gave one variable to VAR') in model 166 in generation 0: VAR\n",
      "Model Number: 167 with model ARIMA in generation 0 of 3\n",
      "Model Number: 168 with model UnobservedComponents in generation 0 of 3\n",
      "Model Number: 169 with model UnivariateMotif in generation 0 of 3\n",
      "Template Eval Error: ValueError('kth(=100) out of bounds (51)') in model 169 in generation 0: UnivariateMotif\n",
      "Model Number: 170 with model VAR in generation 0 of 3\n",
      "Template Eval Error: ValueError('Only gave one variable to VAR') in model 170 in generation 0: VAR\n",
      "Model Number: 171 with model Theta in generation 0 of 3\n",
      "Model Number: 172 with model MultivariateMotif in generation 0 of 3\n",
      "Model Number: 173 with model UnobservedComponents in generation 0 of 3\n",
      "Model Number: 174 with model WindowRegression in generation 0 of 3\n",
      "Model Number: 175 with model SeasonalNaive in generation 0 of 3\n",
      "Model Number: 176 with model ARDL in generation 0 of 3\n",
      "Model Number: 177 with model GLS in generation 0 of 3\n",
      "Model Number: 178 with model SectionalMotif in generation 0 of 3\n",
      "Model Number: 179 with model ARDL in generation 0 of 3\n",
      "Model Number: 180 with model MultivariateMotif in generation 0 of 3\n",
      "Model Number: 181 with model ARCH in generation 0 of 3\n",
      "Template Eval Error: ImportError('`arch` package must be installed from pip') in model 181 in generation 0: ARCH\n",
      "Model Number: 182 with model SectionalMotif in generation 0 of 3\n",
      "Model Number: 183 with model ARIMA in generation 0 of 3\n",
      "Model Number: 184 with model DatepartRegression in generation 0 of 3\n",
      "Model Number: 185 with model ETS in generation 0 of 3\n",
      "ETS error ValueError('Cannot compute initial seasonals using heuristic method with less than two full seasonal cycles in the data.')\n",
      "ETS failed on NET_SALES with ValueError('Cannot compute initial seasonals using heuristic method with less than two full seasonal cycles in the data.')\n",
      "Model Number: 186 with model VECM in generation 0 of 3\n",
      "Template Eval Error: ValueError('Only gave one variable to VECM') in model 186 in generation 0: VECM\n",
      "New Generation: 1 of 3\n",
      "Model Number: 187 with model GLM in generation 1 of 3\n",
      "Model Number: 188 with model ARIMA in generation 1 of 3\n",
      "Model Number: 189 with model UnobservedComponents in generation 1 of 3\n",
      "Model Number: 190 with model UnivariateMotif in generation 1 of 3\n",
      "Model Number: 191 with model MultivariateRegression in generation 1 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.908e+13, tolerance: 4.044e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 192 with model DatepartRegression in generation 1 of 3\n",
      "Template Eval Error: ValueError('Model DatepartRegression returned NaN for one or more series. fail_on_forecast_nan=True') in model 192 in generation 1: DatepartRegression\n",
      "Model Number: 193 with model SectionalMotif in generation 1 of 3\n",
      "Model Number: 194 with model GLS in generation 1 of 3\n",
      "Model Number: 195 with model Theta in generation 1 of 3\n",
      "Model Number: 196 with model ConstantNaive in generation 1 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\neighbors\\_regression.py:494: UserWarning: One or more samples have no neighbors within specified radius; predicting NaN.\n",
      "  warnings.warn(empty_warning_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 197 with model ARIMA in generation 1 of 3\n",
      "Model Number: 198 with model SeasonalNaive in generation 1 of 3\n",
      "Model Number: 199 with model GLS in generation 1 of 3\n",
      "Model Number: 200 with model DatepartRegression in generation 1 of 3\n",
      "Template Eval Error: Exception('Transformer AlignLastValue failed on inverse') in model 200 in generation 1: DatepartRegression\n",
      "Model Number: 201 with model MetricMotif in generation 1 of 3\n",
      "Model Number: 202 with model ARIMA in generation 1 of 3\n",
      "Model Number: 203 with model SeasonalNaive in generation 1 of 3\n",
      "Model Number: 204 with model Theta in generation 1 of 3\n",
      "Model Number: 205 with model DatepartRegression in generation 1 of 3\n",
      "Model Number: 206 with model NVAR in generation 1 of 3\n",
      "Model Number: 207 with model ARDL in generation 1 of 3\n",
      "Model Number: 208 with model MultivariateMotif in generation 1 of 3\n",
      "Model Number: 209 with model SeasonalNaive in generation 1 of 3\n",
      "Model Number: 210 with model SeasonalNaive in generation 1 of 3\n",
      "Model Number: 211 with model SeasonalNaive in generation 1 of 3\n",
      "Model Number: 212 with model SectionalMotif in generation 1 of 3\n",
      "Model Number: 213 with model SectionalMotif in generation 1 of 3\n",
      "Model Number: 214 with model LastValueNaive in generation 1 of 3\n",
      "Model Number: 215 with model SectionalMotif in generation 1 of 3\n",
      "Model Number: 216 with model UnobservedComponents in generation 1 of 3\n",
      "Template Eval Error: Exception('Transformer PowerTransformer failed on fit') in model 216 in generation 1: UnobservedComponents\n",
      "Model Number: 217 with model GLS in generation 1 of 3\n",
      "Model Number: 218 with model MetricMotif in generation 1 of 3\n",
      "Template Eval Error: ValueError('kth(=99) out of bounds (53)') in model 218 in generation 1: MetricMotif\n",
      "Model Number: 219 with model FBProphet in generation 1 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16:10:44 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:10:44 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:10:45 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:10:45 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 220 with model DatepartRegression in generation 1 of 3\n",
      "Model Number: 221 with model Theta in generation 1 of 3\n",
      "Model Number: 222 with model SectionalMotif in generation 1 of 3\n",
      "Model Number: 223 with model ARDL in generation 1 of 3\n",
      "Model Number: 224 with model FBProphet in generation 1 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16:10:45 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:10:45 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 225 with model MultivariateRegression in generation 1 of 3\n",
      "Model Number: 226 with model ETS in generation 1 of 3\n",
      "Model Number: 227 with model MultivariateMotif in generation 1 of 3\n",
      "Model Number: 228 with model UnobservedComponents in generation 1 of 3\n",
      "Model Number: 229 with model ARDL in generation 1 of 3\n",
      "Model Number: 230 with model UnivariateRegression in generation 1 of 3\n",
      "Model Number: 231 with model WindowRegression in generation 1 of 3\n",
      "Template Eval Error: Exception('Transformer RegressionFilter failed on fit') in model 231 in generation 1: WindowRegression\n",
      "Model Number: 232 with model FBProphet in generation 1 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16:10:47 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:10:47 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 233 with model MetricMotif in generation 1 of 3\n",
      "Template Eval Error: ValueError('kth(=99) out of bounds (63)') in model 233 in generation 1: MetricMotif\n",
      "Model Number: 234 with model AverageValueNaive in generation 1 of 3\n",
      "Model Number: 235 with model AverageValueNaive in generation 1 of 3\n",
      "Model Number: 236 with model ARIMA in generation 1 of 3\n",
      "Model Number: 237 with model UnivariateMotif in generation 1 of 3\n",
      "Model Number: 238 with model GLS in generation 1 of 3\n",
      "Model Number: 239 with model ARDL in generation 1 of 3\n",
      "Model Number: 240 with model Theta in generation 1 of 3\n",
      "Model Number: 241 with model SeasonalNaive in generation 1 of 3\n",
      "Model Number: 242 with model WindowRegression in generation 1 of 3\n",
      "Model Number: 243 with model GLM in generation 1 of 3\n",
      "Template Eval Error: Exception('Transformer AlignLastValue failed on inverse') in model 243 in generation 1: GLM\n",
      "Model Number: 244 with model ETS in generation 1 of 3\n",
      "ETS error ValueError('Can only dampen the trend component')\n",
      "ETS failed on NET_SALES with ValueError('Can only dampen the trend component')\n",
      "Model Number: 245 with model Theta in generation 1 of 3\n",
      "Model Number: 246 with model UnobservedComponents in generation 1 of 3\n",
      "Model Number: 247 with model ARIMA in generation 1 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\statsmodels\\genmod\\families\\links.py:198: RuntimeWarning: overflow encountered in exp\n",
      "  t = np.exp(-z)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 248 with model ETS in generation 1 of 3\n",
      "Model Number: 249 with model MultivariateMotif in generation 1 of 3\n",
      "Model Number: 250 with model ETS in generation 1 of 3\n",
      "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
      "ETS failed on NET_SALES with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
      "Model Number: 251 with model SeasonalNaive in generation 1 of 3\n",
      "Model Number: 252 with model GLS in generation 1 of 3\n",
      "Model Number: 253 with model SectionalMotif in generation 1 of 3\n",
      "Model Number: 254 with model AverageValueNaive in generation 1 of 3\n",
      "Template Eval Error: Exception('Transformer BTCD failed on fit') in model 254 in generation 1: AverageValueNaive\n",
      "Model Number: 255 with model DatepartRegression in generation 1 of 3\n",
      "Model Number: 256 with model UnobservedComponents in generation 1 of 3\n",
      "Model Number: 257 with model AverageValueNaive in generation 1 of 3\n",
      "Model Number: 258 with model GLM in generation 1 of 3\n",
      "Model Number: 259 with model MultivariateRegression in generation 1 of 3\n",
      "Model Number: 260 with model Theta in generation 1 of 3\n",
      "Model Number: 261 with model UnobservedComponents in generation 1 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 262 with model Theta in generation 1 of 3\n",
      "Model Number: 263 with model ConstantNaive in generation 1 of 3\n",
      "Model Number: 264 with model AverageValueNaive in generation 1 of 3\n",
      "Model Number: 265 with model SeasonalNaive in generation 1 of 3\n",
      "Model Number: 266 with model Theta in generation 1 of 3\n",
      "Model Number: 267 with model ETS in generation 1 of 3\n",
      "Model Number: 268 with model MultivariateRegression in generation 1 of 3\n",
      "Model Number: 269 with model UnivariateRegression in generation 1 of 3\n",
      "Model Number: 270 with model MultivariateMotif in generation 1 of 3\n",
      "Model Number: 271 with model SeasonalNaive in generation 1 of 3\n",
      "Template Eval Error: Exception('Transformer AlignLastValue failed on inverse') in model 271 in generation 1: SeasonalNaive\n",
      "Model Number: 272 with model SectionalMotif in generation 1 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 273 with model SeasonalNaive in generation 1 of 3\n",
      "Model Number: 274 with model WindowRegression in generation 1 of 3\n",
      "Model Number: 275 with model GLS in generation 1 of 3\n",
      "Model Number: 276 with model WindowRegression in generation 1 of 3\n",
      "Model Number: 277 with model FBProphet in generation 1 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "16:10:49 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:10:49 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 278 with model WindowRegression in generation 1 of 3\n",
      "Model Number: 279 with model MultivariateRegression in generation 1 of 3\n",
      "Model Number: 280 with model MultivariateRegression in generation 1 of 3\n",
      "Model Number: 281 with model GLS in generation 1 of 3\n",
      "Model Number: 282 with model VAR in generation 1 of 3\n",
      "Template Eval Error: ValueError('Only gave one variable to VAR') in model 282 in generation 1: VAR\n",
      "Model Number: 283 with model MultivariateMotif in generation 1 of 3\n",
      "Model Number: 284 with model LastValueNaive in generation 1 of 3\n",
      "Model Number: 285 with model SeasonalNaive in generation 1 of 3\n",
      "Model Number: 286 with model NVAR in generation 1 of 3\n",
      "Model Number: 287 with model LastValueNaive in generation 1 of 3\n",
      "Model Number: 288 with model MetricMotif in generation 1 of 3\n",
      "Model Number: 289 with model DatepartRegression in generation 1 of 3\n",
      "Model Number: 290 with model DatepartRegression in generation 1 of 3\n",
      "Template Eval Error: ImportError('Tensorflow not available, install with pip install tensorflow.') in model 290 in generation 1: DatepartRegression\n",
      "Model Number: 291 with model GLS in generation 1 of 3\n",
      "Model Number: 292 with model ETS in generation 1 of 3\n",
      "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
      "ETS failed on NET_SALES with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
      "Model Number: 293 with model UnivariateMotif in generation 1 of 3\n",
      "Model Number: 294 with model MetricMotif in generation 1 of 3\n",
      "Model Number: 295 with model ConstantNaive in generation 1 of 3\n",
      "Model Number: 296 with model SeasonalNaive in generation 1 of 3\n",
      "Model Number: 297 with model SectionalMotif in generation 1 of 3\n",
      "Model Number: 298 with model UnobservedComponents in generation 1 of 3\n",
      "Model Number: 299 with model LastValueNaive in generation 1 of 3\n",
      "Model Number: 300 with model NVAR in generation 1 of 3\n",
      "Model Number: 301 with model GLM in generation 1 of 3\n",
      "Model Number: 302 with model WindowRegression in generation 1 of 3\n",
      "Model Number: 303 with model ConstantNaive in generation 1 of 3\n",
      "Model Number: 304 with model ETS in generation 1 of 3\n",
      "Model Number: 305 with model ETS in generation 1 of 3\n",
      "Model Number: 306 with model MetricMotif in generation 1 of 3\n",
      "Model Number: 307 with model WindowRegression in generation 1 of 3\n",
      "Model Number: 308 with model UnivariateMotif in generation 1 of 3\n",
      "Model Number: 309 with model MultivariateRegression in generation 1 of 3\n",
      "Model Number: 310 with model NVAR in generation 1 of 3\n",
      "Model Number: 311 with model ConstantNaive in generation 1 of 3\n",
      "New Generation: 2 of 3\n",
      "Model Number: 312 with model SeasonalNaive in generation 2 of 3\n",
      "Model Number: 313 with model SectionalMotif in generation 2 of 3\n",
      "Model Number: 314 with model SeasonalNaive in generation 2 of 3\n",
      "Model Number: 315 with model AverageValueNaive in generation 2 of 3\n",
      "Model Number: 316 with model SectionalMotif in generation 2 of 3\n",
      "Model Number: 317 with model DatepartRegression in generation 2 of 3\n",
      "Model Number: 318 with model UnobservedComponents in generation 2 of 3\n",
      "Model Number: 319 with model MetricMotif in generation 2 of 3\n",
      "Template Eval Error: ValueError('kth(=99) out of bounds (63)') in model 319 in generation 2: MetricMotif\n",
      "Model Number: 320 with model GLS in generation 2 of 3\n",
      "Model Number: 321 with model DatepartRegression in generation 2 of 3\n",
      "Template Eval Error: ValueError('Input X contains NaN.\\nExtraTreesRegressor does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values') in model 321 in generation 2: DatepartRegression\n",
      "Model Number: 322 with model MultivariateRegression in generation 2 of 3\n",
      "Model Number: 323 with model GLM in generation 2 of 3\n",
      "Model Number: 324 with model SeasonalNaive in generation 2 of 3\n",
      "Model Number: 325 with model MetricMotif in generation 2 of 3\n",
      "Model Number: 326 with model SectionalMotif in generation 2 of 3\n",
      "Model Number: 327 with model UnobservedComponents in generation 2 of 3\n",
      "Template Eval Error: Exception('Transformer Cointegration failed on fit') in model 327 in generation 2: UnobservedComponents\n",
      "Model Number: 328 with model ETS in generation 2 of 3\n",
      "Model Number: 329 with model Theta in generation 2 of 3\n",
      "Template Eval Error: Exception('Transformer Detrend failed on fit') in model 329 in generation 2: Theta\n",
      "Model Number: 330 with model LastValueNaive in generation 2 of 3\n",
      "Model Number: 331 with model UnivariateMotif in generation 2 of 3\n",
      "Template Eval Error: Exception('Transformer AlignLastValue failed on inverse') in model 331 in generation 2: UnivariateMotif\n",
      "Model Number: 332 with model ETS in generation 2 of 3\n",
      "Model Number: 333 with model DatepartRegression in generation 2 of 3\n",
      "Template Eval Error: ValueError('Input X contains NaN.\\nElasticNet does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values') in model 333 in generation 2: DatepartRegression\n",
      "Model Number: 334 with model LastValueNaive in generation 2 of 3\n",
      "Model Number: 335 with model SectionalMotif in generation 2 of 3\n",
      "Model Number: 336 with model WindowRegression in generation 2 of 3\n",
      "Model Number: 337 with model ARIMA in generation 2 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 338 with model GLS in generation 2 of 3\n",
      "Model Number: 339 with model MetricMotif in generation 2 of 3\n",
      "Model Number: 340 with model GLM in generation 2 of 3\n",
      "Model Number: 341 with model MultivariateMotif in generation 2 of 3\n",
      "Model Number: 342 with model AverageValueNaive in generation 2 of 3\n",
      "Model Number: 343 with model SeasonalNaive in generation 2 of 3\n",
      "Template Eval Error: Exception('Transformer RegressionFilter failed on fit') in model 343 in generation 2: SeasonalNaive\n",
      "Model Number: 344 with model ARDL in generation 2 of 3\n",
      "Model Number: 345 with model MetricMotif in generation 2 of 3\n",
      "Model Number: 346 with model MetricMotif in generation 2 of 3\n",
      "Model Number: 347 with model GLM in generation 2 of 3\n",
      "Model Number: 348 with model UnivariateRegression in generation 2 of 3\n",
      "Model Number: 349 with model ARDL in generation 2 of 3\n",
      "Model Number: 350 with model DatepartRegression in generation 2 of 3\n",
      "Model Number: 351 with model ETS in generation 2 of 3\n",
      "Template Eval Error: Exception('Transformer PowerTransformer failed on fit') in model 351 in generation 2: ETS\n",
      "Model Number: 352 with model GLS in generation 2 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\linear_model\\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=4.16252e-25): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 353 with model WindowRegression in generation 2 of 3\n",
      "Model Number: 354 with model UnivariateMotif in generation 2 of 3\n",
      "Model Number: 355 with model Theta in generation 2 of 3\n",
      "Model Number: 356 with model ARDL in generation 2 of 3\n",
      "Model Number: 357 with model MultivariateMotif in generation 2 of 3\n",
      "Model Number: 358 with model MetricMotif in generation 2 of 3\n",
      "Model Number: 359 with model DatepartRegression in generation 2 of 3\n",
      "Model Number: 360 with model GLS in generation 2 of 3\n",
      "Model Number: 361 with model GLS in generation 2 of 3\n",
      "Model Number: 362 with model MultivariateRegression in generation 2 of 3\n",
      "Model Number: 363 with model ARDL in generation 2 of 3\n",
      "Model Number: 364 with model ARIMA in generation 2 of 3\n",
      "Model Number: 365 with model SectionalMotif in generation 2 of 3\n",
      "Model Number: 366 with model ETS in generation 2 of 3\n",
      "Model Number: 367 with model AverageValueNaive in generation 2 of 3\n",
      "Model Number: 368 with model ARDL in generation 2 of 3\n",
      "Model Number: 369 with model ARIMA in generation 2 of 3\n",
      "Model Number: 370 with model AverageValueNaive in generation 2 of 3\n",
      "Model Number: 371 with model ARIMA in generation 2 of 3\n",
      "Model Number: 372 with model MetricMotif in generation 2 of 3\n",
      "Model Number: 373 with model WindowRegression in generation 2 of 3\n",
      "Model Number: 374 with model MultivariateRegression in generation 2 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\linear_model\\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.48343e-24): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 375 with model FBProphet in generation 2 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16:11:11 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:11:11 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 376 with model UnivariateMotif in generation 2 of 3\n",
      "Model Number: 377 with model ConstantNaive in generation 2 of 3\n",
      "Model Number: 378 with model ConstantNaive in generation 2 of 3\n",
      "Model Number: 379 with model SectionalMotif in generation 2 of 3\n",
      "Template Eval Error: ValueError('kth(=10) out of bounds (6)') in model 379 in generation 2: SectionalMotif\n",
      "Model Number: 380 with model GLM in generation 2 of 3\n",
      "Model Number: 381 with model Theta in generation 2 of 3\n",
      "Model Number: 382 with model SeasonalNaive in generation 2 of 3\n",
      "Model Number: 383 with model DatepartRegression in generation 2 of 3\n",
      "Model Number: 384 with model LastValueNaive in generation 2 of 3\n",
      "Model Number: 385 with model MultivariateRegression in generation 2 of 3\n",
      "Model Number: 386 with model LastValueNaive in generation 2 of 3\n",
      "Model Number: 387 with model ARIMA in generation 2 of 3\n",
      "Model Number: 388 with model ARDL in generation 2 of 3\n",
      "Template Eval Error: Exception('Transformer RegressionFilter failed on fit') in model 388 in generation 2: ARDL\n",
      "Model Number: 389 with model GLM in generation 2 of 3\n",
      "Model Number: 390 with model SeasonalNaive in generation 2 of 3\n",
      "Model Number: 391 with model UnivariateRegression in generation 2 of 3\n",
      "Model Number: 392 with model SectionalMotif in generation 2 of 3\n",
      "Model Number: 393 with model ETS in generation 2 of 3\n",
      "Model Number: 394 with model NVAR in generation 2 of 3\n",
      "Model Number: 395 with model GLS in generation 2 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\statsmodels\\genmod\\families\\family.py:1367: ValueWarning: Negative binomial dispersion parameter alpha not set. Using default value alpha=1.0.\n",
      "  warnings.warn(\"Negative binomial dispersion parameter alpha not \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 396 with model MultivariateMotif in generation 2 of 3\n",
      "Model Number: 397 with model SeasonalNaive in generation 2 of 3\n",
      "Model Number: 398 with model GLS in generation 2 of 3\n",
      "Model Number: 399 with model ETS in generation 2 of 3\n",
      "Model Number: 400 with model MultivariateRegression in generation 2 of 3\n",
      "Model Number: 401 with model UnivariateMotif in generation 2 of 3\n",
      "Template Eval Error: ValueError('window shape cannot be larger than input array shape') in model 401 in generation 2: UnivariateMotif\n",
      "Model Number: 402 with model ETS in generation 2 of 3\n",
      "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
      "ETS failed on NET_SALES with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
      "Model Number: 403 with model Theta in generation 2 of 3\n",
      "Model Number: 404 with model ARIMA in generation 2 of 3\n",
      "Model Number: 405 with model GLM in generation 2 of 3\n",
      "Model Number: 406 with model DatepartRegression in generation 2 of 3\n",
      "Model Number: 407 with model MetricMotif in generation 2 of 3\n",
      "Model Number: 408 with model UnivariateMotif in generation 2 of 3\n",
      "Model Number: 409 with model ARDL in generation 2 of 3\n",
      "Model Number: 410 with model UnivariateMotif in generation 2 of 3\n",
      "Model Number: 411 with model SeasonalNaive in generation 2 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\decomposition\\_fastica.py:708: FutureWarning: Starting in v1.3, whiten=True should be specified as whiten='arbitrary-variance' (its current behaviour). This behavior is deprecated in 1.1 and will raise ValueError in 1.3.\n",
      "  return self._fit_transform(X, compute_sources=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 412 with model MultivariateMotif in generation 2 of 3\n",
      "Model Number: 413 with model SectionalMotif in generation 2 of 3\n",
      "Model Number: 414 with model MetricMotif in generation 2 of 3\n",
      "Model Number: 415 with model ARIMA in generation 2 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:541: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 416 with model DatepartRegression in generation 2 of 3\n",
      "Model Number: 417 with model SeasonalNaive in generation 2 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 418 with model DatepartRegression in generation 2 of 3\n",
      "Template Eval Error: ValueError(\"Model returned NaN due to a preprocessing transformer {'fillna': 'ffill', 'transformations': {'0': 'QuantileTransformer', '1': 'SeasonalDifference', '2': 'AlignLastValue', '3': 'DatepartRegression'}, 'transformation_params': {'0': {'output_distribution': 'uniform', 'n_quantiles': 24}, '1': {'lag_1': 364, 'method': 'LastValue'}, '2': {'rows': 4, 'lag': 1, 'method': 'multiplicative', 'strength': 1.0, 'first_value_only': True}, '3': {'regression_model': {'model': 'ExtraTrees', 'model_params': {'n_estimators': 100, 'min_samples_leaf': 1, 'max_depth': 20}}, 'datepart_method': 'simple_2', 'polynomial_degree': 2, 'transform_dict': {'fillna': None, 'transformations': {'0': 'ScipyFilter'}, 'transformation_params': {'0': {'method': 'savgol_filter', 'method_args': {'window_length': 31, 'polyorder': 3, 'deriv': 0, 'mode': 'interp'}}}}, 'holiday_countries_used': False}}}. fail_on_forecast_nan=True\") in model 418 in generation 2: DatepartRegression\n",
      "Model Number: 419 with model GLS in generation 2 of 3\n",
      "Model Number: 420 with model LastValueNaive in generation 2 of 3\n",
      "Model Number: 421 with model GLS in generation 2 of 3\n",
      "Model Number: 422 with model UnobservedComponents in generation 2 of 3\n",
      "Model Number: 423 with model UnobservedComponents in generation 2 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\autots\\tools\\probabilistic.py:67: RuntimeWarning: invalid value encountered in divide\n",
      "  (prior_mu / prior_sigma**2) + ((n * data_mu) / prior_sigma**2)\n",
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\autots\\tools\\probabilistic.py:68: RuntimeWarning: divide by zero encountered in divide\n",
      "  ) / ((1 / prior_sigma**2) + (n / prior_sigma**2))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 424 with model GLM in generation 2 of 3\n",
      "Model Number: 425 with model MetricMotif in generation 2 of 3\n",
      "Model Number: 426 with model AverageValueNaive in generation 2 of 3\n",
      "Template Eval Error: Exception('Transformer AlignLastValue failed on inverse') in model 426 in generation 2: AverageValueNaive\n",
      "Model Number: 427 with model NVAR in generation 2 of 3\n",
      "Model Number: 428 with model SeasonalNaive in generation 2 of 3\n",
      "Model Number: 429 with model WindowRegression in generation 2 of 3\n",
      "Template Eval Error: Exception('Transformer AlignLastValue failed on inverse') in model 429 in generation 2: WindowRegression\n",
      "Model Number: 430 with model SectionalMotif in generation 2 of 3\n",
      "Model Number: 431 with model ARIMA in generation 2 of 3\n",
      "Model Number: 432 with model DatepartRegression in generation 2 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 433 with model MultivariateRegression in generation 2 of 3\n",
      "Model Number: 434 with model MultivariateRegression in generation 2 of 3\n",
      "Model Number: 435 with model MetricMotif in generation 2 of 3\n",
      "Model Number: 436 with model ConstantNaive in generation 2 of 3\n",
      "New Generation: 3 of 3\n",
      "Model Number: 437 with model SeasonalNaive in generation 3 of 3\n",
      "Model Number: 438 with model DatepartRegression in generation 3 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\autots\\tools\\probabilistic.py:67: RuntimeWarning: invalid value encountered in divide\n",
      "  (prior_mu / prior_sigma**2) + ((n * data_mu) / prior_sigma**2)\n",
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\autots\\tools\\probabilistic.py:68: RuntimeWarning: divide by zero encountered in divide\n",
      "  ) / ((1 / prior_sigma**2) + (n / prior_sigma**2))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 439 with model SeasonalNaive in generation 3 of 3\n",
      "Model Number: 440 with model MetricMotif in generation 3 of 3\n",
      "Model Number: 441 with model GLM in generation 3 of 3\n",
      "Model Number: 442 with model SectionalMotif in generation 3 of 3\n",
      "Model Number: 443 with model ARIMA in generation 3 of 3\n",
      "Model Number: 444 with model SeasonalNaive in generation 3 of 3\n",
      "Template Eval Error: Exception('Transformer Cointegration failed on fit') in model 444 in generation 3: SeasonalNaive\n",
      "Model Number: 445 with model LastValueNaive in generation 3 of 3\n",
      "Model Number: 446 with model GLS in generation 3 of 3\n",
      "Model Number: 447 with model ARIMA in generation 3 of 3\n",
      "Model Number: 448 with model GLM in generation 3 of 3\n",
      "Model Number: 449 with model GLM in generation 3 of 3\n",
      "Template Eval Error: Exception('Transformer Detrend failed on fit') in model 449 in generation 3: GLM\n",
      "Model Number: 450 with model AverageValueNaive in generation 3 of 3\n",
      "Model Number: 451 with model DatepartRegression in generation 3 of 3\n",
      "Model Number: 452 with model MultivariateRegression in generation 3 of 3\n",
      "Model Number: 453 with model UnobservedComponents in generation 3 of 3\n",
      "Model Number: 454 with model UnobservedComponents in generation 3 of 3\n",
      "Model Number: 455 with model DatepartRegression in generation 3 of 3\n",
      "Template Eval Error: ImportError('Tensorflow not available, install with pip install tensorflow.') in model 455 in generation 3: DatepartRegression\n",
      "Model Number: 456 with model DatepartRegression in generation 3 of 3\n",
      "Model Number: 457 with model UnobservedComponents in generation 3 of 3\n",
      "Model Number: 458 with model GLM in generation 3 of 3\n",
      "Model Number: 459 with model MultivariateRegression in generation 3 of 3\n",
      "Model Number: 460 with model ETS in generation 3 of 3\n",
      "Template Eval Error: Exception('Transformer BTCD failed on fit') in model 460 in generation 3: ETS\n",
      "Model Number: 461 with model DatepartRegression in generation 3 of 3\n",
      "Model Number: 462 with model WindowRegression in generation 3 of 3\n",
      "Model Number: 463 with model NVAR in generation 3 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 464 with model MultivariateRegression in generation 3 of 3\n",
      "Model Number: 465 with model GLS in generation 3 of 3\n",
      "Model Number: 466 with model NVAR in generation 3 of 3\n",
      "Model Number: 467 with model MetricMotif in generation 3 of 3\n",
      "Template Eval Error: Exception('Transformer MaxAbsScaler failed on inverse') in model 467 in generation 3: MetricMotif\n",
      "Model Number: 468 with model WindowRegression in generation 3 of 3\n",
      "Template Eval Error: ImportError('Tensorflow not available, install with pip install tensorflow.') in model 468 in generation 3: WindowRegression\n",
      "Model Number: 469 with model MultivariateMotif in generation 3 of 3\n",
      "Model Number: 470 with model SectionalMotif in generation 3 of 3\n",
      "Model Number: 471 with model AverageValueNaive in generation 3 of 3\n",
      "Template Eval Error: Exception('Transformer PowerTransformer failed on fit') in model 471 in generation 3: AverageValueNaive\n",
      "Model Number: 472 with model MultivariateMotif in generation 3 of 3\n",
      "Template Eval Error: ValueError('kth(=100) out of bounds (54)') in model 472 in generation 3: MultivariateMotif\n",
      "Model Number: 473 with model SectionalMotif in generation 3 of 3\n",
      "Model Number: 474 with model ETS in generation 3 of 3\n",
      "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
      "ETS failed on NET_SALES with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
      "Model Number: 475 with model UnobservedComponents in generation 3 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\linear_model\\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.48343e-24): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 476 with model AverageValueNaive in generation 3 of 3\n",
      "Model Number: 477 with model ConstantNaive in generation 3 of 3\n",
      "Model Number: 478 with model ETS in generation 3 of 3\n",
      "Model Number: 479 with model LastValueNaive in generation 3 of 3\n",
      "Model Number: 480 with model UnivariateMotif in generation 3 of 3\n",
      "Model Number: 481 with model MetricMotif in generation 3 of 3\n",
      "Model Number: 482 with model MultivariateRegression in generation 3 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (250) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 483 with model GLM in generation 3 of 3\n",
      "Template Eval Error: Exception('Transformer Cointegration failed on fit') in model 483 in generation 3: GLM\n",
      "Model Number: 484 with model SectionalMotif in generation 3 of 3\n",
      "Model Number: 485 with model Theta in generation 3 of 3\n",
      "Model Number: 486 with model MultivariateMotif in generation 3 of 3\n",
      "Model Number: 487 with model GLS in generation 3 of 3\n",
      "Model Number: 488 with model NVAR in generation 3 of 3\n",
      "Model Number: 489 with model MultivariateRegression in generation 3 of 3\n",
      "Model Number: 490 with model MetricMotif in generation 3 of 3\n",
      "Model Number: 491 with model GLS in generation 3 of 3\n",
      "Model Number: 492 with model SectionalMotif in generation 3 of 3\n",
      "Model Number: 493 with model DatepartRegression in generation 3 of 3\n",
      "Model Number: 494 with model ETS in generation 3 of 3\n",
      "Model Number: 495 with model ETS in generation 3 of 3\n",
      "Model Number: 496 with model ARIMA in generation 3 of 3\n",
      "Model Number: 497 with model GLM in generation 3 of 3\n",
      "Model Number: 498 with model Theta in generation 3 of 3\n",
      "Model Number: 499 with model ETS in generation 3 of 3\n",
      "Model Number: 500 with model AverageValueNaive in generation 3 of 3\n",
      "Model Number: 501 with model MetricMotif in generation 3 of 3\n",
      "Model Number: 502 with model ARIMA in generation 3 of 3\n",
      "Model Number: 503 with model Theta in generation 3 of 3\n",
      "Model Number: 504 with model ARDL in generation 3 of 3\n",
      "Model Number: 505 with model ARIMA in generation 3 of 3\n",
      "Model Number: 506 with model MultivariateRegression in generation 3 of 3\n",
      "Model Number: 507 with model ETS in generation 3 of 3\n",
      "Model Number: 508 with model GLM in generation 3 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\decomposition\\_fastica.py:708: FutureWarning: Starting in v1.3, whiten=True should be specified as whiten='arbitrary-variance' (its current behaviour). This behavior is deprecated in 1.1 and will raise ValueError in 1.3.\n",
      "  return self._fit_transform(X, compute_sources=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 509 with model DatepartRegression in generation 3 of 3\n",
      "Model Number: 510 with model SeasonalNaive in generation 3 of 3\n",
      "Model Number: 511 with model ARIMA in generation 3 of 3\n",
      "Model Number: 512 with model ETS in generation 3 of 3\n",
      "Model Number: 513 with model SeasonalNaive in generation 3 of 3\n",
      "Model Number: 514 with model AverageValueNaive in generation 3 of 3\n",
      "Model Number: 515 with model SeasonalNaive in generation 3 of 3\n",
      "Model Number: 516 with model GLM in generation 3 of 3\n",
      "Model Number: 517 with model WindowRegression in generation 3 of 3\n",
      "Model Number: 518 with model SeasonalNaive in generation 3 of 3\n",
      "Model Number: 519 with model ConstantNaive in generation 3 of 3\n",
      "Model Number: 520 with model MetricMotif in generation 3 of 3\n",
      "Template Eval Error: Exception('Transformer BTCD failed on fit') in model 520 in generation 3: MetricMotif\n",
      "Model Number: 521 with model MultivariateRegression in generation 3 of 3\n",
      "Model Number: 522 with model MultivariateRegression in generation 3 of 3\n",
      "Model Number: 523 with model UnivariateMotif in generation 3 of 3\n",
      "Model Number: 524 with model ARDL in generation 3 of 3\n",
      "Model Number: 525 with model UnivariateMotif in generation 3 of 3\n",
      "Model Number: 526 with model WindowRegression in generation 3 of 3\n",
      "Template Eval Error: LightGBMError('[tweedie]: at least one target label is negative') in model 526 in generation 3: WindowRegression\n",
      "Model Number: 527 with model MetricMotif in generation 3 of 3\n",
      "Model Number: 528 with model ARIMA in generation 3 of 3\n",
      "Model Number: 529 with model AverageValueNaive in generation 3 of 3\n",
      "Model Number: 530 with model ETS in generation 3 of 3\n",
      "Model Number: 531 with model SectionalMotif in generation 3 of 3\n",
      "Model Number: 532 with model WindowRegression in generation 3 of 3\n",
      "Model Number: 533 with model ARDL in generation 3 of 3\n",
      "Model Number: 534 with model UnobservedComponents in generation 3 of 3\n",
      "Model Number: 535 with model AverageValueNaive in generation 3 of 3\n",
      "Model Number: 536 with model Theta in generation 3 of 3\n",
      "Template Eval Error: Exception('Transformer BTCD failed on fit') in model 536 in generation 3: Theta\n",
      "Model Number: 537 with model MetricMotif in generation 3 of 3\n",
      "Model Number: 538 with model MetricMotif in generation 3 of 3\n",
      "Model Number: 539 with model SeasonalNaive in generation 3 of 3\n",
      "Model Number: 540 with model SeasonalNaive in generation 3 of 3\n",
      "Model Number: 541 with model ARIMA in generation 3 of 3\n",
      "Model Number: 542 with model SeasonalNaive in generation 3 of 3\n",
      "Model Number: 543 with model ARIMA in generation 3 of 3\n",
      "Model Number: 544 with model MultivariateRegression in generation 3 of 3\n",
      "Model Number: 545 with model WindowRegression in generation 3 of 3\n",
      "Model Number: 546 with model ARIMA in generation 3 of 3\n",
      "Model Number: 547 with model ARDL in generation 3 of 3\n",
      "Model Number: 548 with model ETS in generation 3 of 3\n",
      "ETS error ValueError('Cannot compute initial seasonals using heuristic method with less than two full seasonal cycles in the data.')\n",
      "ETS failed on NET_SALES with ValueError('Cannot compute initial seasonals using heuristic method with less than two full seasonal cycles in the data.')\n",
      "Model Number: 549 with model ETS in generation 3 of 3\n",
      "Model Number: 550 with model MetricMotif in generation 3 of 3\n",
      "Model Number: 551 with model GLS in generation 3 of 3\n",
      "Model Number: 552 with model WindowRegression in generation 3 of 3\n",
      "Model Number: 553 with model ARDL in generation 3 of 3\n",
      "Model Number: 554 with model GLM in generation 3 of 3\n",
      "Template Eval Error: Exception('Transformer Detrend failed on fit') in model 554 in generation 3: GLM\n",
      "Model Number: 555 with model UnivariateRegression in generation 3 of 3\n",
      "Model Number: 556 with model SeasonalNaive in generation 3 of 3\n",
      "Model Number: 557 with model UnivariateRegression in generation 3 of 3\n",
      "Model Number: 558 with model GLM in generation 3 of 3\n",
      "Model Number: 559 with model SeasonalNaive in generation 3 of 3\n",
      "Model Number: 560 with model SectionalMotif in generation 3 of 3\n",
      "Model Number: 561 with model UnivariateMotif in generation 3 of 3\n",
      "TotalRuntime missing in 4!\n",
      "Validation Round: 1\n",
      "Model Number: 1 of 84 with model DatepartRegression for Validation 1\n",
      "📈 1 - DatepartRegression with avg smape 41.11: \n",
      "Model Number: 2 of 84 with model ARIMA for Validation 1\n",
      "2 - ARIMA with avg smape 64.42: \n",
      "Model Number: 3 of 84 with model DatepartRegression for Validation 1\n",
      "3 - DatepartRegression with avg smape 43.51: \n",
      "Model Number: 4 of 84 with model SeasonalNaive for Validation 1\n",
      "📈 4 - SeasonalNaive with avg smape 40.1: \n",
      "Model Number: 5 of 84 with model MultivariateRegression for Validation 1\n",
      "📈 5 - MultivariateRegression with avg smape 28.09: \n",
      "Model Number: 6 of 84 with model DatepartRegression for Validation 1\n",
      "6 - DatepartRegression with avg smape 52.84: \n",
      "Model Number: 7 of 84 with model DatepartRegression for Validation 1\n",
      "7 - DatepartRegression with avg smape 38.01: \n",
      "Model Number: 8 of 84 with model DatepartRegression for Validation 1\n",
      "8 - DatepartRegression with avg smape 38.22: \n",
      "Model Number: 9 of 84 with model ARIMA for Validation 1\n",
      "9 - ARIMA with avg smape 109.03: \n",
      "Model Number: 10 of 84 with model ARIMA for Validation 1\n",
      "10 - ARIMA with avg smape 109.03: \n",
      "Model Number: 11 of 84 with model SeasonalNaive for Validation 1\n",
      "11 - SeasonalNaive with avg smape 36.39: \n",
      "Model Number: 12 of 84 with model SectionalMotif for Validation 1\n",
      "12 - SectionalMotif with avg smape 43.74: \n",
      "Model Number: 13 of 84 with model ARDL for Validation 1\n",
      "13 - ARDL with avg smape 34.38: \n",
      "Model Number: 14 of 84 with model SectionalMotif for Validation 1\n",
      "📈 14 - SectionalMotif with avg smape 26.18: \n",
      "Model Number: 15 of 84 with model ARIMA for Validation 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\linear_model\\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.78051e-24): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15 - ARIMA with avg smape 27.73: \n",
      "Model Number: 16 of 84 with model MultivariateRegression for Validation 1\n",
      "16 - MultivariateRegression with avg smape 53.73: \n",
      "Model Number: 17 of 84 with model GLS for Validation 1\n",
      "📈 17 - GLS with avg smape 20.29: \n",
      "Model Number: 18 of 84 with model SeasonalNaive for Validation 1\n",
      "18 - SeasonalNaive with avg smape 28.56: \n",
      "Model Number: 19 of 84 with model UnobservedComponents for Validation 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:541: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19 - UnobservedComponents with avg smape 33.89: \n",
      "Model Number: 20 of 84 with model MetricMotif for Validation 1\n",
      "20 - MetricMotif with avg smape 51.06: \n",
      "Model Number: 21 of 84 with model MetricMotif for Validation 1\n",
      "21 - MetricMotif with avg smape 34.35: \n",
      "Model Number: 22 of 84 with model SeasonalNaive for Validation 1\n",
      "22 - SeasonalNaive with avg smape 35.79: \n",
      "Model Number: 23 of 84 with model MultivariateRegression for Validation 1\n",
      "23 - MultivariateRegression with avg smape 20.56: \n",
      "Model Number: 24 of 84 with model MetricMotif for Validation 1\n",
      "24 - MetricMotif with avg smape 22.62: \n",
      "Model Number: 25 of 84 with model SeasonalNaive for Validation 1\n",
      "25 - SeasonalNaive with avg smape 43.95: \n",
      "Model Number: 26 of 84 with model GLS for Validation 1\n",
      "26 - GLS with avg smape 52.88: \n",
      "Model Number: 27 of 84 with model MultivariateRegression for Validation 1\n",
      "27 - MultivariateRegression with avg smape 29.11: \n",
      "Model Number: 28 of 84 with model GLS for Validation 1\n",
      "28 - GLS with avg smape 51.52: \n",
      "Model Number: 29 of 84 with model MetricMotif for Validation 1\n",
      "29 - MetricMotif with avg smape 64.5: \n",
      "Model Number: 30 of 84 with model GLS for Validation 1\n",
      "30 - GLS with avg smape 30.58: \n",
      "Model Number: 31 of 84 with model GLS for Validation 1\n",
      "31 - GLS with avg smape 30.58: \n",
      "Model Number: 32 of 84 with model MultivariateRegression for Validation 1\n",
      "32 - MultivariateRegression with avg smape 42.85: \n",
      "Model Number: 33 of 84 with model ETS for Validation 1\n",
      "33 - ETS with avg smape 32.58: \n",
      "Model Number: 34 of 84 with model ETS for Validation 1\n",
      "34 - ETS with avg smape 32.4: \n",
      "Model Number: 35 of 84 with model ETS for Validation 1\n",
      "35 - ETS with avg smape 42.57: \n",
      "Model Number: 36 of 84 with model ETS for Validation 1\n",
      "36 - ETS with avg smape 28.32: \n",
      "Model Number: 37 of 84 with model ETS for Validation 1\n",
      "37 - ETS with avg smape 26.25: \n",
      "Model Number: 38 of 84 with model GLM for Validation 1\n",
      "38 - GLM with avg smape 52.86: \n",
      "Model Number: 39 of 84 with model MultivariateMotif for Validation 1\n",
      "39 - MultivariateMotif with avg smape 28.33: \n",
      "Model Number: 40 of 84 with model MetricMotif for Validation 1\n",
      "40 - MetricMotif with avg smape 38.45: \n",
      "Model Number: 41 of 84 with model UnobservedComponents for Validation 1\n",
      "41 - UnobservedComponents with avg smape 26.67: \n",
      "Model Number: 42 of 84 with model UnobservedComponents for Validation 1\n",
      "42 - UnobservedComponents with avg smape 31.39: \n",
      "Model Number: 43 of 84 with model ARIMA for Validation 1\n",
      "43 - ARIMA with avg smape 21.49: \n",
      "Model Number: 44 of 84 with model GLM for Validation 1\n",
      "44 - GLM with avg smape 21.39: \n",
      "Model Number: 45 of 84 with model GLM for Validation 1\n",
      "45 - GLM with avg smape 21.39: \n",
      "Model Number: 46 of 84 with model GLM for Validation 1\n",
      "46 - GLM with avg smape 22.35: \n",
      "Model Number: 47 of 84 with model WindowRegression for Validation 1\n",
      "47 - WindowRegression with avg smape 31.62: \n",
      "Model Number: 48 of 84 with model GLM for Validation 1\n",
      "48 - GLM with avg smape 22.27: \n",
      "Model Number: 49 of 84 with model WindowRegression for Validation 1\n",
      "49 - WindowRegression with avg smape 21.5: \n",
      "Model Number: 50 of 84 with model WindowRegression for Validation 1\n",
      "50 - WindowRegression with avg smape 54.78: \n",
      "Model Number: 51 of 84 with model WindowRegression for Validation 1\n",
      "51 - WindowRegression with avg smape 53.99: \n",
      "Model Number: 52 of 84 with model MultivariateMotif for Validation 1\n",
      "52 - MultivariateMotif with avg smape 20.77: \n",
      "Model Number: 53 of 84 with model SectionalMotif for Validation 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53 - SectionalMotif with avg smape 22.73: \n",
      "Model Number: 54 of 84 with model WindowRegression for Validation 1\n",
      "54 - WindowRegression with avg smape 21.17: \n",
      "Model Number: 55 of 84 with model UnivariateMotif for Validation 1\n",
      "55 - UnivariateMotif with avg smape 24.21: \n",
      "Model Number: 56 of 84 with model SectionalMotif for Validation 1\n",
      "56 - SectionalMotif with avg smape 49.7: \n",
      "Model Number: 57 of 84 with model ARDL for Validation 1\n",
      "57 - ARDL with avg smape 22.55: \n",
      "Model Number: 58 of 84 with model UnobservedComponents for Validation 1\n",
      "58 - UnobservedComponents with avg smape 45.64: \n",
      "Model Number: 59 of 84 with model ARDL for Validation 1\n",
      "59 - ARDL with avg smape 24.98: \n",
      "Model Number: 60 of 84 with model SectionalMotif for Validation 1\n",
      "60 - SectionalMotif with avg smape 25.87: \n",
      "Model Number: 61 of 84 with model UnivariateMotif for Validation 1\n",
      "61 - UnivariateMotif with avg smape 23.77: \n",
      "Model Number: 62 of 84 with model AverageValueNaive for Validation 1\n",
      "62 - AverageValueNaive with avg smape 20.72: \n",
      "Model Number: 63 of 84 with model ConstantNaive for Validation 1\n",
      "63 - ConstantNaive with avg smape 41.98: \n",
      "Model Number: 64 of 84 with model MultivariateMotif for Validation 1\n",
      "64 - MultivariateMotif with avg smape 34.26: \n",
      "Model Number: 65 of 84 with model LastValueNaive for Validation 1\n",
      "65 - LastValueNaive with avg smape 108.78: \n",
      "Model Number: 66 of 84 with model MultivariateMotif for Validation 1\n",
      "66 - MultivariateMotif with avg smape 26.0: \n",
      "Model Number: 67 of 84 with model UnivariateMotif for Validation 1\n",
      "67 - UnivariateMotif with avg smape 22.49: \n",
      "Model Number: 68 of 84 with model Theta for Validation 1\n",
      "68 - Theta with avg smape 55.12: \n",
      "Model Number: 69 of 84 with model AverageValueNaive for Validation 1\n",
      "69 - AverageValueNaive with avg smape 20.75: \n",
      "Model Number: 70 of 84 with model Theta for Validation 1\n",
      "70 - Theta with avg smape 28.62: \n",
      "Model Number: 71 of 84 with model MultivariateMotif for Validation 1\n",
      "71 - MultivariateMotif with avg smape 27.95: \n",
      "Model Number: 72 of 84 with model AverageValueNaive for Validation 1\n",
      "72 - AverageValueNaive with avg smape 20.72: \n",
      "Model Number: 73 of 84 with model AverageValueNaive for Validation 1\n",
      "73 - AverageValueNaive with avg smape 20.72: \n",
      "Model Number: 74 of 84 with model UnivariateMotif for Validation 1\n",
      "74 - UnivariateMotif with avg smape 24.28: \n",
      "Model Number: 75 of 84 with model AverageValueNaive for Validation 1\n",
      "75 - AverageValueNaive with avg smape 21.96: \n",
      "Model Number: 76 of 84 with model ARDL for Validation 1\n",
      "76 - ARDL with avg smape 21.56: \n",
      "Model Number: 77 of 84 with model UnobservedComponents for Validation 1\n",
      "77 - UnobservedComponents with avg smape 26.68: \n",
      "Model Number: 78 of 84 with model Theta for Validation 1\n",
      "78 - Theta with avg smape 29.68: \n",
      "Model Number: 79 of 84 with model Theta for Validation 1\n",
      "79 - Theta with avg smape 29.58: \n",
      "Model Number: 80 of 84 with model ARDL for Validation 1\n",
      "80 - ARDL with avg smape 22.57: \n",
      "Model Number: 81 of 84 with model Theta for Validation 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:541: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81 - Theta with avg smape 29.6: \n",
      "Model Number: 82 of 84 with model UnivariateMotif for Validation 1\n",
      "82 - UnivariateMotif with avg smape 25.78: \n",
      "Model Number: 83 of 84 with model UnivariateRegression for Validation 1\n",
      "83 - UnivariateRegression with avg smape 23.12: \n",
      "Model Number: 84 of 84 with model UnivariateRegression for Validation 1\n",
      "84 - UnivariateRegression with avg smape 21.51: \n",
      "Validation Round: 2\n",
      "Model Number: 1 of 84 with model DatepartRegression for Validation 2\n",
      "📈 1 - DatepartRegression with avg smape 46.18: \n",
      "Model Number: 2 of 84 with model ARIMA for Validation 2\n",
      "📈 2 - ARIMA with avg smape 41.93: \n",
      "Model Number: 3 of 84 with model DatepartRegression for Validation 2\n",
      "3 - DatepartRegression with avg smape 53.95: \n",
      "Model Number: 4 of 84 with model SeasonalNaive for Validation 2\n",
      "4 - SeasonalNaive with avg smape 46.2: \n",
      "Model Number: 5 of 84 with model MultivariateRegression for Validation 2\n",
      "5 - MultivariateRegression with avg smape 48.14: \n",
      "Model Number: 6 of 84 with model DatepartRegression for Validation 2\n",
      "6 - DatepartRegression with avg smape 54.99: \n",
      "Model Number: 7 of 84 with model DatepartRegression for Validation 2\n",
      "7 - DatepartRegression with avg smape 45.47: \n",
      "Model Number: 8 of 84 with model DatepartRegression for Validation 2\n",
      "8 - DatepartRegression with avg smape 52.16: \n",
      "Model Number: 9 of 84 with model ARIMA for Validation 2\n",
      "📈 9 - ARIMA with avg smape 41.92: \n",
      "Model Number: 10 of 84 with model ARIMA for Validation 2\n",
      "10 - ARIMA with avg smape 41.92: \n",
      "Model Number: 11 of 84 with model SeasonalNaive for Validation 2\n",
      "11 - SeasonalNaive with avg smape 46.1: \n",
      "Model Number: 12 of 84 with model SectionalMotif for Validation 2\n",
      "📈 12 - SectionalMotif with avg smape 32.59: \n",
      "Model Number: 13 of 84 with model ARDL for Validation 2\n",
      "13 - ARDL with avg smape 52.24: \n",
      "Model Number: 14 of 84 with model SectionalMotif for Validation 2\n",
      "14 - SectionalMotif with avg smape 48.57: \n",
      "Model Number: 15 of 84 with model ARIMA for Validation 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\linear_model\\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.22635e-24): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15 - ARIMA with avg smape 78.58: \n",
      "Model Number: 16 of 84 with model MultivariateRegression for Validation 2\n",
      "16 - MultivariateRegression with avg smape 36.53: \n",
      "Model Number: 17 of 84 with model GLS for Validation 2\n",
      "17 - GLS with avg smape 35.63: \n",
      "Model Number: 18 of 84 with model SeasonalNaive for Validation 2\n",
      "18 - SeasonalNaive with avg smape 37.54: \n",
      "Model Number: 19 of 84 with model UnobservedComponents for Validation 2\n",
      "19 - UnobservedComponents with avg smape 44.53: \n",
      "Model Number: 20 of 84 with model MetricMotif for Validation 2\n",
      "20 - MetricMotif with avg smape 50.28: \n",
      "Model Number: 21 of 84 with model MetricMotif for Validation 2\n",
      "21 - MetricMotif with avg smape 48.08: \n",
      "Model Number: 22 of 84 with model SeasonalNaive for Validation 2\n",
      "22 - SeasonalNaive with avg smape 43.63: \n",
      "Model Number: 23 of 84 with model MultivariateRegression for Validation 2\n",
      "23 - MultivariateRegression with avg smape 58.76: \n",
      "Model Number: 24 of 84 with model MetricMotif for Validation 2\n",
      "24 - MetricMotif with avg smape 45.86: \n",
      "Model Number: 25 of 84 with model SeasonalNaive for Validation 2\n",
      "25 - SeasonalNaive with avg smape 44.25: \n",
      "Model Number: 26 of 84 with model GLS for Validation 2\n",
      "26 - GLS with avg smape 46.73: \n",
      "Model Number: 27 of 84 with model MultivariateRegression for Validation 2\n",
      "📈 27 - MultivariateRegression with avg smape 29.25: \n",
      "Model Number: 28 of 84 with model GLS for Validation 2\n",
      "28 - GLS with avg smape 47.55: \n",
      "Model Number: 29 of 84 with model MetricMotif for Validation 2\n",
      "29 - MetricMotif with avg smape 56.33: \n",
      "Model Number: 30 of 84 with model GLS for Validation 2\n",
      "30 - GLS with avg smape 44.91: \n",
      "Model Number: 31 of 84 with model GLS for Validation 2\n",
      "31 - GLS with avg smape 44.91: \n",
      "Model Number: 32 of 84 with model MultivariateRegression for Validation 2\n",
      "32 - MultivariateRegression with avg smape 38.85: \n",
      "Model Number: 33 of 84 with model ETS for Validation 2\n",
      "33 - ETS with avg smape 54.14: \n",
      "Model Number: 34 of 84 with model ETS for Validation 2\n",
      "34 - ETS with avg smape 54.78: \n",
      "Model Number: 35 of 84 with model ETS for Validation 2\n",
      "35 - ETS with avg smape 44.98: \n",
      "Model Number: 36 of 84 with model ETS for Validation 2\n",
      "36 - ETS with avg smape 47.07: \n",
      "Model Number: 37 of 84 with model ETS for Validation 2\n",
      "37 - ETS with avg smape 47.6: \n",
      "Model Number: 38 of 84 with model GLM for Validation 2\n",
      "38 - GLM with avg smape 46.74: \n",
      "Model Number: 39 of 84 with model MultivariateMotif for Validation 2\n",
      "Template Eval Error: ValueError('kth(=10) out of bounds (9)') in model 39 in generation 0: MultivariateMotif\n",
      "Model Number: 40 of 84 with model MetricMotif for Validation 2\n",
      "40 - MetricMotif with avg smape 58.3: \n",
      "Model Number: 41 of 84 with model UnobservedComponents for Validation 2\n",
      "41 - UnobservedComponents with avg smape 44.95: \n",
      "Model Number: 42 of 84 with model UnobservedComponents for Validation 2\n",
      "42 - UnobservedComponents with avg smape 45.61: \n",
      "Model Number: 43 of 84 with model ARIMA for Validation 2\n",
      "43 - ARIMA with avg smape 45.04: \n",
      "Model Number: 44 of 84 with model GLM for Validation 2\n",
      "44 - GLM with avg smape 44.35: \n",
      "Model Number: 45 of 84 with model GLM for Validation 2\n",
      "45 - GLM with avg smape 44.35: \n",
      "Model Number: 46 of 84 with model GLM for Validation 2\n",
      "46 - GLM with avg smape 55.96: \n",
      "Model Number: 47 of 84 with model WindowRegression for Validation 2\n",
      "47 - WindowRegression with avg smape 64.44: \n",
      "Model Number: 48 of 84 with model GLM for Validation 2\n",
      "48 - GLM with avg smape 55.88: \n",
      "Model Number: 49 of 84 with model WindowRegression for Validation 2\n",
      "49 - WindowRegression with avg smape 44.27: \n",
      "Model Number: 50 of 84 with model WindowRegression for Validation 2\n",
      "50 - WindowRegression with avg smape 42.83: \n",
      "Model Number: 51 of 84 with model WindowRegression for Validation 2\n",
      "51 - WindowRegression with avg smape 42.83: \n",
      "Model Number: 52 of 84 with model MultivariateMotif for Validation 2\n",
      "52 - MultivariateMotif with avg smape 48.26: \n",
      "Model Number: 53 of 84 with model SectionalMotif for Validation 2\n",
      "53 - SectionalMotif with avg smape 44.35: \n",
      "Model Number: 54 of 84 with model WindowRegression for Validation 2\n",
      "54 - WindowRegression with avg smape 42.74: \n",
      "Model Number: 55 of 84 with model UnivariateMotif for Validation 2\n",
      "55 - UnivariateMotif with avg smape 46.86: \n",
      "Model Number: 56 of 84 with model SectionalMotif for Validation 2\n",
      "56 - SectionalMotif with avg smape 46.95: \n",
      "Model Number: 57 of 84 with model ARDL for Validation 2\n",
      "57 - ARDL with avg smape 58.16: \n",
      "Model Number: 58 of 84 with model UnobservedComponents for Validation 2\n",
      "58 - UnobservedComponents with avg smape 49.81: \n",
      "Model Number: 59 of 84 with model ARDL for Validation 2\n",
      "59 - ARDL with avg smape 58.71: \n",
      "Model Number: 60 of 84 with model SectionalMotif for Validation 2\n",
      "60 - SectionalMotif with avg smape 45.01: \n",
      "Model Number: 61 of 84 with model UnivariateMotif for Validation 2\n",
      "61 - UnivariateMotif with avg smape 43.89: \n",
      "Model Number: 62 of 84 with model AverageValueNaive for Validation 2\n",
      "62 - AverageValueNaive with avg smape 52.66: \n",
      "Model Number: 63 of 84 with model ConstantNaive for Validation 2\n",
      "63 - ConstantNaive with avg smape 44.98: \n",
      "Model Number: 64 of 84 with model MultivariateMotif for Validation 2\n",
      "64 - MultivariateMotif with avg smape 52.65: \n",
      "Model Number: 65 of 84 with model LastValueNaive for Validation 2\n",
      "65 - LastValueNaive with avg smape 29.62: \n",
      "Model Number: 66 of 84 with model MultivariateMotif for Validation 2\n",
      "66 - MultivariateMotif with avg smape 53.36: \n",
      "Model Number: 67 of 84 with model UnivariateMotif for Validation 2\n",
      "67 - UnivariateMotif with avg smape 48.71: \n",
      "Model Number: 68 of 84 with model Theta for Validation 2\n",
      "68 - Theta with avg smape 40.0: \n",
      "Model Number: 69 of 84 with model AverageValueNaive for Validation 2\n",
      "69 - AverageValueNaive with avg smape 40.19: \n",
      "Model Number: 70 of 84 with model Theta for Validation 2\n",
      "70 - Theta with avg smape 50.49: \n",
      "Model Number: 71 of 84 with model MultivariateMotif for Validation 2\n",
      "Template Eval Error: ValueError('kth(=10) out of bounds (9)') in model 71 in generation 0: MultivariateMotif\n",
      "Model Number: 72 of 84 with model AverageValueNaive for Validation 2\n",
      "72 - AverageValueNaive with avg smape 44.21: \n",
      "Model Number: 73 of 84 with model AverageValueNaive for Validation 2\n",
      "73 - AverageValueNaive with avg smape 44.21: \n",
      "Model Number: 74 of 84 with model UnivariateMotif for Validation 2\n",
      "74 - UnivariateMotif with avg smape 53.63: \n",
      "Model Number: 75 of 84 with model AverageValueNaive for Validation 2\n",
      "75 - AverageValueNaive with avg smape 40.14: \n",
      "Model Number: 76 of 84 with model ARDL for Validation 2\n",
      "76 - ARDL with avg smape 50.5: \n",
      "Model Number: 77 of 84 with model UnobservedComponents for Validation 2\n",
      "77 - UnobservedComponents with avg smape 46.22: \n",
      "Model Number: 78 of 84 with model Theta for Validation 2\n",
      "78 - Theta with avg smape 56.14: \n",
      "Model Number: 79 of 84 with model Theta for Validation 2\n",
      "79 - Theta with avg smape 57.36: \n",
      "Model Number: 80 of 84 with model ARDL for Validation 2\n",
      "80 - ARDL with avg smape 39.54: \n",
      "Model Number: 81 of 84 with model Theta for Validation 2\n",
      "81 - Theta with avg smape 56.98: \n",
      "Model Number: 82 of 84 with model UnivariateMotif for Validation 2\n",
      "82 - UnivariateMotif with avg smape 49.11: \n",
      "Model Number: 83 of 84 with model UnivariateRegression for Validation 2\n",
      "83 - UnivariateRegression with avg smape 40.93: \n",
      "Model Number: 84 of 84 with model UnivariateRegression for Validation 2\n",
      "84 - UnivariateRegression with avg smape 38.98: \n",
      "Validation Round: 3\n",
      "Model Number: 1 of 84 with model DatepartRegression for Validation 3\n",
      "📈 1 - DatepartRegression with avg smape 9.97: \n",
      "Model Number: 2 of 84 with model ARIMA for Validation 3\n",
      "📈 2 - ARIMA with avg smape 7.96: \n",
      "Model Number: 3 of 84 with model DatepartRegression for Validation 3\n",
      "Template Eval Error: Exception('Transformer RegressionFilter failed on fit') in model 3 in generation 0: DatepartRegression\n",
      "Model Number: 4 of 84 with model SeasonalNaive for Validation 3\n",
      "4 - SeasonalNaive with avg smape 12.61: \n",
      "Model Number: 5 of 84 with model MultivariateRegression for Validation 3\n",
      "5 - MultivariateRegression with avg smape 16.07: \n",
      "Model Number: 6 of 84 with model DatepartRegression for Validation 3\n",
      "6 - DatepartRegression with avg smape 18.76: \n",
      "Model Number: 7 of 84 with model DatepartRegression for Validation 3\n",
      "Template Eval Error: Exception('Transformer RegressionFilter failed on fit') in model 7 in generation 0: DatepartRegression\n",
      "Model Number: 8 of 84 with model DatepartRegression for Validation 3\n",
      "Template Eval Error: Exception('Transformer RegressionFilter failed on fit') in model 8 in generation 0: DatepartRegression\n",
      "Model Number: 9 of 84 with model ARIMA for Validation 3\n",
      "9 - ARIMA with avg smape 8.77: \n",
      "Model Number: 10 of 84 with model ARIMA for Validation 3\n",
      "10 - ARIMA with avg smape 8.77: \n",
      "Model Number: 11 of 84 with model SeasonalNaive for Validation 3\n",
      "11 - SeasonalNaive with avg smape 14.74: \n",
      "Model Number: 12 of 84 with model SectionalMotif for Validation 3\n",
      "12 - SectionalMotif with avg smape 21.34: \n",
      "Model Number: 13 of 84 with model ARDL for Validation 3\n",
      "13 - ARDL with avg smape 15.91: \n",
      "Model Number: 14 of 84 with model SectionalMotif for Validation 3\n",
      "14 - SectionalMotif with avg smape 10.94: \n",
      "Model Number: 15 of 84 with model ARIMA for Validation 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\linear_model\\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.9706e-24): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15 - ARIMA with avg smape 72.76: \n",
      "Model Number: 16 of 84 with model MultivariateRegression for Validation 3\n",
      "16 - MultivariateRegression with avg smape 8.94: \n",
      "Model Number: 17 of 84 with model GLS for Validation 3\n",
      "17 - GLS with avg smape 9.02: \n",
      "Model Number: 18 of 84 with model SeasonalNaive for Validation 3\n",
      "Template Eval Error: Exception('Transformer RegressionFilter failed on fit') in model 18 in generation 0: SeasonalNaive\n",
      "Model Number: 19 of 84 with model UnobservedComponents for Validation 3\n",
      "Template Eval Error: Exception('Transformer RegressionFilter failed on fit') in model 19 in generation 0: UnobservedComponents\n",
      "Model Number: 20 of 84 with model MetricMotif for Validation 3\n",
      "Template Eval Error: Exception('Transformer Detrend failed on fit') in model 20 in generation 0: MetricMotif\n",
      "Model Number: 21 of 84 with model MetricMotif for Validation 3\n",
      "Template Eval Error: Exception('Transformer Detrend failed on fit') in model 21 in generation 0: MetricMotif\n",
      "Model Number: 22 of 84 with model SeasonalNaive for Validation 3\n",
      "22 - SeasonalNaive with avg smape 14.21: \n",
      "Model Number: 23 of 84 with model MultivariateRegression for Validation 3\n",
      "23 - MultivariateRegression with avg smape 15.33: \n",
      "Model Number: 24 of 84 with model MetricMotif for Validation 3\n",
      "24 - MetricMotif with avg smape 17.5: \n",
      "Model Number: 25 of 84 with model SeasonalNaive for Validation 3\n",
      "25 - SeasonalNaive with avg smape 14.05: \n",
      "Model Number: 26 of 84 with model GLS for Validation 3\n",
      "26 - GLS with avg smape 19.29: \n",
      "Model Number: 27 of 84 with model MultivariateRegression for Validation 3\n",
      "27 - MultivariateRegression with avg smape 13.04: \n",
      "Model Number: 28 of 84 with model GLS for Validation 3\n",
      "Template Eval Error: Exception('Transformer RegressionFilter failed on fit') in model 28 in generation 0: GLS\n",
      "Model Number: 29 of 84 with model MetricMotif for Validation 3\n",
      "29 - MetricMotif with avg smape 15.05: \n",
      "Model Number: 30 of 84 with model GLS for Validation 3\n",
      "30 - GLS with avg smape 18.68: \n",
      "Model Number: 31 of 84 with model GLS for Validation 3\n",
      "31 - GLS with avg smape 18.68: \n",
      "Model Number: 32 of 84 with model MultivariateRegression for Validation 3\n",
      "32 - MultivariateRegression with avg smape 11.25: \n",
      "Model Number: 33 of 84 with model ETS for Validation 3\n",
      "33 - ETS with avg smape 13.04: \n",
      "Model Number: 34 of 84 with model ETS for Validation 3\n",
      "34 - ETS with avg smape 10.71: \n",
      "Model Number: 35 of 84 with model ETS for Validation 3\n",
      "35 - ETS with avg smape 16.3: \n",
      "Model Number: 36 of 84 with model ETS for Validation 3\n",
      "36 - ETS with avg smape 9.74: \n",
      "Model Number: 37 of 84 with model ETS for Validation 3\n",
      "37 - ETS with avg smape 8.57: \n",
      "Model Number: 38 of 84 with model GLM for Validation 3\n",
      "Template Eval Error: Exception('Transformer RegressionFilter failed on fit') in model 38 in generation 0: GLM\n",
      "Model Number: 39 of 84 with model MultivariateMotif for Validation 3\n",
      "Template Eval Error: ValueError('window shape cannot be larger than input array shape') in model 39 in generation 0: MultivariateMotif\n",
      "Model Number: 40 of 84 with model MetricMotif for Validation 3\n",
      "40 - MetricMotif with avg smape 23.9: \n",
      "Model Number: 41 of 84 with model UnobservedComponents for Validation 3\n",
      "41 - UnobservedComponents with avg smape 10.1: \n",
      "Model Number: 42 of 84 with model UnobservedComponents for Validation 3\n",
      "42 - UnobservedComponents with avg smape 8.52: \n",
      "Model Number: 43 of 84 with model ARIMA for Validation 3\n",
      "43 - ARIMA with avg smape 9.69: \n",
      "Model Number: 44 of 84 with model GLM for Validation 3\n",
      "44 - GLM with avg smape 10.45: \n",
      "Model Number: 45 of 84 with model GLM for Validation 3\n",
      "45 - GLM with avg smape 10.45: \n",
      "Model Number: 46 of 84 with model GLM for Validation 3\n",
      "46 - GLM with avg smape 16.43: \n",
      "Model Number: 47 of 84 with model WindowRegression for Validation 3\n",
      "47 - WindowRegression with avg smape 40.52: \n",
      "Model Number: 48 of 84 with model GLM for Validation 3\n",
      "48 - GLM with avg smape 15.02: \n",
      "Model Number: 49 of 84 with model WindowRegression for Validation 3\n",
      "49 - WindowRegression with avg smape 14.19: \n",
      "Model Number: 50 of 84 with model WindowRegression for Validation 3\n",
      "50 - WindowRegression with avg smape 40.54: \n",
      "Model Number: 51 of 84 with model WindowRegression for Validation 3\n",
      "51 - WindowRegression with avg smape 40.54: \n",
      "Model Number: 52 of 84 with model MultivariateMotif for Validation 3\n",
      "52 - MultivariateMotif with avg smape 12.01: \n",
      "Model Number: 53 of 84 with model SectionalMotif for Validation 3\n",
      "53 - SectionalMotif with avg smape 17.72: \n",
      "Model Number: 54 of 84 with model WindowRegression for Validation 3\n",
      "54 - WindowRegression with avg smape 16.51: \n",
      "Model Number: 55 of 84 with model UnivariateMotif for Validation 3\n",
      "55 - UnivariateMotif with avg smape 16.01: \n",
      "Model Number: 56 of 84 with model SectionalMotif for Validation 3\n",
      "56 - SectionalMotif with avg smape 17.49: \n",
      "Model Number: 57 of 84 with model ARDL for Validation 3\n",
      "57 - ARDL with avg smape 15.44: \n",
      "Model Number: 58 of 84 with model UnobservedComponents for Validation 3\n",
      "58 - UnobservedComponents with avg smape 14.86: \n",
      "Model Number: 59 of 84 with model ARDL for Validation 3\n",
      "Template Eval Error: Exception('Transformer RegressionFilter failed on fit') in model 59 in generation 0: ARDL\n",
      "Model Number: 60 of 84 with model SectionalMotif for Validation 3\n",
      "60 - SectionalMotif with avg smape 12.27: \n",
      "Model Number: 61 of 84 with model UnivariateMotif for Validation 3\n",
      "Template Eval Error: Exception('Transformer RegressionFilter failed on fit') in model 61 in generation 0: UnivariateMotif\n",
      "Model Number: 62 of 84 with model AverageValueNaive for Validation 3\n",
      "62 - AverageValueNaive with avg smape 9.88: \n",
      "Model Number: 63 of 84 with model ConstantNaive for Validation 3\n",
      "Template Eval Error: Exception('Transformer RegressionFilter failed on fit') in model 63 in generation 0: ConstantNaive\n",
      "Model Number: 64 of 84 with model MultivariateMotif for Validation 3\n",
      "Template Eval Error: ValueError('window shape cannot be larger than input array shape') in model 64 in generation 0: MultivariateMotif\n",
      "Model Number: 65 of 84 with model LastValueNaive for Validation 3\n",
      "65 - LastValueNaive with avg smape 11.61: \n",
      "Model Number: 66 of 84 with model MultivariateMotif for Validation 3\n",
      "66 - MultivariateMotif with avg smape 11.94: \n",
      "Model Number: 67 of 84 with model UnivariateMotif for Validation 3\n",
      "Template Eval Error: Exception('Transformer RegressionFilter failed on fit') in model 67 in generation 0: UnivariateMotif\n",
      "Model Number: 68 of 84 with model Theta for Validation 3\n",
      "68 - Theta with avg smape 8.66: \n",
      "Model Number: 69 of 84 with model AverageValueNaive for Validation 3\n",
      "69 - AverageValueNaive with avg smape 11.94: \n",
      "Model Number: 70 of 84 with model Theta for Validation 3\n",
      "70 - Theta with avg smape 11.09: \n",
      "Model Number: 71 of 84 with model MultivariateMotif for Validation 3\n",
      "Template Eval Error: ValueError('window shape cannot be larger than input array shape') in model 71 in generation 0: MultivariateMotif\n",
      "Model Number: 72 of 84 with model AverageValueNaive for Validation 3\n",
      "Template Eval Error: Exception('Transformer RegressionFilter failed on fit') in model 72 in generation 0: AverageValueNaive\n",
      "Model Number: 73 of 84 with model AverageValueNaive for Validation 3\n",
      "Template Eval Error: Exception('Transformer RegressionFilter failed on fit') in model 73 in generation 0: AverageValueNaive\n",
      "Model Number: 74 of 84 with model UnivariateMotif for Validation 3\n",
      "74 - UnivariateMotif with avg smape 14.45: \n",
      "Model Number: 75 of 84 with model AverageValueNaive for Validation 3\n",
      "75 - AverageValueNaive with avg smape 12.81: \n",
      "Model Number: 76 of 84 with model ARDL for Validation 3\n",
      "76 - ARDL with avg smape 8.92: \n",
      "Model Number: 77 of 84 with model UnobservedComponents for Validation 3\n",
      "Template Eval Error: Exception('Transformer RegressionFilter failed on fit') in model 77 in generation 0: UnobservedComponents\n",
      "Model Number: 78 of 84 with model Theta for Validation 3\n",
      "78 - Theta with avg smape 12.8: \n",
      "Model Number: 79 of 84 with model Theta for Validation 3\n",
      "79 - Theta with avg smape 13.23: \n",
      "Model Number: 80 of 84 with model ARDL for Validation 3\n",
      "80 - ARDL with avg smape 14.95: \n",
      "Model Number: 81 of 84 with model Theta for Validation 3\n",
      "81 - Theta with avg smape 13.08: \n",
      "Model Number: 82 of 84 with model UnivariateMotif for Validation 3\n",
      "Template Eval Error: Exception('Transformer RegressionFilter failed on fit') in model 82 in generation 0: UnivariateMotif\n",
      "Model Number: 83 of 84 with model UnivariateRegression for Validation 3\n",
      "83 - UnivariateRegression with avg smape 15.86: \n",
      "Model Number: 84 of 84 with model UnivariateRegression for Validation 3\n",
      "84 - UnivariateRegression with avg smape 15.83: \n",
      "TotalRuntime missing in 5!\n",
      "Validation Round: 1\n",
      "TotalRuntime missing in 0!\n",
      "Validation Round: 2\n",
      "TotalRuntime missing in 0!\n",
      "Validation Round: 3\n",
      "TotalRuntime missing in 0!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\crudek\\AppData\\Local\\Temp\\ipykernel_24392\\2714734623.py:60: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  all_predictions = all_predictions.append(temp_fcasts)\n",
      " 14%|█▍        | 2/14 [04:10<25:43, 128.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 6 cpus for n_jobs.\n",
      "Data frequency is: MS, used frequency is: MS\n",
      "Model Number: 1 with model ARIMA in generation 0 of 3\n",
      "Model Number: 2 with model AverageValueNaive in generation 0 of 3\n",
      "Model Number: 3 with model AverageValueNaive in generation 0 of 3\n",
      "Model Number: 4 with model AverageValueNaive in generation 0 of 3\n",
      "Model Number: 5 with model DatepartRegression in generation 0 of 3\n",
      "Model Number: 6 with model DatepartRegression in generation 0 of 3\n",
      "Model Number: 7 with model DatepartRegression in generation 0 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 8 with model DatepartRegression in generation 0 of 3\n",
      "Template Eval Error: ImportError('Tensorflow not available, install with pip install tensorflow.') in model 8 in generation 0: DatepartRegression\n",
      "Model Number: 9 with model ETS in generation 0 of 3\n",
      "Model Number: 10 with model ETS in generation 0 of 3\n",
      "Model Number: 11 with model GLM in generation 0 of 3\n",
      "Model Number: 12 with model GLM in generation 0 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:541: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 13 with model GLS in generation 0 of 3\n",
      "Model Number: 14 with model GLS in generation 0 of 3\n",
      "Model Number: 15 with model GluonTS in generation 0 of 3\n",
      "Template Eval Error: ImportError('GluonTS installation is incompatible with AutoTS. The numpy version is sometimes the issue, try 1.23.1 {as of 06-2023}') in model 15 in generation 0: GluonTS\n",
      "Model Number: 16 with model GluonTS in generation 0 of 3\n",
      "Template Eval Error: ImportError('GluonTS installation is incompatible with AutoTS. The numpy version is sometimes the issue, try 1.23.1 {as of 06-2023}') in model 16 in generation 0: GluonTS\n",
      "Model Number: 17 with model GluonTS in generation 0 of 3\n",
      "Template Eval Error: ImportError('GluonTS installation is incompatible with AutoTS. The numpy version is sometimes the issue, try 1.23.1 {as of 06-2023}') in model 17 in generation 0: GluonTS\n",
      "Model Number: 18 with model GluonTS in generation 0 of 3\n",
      "Template Eval Error: ImportError('GluonTS installation is incompatible with AutoTS. The numpy version is sometimes the issue, try 1.23.1 {as of 06-2023}') in model 18 in generation 0: GluonTS\n",
      "Model Number: 19 with model GluonTS in generation 0 of 3\n",
      "Template Eval Error: ImportError('GluonTS installation is incompatible with AutoTS. The numpy version is sometimes the issue, try 1.23.1 {as of 06-2023}') in model 19 in generation 0: GluonTS\n",
      "Model Number: 20 with model LastValueNaive in generation 0 of 3\n",
      "Model Number: 21 with model LastValueNaive in generation 0 of 3\n",
      "Model Number: 22 with model LastValueNaive in generation 0 of 3\n",
      "Model Number: 23 with model LastValueNaive in generation 0 of 3\n",
      "Model Number: 24 with model SeasonalNaive in generation 0 of 3\n",
      "Model Number: 25 with model SeasonalNaive in generation 0 of 3\n",
      "Model Number: 26 with model SeasonalNaive in generation 0 of 3\n",
      "Model Number: 27 with model UnobservedComponents in generation 0 of 3\n",
      "Model Number: 28 with model UnobservedComponents in generation 0 of 3\n",
      "Model Number: 29 with model UnobservedComponents in generation 0 of 3\n",
      "Model Number: 30 with model VAR in generation 0 of 3\n",
      "Template Eval Error: ValueError('Only gave one variable to VAR') in model 30 in generation 0: VAR\n",
      "Model Number: 31 with model VAR in generation 0 of 3\n",
      "Template Eval Error: ValueError('Only gave one variable to VAR') in model 31 in generation 0: VAR\n",
      "Model Number: 32 with model VECM in generation 0 of 3\n",
      "Template Eval Error: ValueError('Only gave one variable to VECM') in model 32 in generation 0: VECM\n",
      "Model Number: 33 with model VECM in generation 0 of 3\n",
      "Template Eval Error: ValueError('Only gave one variable to VECM') in model 33 in generation 0: VECM\n",
      "Model Number: 34 with model WindowRegression in generation 0 of 3\n",
      "Model Number: 35 with model ConstantNaive in generation 0 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16:12:30 - cmdstanpy - INFO - Chain [1] start processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 36 with model FBProphet in generation 0 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16:12:30 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 37 with model GluonTS in generation 0 of 3\n",
      "Template Eval Error: ImportError('GluonTS installation is incompatible with AutoTS. The numpy version is sometimes the issue, try 1.23.1 {as of 06-2023}') in model 37 in generation 0: GluonTS\n",
      "Model Number: 38 with model MultivariateRegression in generation 0 of 3\n",
      "Model Number: 39 with model MultivariateRegression in generation 0 of 3\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000027 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Model Number: 40 with model DatepartRegression in generation 0 of 3\n",
      "Model Number: 41 with model SeasonalNaive in generation 0 of 3\n",
      "Model Number: 42 with model DatepartRegression in generation 0 of 3\n",
      "Model Number: 43 with model UnobservedComponents in generation 0 of 3\n",
      "Model Number: 44 with model UnobservedComponents in generation 0 of 3\n",
      "Model Number: 45 with model ETS in generation 0 of 3\n",
      "Model Number: 46 with model VECM in generation 0 of 3\n",
      "Template Eval Error: ValueError('Only gave one variable to VECM') in model 46 in generation 0: VECM\n",
      "Model Number: 47 with model ARDL in generation 0 of 3\n",
      "Model Number: 48 with model MultivariateMotif in generation 0 of 3\n",
      "Model Number: 49 with model MultivariateMotif in generation 0 of 3\n",
      "Model Number: 50 with model UnivariateMotif in generation 0 of 3\n",
      "Template Eval Error: ValueError('kth(=10) out of bounds (1)') in model 50 in generation 0: UnivariateMotif\n",
      "Model Number: 51 with model UnivariateMotif in generation 0 of 3\n",
      "Model Number: 52 with model SectionalMotif in generation 0 of 3\n",
      "Model Number: 53 with model SectionalMotif in generation 0 of 3\n",
      "Model Number: 54 with model MultivariateRegression in generation 0 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16:12:33 - cmdstanpy - INFO - Chain [1] start processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 55 with model FBProphet in generation 0 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16:12:52 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 56 with model SeasonalNaive in generation 0 of 3\n",
      "Model Number: 57 with model DatepartRegression in generation 0 of 3\n",
      "Model Number: 58 with model NVAR in generation 0 of 3\n",
      "Model Number: 59 with model Theta in generation 0 of 3\n",
      "Model Number: 60 with model UnivariateRegression in generation 0 of 3\n",
      "Template Eval Error: ValueError('Input X contains NaN.\\nDecisionTreeRegressor does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values') in model 60 in generation 0: UnivariateRegression\n",
      "Model Number: 61 with model ARCH in generation 0 of 3\n",
      "Template Eval Error: ImportError('`arch` package must be installed from pip') in model 61 in generation 0: ARCH\n",
      "Model Number: 62 with model ConstantNaive in generation 0 of 3\n",
      "Model Number: 63 with model LastValueNaive in generation 0 of 3\n",
      "Model Number: 64 with model AverageValueNaive in generation 0 of 3\n",
      "Model Number: 65 with model GLS in generation 0 of 3\n",
      "Model Number: 66 with model SeasonalNaive in generation 0 of 3\n",
      "Model Number: 67 with model GLM in generation 0 of 3\n",
      "Template Eval Error: Exception('Transformer LocalLinearTrend failed on fit') in model 67 in generation 0: GLM\n",
      "Model Number: 68 with model ETS in generation 0 of 3\n",
      "Model Number: 69 with model FBProphet in generation 0 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16:12:52 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:12:53 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:12:53 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:12:54 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 70 with model GluonTS in generation 0 of 3\n",
      "Template Eval Error: ImportError('GluonTS installation is incompatible with AutoTS. The numpy version is sometimes the issue, try 1.23.1 {as of 06-2023}') in model 70 in generation 0: GluonTS\n",
      "Model Number: 71 with model UnobservedComponents in generation 0 of 3\n",
      "Model Number: 72 with model VAR in generation 0 of 3\n",
      "Template Eval Error: ValueError('Only gave one variable to VAR') in model 72 in generation 0: VAR\n",
      "Model Number: 73 with model VECM in generation 0 of 3\n",
      "Template Eval Error: ValueError('Only gave one variable to VECM') in model 73 in generation 0: VECM\n",
      "Model Number: 74 with model ARIMA in generation 0 of 3\n",
      "Model Number: 75 with model WindowRegression in generation 0 of 3\n",
      "Template Eval Error: ImportError('Tensorflow not available, install with pip install tensorflow.') in model 75 in generation 0: WindowRegression\n",
      "Model Number: 76 with model DatepartRegression in generation 0 of 3\n",
      "Template Eval Error: ImportError('Tensorflow not available, install with pip install tensorflow.') in model 76 in generation 0: DatepartRegression\n",
      "Model Number: 77 with model UnivariateRegression in generation 0 of 3\n",
      "Model Number: 78 with model MultivariateRegression in generation 0 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\linear_model\\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.48343e-24): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 79 with model UnivariateMotif in generation 0 of 3\n",
      "Model Number: 80 with model MultivariateMotif in generation 0 of 3\n",
      "Model Number: 81 with model SectionalMotif in generation 0 of 3\n",
      "Model Number: 82 with model NVAR in generation 0 of 3\n",
      "Model Number: 83 with model Theta in generation 0 of 3\n",
      "Model Number: 84 with model ARDL in generation 0 of 3\n",
      "Model Number: 85 with model ARCH in generation 0 of 3\n",
      "Template Eval Error: ImportError('`arch` package must be installed from pip') in model 85 in generation 0: ARCH\n",
      "Model Number: 86 with model MetricMotif in generation 0 of 3\n",
      "Template Eval Error: ValueError('kth(=99) out of bounds (63)') in model 86 in generation 0: MetricMotif\n",
      "Model Number: 87 with model NVAR in generation 0 of 3\n",
      "Model Number: 88 with model GLS in generation 0 of 3\n",
      "Model Number: 89 with model GLM in generation 0 of 3\n",
      "Model Number: 90 with model AverageValueNaive in generation 0 of 3\n",
      "Model Number: 91 with model ARCH in generation 0 of 3\n",
      "Template Eval Error: ImportError('`arch` package must be installed from pip') in model 91 in generation 0: ARCH\n",
      "Model Number: 92 with model VECM in generation 0 of 3\n",
      "Template Eval Error: ValueError('Only gave one variable to VECM') in model 92 in generation 0: VECM\n",
      "Model Number: 93 with model AverageValueNaive in generation 0 of 3\n",
      "Model Number: 94 with model UnivariateMotif in generation 0 of 3\n",
      "Template Eval Error: Exception('Transformer AlignLastValue failed on inverse') in model 94 in generation 0: UnivariateMotif\n",
      "Model Number: 95 with model NVAR in generation 0 of 3\n",
      "Model Number: 96 with model WindowRegression in generation 0 of 3\n",
      "Template Eval Error: Exception('Transformer AlignLastValue failed on inverse') in model 96 in generation 0: WindowRegression\n",
      "Model Number: 97 with model VECM in generation 0 of 3\n",
      "Template Eval Error: ValueError('Only gave one variable to VECM') in model 97 in generation 0: VECM\n",
      "Model Number: 98 with model Theta in generation 0 of 3\n",
      "Model Number: 99 with model GluonTS in generation 0 of 3\n",
      "Template Eval Error: ImportError('GluonTS installation is incompatible with AutoTS. The numpy version is sometimes the issue, try 1.23.1 {as of 06-2023}') in model 99 in generation 0: GluonTS\n",
      "Model Number: 100 with model DatepartRegression in generation 0 of 3\n",
      "Model Number: 101 with model ARDL in generation 0 of 3\n",
      "Model Number: 102 with model WindowRegression in generation 0 of 3\n",
      "Model Number: 103 with model ETS in generation 0 of 3\n",
      "Model Number: 104 with model GLM in generation 0 of 3\n",
      "Template Eval Error: ValueError('NaN, inf or invalid value detected in weights, estimation infeasible.') in model 104 in generation 0: GLM\n",
      "Model Number: 105 with model VECM in generation 0 of 3\n",
      "Template Eval Error: ValueError('Only gave one variable to VECM') in model 105 in generation 0: VECM\n",
      "Model Number: 106 with model ETS in generation 0 of 3\n",
      "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
      "ETS failed on NET_SALES with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
      "Model Number: 107 with model DatepartRegression in generation 0 of 3\n",
      "Model Number: 108 with model UnobservedComponents in generation 0 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\statsmodels\\genmod\\families\\family.py:1367: ValueWarning: Negative binomial dispersion parameter alpha not set. Using default value alpha=1.0.\n",
      "  warnings.warn(\"Negative binomial dispersion parameter alpha not \"\n",
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\statsmodels\\genmod\\families\\links.py:527: RuntimeWarning: overflow encountered in exp\n",
      "  return np.exp(z)\n",
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\statsmodels\\genmod\\families\\family.py:1402: RuntimeWarning: divide by zero encountered in divide\n",
      "  endog_mu = self._clean(endog / mu)\n",
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\statsmodels\\genmod\\families\\family.py:1406: RuntimeWarning: divide by zero encountered in log\n",
      "  resid_dev -= endog_alpha * np.log(endog_alpha / mu_alpha)\n",
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\statsmodels\\genmod\\families\\family.py:1406: RuntimeWarning: invalid value encountered in log\n",
      "  resid_dev -= endog_alpha * np.log(endog_alpha / mu_alpha)\n",
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\statsmodels\\genmod\\families\\family.py:143: RuntimeWarning: invalid value encountered in multiply\n",
      "  return 1. / (self.link.deriv(mu)**2 * self.variance(mu))\n",
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\statsmodels\\genmod\\generalized_linear_model.py:1243: RuntimeWarning: invalid value encountered in multiply\n",
      "  wlsendog = (lin_pred + self.family.link.deriv(mu) * (self.endog-mu)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 109 with model ARDL in generation 0 of 3\n",
      "Model Number: 110 with model SeasonalNaive in generation 0 of 3\n",
      "Model Number: 111 with model ETS in generation 0 of 3\n",
      "ETS error ValueError('Cannot compute initial seasonals using heuristic method with less than two full seasonal cycles in the data.')\n",
      "ETS failed on NET_SALES with ValueError('Cannot compute initial seasonals using heuristic method with less than two full seasonal cycles in the data.')\n",
      "Model Number: 112 with model ConstantNaive in generation 0 of 3\n",
      "Model Number: 113 with model LastValueNaive in generation 0 of 3\n",
      "Model Number: 114 with model ARDL in generation 0 of 3\n",
      "Model Number: 115 with model UnivariateMotif in generation 0 of 3\n",
      "Model Number: 116 with model GLS in generation 0 of 3\n",
      "Model Number: 117 with model SeasonalNaive in generation 0 of 3\n",
      "Model Number: 118 with model Theta in generation 0 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\linear_model\\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.48343e-24): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 119 with model LastValueNaive in generation 0 of 3\n",
      "Template Eval Error: Exception('Transformer AlignLastValue failed on inverse') in model 119 in generation 0: LastValueNaive\n",
      "Model Number: 120 with model MetricMotif in generation 0 of 3\n",
      "Template Eval Error: ValueError('kth(=99) out of bounds (53)') in model 120 in generation 0: MetricMotif\n",
      "Model Number: 121 with model FBProphet in generation 0 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16:13:02 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:13:02 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 122 with model ETS in generation 0 of 3\n",
      "Model Number: 123 with model UnivariateMotif in generation 0 of 3\n",
      "Template Eval Error: ValueError('kth(=100) out of bounds (51)') in model 123 in generation 0: UnivariateMotif\n",
      "Model Number: 124 with model ConstantNaive in generation 0 of 3\n",
      "Model Number: 125 with model LastValueNaive in generation 0 of 3\n",
      "Model Number: 126 with model GLS in generation 0 of 3\n",
      "Model Number: 127 with model UnobservedComponents in generation 0 of 3\n",
      "Model Number: 128 with model UnivariateMotif in generation 0 of 3\n",
      "Model Number: 129 with model GLS in generation 0 of 3\n",
      "Model Number: 130 with model MetricMotif in generation 0 of 3\n",
      "Model Number: 131 with model Theta in generation 0 of 3\n",
      "Model Number: 132 with model UnobservedComponents in generation 0 of 3\n",
      "Model Number: 133 with model ARIMA in generation 0 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\autots\\tools\\thresholding.py:204: RuntimeWarning: overflow encountered in double_scalars\n",
      "  (1 + mean_perc_decrease) ** self.mean_weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 134 with model SeasonalNaive in generation 0 of 3\n",
      "Model Number: 135 with model LastValueNaive in generation 0 of 3\n",
      "Model Number: 136 with model LastValueNaive in generation 0 of 3\n",
      "Model Number: 137 with model ARCH in generation 0 of 3\n",
      "Template Eval Error: ImportError('`arch` package must be installed from pip') in model 137 in generation 0: ARCH\n",
      "Model Number: 138 with model VAR in generation 0 of 3\n",
      "Template Eval Error: ValueError('Only gave one variable to VAR') in model 138 in generation 0: VAR\n",
      "Model Number: 139 with model ETS in generation 0 of 3\n",
      "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
      "ETS failed on NET_SALES with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
      "Model Number: 140 with model MultivariateMotif in generation 0 of 3\n",
      "Model Number: 141 with model DatepartRegression in generation 0 of 3\n",
      "Model Number: 142 with model ARIMA in generation 0 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.107e+13, tolerance: 5.580e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.647e+13, tolerance: 3.631e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Template Eval Error: Exception('Transformer AlignLastValue failed on inverse') in model 142 in generation 0: ARIMA\n",
      "Model Number: 143 with model GLM in generation 0 of 3\n",
      "Template Eval Error: ValueError('NaN, inf or invalid value detected in weights, estimation infeasible.') in model 143 in generation 0: GLM\n",
      "Model Number: 144 with model DatepartRegression in generation 0 of 3\n",
      "Template Eval Error: ValueError('Input X contains NaN.\\nExtraTreesRegressor does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values') in model 144 in generation 0: DatepartRegression\n",
      "Model Number: 145 with model VAR in generation 0 of 3\n",
      "Template Eval Error: ValueError('Only gave one variable to VAR') in model 145 in generation 0: VAR\n",
      "Model Number: 146 with model Theta in generation 0 of 3\n",
      "Model Number: 147 with model ETS in generation 0 of 3\n",
      "ETS error ValueError('Cannot compute initial seasonals using heuristic method with less than two full seasonal cycles in the data.')\n",
      "ETS failed on NET_SALES with ValueError('Cannot compute initial seasonals using heuristic method with less than two full seasonal cycles in the data.')\n",
      "Model Number: 148 with model ConstantNaive in generation 0 of 3\n",
      "Model Number: 149 with model ARDL in generation 0 of 3\n",
      "Model Number: 150 with model SectionalMotif in generation 0 of 3\n",
      "Model Number: 151 with model VAR in generation 0 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\statsmodels\\genmod\\families\\links.py:527: RuntimeWarning: overflow encountered in exp\n",
      "  return np.exp(z)\n",
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\statsmodels\\genmod\\families\\family.py:445: RuntimeWarning: divide by zero encountered in divide\n",
      "  endog_mu = self._clean(endog / mu)\n",
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\statsmodels\\genmod\\families\\family.py:143: RuntimeWarning: invalid value encountered in multiply\n",
      "  return 1. / (self.link.deriv(mu)**2 * self.variance(mu))\n",
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\statsmodels\\genmod\\families\\family.py:143: RuntimeWarning: divide by zero encountered in divide\n",
      "  return 1. / (self.link.deriv(mu)**2 * self.variance(mu))\n",
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\statsmodels\\genmod\\generalized_linear_model.py:1243: RuntimeWarning: invalid value encountered in multiply\n",
      "  wlsendog = (lin_pred + self.family.link.deriv(mu) * (self.endog-mu)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 152 with model DatepartRegression in generation 0 of 3\n",
      "Model Number: 153 with model Theta in generation 0 of 3\n",
      "Model Number: 154 with model MetricMotif in generation 0 of 3\n",
      "Model Number: 155 with model DatepartRegression in generation 0 of 3\n",
      "Model Number: 156 with model GLM in generation 0 of 3\n",
      "Model Number: 157 with model GluonTS in generation 0 of 3\n",
      "Template Eval Error: ImportError('GluonTS installation is incompatible with AutoTS. The numpy version is sometimes the issue, try 1.23.1 {as of 06-2023}') in model 157 in generation 0: GluonTS\n",
      "Model Number: 158 with model DatepartRegression in generation 0 of 3\n",
      "Template Eval Error: Exception('Transformer AlignLastValue failed on inverse') in model 158 in generation 0: DatepartRegression\n",
      "Model Number: 159 with model NVAR in generation 0 of 3\n",
      "Model Number: 160 with model GLS in generation 0 of 3\n",
      "Model Number: 161 with model SectionalMotif in generation 0 of 3\n",
      "Model Number: 162 with model FBProphet in generation 0 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\statsmodels\\genmod\\families\\links.py:198: RuntimeWarning: overflow encountered in exp\n",
      "  t = np.exp(-z)\n",
      "16:13:04 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:13:05 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 163 with model ETS in generation 0 of 3\n",
      "Model Number: 164 with model VAR in generation 0 of 3\n",
      "Template Eval Error: ValueError('Only gave one variable to VAR') in model 164 in generation 0: VAR\n",
      "Model Number: 165 with model MultivariateMotif in generation 0 of 3\n",
      "Model Number: 166 with model VAR in generation 0 of 3\n",
      "Template Eval Error: ValueError('Only gave one variable to VAR') in model 166 in generation 0: VAR\n",
      "Model Number: 167 with model ARIMA in generation 0 of 3\n",
      "Model Number: 168 with model UnobservedComponents in generation 0 of 3\n",
      "Model Number: 169 with model UnivariateMotif in generation 0 of 3\n",
      "Template Eval Error: ValueError('kth(=100) out of bounds (51)') in model 169 in generation 0: UnivariateMotif\n",
      "Model Number: 170 with model VAR in generation 0 of 3\n",
      "Template Eval Error: ValueError('Only gave one variable to VAR') in model 170 in generation 0: VAR\n",
      "Model Number: 171 with model Theta in generation 0 of 3\n",
      "Model Number: 172 with model MultivariateMotif in generation 0 of 3\n",
      "Model Number: 173 with model UnobservedComponents in generation 0 of 3\n",
      "Model Number: 174 with model WindowRegression in generation 0 of 3\n",
      "Model Number: 175 with model SeasonalNaive in generation 0 of 3\n",
      "Model Number: 176 with model ARDL in generation 0 of 3\n",
      "Model Number: 177 with model GLS in generation 0 of 3\n",
      "Model Number: 178 with model SectionalMotif in generation 0 of 3\n",
      "Model Number: 179 with model ARDL in generation 0 of 3\n",
      "Model Number: 180 with model MultivariateMotif in generation 0 of 3\n",
      "Model Number: 181 with model ARCH in generation 0 of 3\n",
      "Template Eval Error: ImportError('`arch` package must be installed from pip') in model 181 in generation 0: ARCH\n",
      "Model Number: 182 with model SectionalMotif in generation 0 of 3\n",
      "Model Number: 183 with model ARIMA in generation 0 of 3\n",
      "Model Number: 184 with model DatepartRegression in generation 0 of 3\n",
      "Model Number: 185 with model ETS in generation 0 of 3\n",
      "ETS error ValueError('Cannot compute initial seasonals using heuristic method with less than two full seasonal cycles in the data.')\n",
      "ETS failed on NET_SALES with ValueError('Cannot compute initial seasonals using heuristic method with less than two full seasonal cycles in the data.')\n",
      "Model Number: 186 with model VECM in generation 0 of 3\n",
      "Template Eval Error: ValueError('Only gave one variable to VECM') in model 186 in generation 0: VECM\n",
      "New Generation: 1 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.105e-01, tolerance: 7.008e-04\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 187 with model Theta in generation 1 of 3\n",
      "Model Number: 188 with model ARIMA in generation 1 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16:13:09 - cmdstanpy - INFO - Chain [1] start processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 189 with model FBProphet in generation 1 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16:13:09 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 190 with model ARDL in generation 1 of 3\n",
      "Template Eval Error: ValueError(\"ARDL series NET_SALES failed with error IndexError('tuple index out of range') exog train None and predict                    MONTH  COVID  AMZN\\nMONTH                                \\n2022-01-01  1.640995e+18    0.0   0.0\\n2022-02-01  1.643674e+18    0.0   0.0\\n2022-03-01  1.646093e+18    0.0   0.0\\n2022-04-01  1.648771e+18    0.0   0.0\\n2022-05-01  1.651363e+18    0.0   0.0\\n2022-06-01  1.654042e+18    0.0   0.0\\n2022-07-01  1.656634e+18    0.0   0.0\\n2022-08-01  1.659312e+18    0.0   0.0\\n2022-09-01  1.661990e+18    0.0   0.0\\n2022-10-01  1.664582e+18    0.0   0.0\\n2022-11-01  1.667261e+18    0.0   0.0\\n2022-12-01  1.669853e+18    0.0   0.0\") in model 190 in generation 1: ARDL\n",
      "Model Number: 191 with model GLM in generation 1 of 3\n",
      "Model Number: 192 with model SeasonalNaive in generation 1 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\autots\\tools\\probabilistic.py:67: RuntimeWarning: invalid value encountered in divide\n",
      "  (prior_mu / prior_sigma**2) + ((n * data_mu) / prior_sigma**2)\n",
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\autots\\tools\\probabilistic.py:68: RuntimeWarning: divide by zero encountered in divide\n",
      "  ) / ((1 / prior_sigma**2) + (n / prior_sigma**2))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 193 with model ETS in generation 1 of 3\n",
      "Template Eval Error: Exception('Transformer Cointegration failed on fit') in model 193 in generation 1: ETS\n",
      "Model Number: 194 with model ARIMA in generation 1 of 3\n",
      "Model Number: 195 with model DatepartRegression in generation 1 of 3\n",
      "Model Number: 196 with model NVAR in generation 1 of 3\n",
      "Model Number: 197 with model MultivariateMotif in generation 1 of 3\n",
      "Model Number: 198 with model ETS in generation 1 of 3\n",
      "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
      "ETS failed on NET_SALES with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
      "Model Number: 199 with model SeasonalNaive in generation 1 of 3\n",
      "Model Number: 200 with model SectionalMotif in generation 1 of 3\n",
      "Model Number: 201 with model NVAR in generation 1 of 3\n",
      "Model Number: 202 with model DatepartRegression in generation 1 of 3\n",
      "Template Eval Error: Exception('Transformer BTCD failed on fit') in model 202 in generation 1: DatepartRegression\n",
      "Model Number: 203 with model GLS in generation 1 of 3\n",
      "Model Number: 204 with model MultivariateRegression in generation 1 of 3\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000034 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Model Number: 205 with model AverageValueNaive in generation 1 of 3\n",
      "Model Number: 206 with model WindowRegression in generation 1 of 3\n",
      "Model Number: 207 with model GLS in generation 1 of 3\n",
      "Model Number: 208 with model MultivariateMotif in generation 1 of 3\n",
      "Model Number: 209 with model SeasonalNaive in generation 1 of 3\n",
      "Template Eval Error: Exception('Transformer AlignLastValue failed on inverse') in model 209 in generation 1: SeasonalNaive\n",
      "Model Number: 210 with model UnobservedComponents in generation 1 of 3\n",
      "Model Number: 211 with model ARIMA in generation 1 of 3\n",
      "Model Number: 212 with model SeasonalNaive in generation 1 of 3\n",
      "Model Number: 213 with model MultivariateRegression in generation 1 of 3\n",
      "Model Number: 214 with model ARDL in generation 1 of 3\n",
      "Model Number: 215 with model WindowRegression in generation 1 of 3\n",
      "Model Number: 216 with model GLS in generation 1 of 3\n",
      "Model Number: 217 with model SectionalMotif in generation 1 of 3\n",
      "Model Number: 218 with model SeasonalNaive in generation 1 of 3\n",
      "Model Number: 219 with model FBProphet in generation 1 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (250) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "16:13:14 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:13:14 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 220 with model NVAR in generation 1 of 3\n",
      "Model Number: 221 with model SeasonalNaive in generation 1 of 3\n",
      "Model Number: 222 with model DatepartRegression in generation 1 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\autots\\tools\\probabilistic.py:67: RuntimeWarning: invalid value encountered in divide\n",
      "  (prior_mu / prior_sigma**2) + ((n * data_mu) / prior_sigma**2)\n",
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\autots\\tools\\probabilistic.py:68: RuntimeWarning: divide by zero encountered in divide\n",
      "  ) / ((1 / prior_sigma**2) + (n / prior_sigma**2))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 223 with model MultivariateRegression in generation 1 of 3\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000023 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Model Number: 224 with model NVAR in generation 1 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16:13:15 - cmdstanpy - INFO - Chain [1] start processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 225 with model FBProphet in generation 1 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16:13:15 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 226 with model NVAR in generation 1 of 3\n",
      "Model Number: 227 with model GLS in generation 1 of 3\n",
      "Model Number: 228 with model UnobservedComponents in generation 1 of 3\n",
      "Model Number: 229 with model SectionalMotif in generation 1 of 3\n",
      "Model Number: 230 with model AverageValueNaive in generation 1 of 3\n",
      "Template Eval Error: Exception('Transformer BTCD failed on fit') in model 230 in generation 1: AverageValueNaive\n",
      "Model Number: 231 with model SectionalMotif in generation 1 of 3\n",
      "Template Eval Error: ValueError('kth(=100) out of bounds (51)') in model 231 in generation 1: SectionalMotif\n",
      "Model Number: 232 with model LastValueNaive in generation 1 of 3\n",
      "Model Number: 233 with model SeasonalNaive in generation 1 of 3\n",
      "Model Number: 234 with model SeasonalNaive in generation 1 of 3\n",
      "Model Number: 235 with model SectionalMotif in generation 1 of 3\n",
      "Model Number: 236 with model MultivariateMotif in generation 1 of 3\n",
      "Template Eval Error: ValueError('kth(=10) out of bounds (1)') in model 236 in generation 1: MultivariateMotif\n",
      "Model Number: 237 with model GLM in generation 1 of 3\n",
      "Template Eval Error: Exception('Transformer BTCD failed on fit') in model 237 in generation 1: GLM\n",
      "Model Number: 238 with model ETS in generation 1 of 3\n",
      "Model Number: 239 with model AverageValueNaive in generation 1 of 3\n",
      "Model Number: 240 with model VAR in generation 1 of 3\n",
      "Template Eval Error: ValueError('Only gave one variable to VAR') in model 240 in generation 1: VAR\n",
      "Model Number: 241 with model ARIMA in generation 1 of 3\n",
      "Model Number: 242 with model SeasonalNaive in generation 1 of 3\n",
      "Model Number: 243 with model LastValueNaive in generation 1 of 3\n",
      "Model Number: 244 with model MultivariateMotif in generation 1 of 3\n",
      "Model Number: 245 with model ETS in generation 1 of 3\n",
      "Model Number: 246 with model WindowRegression in generation 1 of 3\n",
      "Model Number: 247 with model Theta in generation 1 of 3\n",
      "Model Number: 248 with model ETS in generation 1 of 3\n",
      "Model Number: 249 with model ETS in generation 1 of 3\n",
      "Model Number: 250 with model GLS in generation 1 of 3\n",
      "Model Number: 251 with model FBProphet in generation 1 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16:13:19 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:13:19 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 252 with model LastValueNaive in generation 1 of 3\n",
      "Model Number: 253 with model SectionalMotif in generation 1 of 3\n",
      "Model Number: 254 with model UnivariateMotif in generation 1 of 3\n",
      "Template Eval Error: Exception('Transformer Detrend failed on fit') in model 254 in generation 1: UnivariateMotif\n",
      "Model Number: 255 with model ARDL in generation 1 of 3\n",
      "Model Number: 256 with model ETS in generation 1 of 3\n",
      "ETS error ValueError('Can only dampen the trend component')\n",
      "ETS failed on NET_SALES with ValueError('Can only dampen the trend component')\n",
      "Model Number: 257 with model MetricMotif in generation 1 of 3\n",
      "Model Number: 258 with model MetricMotif in generation 1 of 3\n",
      "Model Number: 259 with model SectionalMotif in generation 1 of 3\n",
      "Model Number: 260 with model AverageValueNaive in generation 1 of 3\n",
      "Model Number: 261 with model DatepartRegression in generation 1 of 3\n",
      "Model Number: 262 with model UnivariateMotif in generation 1 of 3\n",
      "Model Number: 263 with model DatepartRegression in generation 1 of 3\n",
      "Model Number: 264 with model UnivariateMotif in generation 1 of 3\n",
      "Model Number: 265 with model SectionalMotif in generation 1 of 3\n",
      "Model Number: 266 with model LastValueNaive in generation 1 of 3\n",
      "Model Number: 267 with model ARIMA in generation 1 of 3\n",
      "Model Number: 268 with model MetricMotif in generation 1 of 3\n",
      "Model Number: 269 with model ARDL in generation 1 of 3\n",
      "Model Number: 270 with model ConstantNaive in generation 1 of 3\n",
      "Model Number: 271 with model Theta in generation 1 of 3\n",
      "Model Number: 272 with model GLS in generation 1 of 3\n",
      "Model Number: 273 with model MultivariateRegression in generation 1 of 3\n",
      "Model Number: 274 with model ARIMA in generation 1 of 3\n",
      "Model Number: 275 with model UnobservedComponents in generation 1 of 3\n",
      "Model Number: 276 with model MultivariateRegression in generation 1 of 3\n",
      "Model Number: 277 with model ARDL in generation 1 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\autots\\tools\\thresholding.py:204: RuntimeWarning: overflow encountered in double_scalars\n",
      "  (1 + mean_perc_decrease) ** self.mean_weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 278 with model ARDL in generation 1 of 3\n",
      "Model Number: 279 with model AverageValueNaive in generation 1 of 3\n",
      "Model Number: 280 with model UnobservedComponents in generation 1 of 3\n",
      "Model Number: 281 with model SectionalMotif in generation 1 of 3\n",
      "Model Number: 282 with model DatepartRegression in generation 1 of 3\n",
      "Model Number: 283 with model ConstantNaive in generation 1 of 3\n",
      "Model Number: 284 with model LastValueNaive in generation 1 of 3\n",
      "Model Number: 285 with model MetricMotif in generation 1 of 3\n",
      "Model Number: 286 with model GLM in generation 1 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\autots\\tools\\probabilistic.py:67: RuntimeWarning: invalid value encountered in divide\n",
      "  (prior_mu / prior_sigma**2) + ((n * data_mu) / prior_sigma**2)\n",
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\autots\\tools\\probabilistic.py:68: RuntimeWarning: divide by zero encountered in divide\n",
      "  ) / ((1 / prior_sigma**2) + (n / prior_sigma**2))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 287 with model SectionalMotif in generation 1 of 3\n",
      "Template Eval Error: ValueError('kth(=10) out of bounds (10)') in model 287 in generation 1: SectionalMotif\n",
      "Model Number: 288 with model UnivariateMotif in generation 1 of 3\n",
      "Model Number: 289 with model UnobservedComponents in generation 1 of 3\n",
      "Model Number: 290 with model DatepartRegression in generation 1 of 3\n",
      "Model Number: 291 with model GLS in generation 1 of 3\n",
      "Model Number: 292 with model MultivariateRegression in generation 1 of 3\n",
      "Model Number: 293 with model WindowRegression in generation 1 of 3\n",
      "Model Number: 294 with model GLM in generation 1 of 3\n",
      "Template Eval Error: ValueError('NaN, inf or invalid value detected in weights, estimation infeasible.') in model 294 in generation 1: GLM\n",
      "Model Number: 295 with model UnobservedComponents in generation 1 of 3\n",
      "Model Number: 296 with model ARDL in generation 1 of 3\n",
      "Model Number: 297 with model ARIMA in generation 1 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\statsmodels\\genmod\\families\\family.py:445: RuntimeWarning: divide by zero encountered in divide\n",
      "  endog_mu = self._clean(endog / mu)\n",
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\statsmodels\\genmod\\families\\family.py:143: RuntimeWarning: divide by zero encountered in divide\n",
      "  return 1. / (self.link.deriv(mu)**2 * self.variance(mu))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 298 with model ARDL in generation 1 of 3\n",
      "Template Eval Error: ValueError(\"ARDL series NET_SALES failed with error ValueError('The number of regressors (1104) including deterministics, lags of the endog, lags of the exogenous, and fixed regressors is larger than the sample available for estimation (69).') exog train             dp0  dp1        dp2  dp3  dp4  dp5  dp6  dp7  dp8  dp9  ...  \\\\\\nMONTH                                                               ...   \\n2016-01-01  1.0  0.0  2457388.5  1.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   \\n2016-02-01  1.0  0.0  2457419.5  0.0  1.0  0.0  0.0  0.0  0.0  0.0  ...   \\n2016-03-01  1.0  0.0  2457448.5  0.0  0.0  1.0  0.0  0.0  0.0  0.0  ...   \\n2016-04-01  1.0  0.0  2457479.5  0.0  0.0  0.0  1.0  0.0  0.0  0.0  ...   \\n2016-05-01  1.0  1.0  2457509.5  0.0  0.0  0.0  0.0  1.0  0.0  0.0  ...   \\n...         ...  ...        ...  ...  ...  ...  ...  ...  ...  ...  ...   \\n2021-08-01  1.0  1.0  2459427.5  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   \\n2021-09-01  1.0  0.0  2459458.5  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   \\n2021-10-01  1.0  0.0  2459488.5  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   \\n2021-11-01  1.0  0.0  2459519.5  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   \\n2021-12-01  1.0  0.0  2459549.5  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   \\n\\n            dp265  dp266  dp267  dp268  dp269  dp270  dp271  dp272  dp273  \\\\\\nMONTH                                                                       \\n2016-01-01    0.0    0.0    0.0    0.0    1.0    0.0    0.0    0.0    0.0   \\n2016-02-01    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \\n2016-03-01    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \\n2016-04-01    0.0    0.0    0.0    0.0    1.0    0.0    0.0    0.0    0.0   \\n2016-05-01    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \\n...           ...    ...    ...    ...    ...    ...    ...    ...    ...   \\n2021-08-01    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \\n2021-09-01    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \\n2021-10-01    0.0    0.0    0.0    0.0    1.0    0.0    0.0    0.0    0.0   \\n2021-11-01    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \\n2021-12-01    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \\n\\n            dp274  \\nMONTH              \\n2016-01-01    0.0  \\n2016-02-01    0.0  \\n2016-03-01    0.0  \\n2016-04-01    0.0  \\n2016-05-01    1.0  \\n...           ...  \\n2021-08-01    1.0  \\n2021-09-01    0.0  \\n2021-10-01    0.0  \\n2021-11-01    0.0  \\n2021-12-01    0.0  \\n\\n[72 rows x 275 columns] and predict             dp0  dp1        dp2  dp3  dp4  dp5  dp6  dp7  dp8  dp9  ...  \\\\\\n2022-01-01  1.0  1.0  2459580.5  1.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   \\n2022-02-01  1.0  0.0  2459611.5  0.0  1.0  0.0  0.0  0.0  0.0  0.0  ...   \\n2022-03-01  1.0  0.0  2459639.5  0.0  0.0  1.0  0.0  0.0  0.0  0.0  ...   \\n2022-04-01  1.0  0.0  2459670.5  0.0  0.0  0.0  1.0  0.0  0.0  0.0  ...   \\n2022-05-01  1.0  1.0  2459700.5  0.0  0.0  0.0  0.0  1.0  0.0  0.0  ...   \\n2022-06-01  1.0  0.0  2459731.5  0.0  0.0  0.0  0.0  0.0  1.0  0.0  ...   \\n2022-07-01  1.0  0.0  2459761.5  0.0  0.0  0.0  0.0  0.0  0.0  1.0  ...   \\n2022-08-01  1.0  0.0  2459792.5  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   \\n2022-09-01  1.0  0.0  2459823.5  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   \\n2022-10-01  1.0  1.0  2459853.5  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   \\n2022-11-01  1.0  0.0  2459884.5  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   \\n2022-12-01  1.0  0.0  2459914.5  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   \\n\\n            dp265  dp266  dp267  dp268  dp269  dp270  dp271  dp272  dp273  \\\\\\n2022-01-01    0.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0   \\n2022-02-01    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \\n2022-03-01    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \\n2022-04-01    0.0    0.0    0.0    0.0    1.0    0.0    0.0    0.0    0.0   \\n2022-05-01    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \\n2022-06-01    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \\n2022-07-01    0.0    0.0    0.0    0.0    1.0    0.0    0.0    0.0    0.0   \\n2022-08-01    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \\n2022-09-01    1.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \\n2022-10-01    0.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0   \\n2022-11-01    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \\n2022-12-01    1.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \\n\\n            dp274  \\n2022-01-01    0.0  \\n2022-02-01    0.0  \\n2022-03-01    0.0  \\n2022-04-01    0.0  \\n2022-05-01    1.0  \\n2022-06-01    0.0  \\n2022-07-01    0.0  \\n2022-08-01    0.0  \\n2022-09-01    0.0  \\n2022-10-01    0.0  \\n2022-11-01    0.0  \\n2022-12-01    0.0  \\n\\n[12 rows x 275 columns]\") in model 298 in generation 1: ARDL\n",
      "Model Number: 299 with model GLS in generation 1 of 3\n",
      "Model Number: 300 with model MultivariateMotif in generation 1 of 3\n",
      "Model Number: 301 with model AverageValueNaive in generation 1 of 3\n",
      "Model Number: 302 with model UnobservedComponents in generation 1 of 3\n",
      "Model Number: 303 with model DatepartRegression in generation 1 of 3\n",
      "Model Number: 304 with model AverageValueNaive in generation 1 of 3\n",
      "Model Number: 305 with model Theta in generation 1 of 3\n",
      "Model Number: 306 with model SectionalMotif in generation 1 of 3\n",
      "Model Number: 307 with model GLS in generation 1 of 3\n",
      "Model Number: 308 with model MultivariateMotif in generation 1 of 3\n",
      "Model Number: 309 with model SectionalMotif in generation 1 of 3\n",
      "Model Number: 310 with model UnivariateRegression in generation 1 of 3\n",
      "Model Number: 311 with model NVAR in generation 1 of 3\n",
      "New Generation: 2 of 3\n",
      "Model Number: 312 with model ARIMA in generation 2 of 3\n",
      "Model Number: 313 with model ETS in generation 2 of 3\n",
      "ETS error ValueError('Can only dampen the trend component')\n",
      "ETS failed on NET_SALES with ValueError('Can only dampen the trend component')\n",
      "Model Number: 314 with model UnobservedComponents in generation 2 of 3\n",
      "Model Number: 315 with model SectionalMotif in generation 2 of 3\n",
      "Template Eval Error: ValueError('Unknown Distance Metric: kulsinski') in model 315 in generation 2: SectionalMotif\n",
      "Model Number: 316 with model ARIMA in generation 2 of 3\n",
      "Template Eval Error: Exception('Transformer BTCD failed on fit') in model 316 in generation 2: ARIMA\n",
      "Model Number: 317 with model ARDL in generation 2 of 3\n",
      "Model Number: 318 with model SectionalMotif in generation 2 of 3\n",
      "Model Number: 319 with model ARIMA in generation 2 of 3\n",
      "Model Number: 320 with model DatepartRegression in generation 2 of 3\n",
      "Model Number: 321 with model AverageValueNaive in generation 2 of 3\n",
      "Model Number: 322 with model SectionalMotif in generation 2 of 3\n",
      "Template Eval Error: ValueError('Unknown Distance Metric: kulsinski') in model 322 in generation 2: SectionalMotif\n",
      "Model Number: 323 with model Theta in generation 2 of 3\n",
      "Model Number: 324 with model UnobservedComponents in generation 2 of 3\n",
      "Template Eval Error: Exception('Transformer Detrend failed on fit') in model 324 in generation 2: UnobservedComponents\n",
      "Model Number: 325 with model AverageValueNaive in generation 2 of 3\n",
      "Model Number: 326 with model SectionalMotif in generation 2 of 3\n",
      "Template Eval Error: ValueError('kth(=5) out of bounds (4)') in model 326 in generation 2: SectionalMotif\n",
      "Model Number: 327 with model ARIMA in generation 2 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.089e+13, tolerance: 9.209e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 328 with model UnobservedComponents in generation 2 of 3\n",
      "Model Number: 329 with model ARIMA in generation 2 of 3\n",
      "Model Number: 330 with model MetricMotif in generation 2 of 3\n",
      "Model Number: 331 with model UnivariateMotif in generation 2 of 3\n",
      "Template Eval Error: ValueError('Model UnivariateMotif returned NaN for one or more series. fail_on_forecast_nan=True') in model 331 in generation 2: UnivariateMotif\n",
      "Model Number: 332 with model MultivariateMotif in generation 2 of 3\n",
      "Model Number: 333 with model ARIMA in generation 2 of 3\n",
      "Model Number: 334 with model GLM in generation 2 of 3\n",
      "Model Number: 335 with model ETS in generation 2 of 3\n",
      "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
      "ETS failed on NET_SALES with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
      "Model Number: 336 with model MultivariateMotif in generation 2 of 3\n",
      "Model Number: 337 with model ETS in generation 2 of 3\n",
      "Template Eval Error: Exception('Transformer Cointegration failed on fit') in model 337 in generation 2: ETS\n",
      "Model Number: 338 with model DatepartRegression in generation 2 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\statsmodels\\genmod\\families\\links.py:198: RuntimeWarning: overflow encountered in exp\n",
      "  t = np.exp(-z)\n",
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.107e+13, tolerance: 5.580e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 339 with model SeasonalNaive in generation 2 of 3\n",
      "Template Eval Error: Exception('Transformer AlignLastValue failed on inverse') in model 339 in generation 2: SeasonalNaive\n",
      "Model Number: 340 with model GLS in generation 2 of 3\n",
      "Model Number: 341 with model GLS in generation 2 of 3\n",
      "Model Number: 342 with model MultivariateMotif in generation 2 of 3\n",
      "Model Number: 343 with model ARDL in generation 2 of 3\n",
      "Model Number: 344 with model MetricMotif in generation 2 of 3\n",
      "Model Number: 345 with model ConstantNaive in generation 2 of 3\n",
      "Model Number: 346 with model GLM in generation 2 of 3\n",
      "Model Number: 347 with model ARDL in generation 2 of 3\n",
      "Model Number: 348 with model FBProphet in generation 2 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16:13:32 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:13:33 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 349 with model ARDL in generation 2 of 3\n",
      "Model Number: 350 with model ARDL in generation 2 of 3\n",
      "Model Number: 351 with model ARDL in generation 2 of 3\n",
      "Model Number: 352 with model ETS in generation 2 of 3\n",
      "Model Number: 353 with model GLM in generation 2 of 3\n",
      "Model Number: 354 with model ETS in generation 2 of 3\n",
      "Model Number: 355 with model ETS in generation 2 of 3\n",
      "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
      "ETS failed on NET_SALES with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
      "Model Number: 356 with model DatepartRegression in generation 2 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.107e+13, tolerance: 5.580e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 357 with model Theta in generation 2 of 3\n",
      "Model Number: 358 with model UnivariateMotif in generation 2 of 3\n",
      "Model Number: 359 with model UnivariateMotif in generation 2 of 3\n",
      "Model Number: 360 with model AverageValueNaive in generation 2 of 3\n",
      "Model Number: 361 with model SectionalMotif in generation 2 of 3\n",
      "Model Number: 362 with model MultivariateMotif in generation 2 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\autots\\tools\\probabilistic.py:67: RuntimeWarning: invalid value encountered in divide\n",
      "  (prior_mu / prior_sigma**2) + ((n * data_mu) / prior_sigma**2)\n",
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\autots\\tools\\probabilistic.py:68: RuntimeWarning: divide by zero encountered in divide\n",
      "  ) / ((1 / prior_sigma**2) + (n / prior_sigma**2))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 363 with model GLM in generation 2 of 3\n",
      "Model Number: 364 with model UnivariateRegression in generation 2 of 3\n",
      "Model Number: 365 with model WindowRegression in generation 2 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\statsmodels\\genmod\\families\\links.py:198: RuntimeWarning: overflow encountered in exp\n",
      "  t = np.exp(-z)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 366 with model WindowRegression in generation 2 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:541: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 367 with model MultivariateRegression in generation 2 of 3\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000065 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Model Number: 368 with model GLM in generation 2 of 3\n",
      "Model Number: 369 with model GLS in generation 2 of 3\n",
      "Model Number: 370 with model ARDL in generation 2 of 3\n",
      "Model Number: 371 with model ETS in generation 2 of 3\n",
      "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
      "ETS failed on NET_SALES with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
      "Model Number: 372 with model SectionalMotif in generation 2 of 3\n",
      "Model Number: 373 with model SectionalMotif in generation 2 of 3\n",
      "Template Eval Error: ValueError('kth(=10) out of bounds (6)') in model 373 in generation 2: SectionalMotif\n",
      "Model Number: 374 with model GLS in generation 2 of 3\n",
      "Model Number: 375 with model MultivariateRegression in generation 2 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.107e+13, tolerance: 5.580e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\autots\\tools\\probabilistic.py:67: RuntimeWarning: invalid value encountered in divide\n",
      "  (prior_mu / prior_sigma**2) + ((n * data_mu) / prior_sigma**2)\n",
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\autots\\tools\\probabilistic.py:68: RuntimeWarning: divide by zero encountered in divide\n",
      "  ) / ((1 / prior_sigma**2) + (n / prior_sigma**2))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 376 with model NVAR in generation 2 of 3\n",
      "Model Number: 377 with model AverageValueNaive in generation 2 of 3\n",
      "Model Number: 378 with model Theta in generation 2 of 3\n",
      "Model Number: 379 with model FBProphet in generation 2 of 3\n",
      "No anomalies detected.\n",
      "Model Number: 380 with model ConstantNaive in generation 2 of 3\n",
      "Template Eval Error: Exception('Transformer AlignLastValue failed on inverse') in model 380 in generation 2: ConstantNaive\n",
      "Model Number: 381 with model Theta in generation 2 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\linear_model\\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.48343e-24): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\linear_model\\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.48343e-24): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 382 with model LastValueNaive in generation 2 of 3\n",
      "Model Number: 383 with model UnivariateMotif in generation 2 of 3\n",
      "Model Number: 384 with model SeasonalNaive in generation 2 of 3\n",
      "Model Number: 385 with model ARDL in generation 2 of 3\n",
      "Template Eval Error: Exception('Transformer BTCD failed on fit') in model 385 in generation 2: ARDL\n",
      "Model Number: 386 with model UnobservedComponents in generation 2 of 3\n",
      "Model Number: 387 with model DatepartRegression in generation 2 of 3\n",
      "Model Number: 388 with model UnivariateRegression in generation 2 of 3\n",
      "Model Number: 389 with model MetricMotif in generation 2 of 3\n",
      "Model Number: 390 with model SeasonalNaive in generation 2 of 3\n",
      "Model Number: 391 with model MetricMotif in generation 2 of 3\n",
      "Model Number: 392 with model UnobservedComponents in generation 2 of 3\n",
      "Model Number: 393 with model LastValueNaive in generation 2 of 3\n",
      "Model Number: 394 with model MultivariateRegression in generation 2 of 3\n",
      "Model Number: 395 with model SectionalMotif in generation 2 of 3\n",
      "Template Eval Error: ValueError('kth(=10) out of bounds (6)') in model 395 in generation 2: SectionalMotif\n",
      "Model Number: 396 with model ARDL in generation 2 of 3\n",
      "Model Number: 397 with model DatepartRegression in generation 2 of 3\n",
      "Model Number: 398 with model MultivariateRegression in generation 2 of 3\n",
      "Model Number: 399 with model UnobservedComponents in generation 2 of 3\n",
      "Model Number: 400 with model MultivariateMotif in generation 2 of 3\n",
      "Model Number: 401 with model MultivariateRegression in generation 2 of 3\n",
      "Model Number: 402 with model GLM in generation 2 of 3\n",
      "Model Number: 403 with model SectionalMotif in generation 2 of 3\n",
      "Model Number: 404 with model Theta in generation 2 of 3\n",
      "Model Number: 405 with model MultivariateMotif in generation 2 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\statsmodels\\genmod\\families\\links.py:198: RuntimeWarning: overflow encountered in exp\n",
      "  t = np.exp(-z)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 406 with model WindowRegression in generation 2 of 3\n",
      "Template Eval Error: Exception('Transformer QuantileTransformer failed on fit') in model 406 in generation 2: WindowRegression\n",
      "Model Number: 407 with model MultivariateRegression in generation 2 of 3\n",
      "Model Number: 408 with model WindowRegression in generation 2 of 3\n",
      "Model Number: 409 with model GLM in generation 2 of 3\n",
      "Model Number: 410 with model ETS in generation 2 of 3\n",
      "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
      "ETS failed on NET_SALES with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
      "Model Number: 411 with model GLS in generation 2 of 3\n",
      "Model Number: 412 with model MultivariateMotif in generation 2 of 3\n",
      "Model Number: 413 with model Theta in generation 2 of 3\n",
      "Model Number: 414 with model FBProphet in generation 2 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16:13:42 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:13:43 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 415 with model GLS in generation 2 of 3\n",
      "Model Number: 416 with model ETS in generation 2 of 3\n",
      "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
      "ETS failed on NET_SALES with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
      "Model Number: 417 with model GLS in generation 2 of 3\n",
      "Model Number: 418 with model ARIMA in generation 2 of 3\n",
      "Model Number: 419 with model SectionalMotif in generation 2 of 3\n",
      "Model Number: 420 with model DatepartRegression in generation 2 of 3\n",
      "Template Eval Error: Exception('Transformer AlignLastValue failed on inverse') in model 420 in generation 2: DatepartRegression\n",
      "Model Number: 421 with model NVAR in generation 2 of 3\n",
      "Model Number: 422 with model NVAR in generation 2 of 3\n",
      "Model Number: 423 with model WindowRegression in generation 2 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\decomposition\\_fastica.py:583: UserWarning: Ignoring n_components with whiten=False.\n",
      "  warnings.warn(\"Ignoring n_components with whiten=False.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 424 with model LastValueNaive in generation 2 of 3\n",
      "Model Number: 425 with model UnivariateMotif in generation 2 of 3\n",
      "Model Number: 426 with model MultivariateRegression in generation 2 of 3\n",
      "Model Number: 427 with model SeasonalNaive in generation 2 of 3\n",
      "Model Number: 428 with model SeasonalNaive in generation 2 of 3\n",
      "Model Number: 429 with model Theta in generation 2 of 3\n",
      "Model Number: 430 with model SectionalMotif in generation 2 of 3\n",
      "Model Number: 431 with model GLM in generation 2 of 3\n",
      "Model Number: 432 with model ARDL in generation 2 of 3\n",
      "Model Number: 433 with model GLS in generation 2 of 3\n",
      "Template Eval Error: Exception('Transformer BTCD failed on fit') in model 433 in generation 2: GLS\n",
      "Model Number: 434 with model LastValueNaive in generation 2 of 3\n",
      "Model Number: 435 with model GLM in generation 2 of 3\n",
      "Model Number: 436 with model FBProphet in generation 2 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16:13:45 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:13:45 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Generation: 3 of 3\n",
      "Model Number: 437 with model MultivariateRegression in generation 3 of 3\n",
      "Model Number: 438 with model UnobservedComponents in generation 3 of 3\n",
      "Model Number: 439 with model ETS in generation 3 of 3\n",
      "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
      "ETS failed on NET_SALES with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
      "Model Number: 440 with model MetricMotif in generation 3 of 3\n",
      "Model Number: 441 with model SectionalMotif in generation 3 of 3\n",
      "Model Number: 442 with model AverageValueNaive in generation 3 of 3\n",
      "Model Number: 443 with model ARDL in generation 3 of 3\n",
      "Model Number: 444 with model MetricMotif in generation 3 of 3\n",
      "Model Number: 445 with model UnobservedComponents in generation 3 of 3\n",
      "Model Number: 446 with model UnivariateMotif in generation 3 of 3\n",
      "Model Number: 447 with model SeasonalNaive in generation 3 of 3\n",
      "Model Number: 448 with model MultivariateRegression in generation 3 of 3\n",
      "Model Number: 449 with model SectionalMotif in generation 3 of 3\n",
      "Model Number: 450 with model SeasonalNaive in generation 3 of 3\n",
      "Model Number: 451 with model SectionalMotif in generation 3 of 3\n",
      "Model Number: 452 with model MultivariateRegression in generation 3 of 3\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000037 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Model Number: 453 with model ARDL in generation 3 of 3\n",
      "Model Number: 454 with model UnivariateRegression in generation 3 of 3\n",
      "Model Number: 455 with model ETS in generation 3 of 3\n",
      "Model Number: 456 with model ETS in generation 3 of 3\n",
      "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
      "ETS failed on NET_SALES with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
      "Model Number: 457 with model UnobservedComponents in generation 3 of 3\n",
      "Template Eval Error: Exception('Transformer QuantileTransformer failed on inverse') in model 457 in generation 3: UnobservedComponents\n",
      "Model Number: 458 with model ARIMA in generation 3 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.107e+13, tolerance: 5.580e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 459 with model MetricMotif in generation 3 of 3\n",
      "Model Number: 460 with model ETS in generation 3 of 3\n",
      "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
      "ETS failed on NET_SALES with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
      "Model Number: 461 with model ARIMA in generation 3 of 3\n",
      "Model Number: 462 with model UnobservedComponents in generation 3 of 3\n",
      "Model Number: 463 with model MultivariateMotif in generation 3 of 3\n",
      "Model Number: 464 with model SeasonalNaive in generation 3 of 3\n",
      "Model Number: 465 with model Theta in generation 3 of 3\n",
      "Model Number: 466 with model SeasonalNaive in generation 3 of 3\n",
      "Model Number: 467 with model AverageValueNaive in generation 3 of 3\n",
      "Model Number: 468 with model DatepartRegression in generation 3 of 3\n",
      "Model Number: 469 with model WindowRegression in generation 3 of 3\n",
      "Model Number: 470 with model MultivariateMotif in generation 3 of 3\n",
      "Model Number: 471 with model NVAR in generation 3 of 3\n",
      "Model Number: 472 with model ARDL in generation 3 of 3\n",
      "Model Number: 473 with model DatepartRegression in generation 3 of 3\n",
      "Model Number: 474 with model SectionalMotif in generation 3 of 3\n",
      "Model Number: 475 with model ARDL in generation 3 of 3\n",
      "Model Number: 476 with model GLS in generation 3 of 3\n",
      "Model Number: 477 with model MetricMotif in generation 3 of 3\n",
      "Model Number: 478 with model UnivariateMotif in generation 3 of 3\n",
      "Model Number: 479 with model ETS in generation 3 of 3\n",
      "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
      "ETS failed on NET_SALES with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
      "Model Number: 480 with model LastValueNaive in generation 3 of 3\n",
      "Model Number: 481 with model UnivariateMotif in generation 3 of 3\n",
      "Model Number: 482 with model MultivariateRegression in generation 3 of 3\n",
      "Template Eval Error: ValueError(\"Some value(s) of y are out of the valid range of the loss 'HalfPoissonLoss'.\") in model 482 in generation 3: MultivariateRegression\n",
      "Model Number: 483 with model SectionalMotif in generation 3 of 3\n",
      "Model Number: 484 with model Theta in generation 3 of 3\n",
      "Model Number: 485 with model UnobservedComponents in generation 3 of 3\n",
      "Template Eval Error: ValueError(\"Model returned NaN due to a preprocessing transformer {'fillna': 'nearest', 'transformations': {'0': 'Detrend', '1': 'bkfilter', '2': 'AlignLastValue'}, 'transformation_params': {'0': {'model': 'GLS', 'phi': 1, 'window': None, 'transform_dict': None}, '1': {}, '2': {'rows': 7, 'lag': 1, 'method': 'multiplicative', 'strength': 0.7, 'first_value_only': False}}}. fail_on_forecast_nan=True\") in model 485 in generation 3: UnobservedComponents\n",
      "Model Number: 486 with model AverageValueNaive in generation 3 of 3\n",
      "Model Number: 487 with model SectionalMotif in generation 3 of 3\n",
      "Model Number: 488 with model MultivariateMotif in generation 3 of 3\n",
      "Model Number: 489 with model UnivariateMotif in generation 3 of 3\n",
      "Model Number: 490 with model AverageValueNaive in generation 3 of 3\n",
      "Model Number: 491 with model WindowRegression in generation 3 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:541: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 492 with model ARIMA in generation 3 of 3\n",
      "Model Number: 493 with model NVAR in generation 3 of 3\n",
      "Model Number: 494 with model ETS in generation 3 of 3\n",
      "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
      "ETS failed on NET_SALES with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
      "Model Number: 495 with model SeasonalNaive in generation 3 of 3\n",
      "Model Number: 496 with model ARIMA in generation 3 of 3\n",
      "Model Number: 497 with model GLM in generation 3 of 3\n",
      "Template Eval Error: Exception('Transformer BTCD failed on fit') in model 497 in generation 3: GLM\n",
      "Model Number: 498 with model ARIMA in generation 3 of 3\n",
      "Model Number: 499 with model ARIMA in generation 3 of 3\n",
      "Model Number: 500 with model ARDL in generation 3 of 3\n",
      "Model Number: 501 with model ETS in generation 3 of 3\n",
      "Template Eval Error: Exception('Transformer AlignLastValue failed on inverse') in model 501 in generation 3: ETS\n",
      "Model Number: 502 with model DatepartRegression in generation 3 of 3\n",
      "Model Number: 503 with model SectionalMotif in generation 3 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.107e+13, tolerance: 5.580e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 504 with model ETS in generation 3 of 3\n",
      "Model Number: 505 with model GLM in generation 3 of 3\n",
      "Model Number: 506 with model MultivariateMotif in generation 3 of 3\n",
      "Model Number: 507 with model WindowRegression in generation 3 of 3\n",
      "Template Eval Error: ValueError('Found array with 0 sample(s) (shape=(0, 0)) while a minimum of 1 is required by BayesianRidge.') in model 507 in generation 3: WindowRegression\n",
      "Model Number: 508 with model GLM in generation 3 of 3\n",
      "Model Number: 509 with model Theta in generation 3 of 3\n",
      "Model Number: 510 with model GLS in generation 3 of 3\n",
      "Model Number: 511 with model AverageValueNaive in generation 3 of 3\n",
      "Model Number: 512 with model SectionalMotif in generation 3 of 3\n",
      "Model Number: 513 with model ARIMA in generation 3 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\linear_model\\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.96794e-24): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 514 with model ARDL in generation 3 of 3\n",
      "Model Number: 515 with model GLM in generation 3 of 3\n",
      "Model Number: 516 with model ARDL in generation 3 of 3\n",
      "Template Eval Error: ValueError(\"ARDL series NET_SALES failed with error ValueError('integer orders must be at least 1 when causal is True.') exog train                    MONTH  COVID  AMZN\\nMONTH                                \\n2016-01-01  1.451606e+18    0.0   0.0\\n2016-02-01  1.454285e+18    0.0   0.0\\n2016-03-01  1.456790e+18    0.0   0.0\\n2016-04-01  1.459469e+18    0.0   0.0\\n2016-05-01  1.462061e+18    0.0   0.0\\n...                  ...    ...   ...\\n2021-08-01  1.627776e+18    1.0   0.0\\n2021-09-01  1.630454e+18    1.0   0.0\\n2021-10-01  1.633046e+18    1.0   0.0\\n2021-11-01  1.635725e+18    1.0   0.0\\n2021-12-01  1.638317e+18    1.0   0.0\\n\\n[72 rows x 3 columns] and predict                    MONTH  COVID  AMZN\\nMONTH                                \\n2022-01-01  1.640995e+18    0.0   0.0\\n2022-02-01  1.643674e+18    0.0   0.0\\n2022-03-01  1.646093e+18    0.0   0.0\\n2022-04-01  1.648771e+18    0.0   0.0\\n2022-05-01  1.651363e+18    0.0   0.0\\n2022-06-01  1.654042e+18    0.0   0.0\\n2022-07-01  1.656634e+18    0.0   0.0\\n2022-08-01  1.659312e+18    0.0   0.0\\n2022-09-01  1.661990e+18    0.0   0.0\\n2022-10-01  1.664582e+18    0.0   0.0\\n2022-11-01  1.667261e+18    0.0   0.0\\n2022-12-01  1.669853e+18    0.0   0.0\") in model 516 in generation 3: ARDL\n",
      "Model Number: 517 with model GLS in generation 3 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\statsmodels\\genmod\\families\\links.py:198: RuntimeWarning: overflow encountered in exp\n",
      "  t = np.exp(-z)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 518 with model AverageValueNaive in generation 3 of 3\n",
      "Model Number: 519 with model SectionalMotif in generation 3 of 3\n",
      "Model Number: 520 with model ETS in generation 3 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\autots\\tools\\probabilistic.py:67: RuntimeWarning: invalid value encountered in divide\n",
      "  (prior_mu / prior_sigma**2) + ((n * data_mu) / prior_sigma**2)\n",
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\autots\\tools\\probabilistic.py:68: RuntimeWarning: divide by zero encountered in divide\n",
      "  ) / ((1 / prior_sigma**2) + (n / prior_sigma**2))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 521 with model DatepartRegression in generation 3 of 3\n",
      "Model Number: 522 with model Theta in generation 3 of 3\n",
      "Model Number: 523 with model MultivariateMotif in generation 3 of 3\n",
      "Model Number: 524 with model AverageValueNaive in generation 3 of 3\n",
      "Model Number: 525 with model SeasonalNaive in generation 3 of 3\n",
      "Model Number: 526 with model ARDL in generation 3 of 3\n",
      "Model Number: 527 with model MetricMotif in generation 3 of 3\n",
      "Model Number: 528 with model ETS in generation 3 of 3\n",
      "Model Number: 529 with model ARDL in generation 3 of 3\n",
      "Model Number: 530 with model LastValueNaive in generation 3 of 3\n",
      "Model Number: 531 with model SeasonalNaive in generation 3 of 3\n",
      "Model Number: 532 with model SectionalMotif in generation 3 of 3\n",
      "Model Number: 533 with model ARDL in generation 3 of 3\n",
      "Model Number: 534 with model NVAR in generation 3 of 3\n",
      "Model Number: 535 with model GLM in generation 3 of 3\n",
      "Model Number: 536 with model MultivariateMotif in generation 3 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\linear_model\\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.48343e-24): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 537 with model AverageValueNaive in generation 3 of 3\n",
      "Model Number: 538 with model SeasonalNaive in generation 3 of 3\n",
      "Model Number: 539 with model UnivariateMotif in generation 3 of 3\n",
      "Model Number: 540 with model GLS in generation 3 of 3\n",
      "Model Number: 541 with model ARDL in generation 3 of 3\n",
      "Model Number: 542 with model ARDL in generation 3 of 3\n",
      "Model Number: 543 with model MetricMotif in generation 3 of 3\n",
      "Model Number: 544 with model UnivariateMotif in generation 3 of 3\n",
      "Model Number: 545 with model MultivariateMotif in generation 3 of 3\n",
      "Model Number: 546 with model GLM in generation 3 of 3\n",
      "Model Number: 547 with model NVAR in generation 3 of 3\n",
      "Model Number: 548 with model ConstantNaive in generation 3 of 3\n",
      "Model Number: 549 with model GLS in generation 3 of 3\n",
      "Model Number: 550 with model MultivariateRegression in generation 3 of 3\n",
      "Model Number: 551 with model GLS in generation 3 of 3\n",
      "Model Number: 552 with model MultivariateMotif in generation 3 of 3\n",
      "Model Number: 553 with model WindowRegression in generation 3 of 3\n",
      "Model Number: 554 with model UnivariateMotif in generation 3 of 3\n",
      "Model Number: 555 with model GLM in generation 3 of 3\n",
      "Template Eval Error: Exception('Transformer AlignLastValue failed on inverse') in model 555 in generation 3: GLM\n",
      "Model Number: 556 with model FBProphet in generation 3 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\statsmodels\\genmod\\families\\family.py:1367: ValueWarning: Negative binomial dispersion parameter alpha not set. Using default value alpha=1.0.\n",
      "  warnings.warn(\"Negative binomial dispersion parameter alpha not \"\n",
      "16:14:01 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:14:02 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 557 with model LastValueNaive in generation 3 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.107e+13, tolerance: 5.580e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 558 with model ETS in generation 3 of 3\n",
      "Model Number: 559 with model GLS in generation 3 of 3\n",
      "Model Number: 560 with model SectionalMotif in generation 3 of 3\n",
      "Model Number: 561 with model SeasonalNaive in generation 3 of 3\n",
      "TotalRuntime missing in 4!\n",
      "Validation Round: 1\n",
      "Model Number: 1 of 84 with model SectionalMotif for Validation 1\n",
      "📈 1 - SectionalMotif with avg smape 31.53: \n",
      "Model Number: 2 of 84 with model SectionalMotif for Validation 1\n",
      "2 - SectionalMotif with avg smape 37.53: \n",
      "Model Number: 3 of 84 with model SectionalMotif for Validation 1\n",
      "3 - SectionalMotif with avg smape 40.53: \n",
      "Model Number: 4 of 84 with model SectionalMotif for Validation 1\n",
      "4 - SectionalMotif with avg smape 34.79: \n",
      "Model Number: 5 of 84 with model WindowRegression for Validation 1\n",
      "5 - WindowRegression with avg smape 46.1: \n",
      "Model Number: 6 of 84 with model UnivariateMotif for Validation 1\n",
      "6 - UnivariateMotif with avg smape 32.88: \n",
      "Model Number: 7 of 84 with model SectionalMotif for Validation 1\n",
      "7 - SectionalMotif with avg smape 35.45: \n",
      "Model Number: 8 of 84 with model MultivariateMotif for Validation 1\n",
      "8 - MultivariateMotif with avg smape 41.79: \n",
      "Model Number: 9 of 84 with model Theta for Validation 1\n",
      "📈 9 - Theta with avg smape 20.05: \n",
      "Model Number: 10 of 84 with model MultivariateMotif for Validation 1\n",
      "10 - MultivariateMotif with avg smape 26.86: \n",
      "Model Number: 11 of 84 with model SeasonalNaive for Validation 1\n",
      "11 - SeasonalNaive with avg smape 36.37: \n",
      "Model Number: 12 of 84 with model SeasonalNaive for Validation 1\n",
      "12 - SeasonalNaive with avg smape 43.44: \n",
      "Model Number: 13 of 84 with model UnivariateMotif for Validation 1\n",
      "13 - UnivariateMotif with avg smape 37.13: \n",
      "Model Number: 14 of 84 with model SeasonalNaive for Validation 1\n",
      "14 - SeasonalNaive with avg smape 44.43: \n",
      "Model Number: 15 of 84 with model UnivariateMotif for Validation 1\n",
      "15 - UnivariateMotif with avg smape 31.5: \n",
      "Model Number: 16 of 84 with model SeasonalNaive for Validation 1\n",
      "16 - SeasonalNaive with avg smape 34.58: \n",
      "Model Number: 17 of 84 with model UnivariateMotif for Validation 1\n",
      "17 - UnivariateMotif with avg smape 31.42: \n",
      "Model Number: 18 of 84 with model AverageValueNaive for Validation 1\n",
      "18 - AverageValueNaive with avg smape 30.57: \n",
      "Model Number: 19 of 84 with model AverageValueNaive for Validation 1\n",
      "19 - AverageValueNaive with avg smape 35.99: \n",
      "Model Number: 20 of 84 with model UnobservedComponents for Validation 1\n",
      "20 - UnobservedComponents with avg smape 35.86: \n",
      "Model Number: 21 of 84 with model AverageValueNaive for Validation 1\n",
      "21 - AverageValueNaive with avg smape 35.86: \n",
      "Model Number: 22 of 84 with model AverageValueNaive for Validation 1\n",
      "22 - AverageValueNaive with avg smape 35.75: \n",
      "Model Number: 23 of 84 with model AverageValueNaive for Validation 1\n",
      "23 - AverageValueNaive with avg smape 35.4: \n",
      "Model Number: 24 of 84 with model MetricMotif for Validation 1\n",
      "24 - MetricMotif with avg smape 25.63: \n",
      "Model Number: 25 of 84 with model Theta for Validation 1\n",
      "25 - Theta with avg smape 20.84: \n",
      "Model Number: 26 of 84 with model MultivariateMotif for Validation 1\n",
      "26 - MultivariateMotif with avg smape 35.37: \n",
      "Model Number: 27 of 84 with model MetricMotif for Validation 1\n",
      "27 - MetricMotif with avg smape 25.61: \n",
      "Model Number: 28 of 84 with model ETS for Validation 1\n",
      "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
      "ETS failed on NET_SALES with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
      "28 - ETS with avg smape 35.86: \n",
      "Model Number: 29 of 84 with model MultivariateMotif for Validation 1\n",
      "29 - MultivariateMotif with avg smape 43.93: \n",
      "Model Number: 30 of 84 with model SeasonalNaive for Validation 1\n",
      "30 - SeasonalNaive with avg smape 24.68: \n",
      "Model Number: 31 of 84 with model UnivariateMotif for Validation 1\n",
      "31 - UnivariateMotif with avg smape 25.76: \n",
      "Model Number: 32 of 84 with model MultivariateMotif for Validation 1\n",
      "32 - MultivariateMotif with avg smape 35.73: \n",
      "Model Number: 33 of 84 with model ETS for Validation 1\n",
      "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
      "ETS failed on NET_SALES with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
      "33 - ETS with avg smape 35.86: \n",
      "Model Number: 34 of 84 with model DatepartRegression for Validation 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.810e+13, tolerance: 4.867e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.810e+13, tolerance: 4.867e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34 - DatepartRegression with avg smape 29.56: \n",
      "Model Number: 35 of 84 with model ETS for Validation 1\n",
      "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
      "ETS failed on NET_SALES with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
      "35 - ETS with avg smape 35.86: \n",
      "Model Number: 36 of 84 with model ETS for Validation 1\n",
      "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
      "ETS failed on NET_SALES with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
      "36 - ETS with avg smape 35.86: \n",
      "Model Number: 37 of 84 with model ARDL for Validation 1\n",
      "37 - ARDL with avg smape 29.6: \n",
      "Model Number: 38 of 84 with model ARDL for Validation 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.810e+13, tolerance: 4.867e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38 - ARDL with avg smape 36.46: \n",
      "Model Number: 39 of 84 with model GLM for Validation 1\n",
      "39 - GLM with avg smape 35.78: \n",
      "Model Number: 40 of 84 with model GLS for Validation 1\n",
      "40 - GLS with avg smape 26.43: \n",
      "Model Number: 41 of 84 with model ARIMA for Validation 1\n",
      "41 - ARIMA with avg smape 24.8: \n",
      "Model Number: 42 of 84 with model ARDL for Validation 1\n",
      "42 - ARDL with avg smape 34.98: \n",
      "Model Number: 43 of 84 with model ARDL for Validation 1\n",
      "43 - ARDL with avg smape 37.9: \n",
      "Model Number: 44 of 84 with model ETS for Validation 1\n",
      "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
      "ETS failed on NET_SALES with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
      "44 - ETS with avg smape 35.86: \n",
      "Model Number: 45 of 84 with model GLS for Validation 1\n",
      "45 - GLS with avg smape 36.0: \n",
      "Model Number: 46 of 84 with model ARIMA for Validation 1\n",
      "46 - ARIMA with avg smape 24.09: \n",
      "Model Number: 47 of 84 with model ARDL for Validation 1\n",
      "47 - ARDL with avg smape 30.49: \n",
      "Model Number: 48 of 84 with model GLM for Validation 1\n",
      "48 - GLM with avg smape 35.95: \n",
      "Model Number: 49 of 84 with model GLM for Validation 1\n",
      "49 - GLM with avg smape 35.98: \n",
      "Model Number: 50 of 84 with model GLS for Validation 1\n",
      "50 - GLS with avg smape 35.97: \n",
      "Model Number: 51 of 84 with model MetricMotif for Validation 1\n",
      "51 - MetricMotif with avg smape 23.56: \n",
      "Model Number: 52 of 84 with model GLS for Validation 1\n",
      "52 - GLS with avg smape 35.22: \n",
      "Model Number: 53 of 84 with model DatepartRegression for Validation 1\n",
      "53 - DatepartRegression with avg smape 28.55: \n",
      "Model Number: 54 of 84 with model GLS for Validation 1\n",
      "54 - GLS with avg smape 27.0: \n",
      "Model Number: 55 of 84 with model DatepartRegression for Validation 1\n",
      "55 - DatepartRegression with avg smape 28.54: \n",
      "Model Number: 56 of 84 with model MetricMotif for Validation 1\n",
      "56 - MetricMotif with avg smape 36.18: \n",
      "Model Number: 57 of 84 with model DatepartRegression for Validation 1\n",
      "57 - DatepartRegression with avg smape 28.22: \n",
      "Model Number: 58 of 84 with model MultivariateRegression for Validation 1\n",
      "58 - MultivariateRegression with avg smape 26.52: \n",
      "Model Number: 59 of 84 with model MultivariateRegression for Validation 1\n",
      "59 - MultivariateRegression with avg smape 26.49: \n",
      "Model Number: 60 of 84 with model MultivariateRegression for Validation 1\n",
      "60 - MultivariateRegression with avg smape 25.19: \n",
      "Model Number: 61 of 84 with model MultivariateRegression for Validation 1\n",
      "61 - MultivariateRegression with avg smape 25.19: \n",
      "Model Number: 62 of 84 with model NVAR for Validation 1\n",
      "62 - NVAR with avg smape 34.89: \n",
      "Model Number: 63 of 84 with model UnobservedComponents for Validation 1\n",
      "63 - UnobservedComponents with avg smape 31.21: \n",
      "Model Number: 64 of 84 with model NVAR for Validation 1\n",
      "64 - NVAR with avg smape 34.36: \n",
      "Model Number: 65 of 84 with model NVAR for Validation 1\n",
      "65 - NVAR with avg smape 34.28: \n",
      "Model Number: 66 of 84 with model NVAR for Validation 1\n",
      "66 - NVAR with avg smape 34.28: \n",
      "Model Number: 67 of 84 with model MetricMotif for Validation 1\n",
      "67 - MetricMotif with avg smape 26.1: \n",
      "Model Number: 68 of 84 with model UnobservedComponents for Validation 1\n",
      "68 - UnobservedComponents with avg smape 54.13: \n",
      "Model Number: 69 of 84 with model UnobservedComponents for Validation 1\n",
      "69 - UnobservedComponents with avg smape 54.13: \n",
      "Model Number: 70 of 84 with model GLM for Validation 1\n",
      "70 - GLM with avg smape 24.65: \n",
      "Model Number: 71 of 84 with model LastValueNaive for Validation 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\statsmodels\\genmod\\families\\links.py:198: RuntimeWarning: overflow encountered in exp\n",
      "  t = np.exp(-z)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71 - LastValueNaive with avg smape 72.86: \n",
      "Model Number: 72 of 84 with model UnobservedComponents for Validation 1\n",
      "72 - UnobservedComponents with avg smape 21.93: \n",
      "Model Number: 73 of 84 with model ARIMA for Validation 1\n",
      "73 - ARIMA with avg smape 34.26: \n",
      "Model Number: 74 of 84 with model ARIMA for Validation 1\n",
      "74 - ARIMA with avg smape 27.65: \n",
      "Model Number: 75 of 84 with model NVAR for Validation 1\n",
      "75 - NVAR with avg smape 37.79: \n",
      "Model Number: 76 of 84 with model ARIMA for Validation 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\linear_model\\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.78051e-24): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76 - ARIMA with avg smape 32.53: \n",
      "Model Number: 77 of 84 with model ConstantNaive for Validation 1\n",
      "77 - ConstantNaive with avg smape 28.42: \n",
      "Model Number: 78 of 84 with model WindowRegression for Validation 1\n",
      "78 - WindowRegression with avg smape 86.01: \n",
      "Model Number: 79 of 84 with model DatepartRegression for Validation 1\n",
      "79 - DatepartRegression with avg smape 35.85: \n",
      "Model Number: 80 of 84 with model MultivariateRegression for Validation 1\n",
      "80 - MultivariateRegression with avg smape 25.91: \n",
      "Model Number: 81 of 84 with model GLM for Validation 1\n",
      "81 - GLM with avg smape 51.95: \n",
      "Model Number: 82 of 84 with model Theta for Validation 1\n",
      "82 - Theta with avg smape 25.93: \n",
      "Model Number: 83 of 84 with model LastValueNaive for Validation 1\n",
      "83 - LastValueNaive with avg smape 84.18: \n",
      "Model Number: 84 of 84 with model WindowRegression for Validation 1\n",
      "84 - WindowRegression with avg smape 30.18: \n",
      "Validation Round: 2\n",
      "Model Number: 1 of 84 with model SectionalMotif for Validation 2\n",
      "📈 1 - SectionalMotif with avg smape 51.1: \n",
      "Model Number: 2 of 84 with model SectionalMotif for Validation 2\n",
      "Template Eval Error: ValueError('kth(=3) out of bounds (3)') in model 2 in generation 0: SectionalMotif\n",
      "Model Number: 3 of 84 with model SectionalMotif for Validation 2\n",
      "3 - SectionalMotif with avg smape 52.02: \n",
      "Model Number: 4 of 84 with model SectionalMotif for Validation 2\n",
      "Template Eval Error: ValueError('kth(=3) out of bounds (3)') in model 4 in generation 0: SectionalMotif\n",
      "Model Number: 5 of 84 with model WindowRegression for Validation 2\n",
      "5 - WindowRegression with avg smape 60.52: \n",
      "Model Number: 6 of 84 with model UnivariateMotif for Validation 2\n",
      "📈 6 - UnivariateMotif with avg smape 50.9: \n",
      "Model Number: 7 of 84 with model SectionalMotif for Validation 2\n",
      "Template Eval Error: ValueError('kth(=3) out of bounds (3)') in model 7 in generation 0: SectionalMotif\n",
      "Model Number: 8 of 84 with model MultivariateMotif for Validation 2\n",
      "8 - MultivariateMotif with avg smape 55.42: \n",
      "Model Number: 9 of 84 with model Theta for Validation 2\n",
      "📈 9 - Theta with avg smape 50.02: \n",
      "Model Number: 10 of 84 with model MultivariateMotif for Validation 2\n",
      "10 - MultivariateMotif with avg smape 50.66: \n",
      "Model Number: 11 of 84 with model SeasonalNaive for Validation 2\n",
      "📈 11 - SeasonalNaive with avg smape 46.83: \n",
      "Model Number: 12 of 84 with model SeasonalNaive for Validation 2\n",
      "12 - SeasonalNaive with avg smape 54.58: \n",
      "Model Number: 13 of 84 with model UnivariateMotif for Validation 2\n",
      "13 - UnivariateMotif with avg smape 54.88: \n",
      "Model Number: 14 of 84 with model SeasonalNaive for Validation 2\n",
      "14 - SeasonalNaive with avg smape 62.25: \n",
      "Model Number: 15 of 84 with model UnivariateMotif for Validation 2\n",
      "15 - UnivariateMotif with avg smape 56.59: \n",
      "Model Number: 16 of 84 with model SeasonalNaive for Validation 2\n",
      "16 - SeasonalNaive with avg smape 52.02: \n",
      "Model Number: 17 of 84 with model UnivariateMotif for Validation 2\n",
      "17 - UnivariateMotif with avg smape 48.28: \n",
      "Model Number: 18 of 84 with model AverageValueNaive for Validation 2\n",
      "18 - AverageValueNaive with avg smape 51.91: \n",
      "Model Number: 19 of 84 with model AverageValueNaive for Validation 2\n",
      "19 - AverageValueNaive with avg smape 51.39: \n",
      "Model Number: 20 of 84 with model UnobservedComponents for Validation 2\n",
      "20 - UnobservedComponents with avg smape 50.85: \n",
      "Model Number: 21 of 84 with model AverageValueNaive for Validation 2\n",
      "21 - AverageValueNaive with avg smape 50.85: \n",
      "Model Number: 22 of 84 with model AverageValueNaive for Validation 2\n",
      "22 - AverageValueNaive with avg smape 51.09: \n",
      "Model Number: 23 of 84 with model AverageValueNaive for Validation 2\n",
      "23 - AverageValueNaive with avg smape 53.31: \n",
      "Model Number: 24 of 84 with model MetricMotif for Validation 2\n",
      "Template Eval Error: ValueError('kth(=9) out of bounds (7)') in model 24 in generation 0: MetricMotif\n",
      "Model Number: 25 of 84 with model Theta for Validation 2\n",
      "25 - Theta with avg smape 49.82: \n",
      "Model Number: 26 of 84 with model MultivariateMotif for Validation 2\n",
      "26 - MultivariateMotif with avg smape 53.0: \n",
      "Model Number: 27 of 84 with model MetricMotif for Validation 2\n",
      "📈 27 - MetricMotif with avg smape 46.24: \n",
      "Model Number: 28 of 84 with model ETS for Validation 2\n",
      "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
      "ETS failed on NET_SALES with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
      "28 - ETS with avg smape 50.85: \n",
      "Model Number: 29 of 84 with model MultivariateMotif for Validation 2\n",
      "29 - MultivariateMotif with avg smape 57.36: \n",
      "Model Number: 30 of 84 with model SeasonalNaive for Validation 2\n",
      "30 - SeasonalNaive with avg smape 47.2: \n",
      "Model Number: 31 of 84 with model UnivariateMotif for Validation 2\n",
      "31 - UnivariateMotif with avg smape 51.99: \n",
      "Model Number: 32 of 84 with model MultivariateMotif for Validation 2\n",
      "32 - MultivariateMotif with avg smape 55.38: \n",
      "Model Number: 33 of 84 with model ETS for Validation 2\n",
      "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
      "ETS failed on NET_SALES with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
      "33 - ETS with avg smape 50.85: \n",
      "Model Number: 34 of 84 with model DatepartRegression for Validation 2\n",
      "34 - DatepartRegression with avg smape 47.83: \n",
      "Model Number: 35 of 84 with model ETS for Validation 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.722e+12, tolerance: 1.897e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.722e+12, tolerance: 1.897e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
      "ETS failed on NET_SALES with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
      "35 - ETS with avg smape 50.85: \n",
      "Model Number: 36 of 84 with model ETS for Validation 2\n",
      "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
      "ETS failed on NET_SALES with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
      "36 - ETS with avg smape 50.85: \n",
      "Model Number: 37 of 84 with model ARDL for Validation 2\n",
      "37 - ARDL with avg smape 57.34: \n",
      "Model Number: 38 of 84 with model ARDL for Validation 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.722e+12, tolerance: 1.897e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38 - ARDL with avg smape 51.57: \n",
      "Model Number: 39 of 84 with model GLM for Validation 2\n",
      "39 - GLM with avg smape 52.26: \n",
      "Model Number: 40 of 84 with model GLS for Validation 2\n",
      "40 - GLS with avg smape 47.48: \n",
      "Model Number: 41 of 84 with model ARIMA for Validation 2\n",
      "41 - ARIMA with avg smape 50.77: \n",
      "Model Number: 42 of 84 with model ARDL for Validation 2\n",
      "42 - ARDL with avg smape 50.8: \n",
      "Model Number: 43 of 84 with model ARDL for Validation 2\n",
      "43 - ARDL with avg smape 48.89: \n",
      "Model Number: 44 of 84 with model ETS for Validation 2\n",
      "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
      "ETS failed on NET_SALES with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
      "44 - ETS with avg smape 50.85: \n",
      "Model Number: 45 of 84 with model GLS for Validation 2\n",
      "45 - GLS with avg smape 51.5: \n",
      "Model Number: 46 of 84 with model ARIMA for Validation 2\n",
      "46 - ARIMA with avg smape 54.19: \n",
      "Model Number: 47 of 84 with model ARDL for Validation 2\n",
      "47 - ARDL with avg smape 49.73: \n",
      "Model Number: 48 of 84 with model GLM for Validation 2\n",
      "48 - GLM with avg smape 51.42: \n",
      "Model Number: 49 of 84 with model GLM for Validation 2\n",
      "49 - GLM with avg smape 51.31: \n",
      "Model Number: 50 of 84 with model GLS for Validation 2\n",
      "50 - GLS with avg smape 51.47: \n",
      "Model Number: 51 of 84 with model MetricMotif for Validation 2\n",
      "📈 51 - MetricMotif with avg smape 45.62: \n",
      "Model Number: 52 of 84 with model GLS for Validation 2\n",
      "52 - GLS with avg smape 50.74: \n",
      "Model Number: 53 of 84 with model DatepartRegression for Validation 2\n",
      "53 - DatepartRegression with avg smape 49.82: \n",
      "Model Number: 54 of 84 with model GLS for Validation 2\n",
      "54 - GLS with avg smape 48.25: \n",
      "Model Number: 55 of 84 with model DatepartRegression for Validation 2\n",
      "55 - DatepartRegression with avg smape 48.12: \n",
      "Model Number: 56 of 84 with model MetricMotif for Validation 2\n",
      "Template Eval Error: ValueError('kth(=9) out of bounds (7)') in model 56 in generation 0: MetricMotif\n",
      "Model Number: 57 of 84 with model DatepartRegression for Validation 2\n",
      "57 - DatepartRegression with avg smape 49.18: \n",
      "Model Number: 58 of 84 with model MultivariateRegression for Validation 2\n",
      "58 - MultivariateRegression with avg smape 47.51: \n",
      "Model Number: 59 of 84 with model MultivariateRegression for Validation 2\n",
      "59 - MultivariateRegression with avg smape 47.5: \n",
      "Model Number: 60 of 84 with model MultivariateRegression for Validation 2\n",
      "📈 60 - MultivariateRegression with avg smape 43.14: \n",
      "Model Number: 61 of 84 with model MultivariateRegression for Validation 2\n",
      "61 - MultivariateRegression with avg smape 43.14: \n",
      "Model Number: 62 of 84 with model NVAR for Validation 2\n",
      "62 - NVAR with avg smape 51.99: \n",
      "Model Number: 63 of 84 with model UnobservedComponents for Validation 2\n",
      "📈 63 - UnobservedComponents with avg smape 40.98: \n",
      "Model Number: 64 of 84 with model NVAR for Validation 2\n",
      "64 - NVAR with avg smape 52.06: \n",
      "Model Number: 65 of 84 with model NVAR for Validation 2\n",
      "65 - NVAR with avg smape 52.25: \n",
      "Model Number: 66 of 84 with model NVAR for Validation 2\n",
      "66 - NVAR with avg smape 52.25: \n",
      "Model Number: 67 of 84 with model MetricMotif for Validation 2\n",
      "Template Eval Error: ValueError('kth(=9) out of bounds (7)') in model 67 in generation 0: MetricMotif\n",
      "Model Number: 68 of 84 with model UnobservedComponents for Validation 2\n",
      "📈 68 - UnobservedComponents with avg smape 35.16: \n",
      "Model Number: 69 of 84 with model UnobservedComponents for Validation 2\n",
      "69 - UnobservedComponents with avg smape 35.16: \n",
      "Model Number: 70 of 84 with model GLM for Validation 2\n",
      "70 - GLM with avg smape 45.51: \n",
      "Model Number: 71 of 84 with model LastValueNaive for Validation 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\statsmodels\\genmod\\families\\links.py:198: RuntimeWarning: overflow encountered in exp\n",
      "  t = np.exp(-z)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71 - LastValueNaive with avg smape 54.47: \n",
      "Model Number: 72 of 84 with model UnobservedComponents for Validation 2\n",
      "72 - UnobservedComponents with avg smape 52.36: \n",
      "Model Number: 73 of 84 with model ARIMA for Validation 2\n",
      "73 - ARIMA with avg smape 52.24: \n",
      "Model Number: 74 of 84 with model ARIMA for Validation 2\n",
      "74 - ARIMA with avg smape 53.96: \n",
      "Model Number: 75 of 84 with model NVAR for Validation 2\n",
      "75 - NVAR with avg smape 53.23: \n",
      "Model Number: 76 of 84 with model ARIMA for Validation 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\linear_model\\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.22635e-24): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76 - ARIMA with avg smape 49.52: \n",
      "Model Number: 77 of 84 with model ConstantNaive for Validation 2\n",
      "77 - ConstantNaive with avg smape 37.77: \n",
      "Model Number: 78 of 84 with model WindowRegression for Validation 2\n",
      "78 - WindowRegression with avg smape 39.92: \n",
      "Model Number: 79 of 84 with model DatepartRegression for Validation 2\n",
      "79 - DatepartRegression with avg smape 46.56: \n",
      "Model Number: 80 of 84 with model MultivariateRegression for Validation 2\n",
      "80 - MultivariateRegression with avg smape 42.46: \n",
      "Model Number: 81 of 84 with model GLM for Validation 2\n",
      "81 - GLM with avg smape 54.81: \n",
      "Model Number: 82 of 84 with model Theta for Validation 2\n",
      "82 - Theta with avg smape 49.92: \n",
      "Model Number: 83 of 84 with model LastValueNaive for Validation 2\n",
      "83 - LastValueNaive with avg smape 118.54: \n",
      "Model Number: 84 of 84 with model WindowRegression for Validation 2\n",
      "84 - WindowRegression with avg smape 48.97: \n",
      "Validation Round: 3\n",
      "Model Number: 1 of 84 with model SectionalMotif for Validation 3\n",
      "Template Eval Error: ValueError('kth(=3) out of bounds (2)') in model 1 in generation 0: SectionalMotif\n",
      "Model Number: 2 of 84 with model SectionalMotif for Validation 3\n",
      "Template Eval Error: ValueError('kth(=3) out of bounds (2)') in model 2 in generation 0: SectionalMotif\n",
      "Model Number: 3 of 84 with model SectionalMotif for Validation 3\n",
      "Template Eval Error: ValueError('kth(=5) out of bounds (4)') in model 3 in generation 0: SectionalMotif\n",
      "Model Number: 4 of 84 with model SectionalMotif for Validation 3\n",
      "Template Eval Error: ValueError('kth(=3) out of bounds (2)') in model 4 in generation 0: SectionalMotif\n",
      "Model Number: 5 of 84 with model WindowRegression for Validation 3\n",
      "📈 5 - WindowRegression with avg smape 16.45: \n",
      "Model Number: 6 of 84 with model UnivariateMotif for Validation 3\n",
      "6 - UnivariateMotif with avg smape 18.26: \n",
      "Model Number: 7 of 84 with model SectionalMotif for Validation 3\n",
      "Template Eval Error: ValueError('kth(=3) out of bounds (2)') in model 7 in generation 0: SectionalMotif\n",
      "Model Number: 8 of 84 with model MultivariateMotif for Validation 3\n",
      "8 - MultivariateMotif with avg smape 17.56: \n",
      "Model Number: 9 of 84 with model Theta for Validation 3\n",
      "9 - Theta with avg smape 17.09: \n",
      "Model Number: 10 of 84 with model MultivariateMotif for Validation 3\n",
      "10 - MultivariateMotif with avg smape 19.02: \n",
      "Model Number: 11 of 84 with model SeasonalNaive for Validation 3\n",
      "11 - SeasonalNaive with avg smape 26.32: \n",
      "Model Number: 12 of 84 with model SeasonalNaive for Validation 3\n",
      "Template Eval Error: Exception('Transformer RegressionFilter failed on fit') in model 12 in generation 0: SeasonalNaive\n",
      "Model Number: 13 of 84 with model UnivariateMotif for Validation 3\n",
      "13 - UnivariateMotif with avg smape 19.61: \n",
      "Model Number: 14 of 84 with model SeasonalNaive for Validation 3\n",
      "Template Eval Error: Exception('Transformer RegressionFilter failed on fit') in model 14 in generation 0: SeasonalNaive\n",
      "Model Number: 15 of 84 with model UnivariateMotif for Validation 3\n",
      "15 - UnivariateMotif with avg smape 18.04: \n",
      "Model Number: 16 of 84 with model SeasonalNaive for Validation 3\n",
      "16 - SeasonalNaive with avg smape 19.47: \n",
      "Model Number: 17 of 84 with model UnivariateMotif for Validation 3\n",
      "17 - UnivariateMotif with avg smape 27.51: \n",
      "Model Number: 18 of 84 with model AverageValueNaive for Validation 3\n",
      "18 - AverageValueNaive with avg smape 19.44: \n",
      "Model Number: 19 of 84 with model AverageValueNaive for Validation 3\n",
      "19 - AverageValueNaive with avg smape 20.03: \n",
      "Model Number: 20 of 84 with model UnobservedComponents for Validation 3\n",
      "20 - UnobservedComponents with avg smape 19.99: \n",
      "Model Number: 21 of 84 with model AverageValueNaive for Validation 3\n",
      "21 - AverageValueNaive with avg smape 19.99: \n",
      "Model Number: 22 of 84 with model AverageValueNaive for Validation 3\n",
      "22 - AverageValueNaive with avg smape 20.36: \n",
      "Model Number: 23 of 84 with model AverageValueNaive for Validation 3\n",
      "23 - AverageValueNaive with avg smape 19.05: \n",
      "Model Number: 24 of 84 with model MetricMotif for Validation 3\n",
      "Template Eval Error: ValueError('window shape cannot be larger than input array shape') in model 24 in generation 0: MetricMotif\n",
      "Model Number: 25 of 84 with model Theta for Validation 3\n",
      "25 - Theta with avg smape 24.08: \n",
      "Model Number: 26 of 84 with model MultivariateMotif for Validation 3\n",
      "26 - MultivariateMotif with avg smape 18.56: \n",
      "Model Number: 27 of 84 with model MetricMotif for Validation 3\n",
      "27 - MetricMotif with avg smape 16.88: \n",
      "Model Number: 28 of 84 with model ETS for Validation 3\n",
      "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
      "ETS failed on NET_SALES with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
      "28 - ETS with avg smape 19.99: \n",
      "Model Number: 29 of 84 with model MultivariateMotif for Validation 3\n",
      "29 - MultivariateMotif with avg smape 18.92: \n",
      "Model Number: 30 of 84 with model SeasonalNaive for Validation 3\n",
      "30 - SeasonalNaive with avg smape 26.37: \n",
      "Model Number: 31 of 84 with model UnivariateMotif for Validation 3\n",
      "📈 31 - UnivariateMotif with avg smape 15.32: \n",
      "Model Number: 32 of 84 with model MultivariateMotif for Validation 3\n",
      "32 - MultivariateMotif with avg smape 18.22: \n",
      "Model Number: 33 of 84 with model ETS for Validation 3\n",
      "Template Eval Error: Exception('Transformer RegressionFilter failed on fit') in model 33 in generation 0: ETS\n",
      "Model Number: 34 of 84 with model DatepartRegression for Validation 3\n",
      "34 - DatepartRegression with avg smape 20.75: \n",
      "Model Number: 35 of 84 with model ETS for Validation 3\n",
      "Template Eval Error: Exception('Transformer RegressionFilter failed on fit') in model 35 in generation 0: ETS\n",
      "Model Number: 36 of 84 with model ETS for Validation 3\n",
      "Template Eval Error: Exception('Transformer RegressionFilter failed on fit') in model 36 in generation 0: ETS\n",
      "Model Number: 37 of 84 with model ARDL for Validation 3\n",
      "37 - ARDL with avg smape 25.07: \n",
      "Model Number: 38 of 84 with model ARDL for Validation 3\n",
      "38 - ARDL with avg smape 20.01: \n",
      "Model Number: 39 of 84 with model GLM for Validation 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.849e+12, tolerance: 1.423e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.849e+12, tolerance: 1.423e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.849e+12, tolerance: 1.423e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39 - GLM with avg smape 20.0: \n",
      "Model Number: 40 of 84 with model GLS for Validation 3\n",
      "Template Eval Error: Exception('Transformer RegressionFilter failed on fit') in model 40 in generation 0: GLS\n",
      "Model Number: 41 of 84 with model ARIMA for Validation 3\n",
      "41 - ARIMA with avg smape 17.64: \n",
      "Model Number: 42 of 84 with model ARDL for Validation 3\n",
      "42 - ARDL with avg smape 20.38: \n",
      "Model Number: 43 of 84 with model ARDL for Validation 3\n",
      "43 - ARDL with avg smape 21.49: \n",
      "Model Number: 44 of 84 with model ETS for Validation 3\n",
      "Template Eval Error: Exception('Transformer RegressionFilter failed on fit') in model 44 in generation 0: ETS\n",
      "Model Number: 45 of 84 with model GLS for Validation 3\n",
      "45 - GLS with avg smape 19.99: \n",
      "Model Number: 46 of 84 with model ARIMA for Validation 3\n",
      "46 - ARIMA with avg smape 19.95: \n",
      "Model Number: 47 of 84 with model ARDL for Validation 3\n",
      "47 - ARDL with avg smape 21.16: \n",
      "Model Number: 48 of 84 with model GLM for Validation 3\n",
      "48 - GLM with avg smape 20.02: \n",
      "Model Number: 49 of 84 with model GLM for Validation 3\n",
      "49 - GLM with avg smape 20.04: \n",
      "Model Number: 50 of 84 with model GLS for Validation 3\n",
      "Template Eval Error: Exception('Transformer RegressionFilter failed on fit') in model 50 in generation 0: GLS\n",
      "Model Number: 51 of 84 with model MetricMotif for Validation 3\n",
      "51 - MetricMotif with avg smape 19.07: \n",
      "Model Number: 52 of 84 with model GLS for Validation 3\n",
      "52 - GLS with avg smape 20.24: \n",
      "Model Number: 53 of 84 with model DatepartRegression for Validation 3\n",
      "53 - DatepartRegression with avg smape 15.69: \n",
      "Model Number: 54 of 84 with model GLS for Validation 3\n",
      "54 - GLS with avg smape 21.78: \n",
      "Model Number: 55 of 84 with model DatepartRegression for Validation 3\n",
      "📈 55 - DatepartRegression with avg smape 15.26: \n",
      "Model Number: 56 of 84 with model MetricMotif for Validation 3\n",
      "Template Eval Error: ValueError('window shape cannot be larger than input array shape') in model 56 in generation 0: MetricMotif\n",
      "Model Number: 57 of 84 with model DatepartRegression for Validation 3\n",
      "📈 57 - DatepartRegression with avg smape 14.14: \n",
      "Model Number: 58 of 84 with model MultivariateRegression for Validation 3\n",
      "58 - MultivariateRegression with avg smape 22.9: \n",
      "Model Number: 59 of 84 with model MultivariateRegression for Validation 3\n",
      "59 - MultivariateRegression with avg smape 22.89: \n",
      "Model Number: 60 of 84 with model MultivariateRegression for Validation 3\n",
      "60 - MultivariateRegression with avg smape 25.72: \n",
      "Model Number: 61 of 84 with model MultivariateRegression for Validation 3\n",
      "61 - MultivariateRegression with avg smape 25.72: \n",
      "Model Number: 62 of 84 with model NVAR for Validation 3\n",
      "62 - NVAR with avg smape 20.24: \n",
      "Model Number: 63 of 84 with model UnobservedComponents for Validation 3\n",
      "63 - UnobservedComponents with avg smape 24.69: \n",
      "Model Number: 64 of 84 with model NVAR for Validation 3\n",
      "64 - NVAR with avg smape 20.37: \n",
      "Model Number: 65 of 84 with model NVAR for Validation 3\n",
      "65 - NVAR with avg smape 20.36: \n",
      "Model Number: 66 of 84 with model NVAR for Validation 3\n",
      "66 - NVAR with avg smape 20.36: \n",
      "Model Number: 67 of 84 with model MetricMotif for Validation 3\n",
      "Template Eval Error: ValueError('window shape cannot be larger than input array shape') in model 67 in generation 0: MetricMotif\n",
      "Model Number: 68 of 84 with model UnobservedComponents for Validation 3\n",
      "68 - UnobservedComponents with avg smape 60.6: \n",
      "Model Number: 69 of 84 with model UnobservedComponents for Validation 3\n",
      "69 - UnobservedComponents with avg smape 60.6: \n",
      "Model Number: 70 of 84 with model GLM for Validation 3\n",
      "70 - GLM with avg smape 25.09: \n",
      "Model Number: 71 of 84 with model LastValueNaive for Validation 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\statsmodels\\genmod\\families\\links.py:198: RuntimeWarning: overflow encountered in exp\n",
      "  t = np.exp(-z)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Template Eval Error: Exception('Transformer RegressionFilter failed on fit') in model 71 in generation 0: LastValueNaive\n",
      "Model Number: 72 of 84 with model UnobservedComponents for Validation 3\n",
      "72 - UnobservedComponents with avg smape 18.4: \n",
      "Model Number: 73 of 84 with model ARIMA for Validation 3\n",
      "73 - ARIMA with avg smape 19.9: \n",
      "Model Number: 74 of 84 with model ARIMA for Validation 3\n",
      "74 - ARIMA with avg smape 28.28: \n",
      "Model Number: 75 of 84 with model NVAR for Validation 3\n",
      "Template Eval Error: Exception('Transformer RegressionFilter failed on fit') in model 75 in generation 0: NVAR\n",
      "Model Number: 76 of 84 with model ARIMA for Validation 3\n",
      "76 - ARIMA with avg smape 46.41: \n",
      "Model Number: 77 of 84 with model ConstantNaive for Validation 3\n",
      "77 - ConstantNaive with avg smape 37.4: \n",
      "Model Number: 78 of 84 with model WindowRegression for Validation 3\n",
      "78 - WindowRegression with avg smape 65.02: \n",
      "Model Number: 79 of 84 with model DatepartRegression for Validation 3\n",
      "79 - DatepartRegression with avg smape 16.45: \n",
      "Model Number: 80 of 84 with model MultivariateRegression for Validation 3\n",
      "80 - MultivariateRegression with avg smape 25.15: \n",
      "Model Number: 81 of 84 with model GLM for Validation 3\n",
      "81 - GLM with avg smape 35.71: \n",
      "Model Number: 82 of 84 with model Theta for Validation 3\n",
      "82 - Theta with avg smape 42.42: \n",
      "Model Number: 83 of 84 with model LastValueNaive for Validation 3\n",
      "Template Eval Error: Exception('Transformer MinMaxScaler failed on fit') in model 83 in generation 0: LastValueNaive\n",
      "Model Number: 84 of 84 with model WindowRegression for Validation 3\n",
      "84 - WindowRegression with avg smape 23.78: \n",
      "TotalRuntime missing in 5!\n",
      "Validation Round: 1\n",
      "TotalRuntime missing in 0!\n",
      "Validation Round: 2\n",
      "TotalRuntime missing in 0!\n",
      "Validation Round: 3\n",
      "TotalRuntime missing in 0!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\crudek\\AppData\\Local\\Temp\\ipykernel_24392\\2714734623.py:60: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  all_predictions = all_predictions.append(temp_fcasts)\n",
      " 21%|██▏       | 3/14 [06:21<23:46, 129.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 6 cpus for n_jobs.\n",
      "Data frequency is: MS, used frequency is: MS\n",
      "Model Number: 1 with model ARIMA in generation 0 of 3\n",
      "Model Number: 2 with model AverageValueNaive in generation 0 of 3\n",
      "Model Number: 3 with model AverageValueNaive in generation 0 of 3\n",
      "Model Number: 4 with model AverageValueNaive in generation 0 of 3\n",
      "Model Number: 5 with model DatepartRegression in generation 0 of 3\n",
      "Model Number: 6 with model DatepartRegression in generation 0 of 3\n",
      "Model Number: 7 with model DatepartRegression in generation 0 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 8 with model DatepartRegression in generation 0 of 3\n",
      "Template Eval Error: ImportError('Tensorflow not available, install with pip install tensorflow.') in model 8 in generation 0: DatepartRegression\n",
      "Model Number: 9 with model ETS in generation 0 of 3\n",
      "Model Number: 10 with model ETS in generation 0 of 3\n",
      "Model Number: 11 with model GLM in generation 0 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:541: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 12 with model GLM in generation 0 of 3\n",
      "Model Number: 13 with model GLS in generation 0 of 3\n",
      "Model Number: 14 with model GLS in generation 0 of 3\n",
      "Model Number: 15 with model GluonTS in generation 0 of 3\n",
      "Template Eval Error: ImportError('GluonTS installation is incompatible with AutoTS. The numpy version is sometimes the issue, try 1.23.1 {as of 06-2023}') in model 15 in generation 0: GluonTS\n",
      "Model Number: 16 with model GluonTS in generation 0 of 3\n",
      "Template Eval Error: ImportError('GluonTS installation is incompatible with AutoTS. The numpy version is sometimes the issue, try 1.23.1 {as of 06-2023}') in model 16 in generation 0: GluonTS\n",
      "Model Number: 17 with model GluonTS in generation 0 of 3\n",
      "Template Eval Error: ImportError('GluonTS installation is incompatible with AutoTS. The numpy version is sometimes the issue, try 1.23.1 {as of 06-2023}') in model 17 in generation 0: GluonTS\n",
      "Model Number: 18 with model GluonTS in generation 0 of 3\n",
      "Template Eval Error: ImportError('GluonTS installation is incompatible with AutoTS. The numpy version is sometimes the issue, try 1.23.1 {as of 06-2023}') in model 18 in generation 0: GluonTS\n",
      "Model Number: 19 with model GluonTS in generation 0 of 3\n",
      "Template Eval Error: ImportError('GluonTS installation is incompatible with AutoTS. The numpy version is sometimes the issue, try 1.23.1 {as of 06-2023}') in model 19 in generation 0: GluonTS\n",
      "Model Number: 20 with model LastValueNaive in generation 0 of 3\n",
      "Model Number: 21 with model LastValueNaive in generation 0 of 3\n",
      "Model Number: 22 with model LastValueNaive in generation 0 of 3\n",
      "Model Number: 23 with model LastValueNaive in generation 0 of 3\n",
      "Model Number: 24 with model SeasonalNaive in generation 0 of 3\n",
      "Model Number: 25 with model SeasonalNaive in generation 0 of 3\n",
      "Model Number: 26 with model SeasonalNaive in generation 0 of 3\n",
      "Model Number: 27 with model UnobservedComponents in generation 0 of 3\n",
      "Model Number: 28 with model UnobservedComponents in generation 0 of 3\n",
      "Model Number: 29 with model UnobservedComponents in generation 0 of 3\n",
      "Model Number: 30 with model VAR in generation 0 of 3\n",
      "Template Eval Error: ValueError('Only gave one variable to VAR') in model 30 in generation 0: VAR\n",
      "Model Number: 31 with model VAR in generation 0 of 3\n",
      "Template Eval Error: ValueError('Only gave one variable to VAR') in model 31 in generation 0: VAR\n",
      "Model Number: 32 with model VECM in generation 0 of 3\n",
      "Template Eval Error: ValueError('Only gave one variable to VECM') in model 32 in generation 0: VECM\n",
      "Model Number: 33 with model VECM in generation 0 of 3\n",
      "Template Eval Error: ValueError('Only gave one variable to VECM') in model 33 in generation 0: VECM\n",
      "Model Number: 34 with model WindowRegression in generation 0 of 3\n",
      "Model Number: 35 with model ConstantNaive in generation 0 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:541: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 36 with model FBProphet in generation 0 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16:14:42 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:14:42 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 37 with model GluonTS in generation 0 of 3\n",
      "Template Eval Error: ImportError('GluonTS installation is incompatible with AutoTS. The numpy version is sometimes the issue, try 1.23.1 {as of 06-2023}') in model 37 in generation 0: GluonTS\n",
      "Model Number: 38 with model MultivariateRegression in generation 0 of 3\n",
      "Model Number: 39 with model MultivariateRegression in generation 0 of 3\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000028 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Model Number: 40 with model DatepartRegression in generation 0 of 3\n",
      "Model Number: 41 with model SeasonalNaive in generation 0 of 3\n",
      "Model Number: 42 with model DatepartRegression in generation 0 of 3\n",
      "Model Number: 43 with model UnobservedComponents in generation 0 of 3\n",
      "Model Number: 44 with model UnobservedComponents in generation 0 of 3\n",
      "Model Number: 45 with model ETS in generation 0 of 3\n",
      "Model Number: 46 with model VECM in generation 0 of 3\n",
      "Template Eval Error: ValueError('Only gave one variable to VECM') in model 46 in generation 0: VECM\n",
      "Model Number: 47 with model ARDL in generation 0 of 3\n",
      "Model Number: 48 with model MultivariateMotif in generation 0 of 3\n",
      "Model Number: 49 with model MultivariateMotif in generation 0 of 3\n",
      "Model Number: 50 with model UnivariateMotif in generation 0 of 3\n",
      "Template Eval Error: ValueError('kth(=10) out of bounds (1)') in model 50 in generation 0: UnivariateMotif\n",
      "Model Number: 51 with model UnivariateMotif in generation 0 of 3\n",
      "Model Number: 52 with model SectionalMotif in generation 0 of 3\n",
      "Model Number: 53 with model SectionalMotif in generation 0 of 3\n",
      "Model Number: 54 with model MultivariateRegression in generation 0 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16:14:45 - cmdstanpy - INFO - Chain [1] start processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 55 with model FBProphet in generation 0 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16:15:10 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 56 with model SeasonalNaive in generation 0 of 3\n",
      "Model Number: 57 with model DatepartRegression in generation 0 of 3\n",
      "Model Number: 58 with model NVAR in generation 0 of 3\n",
      "Model Number: 59 with model Theta in generation 0 of 3\n",
      "Model Number: 60 with model UnivariateRegression in generation 0 of 3\n",
      "Template Eval Error: ValueError('Input X contains NaN.\\nDecisionTreeRegressor does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values') in model 60 in generation 0: UnivariateRegression\n",
      "Model Number: 61 with model ARCH in generation 0 of 3\n",
      "Template Eval Error: ImportError('`arch` package must be installed from pip') in model 61 in generation 0: ARCH\n",
      "Model Number: 62 with model ConstantNaive in generation 0 of 3\n",
      "Model Number: 63 with model LastValueNaive in generation 0 of 3\n",
      "Model Number: 64 with model AverageValueNaive in generation 0 of 3\n",
      "Model Number: 65 with model GLS in generation 0 of 3\n",
      "Model Number: 66 with model SeasonalNaive in generation 0 of 3\n",
      "Model Number: 67 with model GLM in generation 0 of 3\n",
      "Template Eval Error: Exception('Transformer LocalLinearTrend failed on fit') in model 67 in generation 0: GLM\n",
      "Model Number: 68 with model ETS in generation 0 of 3\n",
      "Model Number: 69 with model FBProphet in generation 0 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16:15:11 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:15:11 - cmdstanpy - INFO - Chain [1] done processing\n",
      "16:15:11 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:15:11 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 70 with model GluonTS in generation 0 of 3\n",
      "Template Eval Error: ImportError('GluonTS installation is incompatible with AutoTS. The numpy version is sometimes the issue, try 1.23.1 {as of 06-2023}') in model 70 in generation 0: GluonTS\n",
      "Model Number: 71 with model UnobservedComponents in generation 0 of 3\n",
      "Model Number: 72 with model VAR in generation 0 of 3\n",
      "Template Eval Error: ValueError('Only gave one variable to VAR') in model 72 in generation 0: VAR\n",
      "Model Number: 73 with model VECM in generation 0 of 3\n",
      "Template Eval Error: ValueError('Only gave one variable to VECM') in model 73 in generation 0: VECM\n",
      "Model Number: 74 with model ARIMA in generation 0 of 3\n",
      "Model Number: 75 with model WindowRegression in generation 0 of 3\n",
      "Template Eval Error: ImportError('Tensorflow not available, install with pip install tensorflow.') in model 75 in generation 0: WindowRegression\n",
      "Model Number: 76 with model DatepartRegression in generation 0 of 3\n",
      "Template Eval Error: ImportError('Tensorflow not available, install with pip install tensorflow.') in model 76 in generation 0: DatepartRegression\n",
      "Model Number: 77 with model UnivariateRegression in generation 0 of 3\n",
      "Model Number: 78 with model MultivariateRegression in generation 0 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\linear_model\\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.48343e-24): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 79 with model UnivariateMotif in generation 0 of 3\n",
      "Model Number: 80 with model MultivariateMotif in generation 0 of 3\n",
      "Model Number: 81 with model SectionalMotif in generation 0 of 3\n",
      "Model Number: 82 with model NVAR in generation 0 of 3\n",
      "Model Number: 83 with model Theta in generation 0 of 3\n",
      "Model Number: 84 with model ARDL in generation 0 of 3\n",
      "Model Number: 85 with model ARCH in generation 0 of 3\n",
      "Template Eval Error: ImportError('`arch` package must be installed from pip') in model 85 in generation 0: ARCH\n",
      "Model Number: 86 with model MetricMotif in generation 0 of 3\n",
      "Template Eval Error: ValueError('kth(=99) out of bounds (63)') in model 86 in generation 0: MetricMotif\n",
      "Model Number: 87 with model NVAR in generation 0 of 3\n",
      "Model Number: 88 with model GLS in generation 0 of 3\n",
      "Model Number: 89 with model GLM in generation 0 of 3\n",
      "Model Number: 90 with model AverageValueNaive in generation 0 of 3\n",
      "Model Number: 91 with model ARCH in generation 0 of 3\n",
      "Template Eval Error: ImportError('`arch` package must be installed from pip') in model 91 in generation 0: ARCH\n",
      "Model Number: 92 with model VECM in generation 0 of 3\n",
      "Template Eval Error: ValueError('Only gave one variable to VECM') in model 92 in generation 0: VECM\n",
      "Model Number: 93 with model AverageValueNaive in generation 0 of 3\n",
      "Model Number: 94 with model UnivariateMotif in generation 0 of 3\n",
      "Template Eval Error: Exception('Transformer AlignLastValue failed on inverse') in model 94 in generation 0: UnivariateMotif\n",
      "Model Number: 95 with model NVAR in generation 0 of 3\n",
      "Model Number: 96 with model WindowRegression in generation 0 of 3\n",
      "Template Eval Error: Exception('Transformer AlignLastValue failed on inverse') in model 96 in generation 0: WindowRegression\n",
      "Model Number: 97 with model VECM in generation 0 of 3\n",
      "Template Eval Error: ValueError('Only gave one variable to VECM') in model 97 in generation 0: VECM\n",
      "Model Number: 98 with model Theta in generation 0 of 3\n",
      "Model Number: 99 with model GluonTS in generation 0 of 3\n",
      "Template Eval Error: ImportError('GluonTS installation is incompatible with AutoTS. The numpy version is sometimes the issue, try 1.23.1 {as of 06-2023}') in model 99 in generation 0: GluonTS\n",
      "Model Number: 100 with model DatepartRegression in generation 0 of 3\n",
      "Model Number: 101 with model ARDL in generation 0 of 3\n",
      "Model Number: 102 with model WindowRegression in generation 0 of 3\n",
      "Model Number: 103 with model ETS in generation 0 of 3\n",
      "Model Number: 104 with model GLM in generation 0 of 3\n",
      "Template Eval Error: ValueError('The first guess on the deviance function returned a nan.  This could be a boundary  problem and should be reported.') in model 104 in generation 0: GLM\n",
      "Model Number: 105 with model VECM in generation 0 of 3\n",
      "Template Eval Error: ValueError('Only gave one variable to VECM') in model 105 in generation 0: VECM\n",
      "Model Number: 106 with model ETS in generation 0 of 3\n",
      "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
      "ETS failed on NET_SALES with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
      "Model Number: 107 with model DatepartRegression in generation 0 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\statsmodels\\genmod\\families\\family.py:1367: ValueWarning: Negative binomial dispersion parameter alpha not set. Using default value alpha=1.0.\n",
      "  warnings.warn(\"Negative binomial dispersion parameter alpha not \"\n",
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\statsmodels\\genmod\\families\\family.py:1406: RuntimeWarning: invalid value encountered in log\n",
      "  resid_dev -= endog_alpha * np.log(endog_alpha / mu_alpha)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 108 with model UnobservedComponents in generation 0 of 3\n",
      "Model Number: 109 with model ARDL in generation 0 of 3\n",
      "Model Number: 110 with model SeasonalNaive in generation 0 of 3\n",
      "Model Number: 111 with model ETS in generation 0 of 3\n",
      "ETS error ValueError('Cannot compute initial seasonals using heuristic method with less than two full seasonal cycles in the data.')\n",
      "ETS failed on NET_SALES with ValueError('Cannot compute initial seasonals using heuristic method with less than two full seasonal cycles in the data.')\n",
      "Model Number: 112 with model ConstantNaive in generation 0 of 3\n",
      "Model Number: 113 with model LastValueNaive in generation 0 of 3\n",
      "Model Number: 114 with model ARDL in generation 0 of 3\n",
      "Model Number: 115 with model UnivariateMotif in generation 0 of 3\n",
      "Model Number: 116 with model GLS in generation 0 of 3\n",
      "Model Number: 117 with model SeasonalNaive in generation 0 of 3\n",
      "Model Number: 118 with model Theta in generation 0 of 3\n",
      "Model Number: 119 with model LastValueNaive in generation 0 of 3\n",
      "Template Eval Error: Exception('Transformer AlignLastValue failed on inverse') in model 119 in generation 0: LastValueNaive\n",
      "Model Number: 120 with model MetricMotif in generation 0 of 3\n",
      "Template Eval Error: ValueError('kth(=99) out of bounds (53)') in model 120 in generation 0: MetricMotif\n",
      "Model Number: 121 with model FBProphet in generation 0 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\linear_model\\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.48343e-24): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "16:15:16 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:15:17 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 122 with model ETS in generation 0 of 3\n",
      "Model Number: 123 with model UnivariateMotif in generation 0 of 3\n",
      "Template Eval Error: ValueError('kth(=100) out of bounds (51)') in model 123 in generation 0: UnivariateMotif\n",
      "Model Number: 124 with model ConstantNaive in generation 0 of 3\n",
      "Model Number: 125 with model LastValueNaive in generation 0 of 3\n",
      "Model Number: 126 with model GLS in generation 0 of 3\n",
      "Model Number: 127 with model UnobservedComponents in generation 0 of 3\n",
      "Model Number: 128 with model UnivariateMotif in generation 0 of 3\n",
      "Model Number: 129 with model GLS in generation 0 of 3\n",
      "Model Number: 130 with model MetricMotif in generation 0 of 3\n",
      "Model Number: 131 with model Theta in generation 0 of 3\n",
      "Model Number: 132 with model UnobservedComponents in generation 0 of 3\n",
      "Model Number: 133 with model ARIMA in generation 0 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\autots\\tools\\thresholding.py:204: RuntimeWarning: overflow encountered in double_scalars\n",
      "  (1 + mean_perc_decrease) ** self.mean_weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 134 with model SeasonalNaive in generation 0 of 3\n",
      "Model Number: 135 with model LastValueNaive in generation 0 of 3\n",
      "Model Number: 136 with model LastValueNaive in generation 0 of 3\n",
      "Model Number: 137 with model ARCH in generation 0 of 3\n",
      "Template Eval Error: ImportError('`arch` package must be installed from pip') in model 137 in generation 0: ARCH\n",
      "Model Number: 138 with model VAR in generation 0 of 3\n",
      "Template Eval Error: ValueError('Only gave one variable to VAR') in model 138 in generation 0: VAR\n",
      "Model Number: 139 with model ETS in generation 0 of 3\n",
      "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
      "ETS failed on NET_SALES with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
      "Model Number: 140 with model MultivariateMotif in generation 0 of 3\n",
      "Model Number: 141 with model DatepartRegression in generation 0 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.308e+12, tolerance: 2.896e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.946e+11, tolerance: 9.263e+07\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 142 with model ARIMA in generation 0 of 3\n",
      "Template Eval Error: Exception('Transformer AlignLastValue failed on inverse') in model 142 in generation 0: ARIMA\n",
      "Model Number: 143 with model GLM in generation 0 of 3\n",
      "Template Eval Error: ValueError('NaN, inf or invalid value detected in weights, estimation infeasible.') in model 143 in generation 0: GLM\n",
      "Model Number: 144 with model DatepartRegression in generation 0 of 3\n",
      "Template Eval Error: ValueError('Input X contains NaN.\\nExtraTreesRegressor does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values') in model 144 in generation 0: DatepartRegression\n",
      "Model Number: 145 with model VAR in generation 0 of 3\n",
      "Template Eval Error: ValueError('Only gave one variable to VAR') in model 145 in generation 0: VAR\n",
      "Model Number: 146 with model Theta in generation 0 of 3\n",
      "Model Number: 147 with model ETS in generation 0 of 3\n",
      "ETS error ValueError('Cannot compute initial seasonals using heuristic method with less than two full seasonal cycles in the data.')\n",
      "ETS failed on NET_SALES with ValueError('Cannot compute initial seasonals using heuristic method with less than two full seasonal cycles in the data.')\n",
      "Model Number: 148 with model ConstantNaive in generation 0 of 3\n",
      "Model Number: 149 with model ARDL in generation 0 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\statsmodels\\genmod\\families\\links.py:527: RuntimeWarning: overflow encountered in exp\n",
      "  return np.exp(z)\n",
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\statsmodels\\genmod\\families\\family.py:445: RuntimeWarning: divide by zero encountered in divide\n",
      "  endog_mu = self._clean(endog / mu)\n",
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\statsmodels\\genmod\\families\\family.py:143: RuntimeWarning: invalid value encountered in multiply\n",
      "  return 1. / (self.link.deriv(mu)**2 * self.variance(mu))\n",
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\statsmodels\\genmod\\families\\family.py:143: RuntimeWarning: divide by zero encountered in divide\n",
      "  return 1. / (self.link.deriv(mu)**2 * self.variance(mu))\n",
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\statsmodels\\genmod\\generalized_linear_model.py:1243: RuntimeWarning: invalid value encountered in multiply\n",
      "  wlsendog = (lin_pred + self.family.link.deriv(mu) * (self.endog-mu)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 150 with model SectionalMotif in generation 0 of 3\n",
      "Model Number: 151 with model VAR in generation 0 of 3\n",
      "Model Number: 152 with model DatepartRegression in generation 0 of 3\n",
      "Model Number: 153 with model Theta in generation 0 of 3\n",
      "Model Number: 154 with model MetricMotif in generation 0 of 3\n",
      "Model Number: 155 with model DatepartRegression in generation 0 of 3\n",
      "Model Number: 156 with model GLM in generation 0 of 3\n",
      "Model Number: 157 with model GluonTS in generation 0 of 3\n",
      "Template Eval Error: ImportError('GluonTS installation is incompatible with AutoTS. The numpy version is sometimes the issue, try 1.23.1 {as of 06-2023}') in model 157 in generation 0: GluonTS\n",
      "Model Number: 158 with model DatepartRegression in generation 0 of 3\n",
      "Template Eval Error: Exception('Transformer AlignLastValue failed on inverse') in model 158 in generation 0: DatepartRegression\n",
      "Model Number: 159 with model NVAR in generation 0 of 3\n",
      "Model Number: 160 with model GLS in generation 0 of 3\n",
      "Model Number: 161 with model SectionalMotif in generation 0 of 3\n",
      "Model Number: 162 with model FBProphet in generation 0 of 3"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\statsmodels\\genmod\\families\\links.py:198: RuntimeWarning: overflow encountered in exp\n",
      "  t = np.exp(-z)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16:15:20 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:15:20 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 163 with model ETS in generation 0 of 3\n",
      "Model Number: 164 with model VAR in generation 0 of 3\n",
      "Template Eval Error: ValueError('Only gave one variable to VAR') in model 164 in generation 0: VAR\n",
      "Model Number: 165 with model MultivariateMotif in generation 0 of 3\n",
      "Model Number: 166 with model VAR in generation 0 of 3\n",
      "Template Eval Error: ValueError('Only gave one variable to VAR') in model 166 in generation 0: VAR\n",
      "Model Number: 167 with model ARIMA in generation 0 of 3\n",
      "Model Number: 168 with model UnobservedComponents in generation 0 of 3\n",
      "Model Number: 169 with model UnivariateMotif in generation 0 of 3\n",
      "Template Eval Error: ValueError('kth(=100) out of bounds (51)') in model 169 in generation 0: UnivariateMotif\n",
      "Model Number: 170 with model VAR in generation 0 of 3\n",
      "Template Eval Error: ValueError('Only gave one variable to VAR') in model 170 in generation 0: VAR\n",
      "Model Number: 171 with model Theta in generation 0 of 3\n",
      "Model Number: 172 with model MultivariateMotif in generation 0 of 3\n",
      "Model Number: 173 with model UnobservedComponents in generation 0 of 3\n",
      "Model Number: 174 with model WindowRegression in generation 0 of 3\n",
      "Model Number: 175 with model SeasonalNaive in generation 0 of 3\n",
      "Model Number: 176 with model ARDL in generation 0 of 3\n",
      "Model Number: 177 with model GLS in generation 0 of 3\n",
      "Model Number: 178 with model SectionalMotif in generation 0 of 3\n",
      "Model Number: 179 with model ARDL in generation 0 of 3\n",
      "Model Number: 180 with model MultivariateMotif in generation 0 of 3\n",
      "Model Number: 181 with model ARCH in generation 0 of 3\n",
      "Template Eval Error: ImportError('`arch` package must be installed from pip') in model 181 in generation 0: ARCH\n",
      "Model Number: 182 with model SectionalMotif in generation 0 of 3\n",
      "Model Number: 183 with model ARIMA in generation 0 of 3\n",
      "Model Number: 184 with model DatepartRegression in generation 0 of 3\n",
      "Model Number: 185 with model ETS in generation 0 of 3\n",
      "ETS error ValueError('Cannot compute initial seasonals using heuristic method with less than two full seasonal cycles in the data.')\n",
      "ETS failed on NET_SALES with ValueError('Cannot compute initial seasonals using heuristic method with less than two full seasonal cycles in the data.')\n",
      "Model Number: 186 with model VECM in generation 0 of 3\n",
      "Template Eval Error: ValueError('Only gave one variable to VECM') in model 186 in generation 0: VECM\n",
      "New Generation: 1 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.588e-02, tolerance: 9.014e-04\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 187 with model GLS in generation 1 of 3\n",
      "Model Number: 188 with model DatepartRegression in generation 1 of 3\n",
      "Model Number: 189 with model VAR in generation 1 of 3\n",
      "Template Eval Error: ValueError('Only gave one variable to VAR') in model 189 in generation 1: VAR\n",
      "Model Number: 190 with model UnivariateMotif in generation 1 of 3\n",
      "Model Number: 191 with model GLM in generation 1 of 3\n",
      "Model Number: 192 with model UnivariateMotif in generation 1 of 3\n",
      "Model Number: 193 with model SectionalMotif in generation 1 of 3\n",
      "Template Eval Error: ValueError('kth(=20) out of bounds (6)') in model 193 in generation 1: SectionalMotif\n",
      "Model Number: 194 with model GLS in generation 1 of 3\n",
      "Model Number: 195 with model SeasonalNaive in generation 1 of 3\n",
      "Model Number: 196 with model SectionalMotif in generation 1 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.294e+12, tolerance: 2.870e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 197 with model SectionalMotif in generation 1 of 3\n",
      "Model Number: 198 with model ARDL in generation 1 of 3\n",
      "Model Number: 199 with model UnobservedComponents in generation 1 of 3\n",
      "Model Number: 200 with model SectionalMotif in generation 1 of 3\n",
      "Model Number: 201 with model ARDL in generation 1 of 3\n",
      "Template Eval Error: ValueError(\"ARDL series NET_SALES failed with error IndexError('tuple index out of range') exog train None and predict                    MONTH  COVID  AMZN\\nMONTH                                \\n2022-01-01  1.640995e+18    0.0   0.0\\n2022-02-01  1.643674e+18    0.0   0.0\\n2022-03-01  1.646093e+18    0.0   0.0\\n2022-04-01  1.648771e+18    0.0   0.0\\n2022-05-01  1.651363e+18    0.0   0.0\\n2022-06-01  1.654042e+18    0.0   0.0\\n2022-07-01  1.656634e+18    0.0   0.0\\n2022-08-01  1.659312e+18    0.0   0.0\\n2022-09-01  1.661990e+18    0.0   0.0\\n2022-10-01  1.664582e+18    0.0   0.0\\n2022-11-01  1.667261e+18    0.0   0.0\\n2022-12-01  1.669853e+18    0.0   0.0\") in model 201 in generation 1: ARDL\n",
      "Model Number: 202 with model UnobservedComponents in generation 1 of 3\n",
      "Model Number: 203 with model ConstantNaive in generation 1 of 3\n",
      "Model Number: 204 with model UnobservedComponents in generation 1 of 3\n",
      "Model Number: 205 with model ARIMA in generation 1 of 3\n",
      "Model Number: 206 with model UnobservedComponents in generation 1 of 3\n",
      "Template Eval Error: ValueError('Model UnobservedComponents returned NaN for one or more series. fail_on_forecast_nan=True') in model 206 in generation 1: UnobservedComponents\n",
      "Model Number: 207 with model Theta in generation 1 of 3\n",
      "Model Number: 208 with model SeasonalNaive in generation 1 of 3\n",
      "Model Number: 209 with model FBProphet in generation 1 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16:15:23 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:15:23 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 210 with model ETS in generation 1 of 3\n",
      "ETS error ValueError('Can only dampen the trend component')\n",
      "ETS failed on NET_SALES with ValueError('Can only dampen the trend component')\n",
      "Model Number: 211 with model NVAR in generation 1 of 3\n",
      "Model Number: 212 with model ARDL in generation 1 of 3\n",
      "Template Eval Error: ValueError(\"ARDL series NET_SALES failed with error ValueError('integer orders must be at least 1 when causal is True.') exog train                    MONTH  COVID  AMZN\\nMONTH                                \\n2016-01-01  1.451606e+18    0.0   0.0\\n2016-02-01  1.454285e+18    0.0   0.0\\n2016-03-01  1.456790e+18    0.0   0.0\\n2016-04-01  1.459469e+18    0.0   0.0\\n2016-05-01  1.462061e+18    0.0   0.0\\n...                  ...    ...   ...\\n2021-08-01  1.627776e+18    1.0   0.0\\n2021-09-01  1.630454e+18    1.0   0.0\\n2021-10-01  1.633046e+18    1.0   0.0\\n2021-11-01  1.635725e+18    1.0   0.0\\n2021-12-01  1.638317e+18    1.0   0.0\\n\\n[72 rows x 3 columns] and predict                    MONTH  COVID  AMZN\\nMONTH                                \\n2022-01-01  1.640995e+18    0.0   0.0\\n2022-02-01  1.643674e+18    0.0   0.0\\n2022-03-01  1.646093e+18    0.0   0.0\\n2022-04-01  1.648771e+18    0.0   0.0\\n2022-05-01  1.651363e+18    0.0   0.0\\n2022-06-01  1.654042e+18    0.0   0.0\\n2022-07-01  1.656634e+18    0.0   0.0\\n2022-08-01  1.659312e+18    0.0   0.0\\n2022-09-01  1.661990e+18    0.0   0.0\\n2022-10-01  1.664582e+18    0.0   0.0\\n2022-11-01  1.667261e+18    0.0   0.0\\n2022-12-01  1.669853e+18    0.0   0.0\") in model 212 in generation 1: ARDL\n",
      "Model Number: 213 with model SeasonalNaive in generation 1 of 3\n",
      "Model Number: 214 with model LastValueNaive in generation 1 of 3\n",
      "Model Number: 215 with model ARIMA in generation 1 of 3\n",
      "Model Number: 216 with model UnivariateRegression in generation 1 of 3\n",
      "Model Number: 217 with model ARDL in generation 1 of 3\n",
      "Model Number: 218 with model NVAR in generation 1 of 3\n",
      "Model Number: 219 with model UnobservedComponents in generation 1 of 3\n",
      "Model Number: 220 with model SeasonalNaive in generation 1 of 3\n",
      "Model Number: 221 with model Theta in generation 1 of 3\n",
      "Model Number: 222 with model LastValueNaive in generation 1 of 3\n",
      "Model Number: 223 with model SeasonalNaive in generation 1 of 3\n",
      "Model Number: 224 with model LastValueNaive in generation 1 of 3\n",
      "Model Number: 225 with model ETS in generation 1 of 3\n",
      "Model Number: 226 with model DatepartRegression in generation 1 of 3\n",
      "Template Eval Error: ImportError('Tensorflow not available, install with pip install tensorflow.') in model 226 in generation 1: DatepartRegression\n",
      "Model Number: 227 with model GLM in generation 1 of 3\n",
      "Model Number: 228 with model Theta in generation 1 of 3\n",
      "Model Number: 229 with model GLS in generation 1 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\decomposition\\_fastica.py:708: FutureWarning: Starting in v1.3, whiten=True should be specified as whiten='arbitrary-variance' (its current behaviour). This behavior is deprecated in 1.1 and will raise ValueError in 1.3.\n",
      "  return self._fit_transform(X, compute_sources=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 230 with model GLM in generation 1 of 3\n",
      "Model Number: 231 with model ARIMA in generation 1 of 3\n",
      "Model Number: 232 with model SeasonalNaive in generation 1 of 3\n",
      "Model Number: 233 with model UnobservedComponents in generation 1 of 3\n",
      "Model Number: 234 with model MultivariateRegression in generation 1 of 3\n",
      "Model Number: 235 with model MultivariateRegression in generation 1 of 3\n",
      "Template Eval Error: ValueError(\"Input X contains infinity or a value too large for dtype('float64').\") in model 235 in generation 1: MultivariateRegression\n",
      "Model Number: 236 with model GLM in generation 1 of 3\n",
      "Model Number: 237 with model GLS in generation 1 of 3\n",
      "Model Number: 238 with model UnobservedComponents in generation 1 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 239 with model SectionalMotif in generation 1 of 3\n",
      "Model Number: 240 with model AverageValueNaive in generation 1 of 3\n",
      "Model Number: 241 with model NVAR in generation 1 of 3\n",
      "Model Number: 242 with model AverageValueNaive in generation 1 of 3\n",
      "Model Number: 243 with model DatepartRegression in generation 1 of 3\n",
      "Template Eval Error: ValueError('Model DatepartRegression returned NaN for one or more series. fail_on_forecast_nan=True') in model 243 in generation 1: DatepartRegression\n",
      "Model Number: 244 with model ARDL in generation 1 of 3\n",
      "Model Number: 245 with model LastValueNaive in generation 1 of 3\n",
      "Model Number: 246 with model SeasonalNaive in generation 1 of 3\n",
      "Model Number: 247 with model SectionalMotif in generation 1 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\neighbors\\_regression.py:494: UserWarning: One or more samples have no neighbors within specified radius; predicting NaN.\n",
      "  warnings.warn(empty_warning_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 248 with model LastValueNaive in generation 1 of 3\n",
      "Model Number: 249 with model GLS in generation 1 of 3\n",
      "Model Number: 250 with model AverageValueNaive in generation 1 of 3\n",
      "Model Number: 251 with model GLM in generation 1 of 3\n",
      "Model Number: 252 with model DatepartRegression in generation 1 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\autots\\tools\\probabilistic.py:67: RuntimeWarning: invalid value encountered in divide\n",
      "  (prior_mu / prior_sigma**2) + ((n * data_mu) / prior_sigma**2)\n",
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\autots\\tools\\probabilistic.py:68: RuntimeWarning: divide by zero encountered in divide\n",
      "  ) / ((1 / prior_sigma**2) + (n / prior_sigma**2))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 253 with model UnivariateMotif in generation 1 of 3\n",
      "Model Number: 254 with model MetricMotif in generation 1 of 3\n",
      "Model Number: 255 with model ARDL in generation 1 of 3\n",
      "Model Number: 256 with model ETS in generation 1 of 3\n",
      "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
      "ETS failed on NET_SALES with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
      "Model Number: 257 with model ConstantNaive in generation 1 of 3\n",
      "Model Number: 258 with model GLS in generation 1 of 3\n",
      "Model Number: 259 with model AverageValueNaive in generation 1 of 3\n",
      "Model Number: 260 with model DatepartRegression in generation 1 of 3\n",
      "Model Number: 261 with model ARDL in generation 1 of 3\n",
      "Model Number: 262 with model ETS in generation 1 of 3\n",
      "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
      "ETS failed on NET_SALES with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
      "Model Number: 263 with model ARDL in generation 1 of 3\n",
      "Model Number: 264 with model SectionalMotif in generation 1 of 3\n",
      "Model Number: 265 with model ConstantNaive in generation 1 of 3\n",
      "Model Number: 266 with model LastValueNaive in generation 1 of 3\n",
      "Model Number: 267 with model AverageValueNaive in generation 1 of 3\n",
      "Model Number: 268 with model UnobservedComponents in generation 1 of 3\n",
      "Model Number: 269 with model MultivariateRegression in generation 1 of 3\n",
      "Model Number: 270 with model WindowRegression in generation 1 of 3\n",
      "Model Number: 271 with model AverageValueNaive in generation 1 of 3\n",
      "Model Number: 272 with model ConstantNaive in generation 1 of 3\n",
      "Model Number: 273 with model GLS in generation 1 of 3\n",
      "Model Number: 274 with model NVAR in generation 1 of 3\n",
      "Template Eval Error: Exception('Transformer Detrend failed on fit') in model 274 in generation 1: NVAR\n",
      "Model Number: 275 with model MultivariateMotif in generation 1 of 3\n",
      "Model Number: 276 with model MultivariateMotif in generation 1 of 3\n",
      "Model Number: 277 with model GLM in generation 1 of 3\n",
      "Model Number: 278 with model NVAR in generation 1 of 3\n",
      "Template Eval Error: Exception('Transformer AlignLastValue failed on inverse') in model 278 in generation 1: NVAR\n",
      "Model Number: 279 with model UnivariateMotif in generation 1 of 3\n",
      "Model Number: 280 with model ARIMA in generation 1 of 3\n",
      "Model Number: 281 with model Theta in generation 1 of 3\n",
      "Model Number: 282 with model ARIMA in generation 1 of 3\n",
      "Model Number: 283 with model NVAR in generation 1 of 3\n",
      "Model Number: 284 with model GLS in generation 1 of 3\n",
      "Model Number: 285 with model ARDL in generation 1 of 3\n",
      "Model Number: 286 with model AverageValueNaive in generation 1 of 3\n",
      "Model Number: 287 with model DatepartRegression in generation 1 of 3\n",
      "Model Number: 288 with model UnobservedComponents in generation 1 of 3\n",
      "Model Number: 289 with model FBProphet in generation 1 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16:15:36 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:15:36 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 290 with model UnobservedComponents in generation 1 of 3\n",
      "Model Number: 291 with model NVAR in generation 1 of 3\n",
      "Model Number: 292 with model DatepartRegression in generation 1 of 3\n",
      "Template Eval Error: ImportError('Tensorflow not available, install with pip install tensorflow.') in model 292 in generation 1: DatepartRegression\n",
      "Model Number: 293 with model Theta in generation 1 of 3\n",
      "Model Number: 294 with model LastValueNaive in generation 1 of 3\n",
      "Model Number: 295 with model DatepartRegression in generation 1 of 3\n",
      "Template Eval Error: Exception('Transformer Cointegration failed on fit') in model 295 in generation 1: DatepartRegression\n",
      "Model Number: 296 with model Theta in generation 1 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\linear_model\\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.48343e-24): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 297 with model NVAR in generation 1 of 3\n",
      "Model Number: 298 with model ETS in generation 1 of 3\n",
      "Model Number: 299 with model DatepartRegression in generation 1 of 3\n",
      "Model Number: 300 with model ConstantNaive in generation 1 of 3\n",
      "Model Number: 301 with model SeasonalNaive in generation 1 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16:15:37 - cmdstanpy - INFO - Chain [1] start processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 302 with model MetricMotif in generation 1 of 3\n",
      "Template Eval Error: ValueError('kth(=99) out of bounds (63)') in model 302 in generation 1: MetricMotif\n",
      "Model Number: 303 with model FBProphet in generation 1 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16:15:38 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 304 with model Theta in generation 1 of 3\n",
      "Model Number: 305 with model WindowRegression in generation 1 of 3\n",
      "Model Number: 306 with model ETS in generation 1 of 3\n",
      "Template Eval Error: Exception('Transformer BTCD failed on fit') in model 306 in generation 1: ETS\n",
      "Model Number: 307 with model LastValueNaive in generation 1 of 3\n",
      "Model Number: 308 with model UnivariateMotif in generation 1 of 3\n",
      "Model Number: 309 with model SectionalMotif in generation 1 of 3\n",
      "Model Number: 310 with model SectionalMotif in generation 1 of 3\n",
      "Model Number: 311 with model NVAR in generation 1 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:541: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Generation: 2 of 3\n",
      "Model Number: 312 with model GLS in generation 2 of 3\n",
      "Model Number: 313 with model ETS in generation 2 of 3\n",
      "Model Number: 314 with model FBProphet in generation 2 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16:15:39 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:15:39 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 315 with model MultivariateRegression in generation 2 of 3\n",
      "Model Number: 316 with model LastValueNaive in generation 2 of 3\n",
      "Model Number: 317 with model NVAR in generation 2 of 3\n",
      "Model Number: 318 with model ConstantNaive in generation 2 of 3\n",
      "Model Number: 319 with model WindowRegression in generation 2 of 3\n",
      "Model Number: 320 with model WindowRegression in generation 2 of 3\n",
      "Model Number: 321 with model AverageValueNaive in generation 2 of 3\n",
      "Model Number: 322 with model MultivariateMotif in generation 2 of 3\n",
      "Model Number: 323 with model ConstantNaive in generation 2 of 3\n",
      "Model Number: 324 with model SectionalMotif in generation 2 of 3\n",
      "Model Number: 325 with model SectionalMotif in generation 2 of 3\n",
      "Model Number: 326 with model NVAR in generation 2 of 3\n",
      "Model Number: 327 with model ARDL in generation 2 of 3\n",
      "Model Number: 328 with model GLS in generation 2 of 3\n",
      "Model Number: 329 with model ARIMA in generation 2 of 3\n",
      "Model Number: 330 with model NVAR in generation 2 of 3\n",
      "Model Number: 331 with model GLM in generation 2 of 3\n",
      "Model Number: 332 with model ARDL in generation 2 of 3\n",
      "Model Number: 333 with model GLS in generation 2 of 3\n",
      "Model Number: 334 with model ARDL in generation 2 of 3\n",
      "Template Eval Error: Exception('Transformer Detrend failed on fit') in model 334 in generation 2: ARDL\n",
      "Model Number: 335 with model GLS in generation 2 of 3\n",
      "Model Number: 336 with model GLM in generation 2 of 3\n",
      "Model Number: 337 with model GLM in generation 2 of 3\n",
      "Model Number: 338 with model AverageValueNaive in generation 2 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\decomposition\\_fastica.py:708: FutureWarning: Starting in v1.3, whiten=True should be specified as whiten='arbitrary-variance' (its current behaviour). This behavior is deprecated in 1.1 and will raise ValueError in 1.3.\n",
      "  return self._fit_transform(X, compute_sources=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Template Eval Error: Exception('Transformer Cointegration failed on fit') in model 338 in generation 2: AverageValueNaive\n",
      "Model Number: 339 with model ARDL in generation 2 of 3\n",
      "Model Number: 340 with model GLS in generation 2 of 3\n",
      "Template Eval Error: Exception('Transformer RegressionFilter failed on fit') in model 340 in generation 2: GLS\n",
      "Model Number: 341 with model LastValueNaive in generation 2 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\linear_model\\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.48343e-24): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 342 with model UnobservedComponents in generation 2 of 3\n",
      "Model Number: 343 with model LastValueNaive in generation 2 of 3\n",
      "Model Number: 344 with model ARIMA in generation 2 of 3\n",
      "Template Eval Error: Exception('Transformer Cointegration failed on fit') in model 344 in generation 2: ARIMA\n",
      "Model Number: 345 with model ARIMA in generation 2 of 3\n",
      "Model Number: 346 with model AverageValueNaive in generation 2 of 3\n",
      "Model Number: 347 with model DatepartRegression in generation 2 of 3\n",
      "Model Number: 348 with model AverageValueNaive in generation 2 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.790e+11, tolerance: 3.611e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 349 with model SeasonalNaive in generation 2 of 3\n",
      "Model Number: 350 with model UnivariateMotif in generation 2 of 3\n",
      "Model Number: 351 with model GLM in generation 2 of 3\n",
      "Template Eval Error: ValueError('NaN, inf or invalid value detected in weights, estimation infeasible.') in model 351 in generation 2: GLM\n",
      "Model Number: 352 with model UnobservedComponents in generation 2 of 3\n",
      "Model Number: 353 with model ConstantNaive in generation 2 of 3\n",
      "Model Number: 354 with model ARDL in generation 2 of 3\n",
      "Model Number: 355 with model Theta in generation 2 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\statsmodels\\genmod\\families\\family.py:1367: ValueWarning: Negative binomial dispersion parameter alpha not set. Using default value alpha=1.0.\n",
      "  warnings.warn(\"Negative binomial dispersion parameter alpha not \"\n",
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\statsmodels\\genmod\\families\\family.py:1402: RuntimeWarning: divide by zero encountered in divide\n",
      "  endog_mu = self._clean(endog / mu)\n",
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\statsmodels\\genmod\\families\\family.py:1406: RuntimeWarning: invalid value encountered in log\n",
      "  resid_dev -= endog_alpha * np.log(endog_alpha / mu_alpha)\n",
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\statsmodels\\genmod\\families\\links.py:527: RuntimeWarning: overflow encountered in exp\n",
      "  return np.exp(z)\n",
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\statsmodels\\genmod\\families\\family.py:1406: RuntimeWarning: divide by zero encountered in log\n",
      "  resid_dev -= endog_alpha * np.log(endog_alpha / mu_alpha)\n",
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\numpy\\core\\fromnumeric.py:86: RuntimeWarning: invalid value encountered in reduce\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n",
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\statsmodels\\genmod\\families\\family.py:143: RuntimeWarning: invalid value encountered in multiply\n",
      "  return 1. / (self.link.deriv(mu)**2 * self.variance(mu))\n",
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\statsmodels\\genmod\\generalized_linear_model.py:1243: RuntimeWarning: invalid value encountered in multiply\n",
      "  wlsendog = (lin_pred + self.family.link.deriv(mu) * (self.endog-mu)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 356 with model ARIMA in generation 2 of 3\n",
      "Model Number: 357 with model UnivariateMotif in generation 2 of 3\n",
      "Template Eval Error: Exception('Transformer BTCD failed on fit') in model 357 in generation 2: UnivariateMotif\n",
      "Model Number: 358 with model ETS in generation 2 of 3\n",
      "Model Number: 359 with model NVAR in generation 2 of 3\n",
      "Model Number: 360 with model SectionalMotif in generation 2 of 3\n",
      "Model Number: 361 with model LastValueNaive in generation 2 of 3\n",
      "Model Number: 362 with model ETS in generation 2 of 3\n",
      "Model Number: 363 with model AverageValueNaive in generation 2 of 3\n",
      "Model Number: 364 with model ETS in generation 2 of 3\n",
      "Template Eval Error: Exception('Transformer BTCD failed on fit') in model 364 in generation 2: ETS\n",
      "Model Number: 365 with model ARIMA in generation 2 of 3\n",
      "Model Number: 366 with model GLS in generation 2 of 3\n",
      "Model Number: 367 with model MultivariateRegression in generation 2 of 3\n",
      "Model Number: 368 with model SeasonalNaive in generation 2 of 3\n",
      "Model Number: 369 with model WindowRegression in generation 2 of 3\n",
      "Template Eval Error: ImportError('Tensorflow not available, install with pip install tensorflow.') in model 369 in generation 2: WindowRegression\n",
      "Model Number: 370 with model AverageValueNaive in generation 2 of 3\n",
      "Model Number: 371 with model NVAR in generation 2 of 3\n",
      "Model Number: 372 with model ConstantNaive in generation 2 of 3\n",
      "Model Number: 373 with model SeasonalNaive in generation 2 of 3\n",
      "Model Number: 374 with model ARDL in generation 2 of 3\n",
      "Model Number: 375 with model ETS in generation 2 of 3\n",
      "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
      "ETS failed on NET_SALES with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
      "Model Number: 376 with model ARIMA in generation 2 of 3\n",
      "Model Number: 377 with model UnobservedComponents in generation 2 of 3\n",
      "Model Number: 378 with model MetricMotif in generation 2 of 3\n",
      "Model Number: 379 with model FBProphet in generation 2 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16:15:53 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:15:53 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 380 with model ETS in generation 2 of 3\n",
      "Model Number: 381 with model UnobservedComponents in generation 2 of 3\n",
      "Model Number: 382 with model SeasonalNaive in generation 2 of 3\n",
      "Model Number: 383 with model LastValueNaive in generation 2 of 3\n",
      "Model Number: 384 with model LastValueNaive in generation 2 of 3\n",
      "Model Number: 385 with model NVAR in generation 2 of 3\n",
      "Model Number: 386 with model UnobservedComponents in generation 2 of 3\n",
      "Model Number: 387 with model SeasonalNaive in generation 2 of 3\n",
      "Model Number: 388 with model ARIMA in generation 2 of 3\n",
      "Model Number: 389 with model GLS in generation 2 of 3\n",
      "Model Number: 390 with model LastValueNaive in generation 2 of 3\n",
      "Model Number: 391 with model UnobservedComponents in generation 2 of 3\n",
      "Model Number: 392 with model Theta in generation 2 of 3\n",
      "Model Number: 393 with model SectionalMotif in generation 2 of 3\n",
      "Template Eval Error: ValueError('Unknown Distance Metric: kulsinski') in model 393 in generation 2: SectionalMotif\n",
      "Model Number: 394 with model ARDL in generation 2 of 3\n",
      "Template Eval Error: ValueError(\"ARDL series NET_SALES failed with error ValueError('integer orders must be at least 1 when causal is True.') exog train             weekend  quarter      epoch  month_1  month_2  month_3  month_4  \\\\\\nMONTH                                                                         \\n2016-01-01        0        1  2457388.5      1.0      0.0      0.0      0.0   \\n2016-02-01        0        1  2457419.5      0.0      1.0      0.0      0.0   \\n2016-03-01        0        1  2457448.5      0.0      0.0      1.0      0.0   \\n2016-04-01        0        2  2457479.5      0.0      0.0      0.0      1.0   \\n2016-05-01        1        2  2457509.5      0.0      0.0      0.0      0.0   \\n...             ...      ...        ...      ...      ...      ...      ...   \\n2021-08-01        1        3  2459427.5      0.0      0.0      0.0      0.0   \\n2021-09-01        0        3  2459458.5      0.0      0.0      0.0      0.0   \\n2021-10-01        0        4  2459488.5      0.0      0.0      0.0      0.0   \\n2021-11-01        0        4  2459519.5      0.0      0.0      0.0      0.0   \\n2021-12-01        0        4  2459549.5      0.0      0.0      0.0      0.0   \\n\\n            month_5  month_6  month_7  ...  day_27  day_28  day_29  day_30  \\\\\\nMONTH                                  ...                                   \\n2016-01-01      0.0      0.0      0.0  ...     0.0     0.0     0.0     0.0   \\n2016-02-01      0.0      0.0      0.0  ...     0.0     0.0     0.0     0.0   \\n2016-03-01      0.0      0.0      0.0  ...     0.0     0.0     0.0     0.0   \\n2016-04-01      0.0      0.0      0.0  ...     0.0     0.0     0.0     0.0   \\n2016-05-01      1.0      0.0      0.0  ...     0.0     0.0     0.0     0.0   \\n...             ...      ...      ...  ...     ...     ...     ...     ...   \\n2021-08-01      0.0      0.0      0.0  ...     0.0     0.0     0.0     0.0   \\n2021-09-01      0.0      0.0      0.0  ...     0.0     0.0     0.0     0.0   \\n2021-10-01      0.0      0.0      0.0  ...     0.0     0.0     0.0     0.0   \\n2021-11-01      0.0      0.0      0.0  ...     0.0     0.0     0.0     0.0   \\n2021-12-01      0.0      0.0      0.0  ...     0.0     0.0     0.0     0.0   \\n\\n            day_31  weekdayofmonth_1  weekdayofmonth_2  weekdayofmonth_3  \\\\\\nMONTH                                                                      \\n2016-01-01     0.0               1.0               0.0               0.0   \\n2016-02-01     0.0               1.0               0.0               0.0   \\n2016-03-01     0.0               1.0               0.0               0.0   \\n2016-04-01     0.0               1.0               0.0               0.0   \\n2016-05-01     0.0               1.0               0.0               0.0   \\n...            ...               ...               ...               ...   \\n2021-08-01     0.0               1.0               0.0               0.0   \\n2021-09-01     0.0               1.0               0.0               0.0   \\n2021-10-01     0.0               1.0               0.0               0.0   \\n2021-11-01     0.0               1.0               0.0               0.0   \\n2021-12-01     0.0               1.0               0.0               0.0   \\n\\n            weekdayofmonth_4  weekdayofmonth_5  \\nMONTH                                           \\n2016-01-01               0.0               0.0  \\n2016-02-01               0.0               0.0  \\n2016-03-01               0.0               0.0  \\n2016-04-01               0.0               0.0  \\n2016-05-01               0.0               0.0  \\n...                      ...               ...  \\n2021-08-01               0.0               0.0  \\n2021-09-01               0.0               0.0  \\n2021-10-01               0.0               0.0  \\n2021-11-01               0.0               0.0  \\n2021-12-01               0.0               0.0  \\n\\n[72 rows x 58 columns] and predict             weekend  quarter      epoch  month_1  month_2  month_3  month_4  \\\\\\n2022-01-01        1        1  2459580.5      1.0      0.0      0.0      0.0   \\n2022-02-01        0        1  2459611.5      0.0      1.0      0.0      0.0   \\n2022-03-01        0        1  2459639.5      0.0      0.0      1.0      0.0   \\n2022-04-01        0        2  2459670.5      0.0      0.0      0.0      1.0   \\n2022-05-01        1        2  2459700.5      0.0      0.0      0.0      0.0   \\n2022-06-01        0        2  2459731.5      0.0      0.0      0.0      0.0   \\n2022-07-01        0        3  2459761.5      0.0      0.0      0.0      0.0   \\n2022-08-01        0        3  2459792.5      0.0      0.0      0.0      0.0   \\n2022-09-01        0        3  2459823.5      0.0      0.0      0.0      0.0   \\n2022-10-01        1        4  2459853.5      0.0      0.0      0.0      0.0   \\n2022-11-01        0        4  2459884.5      0.0      0.0      0.0      0.0   \\n2022-12-01        0        4  2459914.5      0.0      0.0      0.0      0.0   \\n\\n            month_5  month_6  month_7  ...  day_27  day_28  day_29  day_30  \\\\\\n2022-01-01      0.0      0.0      0.0  ...     0.0     0.0     0.0     0.0   \\n2022-02-01      0.0      0.0      0.0  ...     0.0     0.0     0.0     0.0   \\n2022-03-01      0.0      0.0      0.0  ...     0.0     0.0     0.0     0.0   \\n2022-04-01      0.0      0.0      0.0  ...     0.0     0.0     0.0     0.0   \\n2022-05-01      1.0      0.0      0.0  ...     0.0     0.0     0.0     0.0   \\n2022-06-01      0.0      1.0      0.0  ...     0.0     0.0     0.0     0.0   \\n2022-07-01      0.0      0.0      1.0  ...     0.0     0.0     0.0     0.0   \\n2022-08-01      0.0      0.0      0.0  ...     0.0     0.0     0.0     0.0   \\n2022-09-01      0.0      0.0      0.0  ...     0.0     0.0     0.0     0.0   \\n2022-10-01      0.0      0.0      0.0  ...     0.0     0.0     0.0     0.0   \\n2022-11-01      0.0      0.0      0.0  ...     0.0     0.0     0.0     0.0   \\n2022-12-01      0.0      0.0      0.0  ...     0.0     0.0     0.0     0.0   \\n\\n            day_31  weekdayofmonth_1  weekdayofmonth_2  weekdayofmonth_3  \\\\\\n2022-01-01     0.0               1.0               0.0               0.0   \\n2022-02-01     0.0               1.0               0.0               0.0   \\n2022-03-01     0.0               1.0               0.0               0.0   \\n2022-04-01     0.0               1.0               0.0               0.0   \\n2022-05-01     0.0               1.0               0.0               0.0   \\n2022-06-01     0.0               1.0               0.0               0.0   \\n2022-07-01     0.0               1.0               0.0               0.0   \\n2022-08-01     0.0               1.0               0.0               0.0   \\n2022-09-01     0.0               1.0               0.0               0.0   \\n2022-10-01     0.0               1.0               0.0               0.0   \\n2022-11-01     0.0               1.0               0.0               0.0   \\n2022-12-01     0.0               1.0               0.0               0.0   \\n\\n            weekdayofmonth_4  weekdayofmonth_5  \\n2022-01-01               0.0               0.0  \\n2022-02-01               0.0               0.0  \\n2022-03-01               0.0               0.0  \\n2022-04-01               0.0               0.0  \\n2022-05-01               0.0               0.0  \\n2022-06-01               0.0               0.0  \\n2022-07-01               0.0               0.0  \\n2022-08-01               0.0               0.0  \\n2022-09-01               0.0               0.0  \\n2022-10-01               0.0               0.0  \\n2022-11-01               0.0               0.0  \\n2022-12-01               0.0               0.0  \\n\\n[12 rows x 58 columns]\") in model 394 in generation 2: ARDL\n",
      "Model Number: 395 with model UnobservedComponents in generation 2 of 3\n",
      "Template Eval Error: Exception('Transformer AlignLastValue failed on inverse') in model 395 in generation 2: UnobservedComponents\n",
      "Model Number: 396 with model ARDL in generation 2 of 3\n",
      "Model Number: 397 with model GLS in generation 2 of 3\n",
      "Model Number: 398 with model ETS in generation 2 of 3\n",
      "ETS error ValueError('Can only dampen the trend component')\n",
      "ETS failed on NET_SALES with ValueError('Can only dampen the trend component')\n",
      "Model Number: 399 with model ARIMA in generation 2 of 3\n",
      "Model Number: 400 with model MultivariateMotif in generation 2 of 3\n",
      "Model Number: 401 with model Theta in generation 2 of 3\n",
      "Model Number: 402 with model GLM in generation 2 of 3\n",
      "Model Number: 403 with model MultivariateRegression in generation 2 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\linear_model\\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.48343e-24): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\statsmodels\\genmod\\families\\links.py:198: RuntimeWarning: overflow encountered in exp\n",
      "  t = np.exp(-z)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 404 with model SectionalMotif in generation 2 of 3\n",
      "Model Number: 405 with model GLS in generation 2 of 3\n",
      "Model Number: 406 with model SeasonalNaive in generation 2 of 3\n",
      "Model Number: 407 with model AverageValueNaive in generation 2 of 3\n",
      "Model Number: 408 with model GLM in generation 2 of 3\n",
      "Template Eval Error: Exception('Transformer ScipyFilter failed on fit') in model 408 in generation 2: GLM\n",
      "Model Number: 409 with model SeasonalNaive in generation 2 of 3\n",
      "Model Number: 410 with model DatepartRegression in generation 2 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\decomposition\\_fastica.py:583: UserWarning: Ignoring n_components with whiten=False.\n",
      "  warnings.warn(\"Ignoring n_components with whiten=False.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 411 with model UnobservedComponents in generation 2 of 3\n",
      "Model Number: 412 with model NVAR in generation 2 of 3\n",
      "Model Number: 413 with model VAR in generation 2 of 3\n",
      "Template Eval Error: ValueError('Only gave one variable to VAR') in model 413 in generation 2: VAR\n",
      "Model Number: 414 with model DatepartRegression in generation 2 of 3\n",
      "Model Number: 415 with model ETS in generation 2 of 3\n",
      "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
      "ETS failed on NET_SALES with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
      "Model Number: 416 with model LastValueNaive in generation 2 of 3\n",
      "Model Number: 417 with model NVAR in generation 2 of 3\n",
      "Model Number: 418 with model AverageValueNaive in generation 2 of 3\n",
      "Template Eval Error: Exception('Transformer BTCD failed on fit') in model 418 in generation 2: AverageValueNaive\n",
      "Model Number: 419 with model DatepartRegression in generation 2 of 3\n",
      "Model Number: 420 with model ETS in generation 2 of 3\n",
      "Model Number: 421 with model MultivariateRegression in generation 2 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\linear_model\\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.48343e-24): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\linear_model\\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=3.02197e-36): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 422 with model UnivariateMotif in generation 2 of 3\n",
      "Model Number: 423 with model DatepartRegression in generation 2 of 3\n",
      "Template Eval Error: ImportError('Tensorflow not available, install with pip install tensorflow.') in model 423 in generation 2: DatepartRegression\n",
      "Model Number: 424 with model GLS in generation 2 of 3\n",
      "Model Number: 425 with model SeasonalNaive in generation 2 of 3\n",
      "Model Number: 426 with model AverageValueNaive in generation 2 of 3\n",
      "Template Eval Error: Exception('Transformer BTCD failed on fit') in model 426 in generation 2: AverageValueNaive\n",
      "Model Number: 427 with model GLM in generation 2 of 3\n",
      "Model Number: 428 with model LastValueNaive in generation 2 of 3\n",
      "Template Eval Error: Exception('Transformer BTCD failed on fit') in model 428 in generation 2: LastValueNaive\n",
      "Model Number: 429 with model MetricMotif in generation 2 of 3\n",
      "Model Number: 430 with model AverageValueNaive in generation 2 of 3\n",
      "Model Number: 431 with model SectionalMotif in generation 2 of 3\n",
      "Template Eval Error: ValueError('zero-size array to reduction operation fmax which has no identity') in model 431 in generation 2: SectionalMotif\n",
      "Model Number: 432 with model NVAR in generation 2 of 3\n",
      "Model Number: 433 with model UnobservedComponents in generation 2 of 3\n",
      "Model Number: 434 with model UnivariateMotif in generation 2 of 3\n",
      "Template Eval Error: Exception('Transformer BTCD failed on fit') in model 434 in generation 2: UnivariateMotif\n",
      "Model Number: 435 with model GLM in generation 2 of 3\n",
      "Model Number: 436 with model UnobservedComponents in generation 2 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis, **keepdims_kw)\n",
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\numpy\\core\\_methods.py:182: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = um.true_divide(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Generation: 3 of 3\n",
      "Model Number: 437 with model GLS in generation 3 of 3\n",
      "Model Number: 438 with model MultivariateRegression in generation 3 of 3\n",
      "Model Number: 439 with model GLM in generation 3 of 3\n",
      "Model Number: 440 with model LastValueNaive in generation 3 of 3\n",
      "Model Number: 441 with model UnobservedComponents in generation 3 of 3\n",
      "Model Number: 442 with model AverageValueNaive in generation 3 of 3\n",
      "Model Number: 443 with model ARIMA in generation 3 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\statsmodels\\genmod\\families\\links.py:198: RuntimeWarning: overflow encountered in exp\n",
      "  t = np.exp(-z)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 444 with model AverageValueNaive in generation 3 of 3\n",
      "Model Number: 445 with model UnobservedComponents in generation 3 of 3\n",
      "Model Number: 446 with model DatepartRegression in generation 3 of 3\n",
      "Template Eval Error: ValueError('Model DatepartRegression returned NaN for one or more series. fail_on_forecast_nan=True') in model 446 in generation 3: DatepartRegression\n",
      "Model Number: 447 with model MultivariateRegression in generation 3 of 3\n",
      "Template Eval Error: Exception('Transformer RobustScaler failed on fit') in model 447 in generation 3: MultivariateRegression\n",
      "Model Number: 448 with model UnobservedComponents in generation 3 of 3\n",
      "Model Number: 449 with model GLS in generation 3 of 3\n",
      "Model Number: 450 with model ConstantNaive in generation 3 of 3\n",
      "Model Number: 451 with model AverageValueNaive in generation 3 of 3\n",
      "Template Eval Error: Exception('Transformer Cointegration failed on fit') in model 451 in generation 3: AverageValueNaive\n",
      "Model Number: 452 with model ARDL in generation 3 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\neighbors\\_regression.py:494: UserWarning: One or more samples have no neighbors within specified radius; predicting NaN.\n",
      "  warnings.warn(empty_warning_msg)\n",
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\autots\\tools\\probabilistic.py:67: RuntimeWarning: invalid value encountered in divide\n",
      "  (prior_mu / prior_sigma**2) + ((n * data_mu) / prior_sigma**2)\n",
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\autots\\tools\\probabilistic.py:68: RuntimeWarning: divide by zero encountered in divide\n",
      "  ) / ((1 / prior_sigma**2) + (n / prior_sigma**2))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 453 with model NVAR in generation 3 of 3\n",
      "Model Number: 454 with model LastValueNaive in generation 3 of 3\n",
      "Template Eval Error: Exception('Transformer Detrend failed on fit') in model 454 in generation 3: LastValueNaive\n",
      "Model Number: 455 with model ARIMA in generation 3 of 3\n",
      "Model Number: 456 with model MultivariateMotif in generation 3 of 3\n",
      "Model Number: 457 with model SeasonalNaive in generation 3 of 3\n",
      "Model Number: 458 with model AverageValueNaive in generation 3 of 3\n",
      "Model Number: 459 with model NVAR in generation 3 of 3\n",
      "Model Number: 460 with model ARDL in generation 3 of 3\n",
      "Model Number: 461 with model GLS in generation 3 of 3\n",
      "Model Number: 462 with model AverageValueNaive in generation 3 of 3\n",
      "Model Number: 463 with model UnivariateMotif in generation 3 of 3\n",
      "Model Number: 464 with model GLM in generation 3 of 3\n",
      "Model Number: 465 with model DatepartRegression in generation 3 of 3\n",
      "Model Number: 466 with model SeasonalNaive in generation 3 of 3\n",
      "Model Number: 467 with model GLS in generation 3 of 3\n",
      "Template Eval Error: Exception('Transformer BTCD failed on fit') in model 467 in generation 3: GLS\n",
      "Model Number: 468 with model UnivariateMotif in generation 3 of 3\n",
      "Model Number: 469 with model Theta in generation 3 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\statsmodels\\genmod\\families\\links.py:198: RuntimeWarning: overflow encountered in exp\n",
      "  t = np.exp(-z)\n",
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.090e-01, tolerance: 5.858e-04\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 470 with model NVAR in generation 3 of 3\n",
      "Model Number: 471 with model SeasonalNaive in generation 3 of 3\n",
      "Template Eval Error: Exception('Transformer AlignLastValue failed on inverse') in model 471 in generation 3: SeasonalNaive\n",
      "Model Number: 472 with model MetricMotif in generation 3 of 3\n",
      "Model Number: 473 with model MetricMotif in generation 3 of 3\n",
      "Model Number: 474 with model ETS in generation 3 of 3\n",
      "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
      "ETS failed on NET_SALES with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
      "Model Number: 475 with model GLM in generation 3 of 3\n",
      "Model Number: 476 with model NVAR in generation 3 of 3\n",
      "Template Eval Error: Exception('Transformer BTCD failed on fit') in model 476 in generation 3: NVAR\n",
      "Model Number: 477 with model UnobservedComponents in generation 3 of 3\n",
      "Model Number: 478 with model GLS in generation 3 of 3\n",
      "Model Number: 479 with model SeasonalNaive in generation 3 of 3\n",
      "Template Eval Error: Exception('Transformer RegressionFilter failed on fit') in model 479 in generation 3: SeasonalNaive\n",
      "Model Number: 480 with model WindowRegression in generation 3 of 3\n",
      "Model Number: 481 with model GLM in generation 3 of 3\n",
      "Model Number: 482 with model SeasonalNaive in generation 3 of 3\n",
      "Model Number: 483 with model WindowRegression in generation 3 of 3\n",
      "Model Number: 484 with model GLS in generation 3 of 3\n",
      "Model Number: 485 with model NVAR in generation 3 of 3\n",
      "Model Number: 486 with model LastValueNaive in generation 3 of 3\n",
      "Model Number: 487 with model SeasonalNaive in generation 3 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\statsmodels\\genmod\\families\\links.py:198: RuntimeWarning: overflow encountered in exp\n",
      "  t = np.exp(-z)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 488 with model SeasonalNaive in generation 3 of 3\n",
      "Template Eval Error: Exception('Transformer RegressionFilter failed on fit') in model 488 in generation 3: SeasonalNaive\n",
      "Model Number: 489 with model ARDL in generation 3 of 3\n",
      "Model Number: 490 with model Theta in generation 3 of 3\n",
      "Model Number: 491 with model AverageValueNaive in generation 3 of 3\n",
      "Model Number: 492 with model NVAR in generation 3 of 3\n",
      "Model Number: 493 with model LastValueNaive in generation 3 of 3\n",
      "Model Number: 494 with model ARIMA in generation 3 of 3\n",
      "Model Number: 495 with model FBProphet in generation 3 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16:16:01 - cmdstanpy - INFO - Chain [1] start processing\n",
      "16:16:02 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 496 with model UnivariateMotif in generation 3 of 3\n",
      "Model Number: 497 with model ARIMA in generation 3 of 3\n",
      "Model Number: 498 with model ETS in generation 3 of 3\n",
      "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
      "ETS failed on NET_SALES with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
      "Model Number: 499 with model UnobservedComponents in generation 3 of 3\n",
      "Model Number: 500 with model ETS in generation 3 of 3\n",
      "ETS error ValueError('Can only dampen the trend component')\n",
      "ETS failed on NET_SALES with ValueError('Can only dampen the trend component')\n",
      "Model Number: 501 with model UnivariateMotif in generation 3 of 3\n",
      "Model Number: 502 with model Theta in generation 3 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.308e+12, tolerance: 2.896e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 503 with model GLM in generation 3 of 3\n",
      "Model Number: 504 with model LastValueNaive in generation 3 of 3\n",
      "Template Eval Error: Exception('Transformer Cointegration failed on fit') in model 504 in generation 3: LastValueNaive\n",
      "Model Number: 505 with model ARDL in generation 3 of 3\n",
      "Model Number: 506 with model AverageValueNaive in generation 3 of 3\n",
      "Model Number: 507 with model ETS in generation 3 of 3\n",
      "ETS error ValueError('Can only dampen the trend component')\n",
      "ETS failed on NET_SALES with ValueError('Can only dampen the trend component')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\decomposition\\_fastica.py:708: FutureWarning: Starting in v1.3, whiten=True should be specified as whiten='arbitrary-variance' (its current behaviour). This behavior is deprecated in 1.1 and will raise ValueError in 1.3.\n",
      "  return self._fit_transform(X, compute_sources=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 508 with model ARDL in generation 3 of 3\n",
      "Model Number: 509 with model NVAR in generation 3 of 3\n",
      "Model Number: 510 with model MultivariateRegression in generation 3 of 3\n",
      "Template Eval Error: ValueError(\"Some value(s) of y are out of the valid range of the loss 'HalfPoissonLoss'.\") in model 510 in generation 3: MultivariateRegression\n",
      "Model Number: 511 with model ETS in generation 3 of 3\n",
      "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
      "ETS failed on NET_SALES with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
      "Model Number: 512 with model GLS in generation 3 of 3\n",
      "Model Number: 513 with model MetricMotif in generation 3 of 3\n",
      "Model Number: 514 with model AverageValueNaive in generation 3 of 3\n",
      "Model Number: 515 with model Theta in generation 3 of 3\n",
      "Model Number: 516 with model GLS in generation 3 of 3\n",
      "Model Number: 517 with model ARIMA in generation 3 of 3\n",
      "Model Number: 518 with model ARDL in generation 3 of 3\n",
      "Template Eval Error: Exception('Transformer Cointegration failed on fit') in model 518 in generation 3: ARDL\n",
      "Model Number: 519 with model LastValueNaive in generation 3 of 3\n",
      "Model Number: 520 with model SectionalMotif in generation 3 of 3\n",
      "Model Number: 521 with model MultivariateMotif in generation 3 of 3\n",
      "Model Number: 522 with model NVAR in generation 3 of 3\n",
      "Template Eval Error: Exception('Transformer BTCD failed on fit') in model 522 in generation 3: NVAR\n",
      "Model Number: 523 with model ARIMA in generation 3 of 3\n",
      "Model Number: 524 with model AverageValueNaive in generation 3 of 3\n",
      "Template Eval Error: Exception('Transformer Cointegration failed on fit') in model 524 in generation 3: AverageValueNaive\n",
      "Model Number: 525 with model SectionalMotif in generation 3 of 3\n",
      "Model Number: 526 with model AverageValueNaive in generation 3 of 3\n",
      "Model Number: 527 with model ARDL in generation 3 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (250) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 528 with model UnobservedComponents in generation 3 of 3\n",
      "Model Number: 529 with model UnobservedComponents in generation 3 of 3\n",
      "Model Number: 530 with model NVAR in generation 3 of 3\n",
      "Model Number: 531 with model UnobservedComponents in generation 3 of 3\n",
      "Model Number: 532 with model ARDL in generation 3 of 3\n",
      "Model Number: 533 with model ARIMA in generation 3 of 3\n",
      "Model Number: 534 with model GLM in generation 3 of 3\n",
      "Model Number: 535 with model LastValueNaive in generation 3 of 3\n",
      "Template Eval Error: Exception('Transformer BTCD failed on fit') in model 535 in generation 3: LastValueNaive\n",
      "Model Number: 536 with model ARDL in generation 3 of 3\n",
      "Template Eval Error: ValueError(\"ARDL series NET_SALES failed with error ValueError('The number of regressors (107) including deterministics, lags of the endog, lags of the exogenous, and fixed regressors is larger than the sample available for estimation (69).') exog train             seasonalitycommonfourier_0  seasonalitycommonfourier_1  \\\\\\nMONTH                                                                \\n2016-01-01                    0.999963                    0.999852   \\n2016-02-01                    0.865487                    0.498137   \\n2016-03-01                    0.520343                   -0.458487   \\n2016-04-01                    0.013977                   -0.999609   \\n2016-05-01                   -0.481264                   -0.536771   \\n...                                ...                         ...   \\n2021-08-01                   -0.872929                    0.524010   \\n2021-09-01                   -0.503720                   -0.492533   \\n2021-10-01                   -0.011826                   -0.999720   \\n2021-11-01                    0.498137                   -0.503720   \\n2021-12-01                    0.861147                    0.483147   \\n\\n            seasonalitycommonfourier_2  seasonalitycommonfourier_3  \\\\\\nMONTH                                                                \\n2016-01-01                    0.999667                   -0.008601   \\n2016-02-01                   -0.003225                    0.500931   \\n2016-03-01                   -0.997483                    0.853958   \\n2016-04-01                   -0.041919                    0.999902   \\n2016-05-01                    0.997920                    0.876576   \\n...                                ...                         ...   \\n2021-08-01                   -0.041919                   -0.487847   \\n2021-09-01                    0.999917                   -0.863867   \\n2021-10-01                    0.035473                   -0.999930   \\n2021-11-01                   -0.999979                   -0.867099   \\n2021-12-01                   -0.029025                   -0.508356   \\n\\n            seasonalitycommonfourier_4  seasonalitycommonfourier_5  \\\\\\nMONTH                                                                \\n2016-01-01                   -0.017202                   -0.025801   \\n2016-02-01                    0.867099                    0.999995   \\n2016-03-01                    0.888701                    0.070900   \\n2016-04-01                    0.027950                   -0.999121   \\n2016-05-01                   -0.843728                   -0.064464   \\n...                                ...                         ...   \\n2021-08-01                    0.851712                   -0.999121   \\n2021-09-01                    0.870294                   -0.012901   \\n2021-10-01                    0.023651                    0.999371   \\n2021-11-01                   -0.863867                    0.006451   \\n2021-12-01                   -0.875539                   -0.999579   \\n\\n            seasonalitycommonfourier_6  seasonalitycommonfourier_7  \\\\\\nMONTH                                                                \\n2016-01-01                   -0.999998                    0.999991   \\n2016-02-01                   -0.991410                    0.965787   \\n2016-03-01                   -0.967439                    0.871878   \\n2016-04-01                   -0.925211                    0.712031   \\n2016-05-01                   -0.868701                    0.509282   \\n...                                ...                         ...   \\n2021-08-01                    0.791221                    0.252062   \\n2021-09-01                    0.865487                    0.498137   \\n2021-10-01                    0.922744                    0.702913   \\n2021-11-01                    0.965787                    0.865487   \\n2021-12-01                    0.991126                    0.964662   \\n\\n            seasonalitycommonfourier_8  seasonalitycommonfourier_9  ...  \\\\\\nMONTH                                                               ...   \\n2016-01-01                   -0.999979                    0.999963  ...   \\n2016-02-01                   -0.923571                    0.865487  ...   \\n2016-03-01                   -0.719539                    0.520343  ...   \\n2016-04-01                   -0.392347                    0.013977  ...   \\n2016-05-01                   -0.016127                   -0.481264  ...   \\n...                                ...                         ...  ...   \\n2021-08-01                   -0.392347                   -0.872929  ...   \\n2021-09-01                   -0.003225                   -0.503720  ...   \\n2021-10-01                    0.374474                   -0.011826  ...   \\n2021-11-01                    0.705965                    0.498137  ...   \\n2021-12-01                    0.921078                    0.861147  ...   \\n\\n            seasonalitycommonfourier_16  seasonalitycommonfourier_17  \\\\\\nMONTH                                                                  \\n2016-01-01                     0.002150                    -0.004301   \\n2016-02-01                    -0.130793                     0.259338   \\n2016-03-01                    -0.253103                     0.489723   \\n2016-04-01                    -0.379453                     0.702148   \\n2016-05-01                    -0.495337                     0.860600   \\n...                                 ...                          ...   \\n2021-08-01                    -0.611530                    -0.967711   \\n2021-09-01                    -0.500931                    -0.867099   \\n2021-10-01                    -0.385413                    -0.711276   \\n2021-11-01                    -0.259338                    -0.500931   \\n2021-12-01                    -0.132924                    -0.263489   \\n\\n            seasonalitycommonfourier_18  seasonalitycommonfourier_19  \\\\\\nMONTH                                                                  \\n2016-01-01                     0.006451                    -0.008601   \\n2016-02-01                    -0.383428                     0.500931   \\n2016-03-01                    -0.694452                     0.853958   \\n2016-04-01                    -0.919817                     0.999902   \\n2016-05-01                    -0.999870                     0.876576   \\n...                                 ...                          ...   \\n2021-08-01                    -0.919817                    -0.487847   \\n2021-09-01                    -0.999995                    -0.863867   \\n2021-10-01                    -0.927238                    -0.999930   \\n2021-11-01                    -0.708246                    -0.867099   \\n2021-12-01                    -0.389378                    -0.508356   \\n\\n            seasonalitycommonfourier_20  seasonalitycommonfourier_21  \\\\\\nMONTH                                                                  \\n2016-01-01                     0.010751                    -0.012901   \\n2016-02-01                    -0.609827                     0.708246   \\n2016-03-01                    -0.957852                     0.999371   \\n2016-04-01                    -0.930424                     0.721775   \\n2016-05-01                    -0.523094                     0.032249   \\n...                                 ...                          ...   \\n2021-08-01                     0.147827                     0.721775   \\n2021-09-01                    -0.495337                     0.006451   \\n2021-10-01                    -0.918121                    -0.694452   \\n2021-11-01                    -0.966618                    -0.999995   \\n2021-12-01                    -0.618313                    -0.717295   \\n\\n            seasonalitycommonfourier_22  seasonalitycommonfourier_23  \\\\\\nMONTH                                                                  \\n2016-01-01                     0.015052                    -0.017202   \\n2016-02-01                    -0.794497                     0.867099   \\n2016-03-01                    -0.975809                     0.888701   \\n2016-04-01                    -0.405165                     0.027950   \\n2016-05-01                     0.467065                    -0.843728   \\n...                                 ...                          ...   \\n2021-08-01                     0.994341                     0.851712   \\n2021-09-01                     0.506504                     0.870294   \\n2021-10-01                    -0.363482                     0.023651   \\n2021-11-01                    -0.964945                    -0.863867   \\n2021-12-01                    -0.803548                    -0.875539   \\n\\n            seasonalitycommonfourier_24  seasonalitycommonfourier_25  \\nMONTH                                                                 \\n2016-01-01                     0.019352                    -0.021501  \\n2016-02-01                    -0.924803                     0.966618  \\n2016-03-01                    -0.743720                     0.550307  \\n2016-04-01                     0.353445                    -0.681972  \\n2016-05-01                     0.998830                    -0.891640  \\n...                                 ...                          ...  \\n2021-08-01                     0.353445                    -0.292406  \\n2021-09-01                     0.999953                     0.860600  \\n2021-10-01                     0.407129                     0.727701  \\n2021-11-01                    -0.703677                    -0.495337  \\n2021-12-01                    -0.931992                    -0.971904  \\n\\n[72 rows x 26 columns] and predict             seasonalitycommonfourier_0  seasonalitycommonfourier_1  \\\\\\n2022-01-01                    1.000000                    1.000000   \\n2022-02-01                    0.861147                    0.483147   \\n2022-03-01                    0.527668                   -0.443132   \\n2022-04-01                    0.022576                   -0.998981   \\n2022-05-01                   -0.473706                   -0.551205   \\n2022-06-01                   -0.855631                    0.464210   \\n2022-07-01                   -0.999609                    0.998438   \\n2022-08-01                   -0.875019                    0.531317   \\n2022-09-01                   -0.507430                   -0.485029   \\n2022-10-01                   -0.016127                   -0.999480   \\n2022-11-01                    0.494403                   -0.511131   \\n2022-12-01                    0.858953                    0.475599   \\n\\n            seasonalitycommonfourier_2  seasonalitycommonfourier_3  \\\\\\n2022-01-01                    1.000000                    0.000000   \\n2022-02-01                   -0.029025                    0.508356   \\n2022-03-01                   -0.995322                    0.849450   \\n2022-04-01                   -0.067683                    0.999745   \\n2022-05-01                    0.995925                    0.880683   \\n2022-06-01                    0.061245                    0.517586   \\n2022-07-01                   -0.996486                    0.027950   \\n2022-08-01                   -0.054805                   -0.484089   \\n2022-09-01                    0.999667                   -0.861693   \\n2022-10-01                    0.048363                   -0.999870   \\n2022-11-01                   -0.999813                   -0.869233   \\n2022-12-01                   -0.041919                   -0.512055   \\n\\n            seasonalitycommonfourier_4  seasonalitycommonfourier_5  \\\\\\n2022-01-01                    0.000000                    0.000000   \\n2022-02-01                    0.875539                    0.999579   \\n2022-03-01                    0.896456                    0.096613   \\n2022-04-01                    0.045141                   -0.997707   \\n2022-05-01                   -0.834370                   -0.090190   \\n2022-06-01                   -0.885725                    0.998123   \\n2022-07-01                   -0.055879                    0.083764   \\n2022-08-01                    0.847173                   -0.998497   \\n2022-09-01                    0.874498                   -0.025801   \\n2022-10-01                    0.032249                    0.998830   \\n2022-11-01                   -0.859503                    0.019352   \\n2022-12-01                   -0.879662                   -0.999121   \\n\\n            seasonalitycommonfourier_6  seasonalitycommonfourier_7  \\\\\\n2022-01-01                    1.000000                    1.000000   \\n2022-02-01                    0.991126                    0.964662   \\n2022-03-01                    0.967981                    0.873976   \\n2022-04-01                    0.926025                    0.715044   \\n2022-05-01                    0.869764                    0.512978   \\n2022-06-01                    0.796452                    0.268671   \\n2022-07-01                    0.712031                    0.013977   \\n2022-08-01                    0.612380                   -0.249981   \\n2022-09-01                    0.501861                   -0.496271   \\n2022-10-01                    0.386405                   -0.701382   \\n2022-11-01                    0.260376                   -0.864408   \\n2022-12-01                    0.133990                   -0.964094   \\n\\n            seasonalitycommonfourier_8  seasonalitycommonfourier_9  ...  \\\\\\n2022-01-01                    1.000000                    1.000000  ...   \\n2022-02-01                    0.921078                    0.861147  ...   \\n2022-03-01                    0.724004                    0.527668  ...   \\n2022-04-01                    0.398272                    0.022576  ...   \\n2022-05-01                    0.022576                   -0.473706  ...   \\n2022-06-01                   -0.368484                   -0.855631  ...   \\n2022-07-01                   -0.692128                   -0.999609  ...   \\n2022-08-01                   -0.918547                   -0.875019  ...   \\n2022-09-01                   -0.999979                   -0.507430  ...   \\n2022-10-01                   -0.928441                   -0.016127  ...   \\n2022-11-01                   -0.710520                    0.494403  ...   \\n2022-12-01                   -0.392347                    0.858953  ...   \\n\\n            seasonalitycommonfourier_16  seasonalitycommonfourier_17  \\\\\\n2022-01-01                     0.000000                     0.000000   \\n2022-02-01                     0.132924                     0.263489   \\n2022-03-01                     0.251022                     0.485969   \\n2022-04-01                     0.377462                     0.699079   \\n2022-05-01                     0.493468                     0.858402   \\n2022-06-01                     0.604702                     0.963232   \\n2022-07-01                     0.702148                     0.999902   \\n2022-08-01                     0.790563                     0.968251   \\n2022-09-01                     0.864948                     0.868168   \\n2022-10-01                     0.922329                     0.712786   \\n2022-11-01                     0.965507                     0.502791   \\n2022-12-01                     0.990983                     0.265563   \\n\\n            seasonalitycommonfourier_18  seasonalitycommonfourier_19  \\\\\\n2022-01-01                     0.000000                     0.000000   \\n2022-02-01                     0.389378                     0.508356   \\n2022-03-01                     0.689796                     0.849450   \\n2022-04-01                     0.917267                     0.999745   \\n2022-05-01                     0.999745                     0.880683   \\n2022-06-01                     0.929634                     0.517586   \\n2022-07-01                     0.721775                     0.027950   \\n2022-08-01                     0.395312                    -0.484089   \\n2022-09-01                     0.006451                    -0.861693   \\n2022-10-01                    -0.371481                    -0.999870   \\n2022-11-01                    -0.703677                    -0.869233   \\n2022-12-01                    -0.919817                    -0.512055   \\n\\n            seasonalitycommonfourier_20  seasonalitycommonfourier_21  \\\\\\n2022-01-01                     0.000000                     0.000000   \\n2022-02-01                     0.618313                     0.717295   \\n2022-03-01                     0.954709                     0.998830   \\n2022-04-01                     0.934311                     0.730644   \\n2022-05-01                     0.532227                     0.045141   \\n2022-06-01                    -0.105170                    -0.685111   \\n2022-07-01                    -0.681972                    -0.999121   \\n2022-08-01                    -0.988204                    -0.726225   \\n2022-09-01                    -0.871351                    -0.012901   \\n2022-10-01                    -0.401229                     0.689796   \\n2022-11-01                     0.251022                     0.999953   \\n2022-12-01                     0.782597                     0.721775   \\n\\n            seasonalitycommonfourier_22  seasonalitycommonfourier_23  \\\\\\n2022-01-01                     0.000000                     0.000000   \\n2022-02-01                     0.803548                     0.875539   \\n2022-03-01                     0.978989                     0.896456   \\n2022-04-01                     0.418879                     0.045141   \\n2022-05-01                    -0.453703                    -0.834370   \\n2022-06-01                    -0.986146                    -0.885725   \\n2022-07-01                    -0.740838                    -0.055879   \\n2022-08-01                     0.098753                     0.847173   \\n2022-09-01                     0.858402                     0.874498   \\n2022-10-01                     0.934311                     0.032249   \\n2022-11-01                     0.269707                    -0.859503   \\n2022-12-01                    -0.589176                    -0.879662   \\n\\n            seasonalitycommonfourier_24  seasonalitycommonfourier_25  \\n2022-01-01                     0.000000                     0.000000  \\n2022-02-01                     0.931992                     0.971904  \\n2022-03-01                     0.756517                     0.568133  \\n2022-04-01                    -0.335276                    -0.666089  \\n2022-05-01                    -0.997707                    -0.901169  \\n2022-06-01                    -0.424728                     0.209174  \\n2022-07-01                     0.661263                     0.997559  \\n2022-08-01                     0.938832                     0.302670  \\n2022-09-01                     0.019352                    -0.855075  \\n2022-10-01                    -0.909388                    -0.735034  \\n2022-11-01                    -0.717295                     0.485969  \\n2022-12-01                     0.353445                     0.974378  \\n\\n[12 rows x 26 columns]\") in model 536 in generation 3: ARDL\n",
      "Model Number: 537 with model SectionalMotif in generation 3 of 3\n",
      "Template Eval Error: LinAlgError('Singular matrix') in model 537 in generation 3: SectionalMotif\n",
      "Model Number: 538 with model GLM in generation 3 of 3\n",
      "Model Number: 539 with model DatepartRegression in generation 3 of 3\n",
      "Model Number: 540 with model GLM in generation 3 of 3\n",
      "Model Number: 541 with model GLS in generation 3 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\statsmodels\\genmod\\families\\links.py:198: RuntimeWarning: overflow encountered in exp\n",
      "  t = np.exp(-z)\n",
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\statsmodels\\genmod\\families\\links.py:198: RuntimeWarning: overflow encountered in exp\n",
      "  t = np.exp(-z)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 542 with model VAR in generation 3 of 3\n",
      "Template Eval Error: ValueError('Only gave one variable to VAR') in model 542 in generation 3: VAR\n",
      "Model Number: 543 with model ConstantNaive in generation 3 of 3\n",
      "Model Number: 544 with model ARIMA in generation 3 of 3\n",
      "Model Number: 545 with model MultivariateRegression in generation 3 of 3\n",
      "Model Number: 546 with model MultivariateRegression in generation 3 of 3\n",
      "Model Number: 547 with model ETS in generation 3 of 3\n",
      "Template Eval Error: Exception('Transformer Cointegration failed on fit') in model 547 in generation 3: ETS\n",
      "Model Number: 548 with model MultivariateMotif in generation 3 of 3\n",
      "Model Number: 549 with model MetricMotif in generation 3 of 3\n",
      "Model Number: 550 with model ARDL in generation 3 of 3\n",
      "Template Eval Error: Exception('Transformer RegressionFilter failed on fit') in model 550 in generation 3: ARDL\n",
      "Model Number: 551 with model UnobservedComponents in generation 3 of 3\n",
      "Model Number: 552 with model SectionalMotif in generation 3 of 3\n",
      "Template Eval Error: Exception('Transformer AlignLastValue failed on inverse') in model 552 in generation 3: SectionalMotif\n",
      "Model Number: 553 with model UnobservedComponents in generation 3 of 3\n",
      "Model Number: 554 with model ETS in generation 3 of 3\n",
      "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
      "ETS failed on NET_SALES with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
      "Model Number: 555 with model SectionalMotif in generation 3 of 3\n",
      "Model Number: 556 with model SeasonalNaive in generation 3 of 3\n",
      "Model Number: 557 with model LastValueNaive in generation 3 of 3\n",
      "Model Number: 558 with model MetricMotif in generation 3 of 3\n",
      "Model Number: 559 with model AverageValueNaive in generation 3 of 3\n",
      "Model Number: 560 with model LastValueNaive in generation 3 of 3\n",
      "Model Number: 561 with model AverageValueNaive in generation 3 of 3\n",
      "TotalRuntime missing in 4!\n",
      "Validation Round: 1\n",
      "Model Number: 1 of 84 with model AverageValueNaive for Validation 1\n",
      "📈 1 - AverageValueNaive with avg smape 67.2: \n",
      "Model Number: 2 of 84 with model AverageValueNaive for Validation 1\n",
      "2 - AverageValueNaive with avg smape 67.2: \n",
      "Model Number: 3 of 84 with model UnobservedComponents for Validation 1\n",
      "3 - UnobservedComponents with avg smape 79.11: \n",
      "Model Number: 4 of 84 with model GLM for Validation 1\n",
      "📈 4 - GLM with avg smape 65.54: \n",
      "Model Number: 5 of 84 with model UnobservedComponents for Validation 1\n",
      "5 - UnobservedComponents with avg smape 65.56: \n",
      "Model Number: 6 of 84 with model GLS for Validation 1\n",
      "6 - GLS with avg smape 76.7: \n",
      "Model Number: 7 of 84 with model UnobservedComponents for Validation 1\n",
      "7 - UnobservedComponents with avg smape 75.15: \n",
      "Model Number: 8 of 84 with model NVAR for Validation 1\n",
      "📈 8 - NVAR with avg smape 47.31: \n",
      "Model Number: 9 of 84 with model GLS for Validation 1\n",
      "9 - GLS with avg smape 65.56: \n",
      "Model Number: 10 of 84 with model GLS for Validation 1\n",
      "10 - GLS with avg smape 65.56: \n",
      "Model Number: 11 of 84 with model GLS for Validation 1\n",
      "11 - GLS with avg smape 65.56: \n",
      "Model Number: 12 of 84 with model GLM for Validation 1\n",
      "12 - GLM with avg smape 65.56: \n",
      "Model Number: 13 of 84 with model GLS for Validation 1\n",
      "13 - GLS with avg smape 65.56: \n",
      "Model Number: 14 of 84 with model AverageValueNaive for Validation 1\n",
      "14 - AverageValueNaive with avg smape 86.99: \n",
      "Model Number: 15 of 84 with model NVAR for Validation 1\n",
      "15 - NVAR with avg smape 49.26: \n",
      "Model Number: 16 of 84 with model NVAR for Validation 1\n",
      "16 - NVAR with avg smape 49.26: \n",
      "Model Number: 17 of 84 with model NVAR for Validation 1\n",
      "17 - NVAR with avg smape 49.26: \n",
      "Model Number: 18 of 84 with model ARDL for Validation 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\statsmodels\\genmod\\families\\links.py:198: RuntimeWarning: overflow encountered in exp\n",
      "  t = np.exp(-z)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18 - ARDL with avg smape 84.61: \n",
      "Model Number: 19 of 84 with model AverageValueNaive for Validation 1\n",
      "19 - AverageValueNaive with avg smape 102.72: \n",
      "Model Number: 20 of 84 with model GLM for Validation 1\n",
      "20 - GLM with avg smape 68.61: \n",
      "Model Number: 21 of 84 with model GLM for Validation 1\n",
      "21 - GLM with avg smape 68.61: \n",
      "Model Number: 22 of 84 with model NVAR for Validation 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\statsmodels\\genmod\\families\\links.py:198: RuntimeWarning: overflow encountered in exp\n",
      "  t = np.exp(-z)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📈 22 - NVAR with avg smape 42.59: \n",
      "Model Number: 23 of 84 with model GLM for Validation 1\n",
      "23 - GLM with avg smape 65.25: \n",
      "Model Number: 24 of 84 with model SeasonalNaive for Validation 1\n",
      "📈 24 - SeasonalNaive with avg smape 32.59: \n",
      "Model Number: 25 of 84 with model ETS for Validation 1\n",
      "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
      "ETS failed on NET_SALES with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
      "25 - ETS with avg smape 38.55: \n",
      "Model Number: 26 of 84 with model AverageValueNaive for Validation 1\n",
      "26 - AverageValueNaive with avg smape 93.92: \n",
      "Model Number: 27 of 84 with model UnobservedComponents for Validation 1\n",
      "27 - UnobservedComponents with avg smape 67.73: \n",
      "Model Number: 28 of 84 with model ETS for Validation 1\n",
      "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
      "ETS failed on NET_SALES with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
      "28 - ETS with avg smape 67.73: \n",
      "Model Number: 29 of 84 with model LastValueNaive for Validation 1\n",
      "📈 29 - LastValueNaive with avg smape 29.4: \n",
      "Model Number: 30 of 84 with model LastValueNaive for Validation 1\n",
      "30 - LastValueNaive with avg smape 33.57: \n",
      "Model Number: 31 of 84 with model UnobservedComponents for Validation 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.146e+11, tolerance: 2.160e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31 - UnobservedComponents with avg smape 71.7: \n",
      "Model Number: 32 of 84 with model ARIMA for Validation 1\n",
      "32 - ARIMA with avg smape 52.62: \n",
      "Model Number: 33 of 84 with model ARDL for Validation 1\n",
      "33 - ARDL with avg smape 46.13: \n",
      "Model Number: 34 of 84 with model ARDL for Validation 1\n",
      "34 - ARDL with avg smape 46.13: \n",
      "Model Number: 35 of 84 with model SeasonalNaive for Validation 1\n",
      "35 - SeasonalNaive with avg smape 77.65: \n",
      "Model Number: 36 of 84 with model ARIMA for Validation 1\n",
      "36 - ARIMA with avg smape 73.51: \n",
      "Model Number: 37 of 84 with model LastValueNaive for Validation 1\n",
      "37 - LastValueNaive with avg smape 30.72: \n",
      "Model Number: 38 of 84 with model SectionalMotif for Validation 1\n",
      "📈 38 - SectionalMotif with avg smape 29.33: \n",
      "Model Number: 39 of 84 with model SectionalMotif for Validation 1\n",
      "39 - SectionalMotif with avg smape 30.17: \n",
      "Model Number: 40 of 84 with model ARDL for Validation 1\n",
      "40 - ARDL with avg smape 43.9: \n",
      "Model Number: 41 of 84 with model ARDL for Validation 1\n",
      "41 - ARDL with avg smape 35.75: \n",
      "Model Number: 42 of 84 with model ETS for Validation 1\n",
      "ETS error ValueError('Can only dampen the trend component')\n",
      "ETS failed on NET_SALES with ValueError('Can only dampen the trend component')\n",
      "42 - ETS with avg smape 54.76: \n",
      "Model Number: 43 of 84 with model ETS for Validation 1\n",
      "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
      "ETS failed on NET_SALES with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
      "43 - ETS with avg smape 54.76: \n",
      "Model Number: 44 of 84 with model ETS for Validation 1\n",
      "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
      "ETS failed on NET_SALES with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
      "44 - ETS with avg smape 54.76: \n",
      "Model Number: 45 of 84 with model ARIMA for Validation 1\n",
      "45 - ARIMA with avg smape 39.11: \n",
      "Model Number: 46 of 84 with model SeasonalNaive for Validation 1\n",
      "46 - SeasonalNaive with avg smape 64.74: \n",
      "Model Number: 47 of 84 with model DatepartRegression for Validation 1\n",
      "47 - DatepartRegression with avg smape 58.54: \n",
      "Model Number: 48 of 84 with model ARIMA for Validation 1\n",
      "48 - ARIMA with avg smape 53.25: \n",
      "Model Number: 49 of 84 with model SectionalMotif for Validation 1\n",
      "49 - SectionalMotif with avg smape 85.57: \n",
      "Model Number: 50 of 84 with model ARIMA for Validation 1\n",
      "50 - ARIMA with avg smape 35.79: \n",
      "Model Number: 51 of 84 with model MultivariateRegression for Validation 1\n",
      "51 - MultivariateRegression with avg smape 49.75: \n",
      "Model Number: 52 of 84 with model LastValueNaive for Validation 1\n",
      "52 - LastValueNaive with avg smape 32.68: \n",
      "Model Number: 53 of 84 with model SeasonalNaive for Validation 1\n",
      "53 - SeasonalNaive with avg smape 100.11: \n",
      "Model Number: 54 of 84 with model LastValueNaive for Validation 1\n",
      "54 - LastValueNaive with avg smape 30.56: \n",
      "Model Number: 55 of 84 with model MultivariateRegression for Validation 1\n",
      "55 - MultivariateRegression with avg smape 35.24: \n",
      "Model Number: 56 of 84 with model SeasonalNaive for Validation 1\n",
      "56 - SeasonalNaive with avg smape 95.34: \n",
      "Model Number: 57 of 84 with model DatepartRegression for Validation 1\n",
      "57 - DatepartRegression with avg smape 30.68: \n",
      "Model Number: 58 of 84 with model DatepartRegression for Validation 1\n",
      "58 - DatepartRegression with avg smape 40.37: \n",
      "Model Number: 59 of 84 with model MultivariateRegression for Validation 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.235e-02, tolerance: 5.369e-04\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59 - MultivariateRegression with avg smape 48.49: \n",
      "Model Number: 60 of 84 with model DatepartRegression for Validation 1\n",
      "60 - DatepartRegression with avg smape 31.41: \n",
      "Model Number: 61 of 84 with model MultivariateMotif for Validation 1\n",
      "61 - MultivariateMotif with avg smape 44.97: \n",
      "Model Number: 62 of 84 with model UnivariateMotif for Validation 1\n",
      "62 - UnivariateMotif with avg smape 41.41: \n",
      "Model Number: 63 of 84 with model UnivariateMotif for Validation 1\n",
      "63 - UnivariateMotif with avg smape 41.41: \n",
      "Model Number: 64 of 84 with model Theta for Validation 1\n",
      "64 - Theta with avg smape 49.5: \n",
      "Model Number: 65 of 84 with model MetricMotif for Validation 1\n",
      "📈 65 - MetricMotif with avg smape 29.31: \n",
      "Model Number: 66 of 84 with model SectionalMotif for Validation 1\n",
      "66 - SectionalMotif with avg smape 35.07: \n",
      "Model Number: 67 of 84 with model Theta for Validation 1\n",
      "📈 67 - Theta with avg smape 27.0: \n",
      "Model Number: 68 of 84 with model SectionalMotif for Validation 1\n",
      "68 - SectionalMotif with avg smape 31.13: \n",
      "Model Number: 69 of 84 with model MultivariateMotif for Validation 1\n",
      "69 - MultivariateMotif with avg smape 43.89: \n",
      "Model Number: 70 of 84 with model UnivariateMotif for Validation 1\n",
      "70 - UnivariateMotif with avg smape 39.63: \n",
      "Model Number: 71 of 84 with model DatepartRegression for Validation 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\linear_model\\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.78051e-24): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71 - DatepartRegression with avg smape 28.58: \n",
      "Model Number: 72 of 84 with model ConstantNaive for Validation 1\n",
      "72 - ConstantNaive with avg smape 33.48: \n",
      "Model Number: 73 of 84 with model UnivariateMotif for Validation 1\n",
      "73 - UnivariateMotif with avg smape 39.91: \n",
      "Model Number: 74 of 84 with model WindowRegression for Validation 1\n",
      "74 - WindowRegression with avg smape 43.85: \n",
      "Model Number: 75 of 84 with model WindowRegression for Validation 1\n",
      "75 - WindowRegression with avg smape 33.01: \n",
      "Model Number: 76 of 84 with model WindowRegression for Validation 1\n",
      "76 - WindowRegression with avg smape 33.33: \n",
      "Model Number: 77 of 84 with model MetricMotif for Validation 1\n",
      "77 - MetricMotif with avg smape 45.28: \n",
      "Model Number: 78 of 84 with model UnivariateMotif for Validation 1\n",
      "78 - UnivariateMotif with avg smape 57.12: \n",
      "Model Number: 79 of 84 with model MetricMotif for Validation 1\n",
      "79 - MetricMotif with avg smape 45.86: \n",
      "Model Number: 80 of 84 with model MetricMotif for Validation 1\n",
      "80 - MetricMotif with avg smape 63.88: \n",
      "Model Number: 81 of 84 with model MetricMotif for Validation 1\n",
      "81 - MetricMotif with avg smape 34.91: \n",
      "Model Number: 82 of 84 with model WindowRegression for Validation 1\n",
      "82 - WindowRegression with avg smape 32.3: \n",
      "Model Number: 83 of 84 with model Theta for Validation 1\n",
      "83 - Theta with avg smape 29.69: \n",
      "Model Number: 84 of 84 with model Theta for Validation 1\n",
      "📈 84 - Theta with avg smape 26.04: \n",
      "Validation Round: 2\n",
      "Model Number: 1 of 84 with model AverageValueNaive for Validation 2\n",
      "📈 1 - AverageValueNaive with avg smape 84.37: \n",
      "Model Number: 2 of 84 with model AverageValueNaive for Validation 2\n",
      "2 - AverageValueNaive with avg smape 84.37: \n",
      "Model Number: 3 of 84 with model UnobservedComponents for Validation 2\n",
      "3 - UnobservedComponents with avg smape 116.27: \n",
      "Model Number: 4 of 84 with model GLM for Validation 2\n",
      "📈 4 - GLM with avg smape 83.15: \n",
      "Model Number: 5 of 84 with model UnobservedComponents for Validation 2\n",
      "5 - UnobservedComponents with avg smape 83.17: \n",
      "Model Number: 6 of 84 with model GLS for Validation 2\n",
      "6 - GLS with avg smape 91.92: \n",
      "Model Number: 7 of 84 with model UnobservedComponents for Validation 2\n",
      "7 - UnobservedComponents with avg smape 114.58: \n",
      "Model Number: 8 of 84 with model NVAR for Validation 2\n",
      "📈 8 - NVAR with avg smape 58.29: \n",
      "Model Number: 9 of 84 with model GLS for Validation 2\n",
      "9 - GLS with avg smape 83.17: \n",
      "Model Number: 10 of 84 with model GLS for Validation 2\n",
      "10 - GLS with avg smape 83.17: \n",
      "Model Number: 11 of 84 with model GLS for Validation 2\n",
      "11 - GLS with avg smape 83.17: \n",
      "Model Number: 12 of 84 with model GLM for Validation 2\n",
      "12 - GLM with avg smape 83.17: \n",
      "Model Number: 13 of 84 with model GLS for Validation 2\n",
      "13 - GLS with avg smape 83.17: \n",
      "Model Number: 14 of 84 with model AverageValueNaive for Validation 2\n",
      "14 - AverageValueNaive with avg smape 120.18: \n",
      "Model Number: 15 of 84 with model NVAR for Validation 2\n",
      "15 - NVAR with avg smape 70.15: \n",
      "Model Number: 16 of 84 with model NVAR for Validation 2\n",
      "16 - NVAR with avg smape 70.15: \n",
      "Model Number: 17 of 84 with model NVAR for Validation 2\n",
      "17 - NVAR with avg smape 70.15: \n",
      "Model Number: 18 of 84 with model ARDL for Validation 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\statsmodels\\genmod\\families\\links.py:198: RuntimeWarning: overflow encountered in exp\n",
      "  t = np.exp(-z)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18 - ARDL with avg smape 117.14: \n",
      "Model Number: 19 of 84 with model AverageValueNaive for Validation 2\n",
      "19 - AverageValueNaive with avg smape 153.28: \n",
      "Model Number: 20 of 84 with model GLM for Validation 2\n",
      "20 - GLM with avg smape 86.16: \n",
      "Model Number: 21 of 84 with model GLM for Validation 2\n",
      "21 - GLM with avg smape 86.16: \n",
      "Model Number: 22 of 84 with model NVAR for Validation 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\statsmodels\\genmod\\families\\links.py:198: RuntimeWarning: overflow encountered in exp\n",
      "  t = np.exp(-z)\n",
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\statsmodels\\genmod\\families\\links.py:198: RuntimeWarning: overflow encountered in exp\n",
      "  t = np.exp(-z)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📈 22 - NVAR with avg smape 58.06: \n",
      "Model Number: 23 of 84 with model GLM for Validation 2\n",
      "23 - GLM with avg smape 116.22: \n",
      "Model Number: 24 of 84 with model SeasonalNaive for Validation 2\n",
      "📈 24 - SeasonalNaive with avg smape 40.04: \n",
      "Model Number: 25 of 84 with model ETS for Validation 2\n",
      "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
      "ETS failed on NET_SALES with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
      "25 - ETS with avg smape 66.97: \n",
      "Model Number: 26 of 84 with model AverageValueNaive for Validation 2\n",
      "26 - AverageValueNaive with avg smape 123.84: \n",
      "Model Number: 27 of 84 with model UnobservedComponents for Validation 2\n",
      "27 - UnobservedComponents with avg smape 140.32: \n",
      "Model Number: 28 of 84 with model ETS for Validation 2\n",
      "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
      "ETS failed on NET_SALES with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
      "28 - ETS with avg smape 140.32: \n",
      "Model Number: 29 of 84 with model LastValueNaive for Validation 2\n",
      "29 - LastValueNaive with avg smape 56.43: \n",
      "Model Number: 30 of 84 with model LastValueNaive for Validation 2\n",
      "30 - LastValueNaive with avg smape 61.8: \n",
      "Model Number: 31 of 84 with model UnobservedComponents for Validation 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.797e+11, tolerance: 1.017e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31 - UnobservedComponents with avg smape 138.76: \n",
      "Model Number: 32 of 84 with model ARIMA for Validation 2\n",
      "32 - ARIMA with avg smape 68.59: \n",
      "Model Number: 33 of 84 with model ARDL for Validation 2\n",
      "33 - ARDL with avg smape 54.65: \n",
      "Model Number: 34 of 84 with model ARDL for Validation 2\n",
      "34 - ARDL with avg smape 54.65: \n",
      "Model Number: 35 of 84 with model SeasonalNaive for Validation 2\n",
      "35 - SeasonalNaive with avg smape 114.27: \n",
      "Model Number: 36 of 84 with model ARIMA for Validation 2\n",
      "36 - ARIMA with avg smape 93.28: \n",
      "Model Number: 37 of 84 with model LastValueNaive for Validation 2\n",
      "37 - LastValueNaive with avg smape 41.55: \n",
      "Model Number: 38 of 84 with model SectionalMotif for Validation 2\n",
      "38 - SectionalMotif with avg smape 57.02: \n",
      "Model Number: 39 of 84 with model SectionalMotif for Validation 2\n",
      "39 - SectionalMotif with avg smape 49.79: \n",
      "Model Number: 40 of 84 with model ARDL for Validation 2\n",
      "40 - ARDL with avg smape 47.3: \n",
      "Model Number: 41 of 84 with model ARDL for Validation 2\n",
      "41 - ARDL with avg smape 74.04: \n",
      "Model Number: 42 of 84 with model ETS for Validation 2\n",
      "ETS error ValueError('Can only dampen the trend component')\n",
      "ETS failed on NET_SALES with ValueError('Can only dampen the trend component')\n",
      "42 - ETS with avg smape 73.49: \n",
      "Model Number: 43 of 84 with model ETS for Validation 2\n",
      "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
      "ETS failed on NET_SALES with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
      "43 - ETS with avg smape 73.49: \n",
      "Model Number: 44 of 84 with model ETS for Validation 2\n",
      "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
      "ETS failed on NET_SALES with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
      "44 - ETS with avg smape 73.49: \n",
      "Model Number: 45 of 84 with model ARIMA for Validation 2\n",
      "45 - ARIMA with avg smape 43.23: \n",
      "Model Number: 46 of 84 with model SeasonalNaive for Validation 2\n",
      "46 - SeasonalNaive with avg smape 78.3: \n",
      "Model Number: 47 of 84 with model DatepartRegression for Validation 2\n",
      "47 - DatepartRegression with avg smape 146.23: \n",
      "Model Number: 48 of 84 with model ARIMA for Validation 2\n",
      "48 - ARIMA with avg smape 68.45: \n",
      "Model Number: 49 of 84 with model SectionalMotif for Validation 2\n",
      "Template Eval Error: ValueError('kth(=3) out of bounds (3)') in model 49 in generation 0: SectionalMotif\n",
      "Model Number: 50 of 84 with model ARIMA for Validation 2\n",
      "50 - ARIMA with avg smape 51.85: \n",
      "Model Number: 51 of 84 with model MultivariateRegression for Validation 2\n",
      "51 - MultivariateRegression with avg smape 75.06: \n",
      "Model Number: 52 of 84 with model LastValueNaive for Validation 2\n",
      "52 - LastValueNaive with avg smape 82.68: \n",
      "Model Number: 53 of 84 with model SeasonalNaive for Validation 2\n",
      "53 - SeasonalNaive with avg smape 106.34: \n",
      "Model Number: 54 of 84 with model LastValueNaive for Validation 2\n",
      "54 - LastValueNaive with avg smape 40.74: \n",
      "Model Number: 55 of 84 with model MultivariateRegression for Validation 2\n",
      "55 - MultivariateRegression with avg smape 42.58: \n",
      "Model Number: 56 of 84 with model SeasonalNaive for Validation 2\n",
      "56 - SeasonalNaive with avg smape 108.55: \n",
      "Model Number: 57 of 84 with model DatepartRegression for Validation 2\n",
      "📈 57 - DatepartRegression with avg smape 38.29: \n",
      "Model Number: 58 of 84 with model DatepartRegression for Validation 2\n",
      "58 - DatepartRegression with avg smape 54.16: \n",
      "Model Number: 59 of 84 with model MultivariateRegression for Validation 2\n",
      "59 - MultivariateRegression with avg smape 80.53: \n",
      "Model Number: 60 of 84 with model DatepartRegression for Validation 2\n",
      "60 - DatepartRegression with avg smape 38.75: \n",
      "Model Number: 61 of 84 with model MultivariateMotif for Validation 2\n",
      "61 - MultivariateMotif with avg smape 39.33: \n",
      "Model Number: 62 of 84 with model UnivariateMotif for Validation 2\n",
      "62 - UnivariateMotif with avg smape 41.97: \n",
      "Model Number: 63 of 84 with model UnivariateMotif for Validation 2\n",
      "63 - UnivariateMotif with avg smape 41.97: \n",
      "Model Number: 64 of 84 with model Theta for Validation 2\n",
      "64 - Theta with avg smape 42.77: \n",
      "Model Number: 65 of 84 with model MetricMotif for Validation 2\n",
      "65 - MetricMotif with avg smape 40.8: \n",
      "Model Number: 66 of 84 with model SectionalMotif for Validation 2\n",
      "66 - SectionalMotif with avg smape 44.82: \n",
      "Model Number: 67 of 84 with model Theta for Validation 2\n",
      "67 - Theta with avg smape 39.6: \n",
      "Model Number: 68 of 84 with model SectionalMotif for Validation 2\n",
      "68 - SectionalMotif with avg smape 115.24: \n",
      "Model Number: 69 of 84 with model MultivariateMotif for Validation 2\n",
      "69 - MultivariateMotif with avg smape 49.8: \n",
      "Model Number: 70 of 84 with model UnivariateMotif for Validation 2\n",
      "70 - UnivariateMotif with avg smape 38.57: \n",
      "Model Number: 71 of 84 with model DatepartRegression for Validation 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\linear_model\\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.22635e-24): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📈 71 - DatepartRegression with avg smape 33.22: \n",
      "Model Number: 72 of 84 with model ConstantNaive for Validation 2\n",
      "72 - ConstantNaive with avg smape 47.3: \n",
      "Model Number: 73 of 84 with model UnivariateMotif for Validation 2\n",
      "73 - UnivariateMotif with avg smape 44.23: \n",
      "Model Number: 74 of 84 with model WindowRegression for Validation 2\n",
      "74 - WindowRegression with avg smape 45.7: \n",
      "Model Number: 75 of 84 with model WindowRegression for Validation 2\n",
      "75 - WindowRegression with avg smape 46.93: \n",
      "Model Number: 76 of 84 with model WindowRegression for Validation 2\n",
      "76 - WindowRegression with avg smape 48.4: \n",
      "Model Number: 77 of 84 with model MetricMotif for Validation 2\n",
      "77 - MetricMotif with avg smape 68.56: \n",
      "Model Number: 78 of 84 with model UnivariateMotif for Validation 2\n",
      "78 - UnivariateMotif with avg smape 66.36: \n",
      "Model Number: 79 of 84 with model MetricMotif for Validation 2\n",
      "79 - MetricMotif with avg smape 38.66: \n",
      "Model Number: 80 of 84 with model MetricMotif for Validation 2\n",
      "80 - MetricMotif with avg smape 40.88: \n",
      "Model Number: 81 of 84 with model MetricMotif for Validation 2\n",
      "📈 81 - MetricMotif with avg smape 33.14: \n",
      "Model Number: 82 of 84 with model WindowRegression for Validation 2\n",
      "82 - WindowRegression with avg smape 44.92: \n",
      "Model Number: 83 of 84 with model Theta for Validation 2\n",
      "📈 83 - Theta with avg smape 28.84: \n",
      "Model Number: 84 of 84 with model Theta for Validation 2\n",
      "84 - Theta with avg smape 41.05: \n",
      "Validation Round: 3\n",
      "Model Number: 1 of 84 with model AverageValueNaive for Validation 3\n",
      "📈 1 - AverageValueNaive with avg smape 91.91: \n",
      "Model Number: 2 of 84 with model AverageValueNaive for Validation 3\n",
      "2 - AverageValueNaive with avg smape 91.91: \n",
      "Model Number: 3 of 84 with model UnobservedComponents for Validation 3\n",
      "3 - UnobservedComponents with avg smape 125.4: \n",
      "Model Number: 4 of 84 with model GLM for Validation 3\n",
      "📈 4 - GLM with avg smape 90.56: \n",
      "Model Number: 5 of 84 with model UnobservedComponents for Validation 3\n",
      "5 - UnobservedComponents with avg smape 90.62: \n",
      "Model Number: 6 of 84 with model GLS for Validation 3\n",
      "6 - GLS with avg smape 107.46: \n",
      "Model Number: 7 of 84 with model UnobservedComponents for Validation 3\n",
      "7 - UnobservedComponents with avg smape 125.21: \n",
      "Model Number: 8 of 84 with model NVAR for Validation 3\n",
      "8 - NVAR with avg smape 92.59: \n",
      "Model Number: 9 of 84 with model GLS for Validation 3\n",
      "9 - GLS with avg smape 90.62: \n",
      "Model Number: 10 of 84 with model GLS for Validation 3\n",
      "10 - GLS with avg smape 90.62: \n",
      "Model Number: 11 of 84 with model GLS for Validation 3\n",
      "11 - GLS with avg smape 90.62: \n",
      "Model Number: 12 of 84 with model GLM for Validation 3\n",
      "12 - GLM with avg smape 90.62: \n",
      "Model Number: 13 of 84 with model GLS for Validation 3\n",
      "13 - GLS with avg smape 90.62: \n",
      "Model Number: 14 of 84 with model AverageValueNaive for Validation 3\n",
      "14 - AverageValueNaive with avg smape 126.42: \n",
      "Model Number: 15 of 84 with model NVAR for Validation 3\n",
      "15 - NVAR with avg smape 180.48: \n",
      "Model Number: 16 of 84 with model NVAR for Validation 3\n",
      "16 - NVAR with avg smape 180.48: \n",
      "Model Number: 17 of 84 with model NVAR for Validation 3\n",
      "17 - NVAR with avg smape 180.48: \n",
      "Model Number: 18 of 84 with model ARDL for Validation 3\n",
      "18 - ARDL with avg smape 125.1: \n",
      "Model Number: 19 of 84 with model AverageValueNaive for Validation 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\statsmodels\\genmod\\families\\links.py:198: RuntimeWarning: overflow encountered in exp\n",
      "  t = np.exp(-z)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19 - AverageValueNaive with avg smape 141.95: \n",
      "Model Number: 20 of 84 with model GLM for Validation 3\n",
      "20 - GLM with avg smape 97.45: \n",
      "Model Number: 21 of 84 with model GLM for Validation 3\n",
      "21 - GLM with avg smape 97.45: \n",
      "Model Number: 22 of 84 with model NVAR for Validation 3\n",
      "Template Eval Error: Exception('Transformer RegressionFilter failed on fit') in model 22 in generation 0: NVAR\n",
      "Model Number: 23 of 84 with model GLM for Validation 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\statsmodels\\genmod\\families\\links.py:198: RuntimeWarning: overflow encountered in exp\n",
      "  t = np.exp(-z)\n",
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\statsmodels\\genmod\\families\\links.py:198: RuntimeWarning: overflow encountered in exp\n",
      "  t = np.exp(-z)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23 - GLM with avg smape 113.75: \n",
      "Model Number: 24 of 84 with model SeasonalNaive for Validation 3\n",
      "📈 24 - SeasonalNaive with avg smape 27.19: \n",
      "Model Number: 25 of 84 with model ETS for Validation 3\n",
      "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
      "ETS failed on NET_SALES with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
      "25 - ETS with avg smape 42.33: \n",
      "Model Number: 26 of 84 with model AverageValueNaive for Validation 3\n",
      "26 - AverageValueNaive with avg smape 119.06: \n",
      "Model Number: 27 of 84 with model UnobservedComponents for Validation 3\n",
      "27 - UnobservedComponents with avg smape 137.23: \n",
      "Model Number: 28 of 84 with model ETS for Validation 3\n",
      "Template Eval Error: Exception('Transformer RegressionFilter failed on fit') in model 28 in generation 0: ETS\n",
      "Model Number: 29 of 84 with model LastValueNaive for Validation 3\n",
      "📈 29 - LastValueNaive with avg smape 22.1: \n",
      "Model Number: 30 of 84 with model LastValueNaive for Validation 3\n",
      "30 - LastValueNaive with avg smape 79.57: \n",
      "Model Number: 31 of 84 with model UnobservedComponents for Validation 3\n",
      "31 - UnobservedComponents with avg smape 137.77: \n",
      "Model Number: 32 of 84 with model ARIMA for Validation 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.860e+11, tolerance: 5.200e+07\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32 - ARIMA with avg smape 79.86: \n",
      "Model Number: 33 of 84 with model ARDL for Validation 3\n",
      "33 - ARDL with avg smape 50.25: \n",
      "Model Number: 34 of 84 with model ARDL for Validation 3\n",
      "34 - ARDL with avg smape 50.25: \n",
      "Model Number: 35 of 84 with model SeasonalNaive for Validation 3\n",
      "Template Eval Error: Exception('Transformer RegressionFilter failed on fit') in model 35 in generation 0: SeasonalNaive\n",
      "Model Number: 36 of 84 with model ARIMA for Validation 3\n",
      "36 - ARIMA with avg smape 96.86: \n",
      "Model Number: 37 of 84 with model LastValueNaive for Validation 3\n",
      "Template Eval Error: Exception('Transformer RegressionFilter failed on fit') in model 37 in generation 0: LastValueNaive\n",
      "Model Number: 38 of 84 with model SectionalMotif for Validation 3\n",
      "38 - SectionalMotif with avg smape 22.23: \n",
      "Model Number: 39 of 84 with model SectionalMotif for Validation 3\n",
      "39 - SectionalMotif with avg smape 24.12: \n",
      "Model Number: 40 of 84 with model ARDL for Validation 3\n",
      "40 - ARDL with avg smape 63.34: \n",
      "Model Number: 41 of 84 with model ARDL for Validation 3\n",
      "41 - ARDL with avg smape 133.99: \n",
      "Model Number: 42 of 84 with model ETS for Validation 3\n",
      "ETS error ValueError('Can only dampen the trend component')\n",
      "ETS failed on NET_SALES with ValueError('Can only dampen the trend component')\n",
      "42 - ETS with avg smape 76.45: \n",
      "Model Number: 43 of 84 with model ETS for Validation 3\n",
      "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
      "ETS failed on NET_SALES with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
      "43 - ETS with avg smape 76.45: \n",
      "Model Number: 44 of 84 with model ETS for Validation 3\n",
      "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
      "ETS failed on NET_SALES with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
      "44 - ETS with avg smape 76.45: \n",
      "Model Number: 45 of 84 with model ARIMA for Validation 3\n",
      "45 - ARIMA with avg smape 52.12: \n",
      "Model Number: 46 of 84 with model SeasonalNaive for Validation 3\n",
      "Template Eval Error: Exception('Transformer RegressionFilter failed on fit') in model 46 in generation 0: SeasonalNaive\n",
      "Model Number: 47 of 84 with model DatepartRegression for Validation 3\n",
      "47 - DatepartRegression with avg smape 137.45: \n",
      "Model Number: 48 of 84 with model ARIMA for Validation 3\n",
      "48 - ARIMA with avg smape 90.77: \n",
      "Model Number: 49 of 84 with model SectionalMotif for Validation 3\n",
      "Template Eval Error: ValueError('kth(=3) out of bounds (2)') in model 49 in generation 0: SectionalMotif\n",
      "Model Number: 50 of 84 with model ARIMA for Validation 3\n",
      "50 - ARIMA with avg smape 31.2: \n",
      "Model Number: 51 of 84 with model MultivariateRegression for Validation 3\n",
      "Template Eval Error: Exception('Transformer RegressionFilter failed on fit') in model 51 in generation 0: MultivariateRegression\n",
      "Model Number: 52 of 84 with model LastValueNaive for Validation 3\n",
      "52 - LastValueNaive with avg smape 33.92: \n",
      "Model Number: 53 of 84 with model SeasonalNaive for Validation 3\n",
      "53 - SeasonalNaive with avg smape 128.0: \n",
      "Model Number: 54 of 84 with model LastValueNaive for Validation 3\n",
      "54 - LastValueNaive with avg smape 50.03: \n",
      "Model Number: 55 of 84 with model MultivariateRegression for Validation 3\n",
      "55 - MultivariateRegression with avg smape 42.73: \n",
      "Model Number: 56 of 84 with model SeasonalNaive for Validation 3\n",
      "56 - SeasonalNaive with avg smape 108.15: \n",
      "Model Number: 57 of 84 with model DatepartRegression for Validation 3\n",
      "57 - DatepartRegression with avg smape 22.39: \n",
      "Model Number: 58 of 84 with model DatepartRegression for Validation 3\n",
      "58 - DatepartRegression with avg smape 54.94: \n",
      "Model Number: 59 of 84 with model MultivariateRegression for Validation 3\n",
      "59 - MultivariateRegression with avg smape 87.72: \n",
      "Model Number: 60 of 84 with model DatepartRegression for Validation 3\n",
      "📈 60 - DatepartRegression with avg smape 20.14: \n",
      "Model Number: 61 of 84 with model MultivariateMotif for Validation 3\n",
      "61 - MultivariateMotif with avg smape 76.03: \n",
      "Model Number: 62 of 84 with model UnivariateMotif for Validation 3\n",
      "62 - UnivariateMotif with avg smape 78.79: \n",
      "Model Number: 63 of 84 with model UnivariateMotif for Validation 3\n",
      "63 - UnivariateMotif with avg smape 78.79: \n",
      "Model Number: 64 of 84 with model Theta for Validation 3\n",
      "Template Eval Error: Exception('Transformer RegressionFilter failed on fit') in model 64 in generation 0: Theta\n",
      "Model Number: 65 of 84 with model MetricMotif for Validation 3\n",
      "Template Eval Error: ValueError('window shape cannot be larger than input array shape') in model 65 in generation 0: MetricMotif\n",
      "Model Number: 66 of 84 with model SectionalMotif for Validation 3\n",
      "66 - SectionalMotif with avg smape 93.28: \n",
      "Model Number: 67 of 84 with model Theta for Validation 3\n",
      "67 - Theta with avg smape 28.9: \n",
      "Model Number: 68 of 84 with model SectionalMotif for Validation 3\n",
      "68 - SectionalMotif with avg smape 39.78: \n",
      "Model Number: 69 of 84 with model MultivariateMotif for Validation 3\n",
      "69 - MultivariateMotif with avg smape 73.97: \n",
      "Model Number: 70 of 84 with model UnivariateMotif for Validation 3\n",
      "70 - UnivariateMotif with avg smape 79.58: \n",
      "Model Number: 71 of 84 with model DatepartRegression for Validation 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\linear_model\\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.9706e-24): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71 - DatepartRegression with avg smape 24.44: \n",
      "Model Number: 72 of 84 with model ConstantNaive for Validation 3\n",
      "72 - ConstantNaive with avg smape 50.87: \n",
      "Model Number: 73 of 84 with model UnivariateMotif for Validation 3\n",
      "73 - UnivariateMotif with avg smape 88.24: \n",
      "Model Number: 74 of 84 with model WindowRegression for Validation 3\n",
      "74 - WindowRegression with avg smape 85.5: \n",
      "Model Number: 75 of 84 with model WindowRegression for Validation 3\n",
      "75 - WindowRegression with avg smape 64.59: \n",
      "Model Number: 76 of 84 with model WindowRegression for Validation 3\n",
      "76 - WindowRegression with avg smape 72.12: \n",
      "Model Number: 77 of 84 with model MetricMotif for Validation 3\n",
      "Template Eval Error: ValueError('window shape cannot be larger than input array shape') in model 77 in generation 0: MetricMotif\n",
      "Model Number: 78 of 84 with model UnivariateMotif for Validation 3\n",
      "78 - UnivariateMotif with avg smape 69.37: \n",
      "Model Number: 79 of 84 with model MetricMotif for Validation 3\n",
      "79 - MetricMotif with avg smape 47.55: \n",
      "Model Number: 80 of 84 with model MetricMotif for Validation 3\n",
      "80 - MetricMotif with avg smape 51.04: \n",
      "Model Number: 81 of 84 with model MetricMotif for Validation 3\n",
      "81 - MetricMotif with avg smape 47.4: \n",
      "Model Number: 82 of 84 with model WindowRegression for Validation 3\n",
      "82 - WindowRegression with avg smape 116.19: \n",
      "Model Number: 83 of 84 with model Theta for Validation 3\n",
      "83 - Theta with avg smape 43.33: \n",
      "Model Number: 84 of 84 with model Theta for Validation 3\n",
      "84 - Theta with avg smape 47.33: \n",
      "TotalRuntime missing in 5!\n",
      "Validation Round: 1\n",
      "TotalRuntime missing in 0!\n",
      "Validation Round: 2\n",
      "TotalRuntime missing in 0!\n",
      "Validation Round: 3\n",
      "TotalRuntime missing in 0!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██▏       | 3/14 [08:08<29:50, 162.74s/it]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "future_regressor and X index failed to align",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 49\u001b[0m\n\u001b[0;32m     39\u001b[0m model \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mfit(\n\u001b[0;32m     40\u001b[0m     df_subset_trim,\n\u001b[0;32m     41\u001b[0m     future_regressor\u001b[39m=\u001b[39mdf_subset_train,\n\u001b[0;32m     42\u001b[0m     date_col\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mMONTH\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m     43\u001b[0m     value_col\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mNET_SALES\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m     44\u001b[0m )\n\u001b[0;32m     46\u001b[0m \u001b[39m# print(model)\u001b[39;00m\n\u001b[0;32m     47\u001b[0m \n\u001b[0;32m     48\u001b[0m \u001b[39m# create prediction\u001b[39;00m\n\u001b[1;32m---> 49\u001b[0m prediction \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mpredict(future_regressor\u001b[39m=\u001b[39;49mdf_subset_fcast, forecast_length\u001b[39m=\u001b[39;49mfh)\n\u001b[0;32m     51\u001b[0m \u001b[39m# temp fcast dataframe\u001b[39;00m\n\u001b[0;32m     52\u001b[0m temp_fcasts \u001b[39m=\u001b[39m prediction\u001b[39m.\u001b[39mforecast\n",
      "File \u001b[1;32mc:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\autots\\evaluator\\auto_ts.py:2199\u001b[0m, in \u001b[0;36mAutoTS.predict\u001b[1;34m(self, forecast_length, prediction_interval, future_regressor, hierarchy, just_point_forecast, fail_on_forecast_nan, verbose)\u001b[0m\n\u001b[0;32m   2197\u001b[0m     \u001b[39mreturn\u001b[39;00m forecast_objects\n\u001b[0;32m   2198\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 2199\u001b[0m     df_forecast \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_predict(\n\u001b[0;32m   2200\u001b[0m         forecast_length\u001b[39m=\u001b[39;49mforecast_length,\n\u001b[0;32m   2201\u001b[0m         prediction_interval\u001b[39m=\u001b[39;49mprediction_interval,\n\u001b[0;32m   2202\u001b[0m         future_regressor\u001b[39m=\u001b[39;49mfuture_regressor,\n\u001b[0;32m   2203\u001b[0m         fail_on_forecast_nan\u001b[39m=\u001b[39;49mfail_on_forecast_nan,\n\u001b[0;32m   2204\u001b[0m         verbose\u001b[39m=\u001b[39;49mverbose,\n\u001b[0;32m   2205\u001b[0m     )\n\u001b[0;32m   2206\u001b[0m     \u001b[39mif\u001b[39;00m just_point_forecast:\n\u001b[0;32m   2207\u001b[0m         \u001b[39mreturn\u001b[39;00m df_forecast\u001b[39m.\u001b[39mforecast\n",
      "File \u001b[1;32mc:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\autots\\evaluator\\auto_ts.py:2074\u001b[0m, in \u001b[0;36mAutoTS._predict\u001b[1;34m(self, forecast_length, prediction_interval, future_regressor, fail_on_forecast_nan, verbose, model_name, model_params, model_transformation_params, df_wide_numeric, future_regressor_train, refit)\u001b[0m\n\u001b[0;32m   2072\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   2073\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mfit_data(use_data, future_regressor\u001b[39m=\u001b[39muse_regr_train)\n\u001b[1;32m-> 2074\u001b[0m     df_forecast \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel\u001b[39m.\u001b[39;49mpredict(\n\u001b[0;32m   2075\u001b[0m         forecast_length, future_regressor\u001b[39m=\u001b[39;49mfuture_regressor\n\u001b[0;32m   2076\u001b[0m     )\n\u001b[0;32m   2077\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   2078\u001b[0m     df_forecast \u001b[39m=\u001b[39m model_forecast(\n\u001b[0;32m   2079\u001b[0m         model_name\u001b[39m=\u001b[39muse_model,\n\u001b[0;32m   2080\u001b[0m         model_param_dict\u001b[39m=\u001b[39muse_params,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2099\u001b[0m         return_model\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[0;32m   2100\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\autots\\evaluator\\auto_model.py:765\u001b[0m, in \u001b[0;36mModelPrediction.predict\u001b[1;34m(self, forecast_length, future_regressor)\u001b[0m\n\u001b[0;32m    763\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fit_complete:\n\u001b[0;32m    764\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mModel not yet fit.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m--> 765\u001b[0m df_forecast \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel\u001b[39m.\u001b[39;49mpredict(\n\u001b[0;32m    766\u001b[0m     forecast_length\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mforecast_length, future_regressor\u001b[39m=\u001b[39;49mfuture_regressor\n\u001b[0;32m    767\u001b[0m )\n\u001b[0;32m    769\u001b[0m \u001b[39m# THIS CHECKS POINT FORECAST FOR NULLS BUT NOT UPPER/LOWER FORECASTS\u001b[39;00m\n\u001b[0;32m    770\u001b[0m \u001b[39m# can maybe remove this eventually and just keep the later one\u001b[39;00m\n\u001b[0;32m    771\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfail_on_forecast_nan:\n",
      "File \u001b[1;32mc:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\autots\\models\\sklearn.py:2047\u001b[0m, in \u001b[0;36mDatepartRegression.predict\u001b[1;34m(self, forecast_length, future_regressor, just_point_forecast, df)\u001b[0m\n\u001b[0;32m   2045\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mX_pred \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mconcat([\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mX_pred, future_regressor], axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m   2046\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mX_pred\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m] \u001b[39m>\u001b[39m index\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]:\n\u001b[1;32m-> 2047\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mfuture_regressor and X index failed to align\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   2048\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mX_pred\u001b[39m.\u001b[39mcolumns \u001b[39m=\u001b[39m [\u001b[39mstr\u001b[39m(xc) \u001b[39mfor\u001b[39;00m xc \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mX_pred\u001b[39m.\u001b[39mcolumns]\n\u001b[0;32m   2050\u001b[0m forecast \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(\n\u001b[0;32m   2051\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mpredict(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mX_pred\u001b[39m.\u001b[39mastype(\u001b[39mfloat\u001b[39m)),\n\u001b[0;32m   2052\u001b[0m     index\u001b[39m=\u001b[39mindex,\n\u001b[0;32m   2053\u001b[0m     columns\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumn_names,\n\u001b[0;32m   2054\u001b[0m )\n",
      "\u001b[1;31mValueError\u001b[0m: future_regressor and X index failed to align"
     ]
    }
   ],
   "source": [
    "### Time Series Loop w/ Regressors ###\n",
    "\n",
    "# Create empty dataframes\n",
    "all_predictions = pd.DataFrame()\n",
    "\n",
    "# list of each dep-ent\n",
    "de_list = df_d_regress1['DEP_ENT'].unique()\n",
    "\n",
    "for i in tqdm(de_list):\n",
    "\n",
    "    df_subset = df_d_regress1[df_d_regress1['DEP_ENT'] == i]\n",
    "    df_subset_trim = df_subset[df_subset['MONTH'] <= end_of_data]\n",
    "    df_subset_trim = df_subset_trim[['MONTH', 'NET_SALES']]\n",
    "\n",
    "    # split the train and original df\n",
    "\n",
    "    # train\n",
    "    df_subset_train = df_subset[df_subset['MONTH'] <= end_of_data]\n",
    "    df_subset_train = df_subset_train[[\"MONTH\", \"COVID\", \"AMZN\"]]\n",
    "\n",
    "    # for future forecast\n",
    "    df_subset_fcast = df_subset[df_subset['MONTH'] > end_of_data]\n",
    "    df_subset_fcast = df_subset_fcast[[\"MONTH\", \"COVID\", \"AMZN\"]]\n",
    "\n",
    "    # model\n",
    "    model = AutoTS(\n",
    "        forecast_length=fh,\n",
    "        frequency='infer',\n",
    "        # prediction_interval=0.95,\n",
    "        # ensemble='simple',\n",
    "        # models_mode='deep',\n",
    "        # model_list = 'univariate', # or could do a list like ['ARIMA','ETS']\n",
    "        max_generations=3,\n",
    "        num_validations=3,\n",
    "        no_negatives=True,\n",
    "        n_jobs='auto'\n",
    "    )\n",
    "\n",
    "    model = model.fit(\n",
    "        df_subset_trim,\n",
    "        future_regressor=df_subset_train,\n",
    "        date_col='MONTH',\n",
    "        value_col='NET_SALES',\n",
    "    )\n",
    "\n",
    "    # print(model)\n",
    "\n",
    "    # create prediction\n",
    "    prediction = model.predict(future_regressor=df_subset_fcast, forecast_length=fh)\n",
    "\n",
    "    # temp fcast dataframe\n",
    "    temp_fcasts = prediction.forecast\n",
    "\n",
    "    # rename\n",
    "    temp_fcasts.rename(columns={'index': 'MONTH'}, inplace=True)\n",
    "\n",
    "    temp_fcasts['DEP_ENT'] = i  # add dep\n",
    "\n",
    "    # append to master dataframe\n",
    "    all_predictions = all_predictions.append(temp_fcasts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### AFTER THE LOOP ###\n",
    "\n",
    "# rename index col\n",
    "all_predictions.rename(columns={'index': 'MONTH', 'NET_SALES': 'PRED'}, inplace=True)\n",
    "\n",
    "# initial sales pull\n",
    "sales = df_initial\n",
    "# select cols\n",
    "sales = sales[[\"DEP_ENT\", \"MONTH\", \"NET_SALES\"]]\n",
    "# only include sales data for the full months we have\n",
    "first_of_month = datetime.today().replace(day=1).date()\n",
    "sales = sales[sales['MONTH'] < pd.to_datetime(first_of_month)]\n",
    "\n",
    "# combine prediction data and original sales data\n",
    "merged = pd.merge(all_predictions, sales, how='left', on=['DEP_ENT', 'MONTH'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (py.warnings._showwarnmsg) - C:\\Users\\crudek\\AppData\\Local\\Temp\\ipykernel_12204\\3534014428.py:8: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  budg = pd.read_sql_query(query.read(),conn)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### Budget ###\n",
    "\n",
    "# Establish a connection to Snowflake\n",
    "conn = snowflake.connector.connect(**connection_params)\n",
    "\n",
    "with open('budget_query.sql', 'r') as query:\n",
    "    # connection == the connection to your database, in your case prob_db\n",
    "    budg = pd.read_sql_query(query.read(), conn)\n",
    "\n",
    "# Close the connection\n",
    "conn.close()\n",
    "\n",
    "# convert month to datetime\n",
    "budg[\"MONTH\"] = pd.to_datetime(budg[\"MONTH\"])\n",
    "# select cols\n",
    "budg = budg[[\"MONTH\", \"BUDGET_AMOUNT\", \"DEP_ENT\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine prediction/sales data with budget data\n",
    "merged2 = pd.merge(merged, budg, how='left', on=['DEP_ENT', 'MONTH'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write csv\n",
    "merged2.to_csv('auto_ts_results.csv')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "newpycaret",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
