{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "use newpycaret env\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# packages\n",
    "import snowflake.connector\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from autots import AutoTS\n",
    "from sklearn.impute import SimpleImputer\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime, timedelta\n",
    "from dateutil import relativedelta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Load Data\n",
    "\n",
    "---\n",
    "\n",
    "### To Do: copy and paste in to a new chunk, enter credentials and run to save in environment. Then delete chunk\n",
    "\n",
    "%env snowflakeuser=<your_snowflake_username> <br>\n",
    "%env snowflakepass=<your_snowflake_password>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\crudek\\AppData\\Local\\Temp\\ipykernel_11000\\2623517584.py:19: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_initial = pd.read_sql_query(query.read(), conn)\n"
     ]
    }
   ],
   "source": [
    "# Query Snowflake\n",
    "\n",
    "# Snowflake connection parameters\n",
    "connection_params = {\n",
    "    \"user\": os.environ['snowflakeuser'],\n",
    "    \"password\": os.environ['snowflakepass'],\n",
    "    \"account\": \"zib52348.us-east-1\",\n",
    "    \"role\": \"ACCOUNTADMIN\",\n",
    "    \"warehouse\": \"REPORTING\",\n",
    "    \"database\": \"ANALYTICS\",\n",
    "    \"schema\": \"FORECASTING\",\n",
    "}\n",
    "\n",
    "# Establish a connection to Snowflake\n",
    "conn = snowflake.connector.connect(**connection_params)\n",
    "\n",
    "with open('net_sales_query.sql', 'r') as query:\n",
    "    # connection == the connection to your database, in your case prob_db\n",
    "    df_initial = pd.read_sql_query(query.read(), conn)\n",
    "\n",
    "# Close the connection\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/14 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\crudek\\AppData\\Local\\Temp\\ipykernel_11000\\508753571.py:108: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_subset_all = df_subset_all.append(df_merged)\n",
      "C:\\Users\\crudek\\AppData\\Local\\Temp\\ipykernel_11000\\508753571.py:108: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_subset_all = df_subset_all.append(df_merged)\n",
      "C:\\Users\\crudek\\AppData\\Local\\Temp\\ipykernel_11000\\508753571.py:108: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_subset_all = df_subset_all.append(df_merged)\n",
      "C:\\Users\\crudek\\AppData\\Local\\Temp\\ipykernel_11000\\508753571.py:108: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_subset_all = df_subset_all.append(df_merged)\n",
      "C:\\Users\\crudek\\AppData\\Local\\Temp\\ipykernel_11000\\508753571.py:108: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_subset_all = df_subset_all.append(df_merged)\n",
      "C:\\Users\\crudek\\AppData\\Local\\Temp\\ipykernel_11000\\508753571.py:108: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_subset_all = df_subset_all.append(df_merged)\n",
      "C:\\Users\\crudek\\AppData\\Local\\Temp\\ipykernel_11000\\508753571.py:108: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_subset_all = df_subset_all.append(df_merged)\n",
      "C:\\Users\\crudek\\AppData\\Local\\Temp\\ipykernel_11000\\508753571.py:108: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_subset_all = df_subset_all.append(df_merged)\n",
      "C:\\Users\\crudek\\AppData\\Local\\Temp\\ipykernel_11000\\508753571.py:108: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_subset_all = df_subset_all.append(df_merged)\n",
      "C:\\Users\\crudek\\AppData\\Local\\Temp\\ipykernel_11000\\508753571.py:108: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_subset_all = df_subset_all.append(df_merged)\n",
      "C:\\Users\\crudek\\AppData\\Local\\Temp\\ipykernel_11000\\508753571.py:108: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_subset_all = df_subset_all.append(df_merged)\n",
      "C:\\Users\\crudek\\AppData\\Local\\Temp\\ipykernel_11000\\508753571.py:108: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_subset_all = df_subset_all.append(df_merged)\n",
      "C:\\Users\\crudek\\AppData\\Local\\Temp\\ipykernel_11000\\508753571.py:108: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_subset_all = df_subset_all.append(df_merged)\n",
      "C:\\Users\\crudek\\AppData\\Local\\Temp\\ipykernel_11000\\508753571.py:108: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_subset_all = df_subset_all.append(df_merged)\n",
      "100%|██████████| 14/14 [00:00<00:00, 379.59it/s]\n",
      "  0%|          | 0/14 [00:00<?, ?it/s]C:\\Users\\crudek\\AppData\\Local\\Temp\\ipykernel_11000\\508753571.py:126: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_subset_all2 = df_subset_all2.append(temp_result2)\n",
      "C:\\Users\\crudek\\AppData\\Local\\Temp\\ipykernel_11000\\508753571.py:126: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_subset_all2 = df_subset_all2.append(temp_result2)\n",
      "C:\\Users\\crudek\\AppData\\Local\\Temp\\ipykernel_11000\\508753571.py:126: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_subset_all2 = df_subset_all2.append(temp_result2)\n",
      "C:\\Users\\crudek\\AppData\\Local\\Temp\\ipykernel_11000\\508753571.py:126: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_subset_all2 = df_subset_all2.append(temp_result2)\n",
      "C:\\Users\\crudek\\AppData\\Local\\Temp\\ipykernel_11000\\508753571.py:126: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_subset_all2 = df_subset_all2.append(temp_result2)\n",
      "C:\\Users\\crudek\\AppData\\Local\\Temp\\ipykernel_11000\\508753571.py:126: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_subset_all2 = df_subset_all2.append(temp_result2)\n",
      "C:\\Users\\crudek\\AppData\\Local\\Temp\\ipykernel_11000\\508753571.py:126: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_subset_all2 = df_subset_all2.append(temp_result2)\n",
      "C:\\Users\\crudek\\AppData\\Local\\Temp\\ipykernel_11000\\508753571.py:126: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_subset_all2 = df_subset_all2.append(temp_result2)\n",
      "C:\\Users\\crudek\\AppData\\Local\\Temp\\ipykernel_11000\\508753571.py:126: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_subset_all2 = df_subset_all2.append(temp_result2)\n",
      "C:\\Users\\crudek\\AppData\\Local\\Temp\\ipykernel_11000\\508753571.py:126: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_subset_all2 = df_subset_all2.append(temp_result2)\n",
      "C:\\Users\\crudek\\AppData\\Local\\Temp\\ipykernel_11000\\508753571.py:126: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_subset_all2 = df_subset_all2.append(temp_result2)\n",
      "C:\\Users\\crudek\\AppData\\Local\\Temp\\ipykernel_11000\\508753571.py:126: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_subset_all2 = df_subset_all2.append(temp_result2)\n",
      "C:\\Users\\crudek\\AppData\\Local\\Temp\\ipykernel_11000\\508753571.py:126: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_subset_all2 = df_subset_all2.append(temp_result2)\n",
      "C:\\Users\\crudek\\AppData\\Local\\Temp\\ipykernel_11000\\508753571.py:126: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_subset_all2 = df_subset_all2.append(temp_result2)\n",
      "100%|██████████| 14/14 [00:00<00:00, 561.88it/s]\n"
     ]
    }
   ],
   "source": [
    "##### INITIAL VARIABLE DECLARATION #####\n",
    "\n",
    "# Get the current date\n",
    "current_date = datetime.today()\n",
    "\n",
    "# Calculate the first day of the current month\n",
    "first_day_of_current_month = pd.to_datetime(current_date.replace(day=1))\n",
    "\n",
    "# Calculate the first day of the next month\n",
    "first_day_of_next_month = datetime(current_date.year, current_date.month + 1, 1)\n",
    "\n",
    "# Calculate the first day of the last month\n",
    "last_day_of_last_month = first_day_of_current_month - timedelta(days=1)\n",
    "first_day_of_last_month = last_day_of_last_month.replace(day=1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### MANUAL INPUTS ###\n",
    "\n",
    "# how much data do you want to keep to train models. \n",
    "#end_of_data = first_day_of_last_month # the default which is the max date this should ever be because it would include all months that have full data\n",
    "end_of_data = pd.to_datetime('2022-12-01')\n",
    "\n",
    "# forecast horizon = how many months in to the future you want to forecast. So, we will forecast this many months past the above end_of_data\n",
    "fh = 12\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### FORECAST HORIZON (FH) DATAFRAME ###\n",
    "\n",
    "end_of_data_next_month = end_of_data + relativedelta.relativedelta(months=1, day=1)\n",
    "end_of_data_df = pd.DataFrame({'end_of_data': [end_of_data_next_month]})\n",
    "end_of_data_df['end_of_data'] = pd.to_datetime(end_of_data_df['end_of_data'])\n",
    "\n",
    "# Create a date range for the next 12 months\n",
    "next_12_months = pd.date_range(start=end_of_data_df['end_of_data'].iloc[0], periods=fh, freq='MS')\n",
    "\n",
    "fh_dates_df = pd.DataFrame({'MONTH': next_12_months})\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### INITIAL DATA PREPARATION ###\n",
    "\n",
    "# create copy of df_d\n",
    "df = df_initial.copy(deep=True)\n",
    "\n",
    "# convert month field to date\n",
    "df[\"MONTH\"] = pd.to_datetime(df[\"MONTH\"])\n",
    "\n",
    "# Some random months will have data that we want to remove (* Want to test without July though)\n",
    "df = df[[\"DEP_ENT\", \"MONTH\", \"NET_SALES\"]]  # select fields of interest\n",
    "df = df.sort_values(['DEP_ENT', 'MONTH'])  # reorder dataframe\n",
    "\n",
    "# remove data after the 'end of data' setting above\n",
    "df_sub = df[df['MONTH'] <= end_of_data]\n",
    "\n",
    "# create series\n",
    "df_s = df_sub.set_index(['DEP_ENT','MONTH'])['NET_SALES']\n",
    "# convert back to dataframe\n",
    "df_d = df_s.to_frame()\n",
    "#reset index\n",
    "df_d.reset_index(inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### IMPUTE MISSIG VALUES WITH MONTH AND MEAN ###\n",
    "\n",
    "# list of each dep-ent\n",
    "all_dep_ent = df_d['DEP_ENT'].unique()\n",
    "\n",
    "# Create empty dataframe\n",
    "df_subset_all = pd.DataFrame()\n",
    "\n",
    "for i in tqdm(all_dep_ent):\n",
    "    \n",
    "    temp_subset = df_d[df_d['DEP_ENT'] == i]\n",
    "    \n",
    "    # Define the minimum and maximum dates\n",
    "    min_date = min(temp_subset['MONTH'])\n",
    "    max_date = max(temp_subset['MONTH'])\n",
    "\n",
    "    # Generate a list of dates for each month in between\n",
    "    date_range = []\n",
    "    current_month = min_date.replace(day=1)\n",
    "    while current_month <= max_date:\n",
    "        date_range.append(current_month)\n",
    "        current_month = current_month + timedelta(days=32)\n",
    "        current_month = current_month.replace(day=1)\n",
    "\n",
    "    # Create a DataFrame from the list of dates\n",
    "    date_range_df = pd.DataFrame({'MONTH': date_range})\n",
    "\n",
    "    df_merged = pd.merge(date_range_df, temp_subset, on='MONTH', how='left')\n",
    "\n",
    "    #Finding the mean of the column having NaN\n",
    "    mean_value = df_merged['NET_SALES'].mean()\n",
    "    \n",
    "    # Replace NaNs in column S2 with the\n",
    "    # mean of values in the same column\n",
    "    df_merged['NET_SALES'].fillna(value=mean_value, inplace=True)\n",
    "    \n",
    "    df_merged['DEP_ENT'] = i\n",
    "\n",
    "    df_subset_all = df_subset_all.append(df_merged)\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "### FILL DATES THROUGH END OF FORECAST HORIZON ###\n",
    "\n",
    "# Create empty dataframe\n",
    "df_subset_all2 = pd.DataFrame()\n",
    "\n",
    "for i in tqdm(all_dep_ent):\n",
    "    # filter to one dep_ent\n",
    "    temp_subset2 = df_subset_all[df_subset_all['DEP_ENT'] == i]\n",
    "    # temp result\n",
    "    temp_result2 = pd.merge(temp_subset2, fh_dates_df, on='MONTH', how='outer')\n",
    "    temp_result2['DEP_ENT'] = i\n",
    "    \n",
    "    # combine for all dep_ents\n",
    "    df_subset_all2 = df_subset_all2.append(temp_result2)\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "### REGRESSOR DATA PREPARATION ###\n",
    "\n",
    "# create copy of df_d\n",
    "df_d_regress = df_subset_all2.copy(deep=True)\n",
    "\n",
    "# Prepare regressors\n",
    "\n",
    "# Define the prime COVID period\n",
    "cov_start_date = pd.Timestamp(2020, 1, 1)\n",
    "cov_end_date = pd.Timestamp(2021, 12, 1)\n",
    "\n",
    "# Create the binary dummy variable\n",
    "df_d_regress['COVID'] = df_d_regress['MONTH'].apply(lambda date: '1' if cov_start_date <= date <= cov_end_date else '0')\n",
    "\n",
    "# Amazon prime day shipments\n",
    "\n",
    "# Define the dictionary\n",
    "amzn_ship_dict = {\n",
    "    'MONTH': [pd.Timestamp(2016, 7, 1), pd.Timestamp(2017, 5, 1), pd.Timestamp(2018, 6, 1), pd.Timestamp(2019, 6, 1), pd.Timestamp(2020, 6, 1),\n",
    "              pd.Timestamp(2020, 10, 1), pd.Timestamp(2021, 5, 1), pd.Timestamp(2022, 5, 1), pd.Timestamp(2023, 5, 1), pd.Timestamp(2023, 6, 1), pd.Timestamp(2023, 7, 1)],\n",
    "    'AMZN': ['1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1']\n",
    "}\n",
    "\n",
    "# Create a DataFrame from the dictionary\n",
    "amzn_ship_df = pd.DataFrame(amzn_ship_dict)\n",
    "# add Amazon department\n",
    "amzn_ship_df['DEP_ENT'] = '250_155'\n",
    "\n",
    "# combine in to single table\n",
    "df_d_regress1 = df_d_regress.merge(\n",
    "    amzn_ship_df, on=['DEP_ENT', 'MONTH'], how='left')\n",
    "\n",
    "df_d_regress1['AMZN'] = df_d_regress1['AMZN'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEP_ENT\n",
      "160_155    96\n",
      "170_155    96\n",
      "200_155    96\n",
      "200_310    96\n",
      "210_155    96\n",
      "210_165    96\n",
      "210_310    96\n",
      "220_155    96\n",
      "220_310    91\n",
      "240_155    96\n",
      "250_155    96\n",
      "250_165    63\n",
      "250_310    96\n",
      "260_155    59\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df_d_regress1.groupby(['DEP_ENT']).size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/14 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 6 cpus for n_jobs.\n",
      "Data frequency is: MS, used frequency is: MS\n",
      "Model Number: 1 with model ARIMA in generation 0 of 3\n",
      "Model Number: 2 with model AverageValueNaive in generation 0 of 3\n",
      "Model Number: 3 with model AverageValueNaive in generation 0 of 3\n",
      "Model Number: 4 with model AverageValueNaive in generation 0 of 3\n",
      "Model Number: 5 with model DatepartRegression in generation 0 of 3\n",
      "Model Number: 6 with model DatepartRegression in generation 0 of 3\n",
      "Model Number: 7 with model DatepartRegression in generation 0 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 8 with model DatepartRegression in generation 0 of 3\n",
      "Template Eval Error: ImportError('Tensorflow not available, install with pip install tensorflow.') in model 8 in generation 0: DatepartRegression\n",
      "Model Number: 9 with model ETS in generation 0 of 3\n",
      "Model Number: 10 with model ETS in generation 0 of 3\n",
      "Model Number: 11 with model GLM in generation 0 of 3\n",
      "Model Number: 12 with model GLM in generation 0 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:541: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 13 with model GLS in generation 0 of 3\n",
      "Model Number: 14 with model GLS in generation 0 of 3\n",
      "Model Number: 15 with model GluonTS in generation 0 of 3\n",
      "Template Eval Error: ImportError('GluonTS installation is incompatible with AutoTS. The numpy version is sometimes the issue, try 1.23.1 {as of 06-2023}') in model 15 in generation 0: GluonTS\n",
      "Model Number: 16 with model GluonTS in generation 0 of 3\n",
      "Template Eval Error: ImportError('GluonTS installation is incompatible with AutoTS. The numpy version is sometimes the issue, try 1.23.1 {as of 06-2023}') in model 16 in generation 0: GluonTS\n",
      "Model Number: 17 with model GluonTS in generation 0 of 3\n",
      "Template Eval Error: ImportError('GluonTS installation is incompatible with AutoTS. The numpy version is sometimes the issue, try 1.23.1 {as of 06-2023}') in model 17 in generation 0: GluonTS\n",
      "Model Number: 18 with model GluonTS in generation 0 of 3\n",
      "Template Eval Error: ImportError('GluonTS installation is incompatible with AutoTS. The numpy version is sometimes the issue, try 1.23.1 {as of 06-2023}') in model 18 in generation 0: GluonTS\n",
      "Model Number: 19 with model GluonTS in generation 0 of 3\n",
      "Template Eval Error: ImportError('GluonTS installation is incompatible with AutoTS. The numpy version is sometimes the issue, try 1.23.1 {as of 06-2023}') in model 19 in generation 0: GluonTS\n",
      "Model Number: 20 with model LastValueNaive in generation 0 of 3\n",
      "Model Number: 21 with model LastValueNaive in generation 0 of 3\n",
      "Model Number: 22 with model LastValueNaive in generation 0 of 3\n",
      "Model Number: 23 with model LastValueNaive in generation 0 of 3\n",
      "Model Number: 24 with model SeasonalNaive in generation 0 of 3\n",
      "Model Number: 25 with model SeasonalNaive in generation 0 of 3\n",
      "Model Number: 26 with model SeasonalNaive in generation 0 of 3\n",
      "Model Number: 27 with model UnobservedComponents in generation 0 of 3\n",
      "Model Number: 28 with model UnobservedComponents in generation 0 of 3\n",
      "Model Number: 29 with model UnobservedComponents in generation 0 of 3\n",
      "Model Number: 30 with model VAR in generation 0 of 3\n",
      "Template Eval Error: ValueError('Only gave one variable to VAR') in model 30 in generation 0: VAR\n",
      "Model Number: 31 with model VAR in generation 0 of 3\n",
      "Template Eval Error: ValueError('Only gave one variable to VAR') in model 31 in generation 0: VAR\n",
      "Model Number: 32 with model VECM in generation 0 of 3\n",
      "Template Eval Error: ValueError('Only gave one variable to VECM') in model 32 in generation 0: VECM\n",
      "Model Number: 33 with model VECM in generation 0 of 3\n",
      "Template Eval Error: ValueError('Only gave one variable to VECM') in model 33 in generation 0: VECM\n",
      "Model Number: 34 with model WindowRegression in generation 0 of 3\n",
      "Model Number: 35 with model ConstantNaive in generation 0 of 3\n",
      "Model Number: 36 with model FBProphet in generation 0 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18:57:31 - cmdstanpy - INFO - Chain [1] start processing\n",
      "18:57:31 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 37 with model GluonTS in generation 0 of 3\n",
      "Template Eval Error: ImportError('GluonTS installation is incompatible with AutoTS. The numpy version is sometimes the issue, try 1.23.1 {as of 06-2023}') in model 37 in generation 0: GluonTS\n",
      "Model Number: 38 with model MultivariateRegression in generation 0 of 3\n",
      "Model Number: 39 with model MultivariateRegression in generation 0 of 3\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000028 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Model Number: 40 with model DatepartRegression in generation 0 of 3\n",
      "Model Number: 41 with model SeasonalNaive in generation 0 of 3\n",
      "Model Number: 42 with model DatepartRegression in generation 0 of 3\n",
      "Model Number: 43 with model UnobservedComponents in generation 0 of 3\n",
      "Model Number: 44 with model UnobservedComponents in generation 0 of 3\n",
      "Model Number: 45 with model ETS in generation 0 of 3\n",
      "Model Number: 46 with model VECM in generation 0 of 3\n",
      "Template Eval Error: ValueError('Only gave one variable to VECM') in model 46 in generation 0: VECM\n",
      "Model Number: 47 with model ARDL in generation 0 of 3\n",
      "Model Number: 48 with model MultivariateMotif in generation 0 of 3\n",
      "Model Number: 49 with model MultivariateMotif in generation 0 of 3\n",
      "Model Number: 50 with model UnivariateMotif in generation 0 of 3\n",
      "Template Eval Error: ValueError('kth(=10) out of bounds (1)') in model 50 in generation 0: UnivariateMotif\n",
      "Model Number: 51 with model UnivariateMotif in generation 0 of 3\n",
      "Model Number: 52 with model SectionalMotif in generation 0 of 3\n",
      "Model Number: 53 with model SectionalMotif in generation 0 of 3\n",
      "Model Number: 54 with model MultivariateRegression in generation 0 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18:57:34 - cmdstanpy - INFO - Chain [1] start processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 55 with model FBProphet in generation 0 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18:57:56 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 56 with model SeasonalNaive in generation 0 of 3\n",
      "Model Number: 57 with model DatepartRegression in generation 0 of 3\n",
      "Model Number: 58 with model NVAR in generation 0 of 3\n",
      "Model Number: 59 with model Theta in generation 0 of 3\n",
      "Model Number: 60 with model UnivariateRegression in generation 0 of 3\n",
      "Template Eval Error: ValueError('Input X contains NaN.\\nDecisionTreeRegressor does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values') in model 60 in generation 0: UnivariateRegression\n",
      "Model Number: 61 with model ARCH in generation 0 of 3\n",
      "Template Eval Error: ImportError('`arch` package must be installed from pip') in model 61 in generation 0: ARCH\n",
      "Model Number: 62 with model ConstantNaive in generation 0 of 3\n",
      "Model Number: 63 with model LastValueNaive in generation 0 of 3\n",
      "Model Number: 64 with model AverageValueNaive in generation 0 of 3\n",
      "Model Number: 65 with model GLS in generation 0 of 3\n",
      "Model Number: 66 with model SeasonalNaive in generation 0 of 3\n",
      "Model Number: 67 with model GLM in generation 0 of 3\n",
      "Template Eval Error: ValueError('The first guess on the deviance function returned a nan.  This could be a boundary  problem and should be reported.') in model 67 in generation 0: GLM\n",
      "Model Number: 68 with model ETS in generation 0 of 3\n",
      "Model Number: 69 with model FBProphet in generation 0 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\statsmodels\\genmod\\families\\family.py:1367: ValueWarning: Negative binomial dispersion parameter alpha not set. Using default value alpha=1.0.\n",
      "  warnings.warn(\"Negative binomial dispersion parameter alpha not \"\n",
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\statsmodels\\genmod\\families\\family.py:1406: RuntimeWarning: invalid value encountered in log\n",
      "  resid_dev -= endog_alpha * np.log(endog_alpha / mu_alpha)\n",
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.336e+12, tolerance: 2.160e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "18:57:57 - cmdstanpy - INFO - Chain [1] start processing\n",
      "18:57:58 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 70 with model GluonTS in generation 0 of 3\n",
      "Template Eval Error: ImportError('GluonTS installation is incompatible with AutoTS. The numpy version is sometimes the issue, try 1.23.1 {as of 06-2023}') in model 70 in generation 0: GluonTS\n",
      "Model Number: 71 with model UnobservedComponents in generation 0 of 3\n",
      "Model Number: 72 with model VAR in generation 0 of 3\n",
      "Template Eval Error: ValueError('Only gave one variable to VAR') in model 72 in generation 0: VAR\n",
      "Model Number: 73 with model VECM in generation 0 of 3\n",
      "Template Eval Error: ValueError('Only gave one variable to VECM') in model 73 in generation 0: VECM\n",
      "Model Number: 74 with model ARIMA in generation 0 of 3\n",
      "Model Number: 75 with model WindowRegression in generation 0 of 3\n",
      "Model Number: 76 with model DatepartRegression in generation 0 of 3\n",
      "Model Number: 77 with model UnivariateRegression in generation 0 of 3\n",
      "Model Number: 78 with model MultivariateRegression in generation 0 of 3\n",
      "Model Number: 79 with model UnivariateMotif in generation 0 of 3\n",
      "Model Number: 80 with model MultivariateMotif in generation 0 of 3\n",
      "Template Eval Error: ValueError('kth(=100) out of bounds (51)') in model 80 in generation 0: MultivariateMotif\n",
      "Model Number: 81 with model SectionalMotif in generation 0 of 3\n",
      "Template Eval Error: ValueError(\"Model returned NaN due to a preprocessing transformer {'fillna': 'rolling_mean', 'transformations': {'0': 'SeasonalDifference', '1': 'AlignLastValue', '2': 'AlignLastValue', '3': 'EWMAFilter'}, 'transformation_params': {'0': {'lag_1': 7, 'method': 'LastValue'}, '1': {'rows': 1, 'lag': 1, 'method': 'multiplicative', 'strength': 1.0, 'first_value_only': False}, '2': {'rows': 1, 'lag': 1, 'method': 'additive', 'strength': 1.0, 'first_value_only': False}, '3': {'span': 12}}}. fail_on_forecast_nan=True\") in model 81 in generation 0: SectionalMotif\n",
      "Model Number: 82 with model NVAR in generation 0 of 3\n",
      "Model Number: 83 with model Theta in generation 0 of 3\n",
      "Model Number: 84 with model ARDL in generation 0 of 3\n",
      "Model Number: 85 with model ARCH in generation 0 of 3\n",
      "Template Eval Error: ImportError('`arch` package must be installed from pip') in model 85 in generation 0: ARCH\n",
      "Model Number: 86 with model MetricMotif in generation 0 of 3\n",
      "Model Number: 87 with model AverageValueNaive in generation 0 of 3\n",
      "Model Number: 88 with model UnobservedComponents in generation 0 of 3\n",
      "Model Number: 89 with model AverageValueNaive in generation 0 of 3\n",
      "Model Number: 90 with model LastValueNaive in generation 0 of 3\n",
      "Model Number: 91 with model ARDL in generation 0 of 3\n",
      "Model Number: 92 with model WindowRegression in generation 0 of 3\n",
      "Model Number: 93 with model ConstantNaive in generation 0 of 3\n",
      "Model Number: 94 with model SeasonalNaive in generation 0 of 3\n",
      "Model Number: 95 with model ARDL in generation 0 of 3\n",
      "Template Eval Error: ValueError(\"ARDL series NET_SALES failed with error ValueError('The number of regressors (178) including deterministics, lags of the endog, lags of the exogenous, and fixed regressors is larger than the sample available for estimation (69).') exog train             weekend  quarter      epoch  month_1  month_2  month_3  month_4  \\\\\\nMONTH                                                                         \\n2016-01-01        0        1  2457388.5      1.0      0.0      0.0      0.0   \\n2016-02-01        0        1  2457419.5      0.0      1.0      0.0      0.0   \\n2016-03-01        0        1  2457448.5      0.0      0.0      1.0      0.0   \\n2016-04-01        0        2  2457479.5      0.0      0.0      0.0      1.0   \\n2016-05-01        1        2  2457509.5      0.0      0.0      0.0      0.0   \\n...             ...      ...        ...      ...      ...      ...      ...   \\n2021-08-01        1        3  2459427.5      0.0      0.0      0.0      0.0   \\n2021-09-01        0        3  2459458.5      0.0      0.0      0.0      0.0   \\n2021-10-01        0        4  2459488.5      0.0      0.0      0.0      0.0   \\n2021-11-01        0        4  2459519.5      0.0      0.0      0.0      0.0   \\n2021-12-01        0        4  2459549.5      0.0      0.0      0.0      0.0   \\n\\n            month_5  month_6  month_7  ...  day_27  day_28  day_29  day_30  \\\\\\nMONTH                                  ...                                   \\n2016-01-01      0.0      0.0      0.0  ...     0.0     0.0     0.0     0.0   \\n2016-02-01      0.0      0.0      0.0  ...     0.0     0.0     0.0     0.0   \\n2016-03-01      0.0      0.0      0.0  ...     0.0     0.0     0.0     0.0   \\n2016-04-01      0.0      0.0      0.0  ...     0.0     0.0     0.0     0.0   \\n2016-05-01      1.0      0.0      0.0  ...     0.0     0.0     0.0     0.0   \\n...             ...      ...      ...  ...     ...     ...     ...     ...   \\n2021-08-01      0.0      0.0      0.0  ...     0.0     0.0     0.0     0.0   \\n2021-09-01      0.0      0.0      0.0  ...     0.0     0.0     0.0     0.0   \\n2021-10-01      0.0      0.0      0.0  ...     0.0     0.0     0.0     0.0   \\n2021-11-01      0.0      0.0      0.0  ...     0.0     0.0     0.0     0.0   \\n2021-12-01      0.0      0.0      0.0  ...     0.0     0.0     0.0     0.0   \\n\\n            day_31  weekdayofmonth_1  weekdayofmonth_2  weekdayofmonth_3  \\\\\\nMONTH                                                                      \\n2016-01-01     0.0               1.0               0.0               0.0   \\n2016-02-01     0.0               1.0               0.0               0.0   \\n2016-03-01     0.0               1.0               0.0               0.0   \\n2016-04-01     0.0               1.0               0.0               0.0   \\n2016-05-01     0.0               1.0               0.0               0.0   \\n...            ...               ...               ...               ...   \\n2021-08-01     0.0               1.0               0.0               0.0   \\n2021-09-01     0.0               1.0               0.0               0.0   \\n2021-10-01     0.0               1.0               0.0               0.0   \\n2021-11-01     0.0               1.0               0.0               0.0   \\n2021-12-01     0.0               1.0               0.0               0.0   \\n\\n            weekdayofmonth_4  weekdayofmonth_5  \\nMONTH                                           \\n2016-01-01               0.0               0.0  \\n2016-02-01               0.0               0.0  \\n2016-03-01               0.0               0.0  \\n2016-04-01               0.0               0.0  \\n2016-05-01               0.0               0.0  \\n...                      ...               ...  \\n2021-08-01               0.0               0.0  \\n2021-09-01               0.0               0.0  \\n2021-10-01               0.0               0.0  \\n2021-11-01               0.0               0.0  \\n2021-12-01               0.0               0.0  \\n\\n[72 rows x 58 columns] and predict             weekend  quarter      epoch  month_1  month_2  month_3  month_4  \\\\\\n2022-01-01        1        1  2459580.5      1.0      0.0      0.0      0.0   \\n2022-02-01        0        1  2459611.5      0.0      1.0      0.0      0.0   \\n2022-03-01        0        1  2459639.5      0.0      0.0      1.0      0.0   \\n2022-04-01        0        2  2459670.5      0.0      0.0      0.0      1.0   \\n2022-05-01        1        2  2459700.5      0.0      0.0      0.0      0.0   \\n2022-06-01        0        2  2459731.5      0.0      0.0      0.0      0.0   \\n2022-07-01        0        3  2459761.5      0.0      0.0      0.0      0.0   \\n2022-08-01        0        3  2459792.5      0.0      0.0      0.0      0.0   \\n2022-09-01        0        3  2459823.5      0.0      0.0      0.0      0.0   \\n2022-10-01        1        4  2459853.5      0.0      0.0      0.0      0.0   \\n2022-11-01        0        4  2459884.5      0.0      0.0      0.0      0.0   \\n2022-12-01        0        4  2459914.5      0.0      0.0      0.0      0.0   \\n\\n            month_5  month_6  month_7  ...  day_27  day_28  day_29  day_30  \\\\\\n2022-01-01      0.0      0.0      0.0  ...     0.0     0.0     0.0     0.0   \\n2022-02-01      0.0      0.0      0.0  ...     0.0     0.0     0.0     0.0   \\n2022-03-01      0.0      0.0      0.0  ...     0.0     0.0     0.0     0.0   \\n2022-04-01      0.0      0.0      0.0  ...     0.0     0.0     0.0     0.0   \\n2022-05-01      1.0      0.0      0.0  ...     0.0     0.0     0.0     0.0   \\n2022-06-01      0.0      1.0      0.0  ...     0.0     0.0     0.0     0.0   \\n2022-07-01      0.0      0.0      1.0  ...     0.0     0.0     0.0     0.0   \\n2022-08-01      0.0      0.0      0.0  ...     0.0     0.0     0.0     0.0   \\n2022-09-01      0.0      0.0      0.0  ...     0.0     0.0     0.0     0.0   \\n2022-10-01      0.0      0.0      0.0  ...     0.0     0.0     0.0     0.0   \\n2022-11-01      0.0      0.0      0.0  ...     0.0     0.0     0.0     0.0   \\n2022-12-01      0.0      0.0      0.0  ...     0.0     0.0     0.0     0.0   \\n\\n            day_31  weekdayofmonth_1  weekdayofmonth_2  weekdayofmonth_3  \\\\\\n2022-01-01     0.0               1.0               0.0               0.0   \\n2022-02-01     0.0               1.0               0.0               0.0   \\n2022-03-01     0.0               1.0               0.0               0.0   \\n2022-04-01     0.0               1.0               0.0               0.0   \\n2022-05-01     0.0               1.0               0.0               0.0   \\n2022-06-01     0.0               1.0               0.0               0.0   \\n2022-07-01     0.0               1.0               0.0               0.0   \\n2022-08-01     0.0               1.0               0.0               0.0   \\n2022-09-01     0.0               1.0               0.0               0.0   \\n2022-10-01     0.0               1.0               0.0               0.0   \\n2022-11-01     0.0               1.0               0.0               0.0   \\n2022-12-01     0.0               1.0               0.0               0.0   \\n\\n            weekdayofmonth_4  weekdayofmonth_5  \\n2022-01-01               0.0               0.0  \\n2022-02-01               0.0               0.0  \\n2022-03-01               0.0               0.0  \\n2022-04-01               0.0               0.0  \\n2022-05-01               0.0               0.0  \\n2022-06-01               0.0               0.0  \\n2022-07-01               0.0               0.0  \\n2022-08-01               0.0               0.0  \\n2022-09-01               0.0               0.0  \\n2022-10-01               0.0               0.0  \\n2022-11-01               0.0               0.0  \\n2022-12-01               0.0               0.0  \\n\\n[12 rows x 58 columns]\") in model 95 in generation 0: ARDL\n",
      "Model Number: 96 with model FBProphet in generation 0 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18:57:59 - cmdstanpy - INFO - Chain [1] start processing\n",
      "18:58:00 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 97 with model ConstantNaive in generation 0 of 3\n",
      "Model Number: 98 with model ConstantNaive in generation 0 of 3\n",
      "Model Number: 99 with model UnobservedComponents in generation 0 of 3\n",
      "Model Number: 100 with model ConstantNaive in generation 0 of 3\n",
      "Model Number: 101 with model VAR in generation 0 of 3\n",
      "Template Eval Error: ValueError('Only gave one variable to VAR') in model 101 in generation 0: VAR\n",
      "Model Number: 102 with model ETS in generation 0 of 3\n",
      "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
      "ETS failed on NET_SALES with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
      "Model Number: 103 with model Theta in generation 0 of 3\n",
      "Model Number: 104 with model DatepartRegression in generation 0 of 3\n",
      "Template Eval Error: ValueError('Model DatepartRegression returned NaN for one or more series. fail_on_forecast_nan=True') in model 104 in generation 0: DatepartRegression\n",
      "Model Number: 105 with model GLM in generation 0 of 3\n",
      "Model Number: 106 with model ARCH in generation 0 of 3\n",
      "Template Eval Error: Exception('Transformer Detrend failed on fit') in model 106 in generation 0: ARCH\n",
      "Model Number: 107 with model AverageValueNaive in generation 0 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\neighbors\\_regression.py:494: UserWarning: One or more samples have no neighbors within specified radius; predicting NaN.\n",
      "  warnings.warn(empty_warning_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 108 with model MetricMotif in generation 0 of 3\n",
      "Model Number: 109 with model ETS in generation 0 of 3\n",
      "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
      "ETS failed on NET_SALES with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
      "Template Eval Error: Exception('Transformer DifferencedTransformer failed on inverse') in model 109 in generation 0: ETS\n",
      "Model Number: 110 with model ETS in generation 0 of 3\n",
      "ETS error ValueError('Cannot compute initial seasonals using heuristic method with less than two full seasonal cycles in the data.')\n",
      "ETS failed on NET_SALES with ValueError('Cannot compute initial seasonals using heuristic method with less than two full seasonal cycles in the data.')\n",
      "Template Eval Error: Exception('Transformer AlignLastValue failed on inverse') in model 110 in generation 0: ETS\n",
      "Model Number: 111 with model SeasonalNaive in generation 0 of 3\n",
      "Model Number: 112 with model ARCH in generation 0 of 3\n",
      "Template Eval Error: ImportError('`arch` package must be installed from pip') in model 112 in generation 0: ARCH\n",
      "Model Number: 113 with model SectionalMotif in generation 0 of 3\n",
      "Model Number: 114 with model SeasonalNaive in generation 0 of 3\n",
      "Model Number: 115 with model UnivariateRegression in generation 0 of 3\n",
      "Model Number: 116 with model VAR in generation 0 of 3\n",
      "Template Eval Error: ValueError('Only gave one variable to VAR') in model 116 in generation 0: VAR\n",
      "Model Number: 117 with model GluonTS in generation 0 of 3\n",
      "Template Eval Error: ImportError('GluonTS installation is incompatible with AutoTS. The numpy version is sometimes the issue, try 1.23.1 {as of 06-2023}') in model 117 in generation 0: GluonTS\n",
      "Model Number: 118 with model GLM in generation 0 of 3\n",
      "Template Eval Error: ValueError('NaN, inf or invalid value detected in weights, estimation infeasible.') in model 118 in generation 0: GLM\n",
      "Model Number: 119 with model MultivariateMotif in generation 0 of 3\n",
      "Model Number: 120 with model AverageValueNaive in generation 0 of 3\n",
      "Model Number: 121 with model ConstantNaive in generation 0 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\statsmodels\\genmod\\families\\family.py:1367: ValueWarning: Negative binomial dispersion parameter alpha not set. Using default value alpha=1.0.\n",
      "  warnings.warn(\"Negative binomial dispersion parameter alpha not \"\n",
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\statsmodels\\genmod\\families\\links.py:527: RuntimeWarning: overflow encountered in exp\n",
      "  return np.exp(z)\n",
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\statsmodels\\genmod\\families\\family.py:1402: RuntimeWarning: divide by zero encountered in divide\n",
      "  endog_mu = self._clean(endog / mu)\n",
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\statsmodels\\genmod\\families\\family.py:1406: RuntimeWarning: divide by zero encountered in log\n",
      "  resid_dev -= endog_alpha * np.log(endog_alpha / mu_alpha)\n",
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\statsmodels\\genmod\\families\\family.py:1406: RuntimeWarning: invalid value encountered in log\n",
      "  resid_dev -= endog_alpha * np.log(endog_alpha / mu_alpha)\n",
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\numpy\\core\\fromnumeric.py:86: RuntimeWarning: invalid value encountered in reduce\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n",
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\statsmodels\\genmod\\families\\family.py:143: RuntimeWarning: invalid value encountered in multiply\n",
      "  return 1. / (self.link.deriv(mu)**2 * self.variance(mu))\n",
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\statsmodels\\genmod\\generalized_linear_model.py:1243: RuntimeWarning: invalid value encountered in multiply\n",
      "  wlsendog = (lin_pred + self.family.link.deriv(mu) * (self.endog-mu)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 122 with model ARCH in generation 0 of 3\n",
      "Template Eval Error: ImportError('`arch` package must be installed from pip') in model 122 in generation 0: ARCH\n",
      "Model Number: 123 with model GLS in generation 0 of 3\n",
      "Model Number: 124 with model LastValueNaive in generation 0 of 3\n",
      "Template Eval Error: Exception('Transformer RegressionFilter failed on fit') in model 124 in generation 0: LastValueNaive\n",
      "Model Number: 125 with model UnobservedComponents in generation 0 of 3\n",
      "Model Number: 126 with model LastValueNaive in generation 0 of 3\n",
      "Model Number: 127 with model SectionalMotif in generation 0 of 3\n",
      "Template Eval Error: ValueError('Unknown Distance Metric: kulsinski') in model 127 in generation 0: SectionalMotif\n",
      "Model Number: 128 with model GLS in generation 0 of 3\n",
      "Model Number: 129 with model Theta in generation 0 of 3\n",
      "Model Number: 130 with model UnobservedComponents in generation 0 of 3\n",
      "Model Number: 131 with model WindowRegression in generation 0 of 3\n",
      "Template Eval Error: ValueError('Input X contains NaN.\\nBayesianRidge does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values') in model 131 in generation 0: WindowRegression\n",
      "Model Number: 132 with model NVAR in generation 0 of 3\n",
      "Model Number: 133 with model SeasonalNaive in generation 0 of 3\n",
      "Model Number: 134 with model UnobservedComponents in generation 0 of 3\n",
      "Template Eval Error: Exception('Transformer Detrend failed on fit') in model 134 in generation 0: UnobservedComponents\n",
      "Model Number: 135 with model GLS in generation 0 of 3\n",
      "Model Number: 136 with model MetricMotif in generation 0 of 3\n",
      "Model Number: 137 with model VAR in generation 0 of 3\n",
      "Template Eval Error: ValueError('Only gave one variable to VAR') in model 137 in generation 0: VAR\n",
      "Model Number: 138 with model WindowRegression in generation 0 of 3\n",
      "Template Eval Error: ImportError('Tensorflow not available, install with pip install tensorflow.') in model 138 in generation 0: WindowRegression\n",
      "Model Number: 139 with model GLM in generation 0 of 3\n",
      "Model Number: 140 with model NVAR in generation 0 of 3\n",
      "Model Number: 141 with model VAR in generation 0 of 3\n",
      "Template Eval Error: ValueError('Only gave one variable to VAR') in model 141 in generation 0: VAR\n",
      "Model Number: 142 with model DatepartRegression in generation 0 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\statsmodels\\genmod\\families\\links.py:198: RuntimeWarning: overflow encountered in exp\n",
      "  t = np.exp(-z)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 143 with model GLS in generation 0 of 3\n",
      "Model Number: 144 with model DatepartRegression in generation 0 of 3\n",
      "Template Eval Error: ValueError('Input X contains NaN.\\nExtraTreesRegressor does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values') in model 144 in generation 0: DatepartRegression\n",
      "Model Number: 145 with model VAR in generation 0 of 3\n",
      "Template Eval Error: ValueError('Only gave one variable to VAR') in model 145 in generation 0: VAR\n",
      "Model Number: 146 with model Theta in generation 0 of 3\n",
      "Model Number: 147 with model ETS in generation 0 of 3\n",
      "ETS error ValueError('Cannot compute initial seasonals using heuristic method with less than two full seasonal cycles in the data.')\n",
      "ETS failed on NET_SALES with ValueError('Cannot compute initial seasonals using heuristic method with less than two full seasonal cycles in the data.')\n",
      "Model Number: 148 with model ConstantNaive in generation 0 of 3\n",
      "Model Number: 149 with model ARDL in generation 0 of 3\n",
      "Model Number: 150 with model SectionalMotif in generation 0 of 3\n",
      "Model Number: 151 with model VAR in generation 0 of 3\n",
      "Model Number: 152 with model DatepartRegression in generation 0 of 3\n",
      "Model Number: 153 with model Theta in generation 0 of 3\n",
      "Model Number: 154 with model MetricMotif in generation 0 of 3\n",
      "Model Number: 155 with model DatepartRegression in generation 0 of 3\n",
      "Model Number: 156 with model GLM in generation 0 of 3\n",
      "Model Number: 157 with model GluonTS in generation 0 of 3\n",
      "Template Eval Error: ImportError('GluonTS installation is incompatible with AutoTS. The numpy version is sometimes the issue, try 1.23.1 {as of 06-2023}') in model 157 in generation 0: GluonTS\n",
      "Model Number: 158 with model DatepartRegression in generation 0 of 3\n",
      "Template Eval Error: Exception('Transformer AlignLastValue failed on inverse') in model 158 in generation 0: DatepartRegression\n",
      "Model Number: 159 with model NVAR in generation 0 of 3\n",
      "Model Number: 160 with model GLS in generation 0 of 3\n",
      "Model Number: 161 with model SectionalMotif in generation 0 of 3\n",
      "Model Number: 162 with model FBProphet in generation 0 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18:58:03 - cmdstanpy - INFO - Chain [1] start processing\n",
      "18:58:03 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 163 with model ETS in generation 0 of 3\n",
      "Model Number: 164 with model VAR in generation 0 of 3\n",
      "Template Eval Error: ValueError('Only gave one variable to VAR') in model 164 in generation 0: VAR\n",
      "Model Number: 165 with model MultivariateMotif in generation 0 of 3\n",
      "Model Number: 166 with model VAR in generation 0 of 3\n",
      "Template Eval Error: ValueError('Only gave one variable to VAR') in model 166 in generation 0: VAR\n",
      "Model Number: 167 with model ARIMA in generation 0 of 3\n",
      "Model Number: 168 with model UnobservedComponents in generation 0 of 3\n",
      "Model Number: 169 with model UnivariateMotif in generation 0 of 3\n",
      "Template Eval Error: ValueError('kth(=100) out of bounds (51)') in model 169 in generation 0: UnivariateMotif\n",
      "Model Number: 170 with model VAR in generation 0 of 3\n",
      "Template Eval Error: ValueError('Only gave one variable to VAR') in model 170 in generation 0: VAR\n",
      "Model Number: 171 with model Theta in generation 0 of 3\n",
      "Model Number: 172 with model MultivariateMotif in generation 0 of 3\n",
      "Model Number: 173 with model UnobservedComponents in generation 0 of 3\n",
      "Model Number: 174 with model WindowRegression in generation 0 of 3\n",
      "Model Number: 175 with model SeasonalNaive in generation 0 of 3\n",
      "Model Number: 176 with model ARDL in generation 0 of 3\n",
      "Model Number: 177 with model GLS in generation 0 of 3\n",
      "Model Number: 178 with model SectionalMotif in generation 0 of 3\n",
      "Model Number: 179 with model ARDL in generation 0 of 3\n",
      "Model Number: 180 with model MultivariateMotif in generation 0 of 3\n",
      "Model Number: 181 with model ARCH in generation 0 of 3\n",
      "Template Eval Error: ImportError('`arch` package must be installed from pip') in model 181 in generation 0: ARCH\n",
      "Model Number: 182 with model SectionalMotif in generation 0 of 3\n",
      "Model Number: 183 with model ARIMA in generation 0 of 3\n",
      "Model Number: 184 with model DatepartRegression in generation 0 of 3\n",
      "Model Number: 185 with model ETS in generation 0 of 3\n",
      "ETS error ValueError('Cannot compute initial seasonals using heuristic method with less than two full seasonal cycles in the data.')\n",
      "ETS failed on NET_SALES with ValueError('Cannot compute initial seasonals using heuristic method with less than two full seasonal cycles in the data.')\n",
      "Model Number: 186 with model VECM in generation 0 of 3\n",
      "Template Eval Error: ValueError('Only gave one variable to VECM') in model 186 in generation 0: VECM\n",
      "New Generation: 1 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.097e-01, tolerance: 5.909e-04\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 187 with model AverageValueNaive in generation 1 of 3\n",
      "Model Number: 188 with model WindowRegression in generation 1 of 3\n",
      "Template Eval Error: LightGBMError('[tweedie]: at least one target label is negative') in model 188 in generation 1: WindowRegression\n",
      "Model Number: 189 with model SeasonalNaive in generation 1 of 3\n",
      "Model Number: 190 with model MultivariateRegression in generation 1 of 3\n",
      "Model Number: 191 with model GLM in generation 1 of 3\n",
      "Model Number: 192 with model UnobservedComponents in generation 1 of 3\n",
      "Model Number: 193 with model AverageValueNaive in generation 1 of 3\n",
      "Model Number: 194 with model UnobservedComponents in generation 1 of 3\n",
      "Model Number: 195 with model MetricMotif in generation 1 of 3\n",
      "Template Eval Error: ValueError('kth(=99) out of bounds (53)') in model 195 in generation 1: MetricMotif\n",
      "Model Number: 196 with model SeasonalNaive in generation 1 of 3\n",
      "Model Number: 197 with model ConstantNaive in generation 1 of 3\n",
      "Model Number: 198 with model SectionalMotif in generation 1 of 3\n",
      "Model Number: 199 with model NVAR in generation 1 of 3\n",
      "Model Number: 200 with model AverageValueNaive in generation 1 of 3\n",
      "Model Number: 201 with model ETS in generation 1 of 3\n",
      "ETS error ValueError('Cannot compute initial seasonals using heuristic method with less than two full seasonal cycles in the data.')\n",
      "ETS failed on NET_SALES with ValueError('Cannot compute initial seasonals using heuristic method with less than two full seasonal cycles in the data.')\n",
      "Model Number: 202 with model WindowRegression in generation 1 of 3\n",
      "Template Eval Error: ValueError('Found array with 0 sample(s) (shape=(0, 0)) while a minimum of 1 is required by PoissonRegressor.') in model 202 in generation 1: WindowRegression\n",
      "Model Number: 203 with model ETS in generation 1 of 3\n",
      "Model Number: 204 with model WindowRegression in generation 1 of 3\n",
      "Model Number: 205 with model NVAR in generation 1 of 3\n",
      "Model Number: 206 with model DatepartRegression in generation 1 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.303e+13, tolerance: 5.043e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 207 with model UnobservedComponents in generation 1 of 3\n",
      "Model Number: 208 with model GLS in generation 1 of 3\n",
      "Model Number: 209 with model SectionalMotif in generation 1 of 3\n",
      "Model Number: 210 with model MultivariateRegression in generation 1 of 3\n",
      "Model Number: 211 with model ARDL in generation 1 of 3\n",
      "Model Number: 212 with model ARIMA in generation 1 of 3\n",
      "Model Number: 213 with model ETS in generation 1 of 3\n",
      "Model Number: 214 with model LastValueNaive in generation 1 of 3\n",
      "Model Number: 215 with model GLS in generation 1 of 3\n",
      "Model Number: 216 with model Theta in generation 1 of 3\n",
      "Model Number: 217 with model MultivariateMotif in generation 1 of 3\n",
      "Model Number: 218 with model GLM in generation 1 of 3\n",
      "Model Number: 219 with model MultivariateMotif in generation 1 of 3\n",
      "Model Number: 220 with model UnobservedComponents in generation 1 of 3\n",
      "Model Number: 221 with model AverageValueNaive in generation 1 of 3\n",
      "Model Number: 222 with model SectionalMotif in generation 1 of 3\n",
      "Model Number: 223 with model AverageValueNaive in generation 1 of 3\n",
      "Model Number: 224 with model SeasonalNaive in generation 1 of 3\n",
      "Model Number: 225 with model DatepartRegression in generation 1 of 3\n",
      "Model Number: 226 with model FBProphet in generation 1 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18:58:11 - cmdstanpy - INFO - Chain [1] start processing\n",
      "18:58:11 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 227 with model ARIMA in generation 1 of 3\n",
      "Model Number: 228 with model ETS in generation 1 of 3\n",
      "Model Number: 229 with model DatepartRegression in generation 1 of 3\n",
      "Model Number: 230 with model ETS in generation 1 of 3\n",
      "ETS error ValueError('Can only dampen the trend component')\n",
      "ETS failed on NET_SALES with ValueError('Can only dampen the trend component')\n",
      "Model Number: 231 with model GLM in generation 1 of 3\n",
      "Model Number: 232 with model MetricMotif in generation 1 of 3\n",
      "Template Eval Error: ValueError('kth(=99) out of bounds (53)') in model 232 in generation 1: MetricMotif\n",
      "Model Number: 233 with model MetricMotif in generation 1 of 3\n",
      "Model Number: 234 with model FBProphet in generation 1 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\decomposition\\_fastica.py:583: UserWarning: Ignoring n_components with whiten=False.\n",
      "  warnings.warn(\"Ignoring n_components with whiten=False.\")\n",
      "18:58:12 - cmdstanpy - INFO - Chain [1] start processing\n",
      "18:58:12 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 235 with model NVAR in generation 1 of 3\n",
      "Model Number: 236 with model UnobservedComponents in generation 1 of 3\n",
      "Model Number: 237 with model NVAR in generation 1 of 3\n",
      "Model Number: 238 with model MultivariateRegression in generation 1 of 3\n",
      "Model Number: 239 with model SeasonalNaive in generation 1 of 3\n",
      "Model Number: 240 with model ETS in generation 1 of 3\n",
      "Model Number: 241 with model ConstantNaive in generation 1 of 3\n",
      "Model Number: 242 with model SectionalMotif in generation 1 of 3\n",
      "Template Eval Error: ValueError('kth(=15) out of bounds (11)') in model 242 in generation 1: SectionalMotif\n",
      "Model Number: 243 with model SeasonalNaive in generation 1 of 3\n",
      "Template Eval Error: Exception('Transformer RegressionFilter failed on fit') in model 243 in generation 1: SeasonalNaive\n",
      "Model Number: 244 with model SeasonalNaive in generation 1 of 3\n",
      "Model Number: 245 with model AverageValueNaive in generation 1 of 3\n",
      "Model Number: 246 with model SectionalMotif in generation 1 of 3\n",
      "Model Number: 247 with model SeasonalNaive in generation 1 of 3\n",
      "Model Number: 248 with model MultivariateMotif in generation 1 of 3\n",
      "Model Number: 249 with model UnivariateRegression in generation 1 of 3\n",
      "Model Number: 250 with model FBProphet in generation 1 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18:58:14 - cmdstanpy - INFO - Chain [1] start processing\n",
      "18:58:14 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 251 with model MetricMotif in generation 1 of 3\n",
      "Template Eval Error: ValueError('kth(=99) out of bounds (53)') in model 251 in generation 1: MetricMotif\n",
      "Model Number: 252 with model SectionalMotif in generation 1 of 3\n",
      "Model Number: 253 with model LastValueNaive in generation 1 of 3\n",
      "Model Number: 254 with model ETS in generation 1 of 3\n",
      "Model Number: 255 with model MultivariateRegression in generation 1 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\decomposition\\_fastica.py:708: FutureWarning: Starting in v1.3, whiten=True should be specified as whiten='arbitrary-variance' (its current behaviour). This behavior is deprecated in 1.1 and will raise ValueError in 1.3.\n",
      "  return self._fit_transform(X, compute_sources=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 256 with model ARDL in generation 1 of 3\n",
      "Model Number: 257 with model SeasonalNaive in generation 1 of 3\n",
      "Model Number: 258 with model DatepartRegression in generation 1 of 3\n",
      "Template Eval Error: Exception('Transformer Cointegration failed on fit') in model 258 in generation 1: DatepartRegression\n",
      "Model Number: 259 with model ARDL in generation 1 of 3\n",
      "Model Number: 260 with model ETS in generation 1 of 3\n",
      "Model Number: 261 with model ARIMA in generation 1 of 3\n",
      "Model Number: 262 with model WindowRegression in generation 1 of 3\n",
      "Template Eval Error: ValueError('Input X contains NaN.\\nRadiusNeighborsRegressor does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values') in model 262 in generation 1: WindowRegression\n",
      "Model Number: 263 with model GLS in generation 1 of 3\n",
      "Model Number: 264 with model UnobservedComponents in generation 1 of 3\n",
      "Model Number: 265 with model AverageValueNaive in generation 1 of 3\n",
      "Model Number: 266 with model ARDL in generation 1 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\neighbors\\_regression.py:494: UserWarning: One or more samples have no neighbors within specified radius; predicting NaN.\n",
      "  warnings.warn(empty_warning_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 267 with model WindowRegression in generation 1 of 3\n",
      "Template Eval Error: ValueError('Model WindowRegression returned NaN for one or more series. fail_on_forecast_nan=True') in model 267 in generation 1: WindowRegression\n",
      "Model Number: 268 with model NVAR in generation 1 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\neighbors\\_regression.py:494: UserWarning: One or more samples have no neighbors within specified radius; predicting NaN.\n",
      "  warnings.warn(empty_warning_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 269 with model ARIMA in generation 1 of 3\n",
      "Model Number: 270 with model UnobservedComponents in generation 1 of 3\n",
      "Model Number: 271 with model ARDL in generation 1 of 3\n",
      "Model Number: 272 with model SectionalMotif in generation 1 of 3\n",
      "Template Eval Error: ValueError('kth(=10) out of bounds (6)') in model 272 in generation 1: SectionalMotif\n",
      "Model Number: 273 with model DatepartRegression in generation 1 of 3\n",
      "Model Number: 274 with model UnobservedComponents in generation 1 of 3\n",
      "Model Number: 275 with model MultivariateMotif in generation 1 of 3\n",
      "Model Number: 276 with model ETS in generation 1 of 3\n",
      "Model Number: 277 with model MultivariateRegression in generation 1 of 3\n",
      "Model Number: 278 with model LastValueNaive in generation 1 of 3\n",
      "Model Number: 279 with model MetricMotif in generation 1 of 3\n",
      "Model Number: 280 with model MetricMotif in generation 1 of 3\n",
      "Model Number: 281 with model MultivariateMotif in generation 1 of 3\n",
      "Model Number: 282 with model UnivariateMotif in generation 1 of 3\n",
      "Model Number: 283 with model SectionalMotif in generation 1 of 3\n",
      "Model Number: 284 with model MultivariateMotif in generation 1 of 3\n",
      "Model Number: 285 with model UnivariateRegression in generation 1 of 3\n",
      "Model Number: 286 with model ARDL in generation 1 of 3\n",
      "Model Number: 287 with model ETS in generation 1 of 3\n",
      "Model Number: 288 with model ETS in generation 1 of 3\n",
      "ETS error ValueError('Can only dampen the trend component')\n",
      "ETS failed on NET_SALES with ValueError('Can only dampen the trend component')\n",
      "Model Number: 289 with model ARDL in generation 1 of 3\n",
      "Model Number: 290 with model ETS in generation 1 of 3\n",
      "Model Number: 291 with model MultivariateMotif in generation 1 of 3\n",
      "Model Number: 292 with model GLS in generation 1 of 3\n",
      "Model Number: 293 with model ConstantNaive in generation 1 of 3\n",
      "Model Number: 294 with model Theta in generation 1 of 3\n",
      "Model Number: 295 with model MultivariateRegression in generation 1 of 3\n",
      "Model Number: 296 with model ARDL in generation 1 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\autots\\tools\\probabilistic.py:67: RuntimeWarning: invalid value encountered in divide\n",
      "  (prior_mu / prior_sigma**2) + ((n * data_mu) / prior_sigma**2)\n",
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\autots\\tools\\probabilistic.py:68: RuntimeWarning: divide by zero encountered in divide\n",
      "  ) / ((1 / prior_sigma**2) + (n / prior_sigma**2))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 297 with model Theta in generation 1 of 3\n",
      "Model Number: 298 with model GLS in generation 1 of 3\n",
      "Model Number: 299 with model MetricMotif in generation 1 of 3\n",
      "Model Number: 300 with model NVAR in generation 1 of 3\n",
      "Model Number: 301 with model UnivariateRegression in generation 1 of 3\n",
      "Model Number: 302 with model UnobservedComponents in generation 1 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 303 with model FBProphet in generation 1 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18:58:19 - cmdstanpy - INFO - Chain [1] start processing\n",
      "18:58:19 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 304 with model MultivariateRegression in generation 1 of 3\n",
      "Model Number: 305 with model GLS in generation 1 of 3\n",
      "Model Number: 306 with model AverageValueNaive in generation 1 of 3\n",
      "Model Number: 307 with model MultivariateMotif in generation 1 of 3\n",
      "Model Number: 308 with model WindowRegression in generation 1 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\decomposition\\_fastica.py:708: FutureWarning: Starting in v1.3, whiten=True should be specified as whiten='arbitrary-variance' (its current behaviour). This behavior is deprecated in 1.1 and will raise ValueError in 1.3.\n",
      "  return self._fit_transform(X, compute_sources=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 309 with model ARDL in generation 1 of 3\n",
      "Model Number: 310 with model LastValueNaive in generation 1 of 3\n",
      "Model Number: 311 with model NVAR in generation 1 of 3\n",
      "New Generation: 2 of 3\n",
      "Model Number: 312 with model LastValueNaive in generation 2 of 3\n",
      "Model Number: 313 with model Theta in generation 2 of 3\n",
      "Model Number: 314 with model MultivariateMotif in generation 2 of 3\n",
      "Model Number: 315 with model UnobservedComponents in generation 2 of 3\n",
      "Model Number: 316 with model MultivariateRegression in generation 2 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\decomposition\\_fastica.py:708: FutureWarning: Starting in v1.3, whiten=True should be specified as whiten='arbitrary-variance' (its current behaviour). This behavior is deprecated in 1.1 and will raise ValueError in 1.3.\n",
      "  return self._fit_transform(X, compute_sources=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 317 with model SeasonalNaive in generation 2 of 3\n",
      "Model Number: 318 with model UnobservedComponents in generation 2 of 3\n",
      "Model Number: 319 with model NVAR in generation 2 of 3\n",
      "Model Number: 320 with model ETS in generation 2 of 3\n",
      "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
      "ETS failed on NET_SALES with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
      "Model Number: 321 with model AverageValueNaive in generation 2 of 3\n",
      "Model Number: 322 with model LastValueNaive in generation 2 of 3\n",
      "Template Eval Error: Exception('Transformer AlignLastValue failed on inverse') in model 322 in generation 2: LastValueNaive\n",
      "Model Number: 323 with model ETS in generation 2 of 3\n",
      "Model Number: 324 with model AverageValueNaive in generation 2 of 3\n",
      "Model Number: 325 with model ETS in generation 2 of 3\n",
      "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
      "ETS failed on NET_SALES with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
      "Model Number: 326 with model ARDL in generation 2 of 3\n",
      "Template Eval Error: Exception('Transformer Detrend failed on fit') in model 326 in generation 2: ARDL\n",
      "Model Number: 327 with model MultivariateMotif in generation 2 of 3\n",
      "Model Number: 328 with model WindowRegression in generation 2 of 3\n",
      "Template Eval Error: ValueError('`min_samples` may not be larger than number of samples: n_samples = 5.') in model 328 in generation 2: WindowRegression\n",
      "Model Number: 329 with model MultivariateMotif in generation 2 of 3\n",
      "Model Number: 330 with model GLM in generation 2 of 3\n",
      "Model Number: 331 with model GLM in generation 2 of 3\n",
      "Model Number: 332 with model GLS in generation 2 of 3\n",
      "Model Number: 333 with model ARDL in generation 2 of 3\n",
      "Model Number: 334 with model MultivariateMotif in generation 2 of 3\n",
      "Model Number: 335 with model ARDL in generation 2 of 3\n",
      "Model Number: 336 with model ETS in generation 2 of 3\n",
      "Model Number: 337 with model AverageValueNaive in generation 2 of 3\n",
      "Model Number: 338 with model AverageValueNaive in generation 2 of 3\n",
      "Model Number: 339 with model SectionalMotif in generation 2 of 3\n",
      "Model Number: 340 with model GLS in generation 2 of 3\n",
      "Model Number: 341 with model DatepartRegression in generation 2 of 3\n",
      "Template Eval Error: ImportError('Tensorflow not available, install with pip install tensorflow.') in model 341 in generation 2: DatepartRegression\n",
      "Model Number: 342 with model DatepartRegression in generation 2 of 3\n",
      "Model Number: 343 with model UnivariateRegression in generation 2 of 3\n",
      "Model Number: 344 with model ConstantNaive in generation 2 of 3\n",
      "Model Number: 345 with model SectionalMotif in generation 2 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\decomposition\\_fastica.py:708: FutureWarning: Starting in v1.3, whiten=True should be specified as whiten='arbitrary-variance' (its current behaviour). This behavior is deprecated in 1.1 and will raise ValueError in 1.3.\n",
      "  return self._fit_transform(X, compute_sources=True)\n",
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\decomposition\\_fastica.py:708: FutureWarning: Starting in v1.3, whiten=True should be specified as whiten='arbitrary-variance' (its current behaviour). This behavior is deprecated in 1.1 and will raise ValueError in 1.3.\n",
      "  return self._fit_transform(X, compute_sources=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 346 with model ARDL in generation 2 of 3\n",
      "Model Number: 347 with model UnivariateRegression in generation 2 of 3\n",
      "Template Eval Error: Exception('Transformer AnomalyRemoval failed on fit') in model 347 in generation 2: UnivariateRegression\n",
      "Model Number: 348 with model ConstantNaive in generation 2 of 3\n",
      "Model Number: 349 with model UnivariateRegression in generation 2 of 3\n",
      "Template Eval Error: ValueError(\"Model returned NaN due to a preprocessing transformer {'fillna': 'ffill', 'transformations': {'0': 'QuantileTransformer', '1': 'SeasonalDifference', '2': 'AlignLastValue', '3': 'DatepartRegression'}, 'transformation_params': {'0': {'output_distribution': 'uniform', 'n_quantiles': 24}, '1': {'lag_1': 364, 'method': 'LastValue'}, '2': {'rows': 4, 'lag': 1, 'method': 'multiplicative', 'strength': 1.0, 'first_value_only': True}, '3': {'regression_model': {'model': 'ExtraTrees', 'model_params': {'n_estimators': 100, 'min_samples_leaf': 1, 'max_depth': 20}}, 'datepart_method': 'simple_2', 'polynomial_degree': 2, 'transform_dict': {'fillna': None, 'transformations': {'0': 'ScipyFilter'}, 'transformation_params': {'0': {'method': 'savgol_filter', 'method_args': {'window_length': 31, 'polyorder': 3, 'deriv': 0, 'mode': 'interp'}}}}, 'holiday_countries_used': False}}}. fail_on_forecast_nan=True\") in model 349 in generation 2: UnivariateRegression\n",
      "Model Number: 350 with model MultivariateMotif in generation 2 of 3\n",
      "Template Eval Error: Exception('Transformer Cointegration failed on fit') in model 350 in generation 2: MultivariateMotif\n",
      "Model Number: 351 with model Theta in generation 2 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\covariance\\_robust_covariance.py:745: UserWarning: The covariance matrix associated to your dataset is not full rank\n",
      "  warnings.warn(\n",
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\autots\\tools\\probabilistic.py:67: RuntimeWarning: invalid value encountered in divide\n",
      "  (prior_mu / prior_sigma**2) + ((n * data_mu) / prior_sigma**2)\n",
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\autots\\tools\\probabilistic.py:68: RuntimeWarning: divide by zero encountered in divide\n",
      "  ) / ((1 / prior_sigma**2) + (n / prior_sigma**2))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 352 with model MetricMotif in generation 2 of 3\n",
      "Model Number: 353 with model NVAR in generation 2 of 3\n",
      "Model Number: 354 with model SectionalMotif in generation 2 of 3\n",
      "Model Number: 355 with model UnobservedComponents in generation 2 of 3\n",
      "Model Number: 356 with model DatepartRegression in generation 2 of 3\n",
      "Model Number: 357 with model MultivariateRegression in generation 2 of 3\n",
      "Model Number: 358 with model ETS in generation 2 of 3\n",
      "Model Number: 359 with model LastValueNaive in generation 2 of 3\n",
      "Model Number: 360 with model WindowRegression in generation 2 of 3\n",
      "Model Number: 361 with model SeasonalNaive in generation 2 of 3\n",
      "Model Number: 362 with model VAR in generation 2 of 3\n",
      "Template Eval Error: ValueError('Only gave one variable to VAR') in model 362 in generation 2: VAR\n",
      "Model Number: 363 with model DatepartRegression in generation 2 of 3\n",
      "Template Eval Error: ImportError('Tensorflow not available, install with pip install tensorflow.') in model 363 in generation 2: DatepartRegression\n",
      "Model Number: 364 with model GLS in generation 2 of 3\n",
      "Model Number: 365 with model MultivariateMotif in generation 2 of 3\n",
      "Model Number: 366 with model ARDL in generation 2 of 3\n",
      "Model Number: 367 with model ETS in generation 2 of 3\n",
      "Model Number: 368 with model UnobservedComponents in generation 2 of 3\n",
      "Model Number: 369 with model GLS in generation 2 of 3\n",
      "Model Number: 370 with model GLS in generation 2 of 3\n",
      "Model Number: 371 with model SectionalMotif in generation 2 of 3\n",
      "Model Number: 372 with model UnivariateMotif in generation 2 of 3\n",
      "Model Number: 373 with model NVAR in generation 2 of 3\n",
      "Model Number: 374 with model AverageValueNaive in generation 2 of 3\n",
      "Model Number: 375 with model NVAR in generation 2 of 3\n",
      "Model Number: 376 with model MultivariateRegression in generation 2 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\linear_model\\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.48343e-24): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 377 with model NVAR in generation 2 of 3\n",
      "Model Number: 378 with model ARDL in generation 2 of 3\n",
      "Template Eval Error: ValueError(\"ARDL series NET_SALES failed with error IndexError('tuple index out of range') exog train None and predict                    MONTH  COVID  AMZN\\nMONTH                                \\n2022-01-01  1.640995e+18    0.0   0.0\\n2022-02-01  1.643674e+18    0.0   0.0\\n2022-03-01  1.646093e+18    0.0   0.0\\n2022-04-01  1.648771e+18    0.0   0.0\\n2022-05-01  1.651363e+18    0.0   0.0\\n2022-06-01  1.654042e+18    0.0   0.0\\n2022-07-01  1.656634e+18    0.0   0.0\\n2022-08-01  1.659312e+18    0.0   0.0\\n2022-09-01  1.661990e+18    0.0   0.0\\n2022-10-01  1.664582e+18    0.0   0.0\\n2022-11-01  1.667261e+18    0.0   0.0\\n2022-12-01  1.669853e+18    0.0   0.0\") in model 378 in generation 2: ARDL\n",
      "Model Number: 379 with model GLS in generation 2 of 3\n",
      "Model Number: 380 with model UnivariateRegression in generation 2 of 3\n",
      "Model Number: 381 with model UnobservedComponents in generation 2 of 3\n",
      "Model Number: 382 with model LastValueNaive in generation 2 of 3\n",
      "Model Number: 383 with model DatepartRegression in generation 2 of 3\n",
      "Template Eval Error: ValueError('Model DatepartRegression returned NaN for one or more series. fail_on_forecast_nan=True') in model 383 in generation 2: DatepartRegression\n",
      "Model Number: 384 with model UnivariateMotif in generation 2 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\neighbors\\_regression.py:494: UserWarning: One or more samples have no neighbors within specified radius; predicting NaN.\n",
      "  warnings.warn(empty_warning_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Template Eval Error: Exception('Transformer AlignLastValue failed on inverse') in model 384 in generation 2: UnivariateMotif\n",
      "Model Number: 385 with model ConstantNaive in generation 2 of 3\n",
      "Model Number: 386 with model ARIMA in generation 2 of 3\n",
      "Model Number: 387 with model UnobservedComponents in generation 2 of 3\n",
      "Model Number: 388 with model AverageValueNaive in generation 2 of 3\n",
      "Model Number: 389 with model MultivariateRegression in generation 2 of 3\n",
      "Model Number: 390 with model LastValueNaive in generation 2 of 3\n",
      "Model Number: 391 with model AverageValueNaive in generation 2 of 3\n",
      "Model Number: 392 with model MetricMotif in generation 2 of 3\n",
      "Model Number: 393 with model GLS in generation 2 of 3\n",
      "Model Number: 394 with model NVAR in generation 2 of 3\n",
      "Model Number: 395 with model ETS in generation 2 of 3\n",
      "Model Number: 396 with model ARIMA in generation 2 of 3\n",
      "Model Number: 397 with model MultivariateRegression in generation 2 of 3\n",
      "Model Number: 398 with model GLS in generation 2 of 3\n",
      "Model Number: 399 with model ETS in generation 2 of 3\n",
      "Model Number: 400 with model DatepartRegression in generation 2 of 3\n",
      "Model Number: 401 with model ETS in generation 2 of 3\n",
      "Model Number: 402 with model Theta in generation 2 of 3\n",
      "Template Eval Error: ValueError('x must have 2 complete cycles requires 24 observations. x only has 21 observation(s)') in model 402 in generation 2: Theta\n",
      "Model Number: 403 with model SectionalMotif in generation 2 of 3\n",
      "Model Number: 404 with model DatepartRegression in generation 2 of 3\n",
      "Model Number: 405 with model GLS in generation 2 of 3\n",
      "Model Number: 406 with model ETS in generation 2 of 3\n",
      "Model Number: 407 with model ARDL in generation 2 of 3\n",
      "Template Eval Error: ValueError(\"ARDL series NET_SALES failed with error ValueError('The number of regressors (94) including deterministics, lags of the endog, lags of the exogenous, and fixed regressors is larger than the sample available for estimation (69).') exog train             weekend  quarter      epoch  month_1  month_2  month_3  month_4  \\\\\\nMONTH                                                                         \\n2016-01-01        0        1  2457388.5      1.0      0.0      0.0      0.0   \\n2016-02-01        0        1  2457419.5      0.0      1.0      0.0      0.0   \\n2016-03-01        0        1  2457448.5      0.0      0.0      1.0      0.0   \\n2016-04-01        0        2  2457479.5      0.0      0.0      0.0      1.0   \\n2016-05-01        1        2  2457509.5      0.0      0.0      0.0      0.0   \\n...             ...      ...        ...      ...      ...      ...      ...   \\n2021-08-01        1        3  2459427.5      0.0      0.0      0.0      0.0   \\n2021-09-01        0        3  2459458.5      0.0      0.0      0.0      0.0   \\n2021-10-01        0        4  2459488.5      0.0      0.0      0.0      0.0   \\n2021-11-01        0        4  2459519.5      0.0      0.0      0.0      0.0   \\n2021-12-01        0        4  2459549.5      0.0      0.0      0.0      0.0   \\n\\n            month_5  month_6  month_7  ...  month_11  month_12  weekday_0  \\\\\\nMONTH                                  ...                                  \\n2016-01-01      0.0      0.0      0.0  ...       0.0       0.0        0.0   \\n2016-02-01      0.0      0.0      0.0  ...       0.0       0.0        1.0   \\n2016-03-01      0.0      0.0      0.0  ...       0.0       0.0        0.0   \\n2016-04-01      0.0      0.0      0.0  ...       0.0       0.0        0.0   \\n2016-05-01      1.0      0.0      0.0  ...       0.0       0.0        0.0   \\n...             ...      ...      ...  ...       ...       ...        ...   \\n2021-08-01      0.0      0.0      0.0  ...       0.0       0.0        0.0   \\n2021-09-01      0.0      0.0      0.0  ...       0.0       0.0        0.0   \\n2021-10-01      0.0      0.0      0.0  ...       0.0       0.0        0.0   \\n2021-11-01      0.0      0.0      0.0  ...       1.0       0.0        1.0   \\n2021-12-01      0.0      0.0      0.0  ...       0.0       1.0        0.0   \\n\\n            weekday_1  weekday_2  weekday_3  weekday_4  weekday_5  weekday_6  \\\\\\nMONTH                                                                          \\n2016-01-01        0.0        0.0        0.0        1.0        0.0        0.0   \\n2016-02-01        0.0        0.0        0.0        0.0        0.0        0.0   \\n2016-03-01        1.0        0.0        0.0        0.0        0.0        0.0   \\n2016-04-01        0.0        0.0        0.0        1.0        0.0        0.0   \\n2016-05-01        0.0        0.0        0.0        0.0        0.0        1.0   \\n...               ...        ...        ...        ...        ...        ...   \\n2021-08-01        0.0        0.0        0.0        0.0        0.0        1.0   \\n2021-09-01        0.0        1.0        0.0        0.0        0.0        0.0   \\n2021-10-01        0.0        0.0        0.0        1.0        0.0        0.0   \\n2021-11-01        0.0        0.0        0.0        0.0        0.0        0.0   \\n2021-12-01        0.0        1.0        0.0        0.0        0.0        0.0   \\n\\n               phase  \\nMONTH                 \\n2016-01-01  0.547495  \\n2016-02-01  0.442910  \\n2016-03-01  0.520471  \\n2016-04-01  0.381729  \\n2016-05-01  0.321422  \\n...              ...  \\n2021-08-01  0.387780  \\n2021-09-01  0.273881  \\n2021-10-01  0.247126  \\n2021-11-01  0.130043  \\n2021-12-01  0.093069  \\n\\n[72 rows x 23 columns] and predict             weekend  quarter      epoch  month_1  month_2  month_3  month_4  \\\\\\n2022-01-01        1        1  2459580.5      1.0      0.0      0.0      0.0   \\n2022-02-01        0        1  2459611.5      0.0      1.0      0.0      0.0   \\n2022-03-01        0        1  2459639.5      0.0      0.0      1.0      0.0   \\n2022-04-01        0        2  2459670.5      0.0      0.0      0.0      1.0   \\n2022-05-01        1        2  2459700.5      0.0      0.0      0.0      0.0   \\n2022-06-01        0        2  2459731.5      0.0      0.0      0.0      0.0   \\n2022-07-01        0        3  2459761.5      0.0      0.0      0.0      0.0   \\n2022-08-01        0        3  2459792.5      0.0      0.0      0.0      0.0   \\n2022-09-01        0        3  2459823.5      0.0      0.0      0.0      0.0   \\n2022-10-01        1        4  2459853.5      0.0      0.0      0.0      0.0   \\n2022-11-01        0        4  2459884.5      0.0      0.0      0.0      0.0   \\n2022-12-01        0        4  2459914.5      0.0      0.0      0.0      0.0   \\n\\n            month_5  month_6  month_7  ...  month_11  month_12  weekday_0  \\\\\\n2022-01-01      0.0      0.0      0.0  ...       0.0       0.0        0.0   \\n2022-02-01      0.0      0.0      0.0  ...       0.0       0.0        0.0   \\n2022-03-01      0.0      0.0      0.0  ...       0.0       0.0        0.0   \\n2022-04-01      0.0      0.0      0.0  ...       0.0       0.0        0.0   \\n2022-05-01      1.0      0.0      0.0  ...       0.0       0.0        0.0   \\n2022-06-01      0.0      1.0      0.0  ...       0.0       0.0        0.0   \\n2022-07-01      0.0      0.0      1.0  ...       0.0       0.0        0.0   \\n2022-08-01      0.0      0.0      0.0  ...       0.0       0.0        1.0   \\n2022-09-01      0.0      0.0      0.0  ...       0.0       0.0        0.0   \\n2022-10-01      0.0      0.0      0.0  ...       0.0       0.0        0.0   \\n2022-11-01      0.0      0.0      0.0  ...       1.0       0.0        0.0   \\n2022-12-01      0.0      0.0      0.0  ...       0.0       1.0        0.0   \\n\\n            weekday_1  weekday_2  weekday_3  weekday_4  weekday_5  weekday_6  \\\\\\n2022-01-01        0.0        0.0        0.0        0.0        1.0        0.0   \\n2022-02-01        1.0        0.0        0.0        0.0        0.0        0.0   \\n2022-03-01        1.0        0.0        0.0        0.0        0.0        0.0   \\n2022-04-01        0.0        0.0        0.0        1.0        0.0        0.0   \\n2022-05-01        0.0        0.0        0.0        0.0        0.0        1.0   \\n2022-06-01        0.0        1.0        0.0        0.0        0.0        0.0   \\n2022-07-01        0.0        0.0        0.0        1.0        0.0        0.0   \\n2022-08-01        0.0        0.0        0.0        0.0        0.0        0.0   \\n2022-09-01        0.0        0.0        1.0        0.0        0.0        0.0   \\n2022-10-01        0.0        0.0        0.0        0.0        1.0        0.0   \\n2022-11-01        1.0        0.0        0.0        0.0        0.0        0.0   \\n2022-12-01        0.0        0.0        1.0        0.0        0.0        0.0   \\n\\n               phase  \\n2022-01-01  0.014061  \\n2022-02-01  0.004344  \\n2022-03-01  0.011285  \\n2022-04-01  0.002806  \\n2022-05-01  0.008211  \\n2022-06-01  0.047322  \\n2022-07-01  0.063280  \\n2022-08-01  0.151187  \\n2022-09-01  0.292373  \\n2022-10-01  0.367633  \\n2022-11-01  0.561603  \\n2022-12-01  0.628538  \\n\\n[12 rows x 23 columns]\") in model 407 in generation 2: ARDL\n",
      "Model Number: 408 with model ARIMA in generation 2 of 3\n",
      "Model Number: 409 with model ARIMA in generation 2 of 3\n",
      "Model Number: 410 with model MultivariateMotif in generation 2 of 3\n",
      "Model Number: 411 with model DatepartRegression in generation 2 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\decomposition\\_fastica.py:583: UserWarning: Ignoring n_components with whiten=False.\n",
      "  warnings.warn(\"Ignoring n_components with whiten=False.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 412 with model ARIMA in generation 2 of 3\n",
      "Model Number: 413 with model UnivariateMotif in generation 2 of 3\n",
      "Template Eval Error: Exception('Transformer AlignLastValue failed on inverse') in model 413 in generation 2: UnivariateMotif\n",
      "Model Number: 414 with model MultivariateMotif in generation 2 of 3\n",
      "Model Number: 415 with model ARDL in generation 2 of 3\n",
      "Model Number: 416 with model Theta in generation 2 of 3\n",
      "Model Number: 417 with model NVAR in generation 2 of 3\n",
      "Model Number: 418 with model MultivariateRegression in generation 2 of 3\n",
      "Model Number: 419 with model UnobservedComponents in generation 2 of 3\n",
      "Model Number: 420 with model AverageValueNaive in generation 2 of 3\n",
      "Model Number: 421 with model MetricMotif in generation 2 of 3\n",
      "Model Number: 422 with model SeasonalNaive in generation 2 of 3\n",
      "Model Number: 423 with model ETS in generation 2 of 3\n",
      "Model Number: 424 with model ARIMA in generation 2 of 3\n",
      "Model Number: 425 with model ARDL in generation 2 of 3\n",
      "Model Number: 426 with model NVAR in generation 2 of 3\n",
      "Model Number: 427 with model SeasonalNaive in generation 2 of 3\n",
      "Model Number: 428 with model WindowRegression in generation 2 of 3\n",
      "Model Number: 429 with model SectionalMotif in generation 2 of 3\n",
      "Model Number: 430 with model ConstantNaive in generation 2 of 3\n",
      "Model Number: 431 with model UnivariateRegression in generation 2 of 3\n",
      "Model Number: 432 with model UnobservedComponents in generation 2 of 3\n",
      "Model Number: 433 with model SectionalMotif in generation 2 of 3\n",
      "Model Number: 434 with model GLM in generation 2 of 3\n",
      "Model Number: 435 with model NVAR in generation 2 of 3\n",
      "Model Number: 436 with model MetricMotif in generation 2 of 3\n",
      "New Generation: 3 of 3\n",
      "Model Number: 437 with model MultivariateRegression in generation 3 of 3\n",
      "Model Number: 438 with model GLS in generation 3 of 3\n",
      "Model Number: 439 with model SectionalMotif in generation 3 of 3\n",
      "Model Number: 440 with model ETS in generation 3 of 3\n",
      "Model Number: 441 with model AverageValueNaive in generation 3 of 3\n",
      "Model Number: 442 with model MetricMotif in generation 3 of 3\n",
      "Model Number: 443 with model ConstantNaive in generation 3 of 3\n",
      "Model Number: 444 with model GLS in generation 3 of 3\n",
      "Model Number: 445 with model SeasonalNaive in generation 3 of 3\n",
      "Model Number: 446 with model AverageValueNaive in generation 3 of 3\n",
      "Model Number: 447 with model GLM in generation 3 of 3\n",
      "Model Number: 448 with model NVAR in generation 3 of 3\n",
      "Model Number: 449 with model GLS in generation 3 of 3\n",
      "Model Number: 450 with model MultivariateRegression in generation 3 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\experimental\\enable_hist_gradient_boosting.py:16: UserWarning: Since version 1.0, it is not needed to import enable_hist_gradient_boosting anymore. HistGradientBoostingClassifier and HistGradientBoostingRegressor are now stable and can be normally imported from sklearn.ensemble.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 451 with model DatepartRegression in generation 3 of 3\n",
      "Template Eval Error: ValueError('Model DatepartRegression returned NaN for one or more series. fail_on_forecast_nan=True') in model 451 in generation 3: DatepartRegression\n",
      "Model Number: 452 with model ARIMA in generation 3 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\neighbors\\_regression.py:494: UserWarning: One or more samples have no neighbors within specified radius; predicting NaN.\n",
      "  warnings.warn(empty_warning_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 453 with model AverageValueNaive in generation 3 of 3\n",
      "Model Number: 454 with model AverageValueNaive in generation 3 of 3\n",
      "Model Number: 455 with model GLS in generation 3 of 3\n",
      "Template Eval Error: Exception('Transformer AlignLastValue failed on inverse') in model 455 in generation 3: GLS\n",
      "Model Number: 456 with model ETS in generation 3 of 3\n",
      "Model Number: 457 with model ARDL in generation 3 of 3\n",
      "Model Number: 458 with model SectionalMotif in generation 3 of 3\n",
      "Model Number: 459 with model UnobservedComponents in generation 3 of 3\n",
      "Template Eval Error: ValueError('Model UnobservedComponents returned NaN for one or more series. fail_on_forecast_nan=True') in model 459 in generation 3: UnobservedComponents\n",
      "Model Number: 460 with model LastValueNaive in generation 3 of 3\n",
      "Model Number: 461 with model ETS in generation 3 of 3\n",
      "Model Number: 462 with model UnobservedComponents in generation 3 of 3\n",
      "Model Number: 463 with model MetricMotif in generation 3 of 3\n",
      "Model Number: 464 with model ConstantNaive in generation 3 of 3\n",
      "Model Number: 465 with model UnivariateMotif in generation 3 of 3\n",
      "Model Number: 466 with model MultivariateMotif in generation 3 of 3\n",
      "Template Eval Error: ValueError('kth(=100) out of bounds (58)') in model 466 in generation 3: MultivariateMotif\n",
      "Model Number: 467 with model ETS in generation 3 of 3\n",
      "Model Number: 468 with model NVAR in generation 3 of 3\n",
      "Model Number: 469 with model SectionalMotif in generation 3 of 3\n",
      "Model Number: 470 with model SeasonalNaive in generation 3 of 3\n",
      "Model Number: 471 with model UnobservedComponents in generation 3 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\decomposition\\_fastica.py:708: FutureWarning: Starting in v1.3, whiten=True should be specified as whiten='arbitrary-variance' (its current behaviour). This behavior is deprecated in 1.1 and will raise ValueError in 1.3.\n",
      "  return self._fit_transform(X, compute_sources=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 472 with model UnobservedComponents in generation 3 of 3\n",
      "Model Number: 473 with model MetricMotif in generation 3 of 3\n",
      "Template Eval Error: Exception('Transformer Cointegration failed on fit') in model 473 in generation 3: MetricMotif\n",
      "Model Number: 474 with model SectionalMotif in generation 3 of 3\n",
      "Model Number: 475 with model UnivariateRegression in generation 3 of 3\n",
      "Model Number: 476 with model ARDL in generation 3 of 3\n",
      "Model Number: 477 with model LastValueNaive in generation 3 of 3\n",
      "Model Number: 478 with model DatepartRegression in generation 3 of 3\n",
      "Model Number: 479 with model MetricMotif in generation 3 of 3\n",
      "Model Number: 480 with model WindowRegression in generation 3 of 3\n",
      "Template Eval Error: ValueError('Found array with 0 sample(s) (shape=(0, 0)) while a minimum of 1 is required by BayesianRidge.') in model 480 in generation 3: WindowRegression\n",
      "Model Number: 481 with model WindowRegression in generation 3 of 3\n",
      "Model Number: 482 with model SeasonalNaive in generation 3 of 3\n",
      "Template Eval Error: Exception('Transformer AlignLastValue failed on inverse') in model 482 in generation 3: SeasonalNaive\n",
      "Model Number: 483 with model MultivariateMotif in generation 3 of 3\n",
      "Model Number: 484 with model DatepartRegression in generation 3 of 3\n",
      "Model Number: 485 with model UnivariateRegression in generation 3 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:541: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 486 with model NVAR in generation 3 of 3\n",
      "Model Number: 487 with model DatepartRegression in generation 3 of 3\n",
      "Template Eval Error: Exception('Transformer RegressionFilter failed on fit') in model 487 in generation 3: DatepartRegression\n",
      "Model Number: 488 with model UnobservedComponents in generation 3 of 3\n",
      "Model Number: 489 with model UnivariateRegression in generation 3 of 3\n",
      "Model Number: 490 with model Theta in generation 3 of 3\n",
      "Model Number: 491 with model ARDL in generation 3 of 3\n",
      "Model Number: 492 with model GLS in generation 3 of 3\n",
      "Model Number: 493 with model LastValueNaive in generation 3 of 3\n",
      "Model Number: 494 with model UnobservedComponents in generation 3 of 3\n",
      "Model Number: 495 with model SectionalMotif in generation 3 of 3\n",
      "Model Number: 496 with model MultivariateMotif in generation 3 of 3\n",
      "Template Eval Error: ValueError('kth(=100) out of bounds (51)') in model 496 in generation 3: MultivariateMotif\n",
      "Model Number: 497 with model ARDL in generation 3 of 3\n",
      "Model Number: 498 with model WindowRegression in generation 3 of 3\n",
      "Model Number: 499 with model GLM in generation 3 of 3\n",
      "Template Eval Error: ValueError('NaN, inf or invalid value detected in weights, estimation infeasible.') in model 499 in generation 3: GLM\n",
      "Model Number: 500 with model SectionalMotif in generation 3 of 3\n",
      "Model Number: 501 with model ARIMA in generation 3 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\statsmodels\\genmod\\families\\links.py:527: RuntimeWarning: overflow encountered in exp\n",
      "  return np.exp(z)\n",
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\statsmodels\\genmod\\families\\family.py:445: RuntimeWarning: divide by zero encountered in divide\n",
      "  endog_mu = self._clean(endog / mu)\n",
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\statsmodels\\genmod\\families\\family.py:143: RuntimeWarning: invalid value encountered in multiply\n",
      "  return 1. / (self.link.deriv(mu)**2 * self.variance(mu))\n",
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\statsmodels\\genmod\\families\\family.py:143: RuntimeWarning: divide by zero encountered in divide\n",
      "  return 1. / (self.link.deriv(mu)**2 * self.variance(mu))\n",
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\statsmodels\\genmod\\generalized_linear_model.py:1243: RuntimeWarning: invalid value encountered in multiply\n",
      "  wlsendog = (lin_pred + self.family.link.deriv(mu) * (self.endog-mu)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 502 with model UnivariateMotif in generation 3 of 3\n",
      "Model Number: 503 with model UnobservedComponents in generation 3 of 3\n",
      "Model Number: 504 with model ETS in generation 3 of 3\n",
      "Model Number: 505 with model MetricMotif in generation 3 of 3\n",
      "Model Number: 506 with model LastValueNaive in generation 3 of 3\n",
      "Model Number: 507 with model AverageValueNaive in generation 3 of 3\n",
      "Model Number: 508 with model DatepartRegression in generation 3 of 3\n",
      "Model Number: 509 with model ETS in generation 3 of 3\n",
      "Model Number: 510 with model AverageValueNaive in generation 3 of 3\n",
      "Model Number: 511 with model NVAR in generation 3 of 3\n",
      "Model Number: 512 with model MetricMotif in generation 3 of 3\n",
      "Model Number: 513 with model MetricMotif in generation 3 of 3\n",
      "Model Number: 514 with model LastValueNaive in generation 3 of 3\n",
      "Model Number: 515 with model NVAR in generation 3 of 3\n",
      "Model Number: 516 with model SectionalMotif in generation 3 of 3\n",
      "Model Number: 517 with model UnivariateRegression in generation 3 of 3\n",
      "Model Number: 518 with model ARIMA in generation 3 of 3\n",
      "Model Number: 519 with model ARDL in generation 3 of 3\n",
      "Model Number: 520 with model LastValueNaive in generation 3 of 3\n",
      "Model Number: 521 with model UnobservedComponents in generation 3 of 3\n",
      "Model Number: 522 with model UnivariateRegression in generation 3 of 3\n",
      "Model Number: 523 with model DatepartRegression in generation 3 of 3\n",
      "Model Number: 524 with model NVAR in generation 3 of 3\n",
      "Model Number: 525 with model AverageValueNaive in generation 3 of 3\n",
      "Model Number: 526 with model Theta in generation 3 of 3\n",
      "Model Number: 527 with model MultivariateMotif in generation 3 of 3\n",
      "Model Number: 528 with model ARDL in generation 3 of 3\n",
      "Model Number: 529 with model ConstantNaive in generation 3 of 3\n",
      "Model Number: 530 with model ARDL in generation 3 of 3\n",
      "Model Number: 531 with model GLM in generation 3 of 3\n",
      "Model Number: 532 with model AverageValueNaive in generation 3 of 3\n",
      "Model Number: 533 with model NVAR in generation 3 of 3\n",
      "Model Number: 534 with model ARDL in generation 3 of 3\n",
      "Template Eval Error: Exception('Transformer Detrend failed on fit') in model 534 in generation 3: ARDL\n",
      "Model Number: 535 with model ConstantNaive in generation 3 of 3\n",
      "Model Number: 536 with model ETS in generation 3 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\statsmodels\\genmod\\families\\family.py:1367: ValueWarning: Negative binomial dispersion parameter alpha not set. Using default value alpha=1.0.\n",
      "  warnings.warn(\"Negative binomial dispersion parameter alpha not \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 537 with model GLM in generation 3 of 3\n",
      "Model Number: 538 with model MultivariateRegression in generation 3 of 3\n",
      "Template Eval Error: ValueError('Input X contains NaN.\\nRadiusNeighborsRegressor does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values') in model 538 in generation 3: MultivariateRegression\n",
      "Model Number: 539 with model GLS in generation 3 of 3\n",
      "Model Number: 540 with model ARDL in generation 3 of 3\n",
      "Model Number: 541 with model GLS in generation 3 of 3\n",
      "Template Eval Error: Exception('Transformer BTCD failed on fit') in model 541 in generation 3: GLS\n",
      "Model Number: 542 with model NVAR in generation 3 of 3\n",
      "Model Number: 543 with model GLM in generation 3 of 3\n",
      "Model Number: 544 with model NVAR in generation 3 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\neighbors\\_regression.py:494: UserWarning: One or more samples have no neighbors within specified radius; predicting NaN.\n",
      "  warnings.warn(empty_warning_msg)\n",
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\statsmodels\\genmod\\families\\family.py:1367: ValueWarning: Negative binomial dispersion parameter alpha not set. Using default value alpha=1.0.\n",
      "  warnings.warn(\"Negative binomial dispersion parameter alpha not \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 545 with model WindowRegression in generation 3 of 3\n",
      "Model Number: 546 with model FBProphet in generation 3 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18:59:05 - cmdstanpy - INFO - Chain [1] start processing\n",
      "18:59:05 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 547 with model UnobservedComponents in generation 3 of 3\n",
      "Model Number: 548 with model AverageValueNaive in generation 3 of 3\n",
      "Model Number: 549 with model UnivariateRegression in generation 3 of 3\n",
      "Model Number: 550 with model GLM in generation 3 of 3\n",
      "Model Number: 551 with model ETS in generation 3 of 3\n",
      "Model Number: 552 with model NVAR in generation 3 of 3\n",
      "Model Number: 553 with model GLS in generation 3 of 3\n",
      "Model Number: 554 with model ETS in generation 3 of 3\n",
      "Model Number: 555 with model UnivariateRegression in generation 3 of 3\n",
      "Model Number: 556 with model ETS in generation 3 of 3\n",
      "Model Number: 557 with model UnivariateRegression in generation 3 of 3\n",
      "Model Number: 558 with model WindowRegression in generation 3 of 3\n",
      "Model Number: 559 with model MetricMotif in generation 3 of 3\n",
      "Model Number: 560 with model ARDL in generation 3 of 3\n",
      "Model Number: 561 with model MultivariateMotif in generation 3 of 3\n",
      "TotalRuntime missing in 4!\n",
      "Validation Round: 1\n",
      "Model Number: 1 of 84 with model ARDL for Validation 1\n",
      "📈 1 - ARDL with avg smape 57.71: \n",
      "Model Number: 2 of 84 with model LastValueNaive for Validation 1\n",
      "📈 2 - LastValueNaive with avg smape 54.4: \n",
      "Model Number: 3 of 84 with model AverageValueNaive for Validation 1\n",
      "📈 3 - AverageValueNaive with avg smape 49.3: \n",
      "Model Number: 4 of 84 with model MetricMotif for Validation 1\n",
      "📈 4 - MetricMotif with avg smape 47.68: \n",
      "Model Number: 5 of 84 with model UnivariateRegression for Validation 1\n",
      "5 - UnivariateRegression with avg smape 63.13: \n",
      "Model Number: 6 of 84 with model UnobservedComponents for Validation 1\n",
      "📈 6 - UnobservedComponents with avg smape 47.01: \n",
      "Model Number: 7 of 84 with model UnobservedComponents for Validation 1\n",
      "📈 7 - UnobservedComponents with avg smape 46.94: \n",
      "Model Number: 8 of 84 with model LastValueNaive for Validation 1\n",
      "📈 8 - LastValueNaive with avg smape 41.93: \n",
      "Model Number: 9 of 84 with model LastValueNaive for Validation 1\n",
      "9 - LastValueNaive with avg smape 42.7: \n",
      "Model Number: 10 of 84 with model UnobservedComponents for Validation 1\n",
      "10 - UnobservedComponents with avg smape 43.01: \n",
      "Model Number: 11 of 84 with model UnivariateRegression for Validation 1\n",
      "11 - UnivariateRegression with avg smape 53.5: \n",
      "Model Number: 12 of 84 with model ARDL for Validation 1\n",
      "12 - ARDL with avg smape 46.18: \n",
      "Model Number: 13 of 84 with model ETS for Validation 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13 - ETS with avg smape 47.76: \n",
      "Model Number: 14 of 84 with model UnivariateRegression for Validation 1\n",
      "14 - UnivariateRegression with avg smape 54.22: \n",
      "Model Number: 15 of 84 with model ARDL for Validation 1\n",
      "15 - ARDL with avg smape 58.15: \n",
      "Model Number: 16 of 84 with model ARDL for Validation 1\n",
      "16 - ARDL with avg smape 58.15: \n",
      "Model Number: 17 of 84 with model NVAR for Validation 1\n",
      "17 - NVAR with avg smape 42.73: \n",
      "Model Number: 18 of 84 with model NVAR for Validation 1\n",
      "18 - NVAR with avg smape 42.91: \n",
      "Model Number: 19 of 84 with model ARDL for Validation 1\n",
      "19 - ARDL with avg smape 44.92: \n",
      "Model Number: 20 of 84 with model ETS for Validation 1\n",
      "20 - ETS with avg smape 54.72: \n",
      "Model Number: 21 of 84 with model GLS for Validation 1\n",
      "21 - GLS with avg smape 45.24: \n",
      "Model Number: 22 of 84 with model NVAR for Validation 1\n",
      "22 - NVAR with avg smape 43.03: \n",
      "Model Number: 23 of 84 with model GLS for Validation 1\n",
      "23 - GLS with avg smape 43.59: \n",
      "Model Number: 24 of 84 with model SeasonalNaive for Validation 1\n",
      "24 - SeasonalNaive with avg smape 43.41: \n",
      "Model Number: 25 of 84 with model DatepartRegression for Validation 1\n",
      "25 - DatepartRegression with avg smape 43.47: \n",
      "Model Number: 26 of 84 with model AverageValueNaive for Validation 1\n",
      "26 - AverageValueNaive with avg smape 41.99: \n",
      "Model Number: 27 of 84 with model NVAR for Validation 1\n",
      "📈 27 - NVAR with avg smape 41.55: \n",
      "Model Number: 28 of 84 with model GLM for Validation 1\n",
      "28 - GLM with avg smape 62.43: \n",
      "Model Number: 29 of 84 with model MetricMotif for Validation 1\n",
      "29 - MetricMotif with avg smape 46.28: \n",
      "Model Number: 30 of 84 with model NVAR for Validation 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 - NVAR with avg smape 42.46: \n",
      "Model Number: 31 of 84 with model ETS for Validation 1\n",
      "31 - ETS with avg smape 46.8: \n",
      "Model Number: 32 of 84 with model ETS for Validation 1\n",
      "32 - ETS with avg smape 47.17: \n",
      "Model Number: 33 of 84 with model GLS for Validation 1\n",
      "33 - GLS with avg smape 44.83: \n",
      "Model Number: 34 of 84 with model AverageValueNaive for Validation 1\n",
      "Template Eval Error: ValueError('Model AverageValueNaive returned NaN for one or more series. fail_on_forecast_nan=True') in model 34 in generation 0: AverageValueNaive\n",
      "Model Number: 35 of 84 with model ETS for Validation 1\n",
      "35 - ETS with avg smape 46.72: \n",
      "Model Number: 36 of 84 with model UnobservedComponents for Validation 1\n",
      "36 - UnobservedComponents with avg smape 47.12: \n",
      "Model Number: 37 of 84 with model SectionalMotif for Validation 1\n",
      "37 - SectionalMotif with avg smape 45.9: \n",
      "Model Number: 38 of 84 with model GLM for Validation 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\numpy\\lib\\function_base.py:550: RuntimeWarning: invalid value encountered in multiply\n",
      "  avg = np.multiply(a, wgt,\n",
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\numpy\\core\\_methods.py:48: RuntimeWarning: invalid value encountered in reduce\n",
      "  return umr_sum(a, axis, dtype, out, keepdims, initial, where)\n",
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\numpy\\lib\\function_base.py:4527: RuntimeWarning: invalid value encountered in subtract\n",
      "  diff_b_a = subtract(b, a)\n",
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\decomposition\\_fastica.py:708: FutureWarning: Starting in v1.3, whiten=True should be specified as whiten='arbitrary-variance' (its current behaviour). This behavior is deprecated in 1.1 and will raise ValueError in 1.3.\n",
      "  return self._fit_transform(X, compute_sources=True)\n",
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\statsmodels\\genmod\\families\\family.py:1367: ValueWarning: Negative binomial dispersion parameter alpha not set. Using default value alpha=1.0.\n",
      "  warnings.warn(\"Negative binomial dispersion parameter alpha not \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38 - GLM with avg smape 61.47: \n",
      "Model Number: 39 of 84 with model DatepartRegression for Validation 1\n",
      "39 - DatepartRegression with avg smape 44.2: \n",
      "Model Number: 40 of 84 with model AverageValueNaive for Validation 1\n",
      "40 - AverageValueNaive with avg smape 46.72: \n",
      "Model Number: 41 of 84 with model AverageValueNaive for Validation 1\n",
      "41 - AverageValueNaive with avg smape 47.86: \n",
      "Model Number: 42 of 84 with model GLS for Validation 1\n",
      "42 - GLS with avg smape 43.51: \n",
      "Model Number: 43 of 84 with model LastValueNaive for Validation 1\n",
      "43 - LastValueNaive with avg smape 44.77: \n",
      "Model Number: 44 of 84 with model MetricMotif for Validation 1\n",
      "44 - MetricMotif with avg smape 43.85: \n",
      "Model Number: 45 of 84 with model MetricMotif for Validation 1\n",
      "45 - MetricMotif with avg smape 52.08: \n",
      "Model Number: 46 of 84 with model MultivariateRegression for Validation 1\n",
      "46 - MultivariateRegression with avg smape 54.72: \n",
      "Model Number: 47 of 84 with model WindowRegression for Validation 1\n",
      "47 - WindowRegression with avg smape 43.51: \n",
      "Model Number: 48 of 84 with model WindowRegression for Validation 1\n",
      "48 - WindowRegression with avg smape 43.51: \n",
      "Model Number: 49 of 84 with model GLM for Validation 1\n",
      "49 - GLM with avg smape 43.02: \n",
      "Model Number: 50 of 84 with model DatepartRegression for Validation 1\n",
      "50 - DatepartRegression with avg smape 47.61: \n",
      "Model Number: 51 of 84 with model DatepartRegression for Validation 1\n",
      "51 - DatepartRegression with avg smape 47.94: \n",
      "Model Number: 52 of 84 with model DatepartRegression for Validation 1\n",
      "52 - DatepartRegression with avg smape 49.52: \n",
      "Model Number: 53 of 84 with model SectionalMotif for Validation 1\n",
      "53 - SectionalMotif with avg smape 44.41: \n",
      "Model Number: 54 of 84 with model UnobservedComponents for Validation 1\n",
      "54 - UnobservedComponents with avg smape 44.49: \n",
      "Model Number: 55 of 84 with model SectionalMotif for Validation 1\n",
      "55 - SectionalMotif with avg smape 42.8: \n",
      "Model Number: 56 of 84 with model SectionalMotif for Validation 1\n",
      "Template Eval Error: ValueError('kth(=20) out of bounds (20)') in model 56 in generation 0: SectionalMotif\n",
      "Model Number: 57 of 84 with model SectionalMotif for Validation 1\n",
      "57 - SectionalMotif with avg smape 45.45: \n",
      "Model Number: 58 of 84 with model MultivariateMotif for Validation 1\n",
      "58 - MultivariateMotif with avg smape 44.86: \n",
      "Model Number: 59 of 84 with model LastValueNaive for Validation 1\n",
      "59 - LastValueNaive with avg smape 42.9: \n",
      "Model Number: 60 of 84 with model UnivariateRegression for Validation 1\n",
      "60 - UnivariateRegression with avg smape 43.15: \n",
      "Model Number: 61 of 84 with model GLS for Validation 1\n",
      "61 - GLS with avg smape 42.89: \n",
      "Model Number: 62 of 84 with model WindowRegression for Validation 1\n",
      "62 - WindowRegression with avg smape 42.33: \n",
      "Model Number: 63 of 84 with model MultivariateMotif for Validation 1\n",
      "63 - MultivariateMotif with avg smape 50.97: \n",
      "Model Number: 64 of 84 with model MetricMotif for Validation 1\n",
      "64 - MetricMotif with avg smape 44.64: \n",
      "Model Number: 65 of 84 with model ARIMA for Validation 1\n",
      "65 - ARIMA with avg smape 200.0: \n",
      "Model Number: 66 of 84 with model MultivariateRegression for Validation 1\n",
      "66 - MultivariateRegression with avg smape 46.48: \n",
      "Model Number: 67 of 84 with model MultivariateMotif for Validation 1\n",
      "67 - MultivariateMotif with avg smape 43.3: \n",
      "Model Number: 68 of 84 with model MultivariateMotif for Validation 1\n",
      "68 - MultivariateMotif with avg smape 52.53: \n",
      "Model Number: 69 of 84 with model ARIMA for Validation 1\n",
      "69 - ARIMA with avg smape 47.09: \n",
      "Model Number: 70 of 84 with model ConstantNaive for Validation 1\n",
      "70 - ConstantNaive with avg smape 44.54: \n",
      "Model Number: 71 of 84 with model MultivariateMotif for Validation 1\n",
      "71 - MultivariateMotif with avg smape 48.79: \n",
      "Model Number: 72 of 84 with model UnivariateRegression for Validation 1\n",
      "72 - UnivariateRegression with avg smape 52.34: \n",
      "Model Number: 73 of 84 with model MultivariateRegression for Validation 1\n",
      "73 - MultivariateRegression with avg smape 43.86: \n",
      "Model Number: 74 of 84 with model MultivariateRegression for Validation 1\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000025 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "74 - MultivariateRegression with avg smape 41.96: \n",
      "Model Number: 75 of 84 with model ARIMA for Validation 1\n",
      "75 - ARIMA with avg smape 48.96: \n",
      "Model Number: 76 of 84 with model WindowRegression for Validation 1\n",
      "76 - WindowRegression with avg smape 101.79: \n",
      "Model Number: 77 of 84 with model GLM for Validation 1\n",
      "77 - GLM with avg smape 44.36: \n",
      "Model Number: 78 of 84 with model GLM for Validation 1\n",
      "78 - GLM with avg smape 52.21: \n",
      "Model Number: 79 of 84 with model ARIMA for Validation 1\n",
      "79 - ARIMA with avg smape 89.29: \n",
      "Model Number: 80 of 84 with model ARIMA for Validation 1\n",
      "80 - ARIMA with avg smape 43.29: \n",
      "Model Number: 81 of 84 with model MultivariateRegression for Validation 1\n",
      "81 - MultivariateRegression with avg smape 42.9: \n",
      "Model Number: 82 of 84 with model UnivariateMotif for Validation 1\n",
      "82 - UnivariateMotif with avg smape 48.47: \n",
      "Model Number: 83 of 84 with model WindowRegression for Validation 1\n",
      "83 - WindowRegression with avg smape 49.59: \n",
      "Model Number: 84 of 84 with model UnivariateMotif for Validation 1\n",
      "📈 84 - UnivariateMotif with avg smape 41.22: \n",
      "Validation Round: 2\n",
      "Model Number: 1 of 84 with model ARDL for Validation 2\n",
      "📈 1 - ARDL with avg smape 29.15: \n",
      "Model Number: 2 of 84 with model LastValueNaive for Validation 2\n",
      "2 - LastValueNaive with avg smape 39.65: \n",
      "Model Number: 3 of 84 with model AverageValueNaive for Validation 2\n",
      "3 - AverageValueNaive with avg smape 31.89: \n",
      "Model Number: 4 of 84 with model MetricMotif for Validation 2\n",
      "4 - MetricMotif with avg smape 31.98: \n",
      "Model Number: 5 of 84 with model UnivariateRegression for Validation 2\n",
      "5 - UnivariateRegression with avg smape 36.26: \n",
      "Model Number: 6 of 84 with model UnobservedComponents for Validation 2\n",
      "6 - UnobservedComponents with avg smape 32.82: \n",
      "Model Number: 7 of 84 with model UnobservedComponents for Validation 2\n",
      "7 - UnobservedComponents with avg smape 32.29: \n",
      "Model Number: 8 of 84 with model LastValueNaive for Validation 2\n",
      "8 - LastValueNaive with avg smape 39.28: \n",
      "Model Number: 9 of 84 with model LastValueNaive for Validation 2\n",
      "9 - LastValueNaive with avg smape 37.91: \n",
      "Model Number: 10 of 84 with model UnobservedComponents for Validation 2\n",
      "10 - UnobservedComponents with avg smape 31.88: \n",
      "Model Number: 11 of 84 with model UnivariateRegression for Validation 2\n",
      "📈 11 - UnivariateRegression with avg smape 27.76: \n",
      "Model Number: 12 of 84 with model ARDL for Validation 2\n",
      "12 - ARDL with avg smape 31.98: \n",
      "Model Number: 13 of 84 with model ETS for Validation 2\n",
      "13 - ETS with avg smape 30.45: \n",
      "Model Number: 14 of 84 with model UnivariateRegression for Validation 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14 - UnivariateRegression with avg smape 31.18: \n",
      "Model Number: 15 of 84 with model ARDL for Validation 2\n",
      "15 - ARDL with avg smape 29.38: \n",
      "Model Number: 16 of 84 with model ARDL for Validation 2\n",
      "16 - ARDL with avg smape 29.38: \n",
      "Model Number: 17 of 84 with model NVAR for Validation 2\n",
      "17 - NVAR with avg smape 35.22: \n",
      "Model Number: 18 of 84 with model NVAR for Validation 2\n",
      "18 - NVAR with avg smape 33.18: \n",
      "Model Number: 19 of 84 with model ARDL for Validation 2\n",
      "19 - ARDL with avg smape 32.79: \n",
      "Model Number: 20 of 84 with model ETS for Validation 2\n",
      "20 - ETS with avg smape 40.42: \n",
      "Model Number: 21 of 84 with model GLS for Validation 2\n",
      "21 - GLS with avg smape 32.78: \n",
      "Model Number: 22 of 84 with model NVAR for Validation 2\n",
      "22 - NVAR with avg smape 38.36: \n",
      "Model Number: 23 of 84 with model GLS for Validation 2\n",
      "23 - GLS with avg smape 33.56: \n",
      "Model Number: 24 of 84 with model SeasonalNaive for Validation 2\n",
      "24 - SeasonalNaive with avg smape 37.41: \n",
      "Model Number: 25 of 84 with model DatepartRegression for Validation 2\n",
      "25 - DatepartRegression with avg smape 33.65: \n",
      "Model Number: 26 of 84 with model AverageValueNaive for Validation 2\n",
      "26 - AverageValueNaive with avg smape 38.6: \n",
      "Model Number: 27 of 84 with model NVAR for Validation 2\n",
      "27 - NVAR with avg smape 37.97: \n",
      "Model Number: 28 of 84 with model GLM for Validation 2\n",
      "28 - GLM with avg smape 42.52: \n",
      "Model Number: 29 of 84 with model MetricMotif for Validation 2\n",
      "29 - MetricMotif with avg smape 38.84: \n",
      "Model Number: 30 of 84 with model NVAR for Validation 2\n",
      "30 - NVAR with avg smape 38.15: \n",
      "Model Number: 31 of 84 with model ETS for Validation 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31 - ETS with avg smape 29.69: \n",
      "Model Number: 32 of 84 with model ETS for Validation 2\n",
      "32 - ETS with avg smape 29.69: \n",
      "Model Number: 33 of 84 with model GLS for Validation 2\n",
      "33 - GLS with avg smape 35.64: \n",
      "Model Number: 34 of 84 with model AverageValueNaive for Validation 2\n",
      "34 - AverageValueNaive with avg smape 32.21: \n",
      "Model Number: 35 of 84 with model ETS for Validation 2\n",
      "35 - ETS with avg smape 30.73: \n",
      "Model Number: 36 of 84 with model UnobservedComponents for Validation 2\n",
      "36 - UnobservedComponents with avg smape 30.67: \n",
      "Model Number: 37 of 84 with model SectionalMotif for Validation 2\n",
      "37 - SectionalMotif with avg smape 35.24: \n",
      "Model Number: 38 of 84 with model GLM for Validation 2\n",
      "38 - GLM with avg smape 40.15: \n",
      "Model Number: 39 of 84 with model DatepartRegression for Validation 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\decomposition\\_fastica.py:708: FutureWarning: Starting in v1.3, whiten=True should be specified as whiten='arbitrary-variance' (its current behaviour). This behavior is deprecated in 1.1 and will raise ValueError in 1.3.\n",
      "  return self._fit_transform(X, compute_sources=True)\n",
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\statsmodels\\genmod\\families\\family.py:1367: ValueWarning: Negative binomial dispersion parameter alpha not set. Using default value alpha=1.0.\n",
      "  warnings.warn(\"Negative binomial dispersion parameter alpha not \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39 - DatepartRegression with avg smape 30.94: \n",
      "Model Number: 40 of 84 with model AverageValueNaive for Validation 2\n",
      "40 - AverageValueNaive with avg smape 30.73: \n",
      "Model Number: 41 of 84 with model AverageValueNaive for Validation 2\n",
      "41 - AverageValueNaive with avg smape 28.94: \n",
      "Model Number: 42 of 84 with model GLS for Validation 2\n",
      "42 - GLS with avg smape 29.28: \n",
      "Model Number: 43 of 84 with model LastValueNaive for Validation 2\n",
      "43 - LastValueNaive with avg smape 38.88: \n",
      "Model Number: 44 of 84 with model MetricMotif for Validation 2\n",
      "44 - MetricMotif with avg smape 39.8: \n",
      "Model Number: 45 of 84 with model MetricMotif for Validation 2\n",
      "45 - MetricMotif with avg smape 32.27: \n",
      "Model Number: 46 of 84 with model MultivariateRegression for Validation 2\n",
      "46 - MultivariateRegression with avg smape 39.6: \n",
      "Model Number: 47 of 84 with model WindowRegression for Validation 2\n",
      "47 - WindowRegression with avg smape 29.97: \n",
      "Model Number: 48 of 84 with model WindowRegression for Validation 2\n",
      "48 - WindowRegression with avg smape 29.97: \n",
      "Model Number: 49 of 84 with model GLM for Validation 2\n",
      "49 - GLM with avg smape 30.79: \n",
      "Model Number: 50 of 84 with model DatepartRegression for Validation 2\n",
      "50 - DatepartRegression with avg smape 34.78: \n",
      "Model Number: 51 of 84 with model DatepartRegression for Validation 2\n",
      "51 - DatepartRegression with avg smape 29.79: \n",
      "Model Number: 52 of 84 with model DatepartRegression for Validation 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.310e-02, tolerance: 2.804e-04\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52 - DatepartRegression with avg smape 39.42: \n",
      "Model Number: 53 of 84 with model SectionalMotif for Validation 2\n",
      "53 - SectionalMotif with avg smape 35.85: \n",
      "Model Number: 54 of 84 with model UnobservedComponents for Validation 2\n",
      "54 - UnobservedComponents with avg smape 45.08: \n",
      "Model Number: 55 of 84 with model SectionalMotif for Validation 2\n",
      "55 - SectionalMotif with avg smape 32.94: \n",
      "Model Number: 56 of 84 with model SectionalMotif for Validation 2\n",
      "Template Eval Error: ValueError('kth(=20) out of bounds (14)') in model 56 in generation 0: SectionalMotif\n",
      "Model Number: 57 of 84 with model SectionalMotif for Validation 2\n",
      "57 - SectionalMotif with avg smape 34.42: \n",
      "Model Number: 58 of 84 with model MultivariateMotif for Validation 2\n",
      "58 - MultivariateMotif with avg smape 31.12: \n",
      "Model Number: 59 of 84 with model LastValueNaive for Validation 2\n",
      "59 - LastValueNaive with avg smape 29.43: \n",
      "Model Number: 60 of 84 with model UnivariateRegression for Validation 2\n",
      "60 - UnivariateRegression with avg smape 33.2: \n",
      "Model Number: 61 of 84 with model GLS for Validation 2\n",
      "61 - GLS with avg smape 30.69: \n",
      "Model Number: 62 of 84 with model WindowRegression for Validation 2\n",
      "62 - WindowRegression with avg smape 36.99: \n",
      "Model Number: 63 of 84 with model MultivariateMotif for Validation 2\n",
      "63 - MultivariateMotif with avg smape 31.71: \n",
      "Model Number: 64 of 84 with model MetricMotif for Validation 2\n",
      "64 - MetricMotif with avg smape 29.79: \n",
      "Model Number: 65 of 84 with model ARIMA for Validation 2\n",
      "65 - ARIMA with avg smape 44.06: \n",
      "Model Number: 66 of 84 with model MultivariateRegression for Validation 2\n",
      "66 - MultivariateRegression with avg smape 31.51: \n",
      "Model Number: 67 of 84 with model MultivariateMotif for Validation 2\n",
      "67 - MultivariateMotif with avg smape 30.56: \n",
      "Model Number: 68 of 84 with model MultivariateMotif for Validation 2\n",
      "68 - MultivariateMotif with avg smape 30.47: \n",
      "Model Number: 69 of 84 with model ARIMA for Validation 2\n",
      "69 - ARIMA with avg smape 32.42: \n",
      "Model Number: 70 of 84 with model ConstantNaive for Validation 2\n",
      "70 - ConstantNaive with avg smape 29.75: \n",
      "Model Number: 71 of 84 with model MultivariateMotif for Validation 2\n",
      "71 - MultivariateMotif with avg smape 36.58: \n",
      "Model Number: 72 of 84 with model UnivariateRegression for Validation 2\n",
      "72 - UnivariateRegression with avg smape 33.1: \n",
      "Model Number: 73 of 84 with model MultivariateRegression for Validation 2\n",
      "73 - MultivariateRegression with avg smape 38.41: \n",
      "Model Number: 74 of 84 with model MultivariateRegression for Validation 2\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000023 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "74 - MultivariateRegression with avg smape 28.26: \n",
      "Model Number: 75 of 84 with model ARIMA for Validation 2\n",
      "75 - ARIMA with avg smape 55.21: \n",
      "Model Number: 76 of 84 with model WindowRegression for Validation 2\n",
      "76 - WindowRegression with avg smape 58.27: \n",
      "Model Number: 77 of 84 with model GLM for Validation 2\n",
      "77 - GLM with avg smape 29.09: \n",
      "Model Number: 78 of 84 with model GLM for Validation 2\n",
      "78 - GLM with avg smape 51.88: \n",
      "Model Number: 79 of 84 with model ARIMA for Validation 2\n",
      "79 - ARIMA with avg smape 32.47: \n",
      "Model Number: 80 of 84 with model ARIMA for Validation 2\n",
      "80 - ARIMA with avg smape 29.17: \n",
      "Model Number: 81 of 84 with model MultivariateRegression for Validation 2\n",
      "81 - MultivariateRegression with avg smape 32.34: \n",
      "Model Number: 82 of 84 with model UnivariateMotif for Validation 2\n",
      "82 - UnivariateMotif with avg smape 35.47: \n",
      "Model Number: 83 of 84 with model WindowRegression for Validation 2\n",
      "83 - WindowRegression with avg smape 31.87: \n",
      "Model Number: 84 of 84 with model UnivariateMotif for Validation 2\n",
      "84 - UnivariateMotif with avg smape 37.49: \n",
      "Validation Round: 3\n",
      "Model Number: 1 of 84 with model ARDL for Validation 3\n",
      "Template Eval Error: Exception('Transformer RegressionFilter failed on fit') in model 1 in generation 0: ARDL\n",
      "Model Number: 2 of 84 with model LastValueNaive for Validation 3\n",
      "Template Eval Error: Exception('Transformer RegressionFilter failed on fit') in model 2 in generation 0: LastValueNaive\n",
      "Model Number: 3 of 84 with model AverageValueNaive for Validation 3\n",
      "Template Eval Error: Exception('Transformer RegressionFilter failed on fit') in model 3 in generation 0: AverageValueNaive\n",
      "Model Number: 4 of 84 with model MetricMotif for Validation 3\n",
      "📈 4 - MetricMotif with avg smape 74.69: \n",
      "Model Number: 5 of 84 with model UnivariateRegression for Validation 3\n",
      "Template Eval Error: Exception('Transformer RegressionFilter failed on fit') in model 5 in generation 0: UnivariateRegression\n",
      "Model Number: 6 of 84 with model UnobservedComponents for Validation 3\n",
      "📈 6 - UnobservedComponents with avg smape 73.8: \n",
      "Model Number: 7 of 84 with model UnobservedComponents for Validation 3\n",
      "📈 7 - UnobservedComponents with avg smape 72.43: \n",
      "Model Number: 8 of 84 with model LastValueNaive for Validation 3\n",
      "Template Eval Error: Exception('Transformer RegressionFilter failed on fit') in model 8 in generation 0: LastValueNaive\n",
      "Model Number: 9 of 84 with model LastValueNaive for Validation 3\n",
      "9 - LastValueNaive with avg smape 77.91: \n",
      "Model Number: 10 of 84 with model UnobservedComponents for Validation 3\n",
      "📈 10 - UnobservedComponents with avg smape 69.97: \n",
      "Model Number: 11 of 84 with model UnivariateRegression for Validation 3\n",
      "Template Eval Error: Exception('Transformer RegressionFilter failed on fit') in model 11 in generation 0: UnivariateRegression\n",
      "Model Number: 12 of 84 with model ARDL for Validation 3\n",
      "Template Eval Error: Exception('Transformer RegressionFilter failed on fit') in model 12 in generation 0: ARDL\n",
      "Model Number: 13 of 84 with model ETS for Validation 3\n",
      "Template Eval Error: Exception('Transformer RegressionFilter failed on fit') in model 13 in generation 0: ETS\n",
      "Model Number: 14 of 84 with model UnivariateRegression for Validation 3\n",
      "Template Eval Error: Exception('Transformer RegressionFilter failed on fit') in model 14 in generation 0: UnivariateRegression\n",
      "Model Number: 15 of 84 with model ARDL for Validation 3\n",
      "📈 15 - ARDL with avg smape 69.45: \n",
      "Model Number: 16 of 84 with model ARDL for Validation 3\n",
      "16 - ARDL with avg smape 69.45: \n",
      "Model Number: 17 of 84 with model NVAR for Validation 3\n",
      "17 - NVAR with avg smape 70.37: \n",
      "Model Number: 18 of 84 with model NVAR for Validation 3\n",
      "📈 18 - NVAR with avg smape 67.4: \n",
      "Model Number: 19 of 84 with model ARDL for Validation 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19 - ARDL with avg smape 70.64: \n",
      "Model Number: 20 of 84 with model ETS for Validation 3\n",
      "20 - ETS with avg smape 111.87: \n",
      "Model Number: 21 of 84 with model GLS for Validation 3\n",
      "21 - GLS with avg smape 70.5: \n",
      "Model Number: 22 of 84 with model NVAR for Validation 3\n",
      "Template Eval Error: Exception('Transformer RegressionFilter failed on fit') in model 22 in generation 0: NVAR\n",
      "Model Number: 23 of 84 with model GLS for Validation 3\n",
      "23 - GLS with avg smape 68.62: \n",
      "Model Number: 24 of 84 with model SeasonalNaive for Validation 3\n",
      "24 - SeasonalNaive with avg smape 75.21: \n",
      "Model Number: 25 of 84 with model DatepartRegression for Validation 3\n",
      "25 - DatepartRegression with avg smape 76.35: \n",
      "Model Number: 26 of 84 with model AverageValueNaive for Validation 3\n",
      "Template Eval Error: Exception('Transformer RegressionFilter failed on fit') in model 26 in generation 0: AverageValueNaive\n",
      "Model Number: 27 of 84 with model NVAR for Validation 3\n",
      "27 - NVAR with avg smape 69.16: \n",
      "Model Number: 28 of 84 with model GLM for Validation 3\n",
      "Template Eval Error: Exception('Transformer RegressionFilter failed on fit') in model 28 in generation 0: GLM\n",
      "Model Number: 29 of 84 with model MetricMotif for Validation 3\n",
      "29 - MetricMotif with avg smape 74.64: \n",
      "Model Number: 30 of 84 with model NVAR for Validation 3\n",
      "30 - NVAR with avg smape 70.35: \n",
      "Model Number: 31 of 84 with model ETS for Validation 3\n",
      "31 - ETS with avg smape 70.03: \n",
      "Model Number: 32 of 84 with model ETS for Validation 3\n",
      "32 - ETS with avg smape 70.03: \n",
      "Model Number: 33 of 84 with model GLS for Validation 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📈 33 - GLS with avg smape 63.75: \n",
      "Model Number: 34 of 84 with model AverageValueNaive for Validation 3\n",
      "Template Eval Error: ValueError('Model AverageValueNaive returned NaN for one or more series. fail_on_forecast_nan=True') in model 34 in generation 0: AverageValueNaive\n",
      "Model Number: 35 of 84 with model ETS for Validation 3\n",
      "35 - ETS with avg smape 70.1: \n",
      "Model Number: 36 of 84 with model UnobservedComponents for Validation 3\n",
      "36 - UnobservedComponents with avg smape 70.19: \n",
      "Model Number: 37 of 84 with model SectionalMotif for Validation 3\n",
      "Template Eval Error: ValueError('kth(=15) out of bounds (15)') in model 37 in generation 0: SectionalMotif\n",
      "Model Number: 38 of 84 with model GLM for Validation 3\n",
      "Template Eval Error: Exception('Transformer RegressionFilter failed on fit') in model 38 in generation 0: GLM\n",
      "Model Number: 39 of 84 with model DatepartRegression for Validation 3\n",
      "39 - DatepartRegression with avg smape 77.94: \n",
      "Model Number: 40 of 84 with model AverageValueNaive for Validation 3\n",
      "40 - AverageValueNaive with avg smape 70.1: \n",
      "Model Number: 41 of 84 with model AverageValueNaive for Validation 3\n",
      "Template Eval Error: Exception('Transformer RegressionFilter failed on fit') in model 41 in generation 0: AverageValueNaive\n",
      "Model Number: 42 of 84 with model GLS for Validation 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\numpy\\lib\\function_base.py:550: RuntimeWarning: invalid value encountered in multiply\n",
      "  avg = np.multiply(a, wgt,\n",
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\numpy\\core\\_methods.py:48: RuntimeWarning: invalid value encountered in reduce\n",
      "  return umr_sum(a, axis, dtype, out, keepdims, initial, where)\n",
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\numpy\\lib\\function_base.py:4527: RuntimeWarning: invalid value encountered in subtract\n",
      "  diff_b_a = subtract(b, a)\n",
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\decomposition\\_fastica.py:708: FutureWarning: Starting in v1.3, whiten=True should be specified as whiten='arbitrary-variance' (its current behaviour). This behavior is deprecated in 1.1 and will raise ValueError in 1.3.\n",
      "  return self._fit_transform(X, compute_sources=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📈 42 - GLS with avg smape 59.75: \n",
      "Model Number: 43 of 84 with model LastValueNaive for Validation 3\n",
      "Template Eval Error: Exception('Transformer RegressionFilter failed on fit') in model 43 in generation 0: LastValueNaive\n",
      "Model Number: 44 of 84 with model MetricMotif for Validation 3\n",
      "44 - MetricMotif with avg smape 71.37: \n",
      "Model Number: 45 of 84 with model MetricMotif for Validation 3\n",
      "45 - MetricMotif with avg smape 73.0: \n",
      "Model Number: 46 of 84 with model MultivariateRegression for Validation 3\n",
      "Template Eval Error: Exception('Transformer RegressionFilter failed on fit') in model 46 in generation 0: MultivariateRegression\n",
      "Model Number: 47 of 84 with model WindowRegression for Validation 3\n",
      "47 - WindowRegression with avg smape 68.15: \n",
      "Model Number: 48 of 84 with model WindowRegression for Validation 3\n",
      "48 - WindowRegression with avg smape 68.15: \n",
      "Model Number: 49 of 84 with model GLM for Validation 3\n",
      "49 - GLM with avg smape 60.38: \n",
      "Model Number: 50 of 84 with model DatepartRegression for Validation 3\n",
      "50 - DatepartRegression with avg smape 70.79: \n",
      "Model Number: 51 of 84 with model DatepartRegression for Validation 3\n",
      "Template Eval Error: Exception('Transformer RegressionFilter failed on fit') in model 51 in generation 0: DatepartRegression\n",
      "Model Number: 52 of 84 with model DatepartRegression for Validation 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.779e-03, tolerance: 1.190e-04\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52 - DatepartRegression with avg smape 82.23: \n",
      "Model Number: 53 of 84 with model SectionalMotif for Validation 3\n",
      "Template Eval Error: Exception('Transformer RegressionFilter failed on fit') in model 53 in generation 0: SectionalMotif\n",
      "Model Number: 54 of 84 with model UnobservedComponents for Validation 3\n",
      "54 - UnobservedComponents with avg smape 142.33: \n",
      "Model Number: 55 of 84 with model SectionalMotif for Validation 3\n",
      "Template Eval Error: Exception('Transformer RegressionFilter failed on fit') in model 55 in generation 0: SectionalMotif\n",
      "Model Number: 56 of 84 with model SectionalMotif for Validation 3\n",
      "Template Eval Error: Exception('Transformer RegressionFilter failed on fit') in model 56 in generation 0: SectionalMotif\n",
      "Model Number: 57 of 84 with model SectionalMotif for Validation 3\n",
      "57 - SectionalMotif with avg smape 117.08: \n",
      "Model Number: 58 of 84 with model MultivariateMotif for Validation 3\n",
      "Template Eval Error: ValueError('kth(=20) out of bounds (15)') in model 58 in generation 0: MultivariateMotif\n",
      "Model Number: 59 of 84 with model LastValueNaive for Validation 3\n",
      "59 - LastValueNaive with avg smape 98.52: \n",
      "Model Number: 60 of 84 with model UnivariateRegression for Validation 3\n",
      "60 - UnivariateRegression with avg smape 64.13: \n",
      "Model Number: 61 of 84 with model GLS for Validation 3\n",
      "61 - GLS with avg smape 61.31: \n",
      "Model Number: 62 of 84 with model WindowRegression for Validation 3\n",
      "Template Eval Error: Exception('Transformer RegressionFilter failed on fit') in model 62 in generation 0: WindowRegression\n",
      "Model Number: 63 of 84 with model MultivariateMotif for Validation 3\n",
      "Template Eval Error: Exception('Transformer RegressionFilter failed on fit') in model 63 in generation 0: MultivariateMotif\n",
      "Model Number: 64 of 84 with model MetricMotif for Validation 3\n",
      "64 - MetricMotif with avg smape 78.91: \n",
      "Model Number: 65 of 84 with model ARIMA for Validation 3\n",
      "65 - ARIMA with avg smape 78.9: \n",
      "Model Number: 66 of 84 with model MultivariateRegression for Validation 3\n",
      "66 - MultivariateRegression with avg smape 97.72: \n",
      "Model Number: 67 of 84 with model MultivariateMotif for Validation 3\n",
      "67 - MultivariateMotif with avg smape 85.54: \n",
      "Model Number: 68 of 84 with model MultivariateMotif for Validation 3\n",
      "Template Eval Error: ValueError('kth(=20) out of bounds (15)') in model 68 in generation 0: MultivariateMotif\n",
      "Model Number: 69 of 84 with model ARIMA for Validation 3\n",
      "69 - ARIMA with avg smape 96.66: \n",
      "Model Number: 70 of 84 with model ConstantNaive for Validation 3\n",
      "70 - ConstantNaive with avg smape 82.95: \n",
      "Model Number: 71 of 84 with model MultivariateMotif for Validation 3\n",
      "Template Eval Error: ValueError('kth(=20) out of bounds (15)') in model 71 in generation 0: MultivariateMotif\n",
      "Model Number: 72 of 84 with model UnivariateRegression for Validation 3\n",
      "72 - UnivariateRegression with avg smape 107.12: \n",
      "Model Number: 73 of 84 with model MultivariateRegression for Validation 3\n",
      "73 - MultivariateRegression with avg smape 66.24: \n",
      "Model Number: 74 of 84 with model MultivariateRegression for Validation 3\n",
      "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "74 - MultivariateRegression with avg smape 79.45: \n",
      "Model Number: 75 of 84 with model ARIMA for Validation 3\n",
      "📈 75 - ARIMA with avg smape 58.14: \n",
      "Model Number: 76 of 84 with model WindowRegression for Validation 3\n",
      "76 - WindowRegression with avg smape 124.17: \n",
      "Model Number: 77 of 84 with model GLM for Validation 3\n",
      "77 - GLM with avg smape 61.49: \n",
      "Model Number: 78 of 84 with model GLM for Validation 3\n",
      "78 - GLM with avg smape 72.86: \n",
      "Model Number: 79 of 84 with model ARIMA for Validation 3\n",
      "79 - ARIMA with avg smape 71.45: \n",
      "Model Number: 80 of 84 with model ARIMA for Validation 3\n",
      "📈 80 - ARIMA with avg smape 58.1: \n",
      "Model Number: 81 of 84 with model MultivariateRegression for Validation 3\n",
      "81 - MultivariateRegression with avg smape 69.29: \n",
      "Model Number: 82 of 84 with model UnivariateMotif for Validation 3\n",
      "82 - UnivariateMotif with avg smape 73.87: \n",
      "Model Number: 83 of 84 with model WindowRegression for Validation 3\n",
      "Template Eval Error: Exception('Transformer RegressionFilter failed on fit') in model 83 in generation 0: WindowRegression\n",
      "Model Number: 84 of 84 with model UnivariateMotif for Validation 3\n",
      "Template Eval Error: Exception('Transformer RegressionFilter failed on fit') in model 84 in generation 0: UnivariateMotif\n",
      "TotalRuntime missing in 5!\n",
      "Validation Round: 1\n",
      "TotalRuntime missing in 0!\n",
      "Validation Round: 2\n",
      "TotalRuntime missing in 0!\n",
      "Validation Round: 3\n",
      "TotalRuntime missing in 0!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\crudek\\AppData\\Local\\Temp\\ipykernel_11000\\1533679110.py:63: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  all_predictions = all_predictions.append(temp_fcasts_ni)\n",
      "  7%|▋         | 1/14 [02:25<31:25, 145.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 6 cpus for n_jobs.\n",
      "Data frequency is: MS, used frequency is: MS\n",
      "Model Number: 1 with model ARIMA in generation 0 of 3\n",
      "Model Number: 2 with model AverageValueNaive in generation 0 of 3\n",
      "Model Number: 3 with model AverageValueNaive in generation 0 of 3\n",
      "Model Number: 4 with model AverageValueNaive in generation 0 of 3\n",
      "Model Number: 5 with model DatepartRegression in generation 0 of 3\n",
      "Model Number: 6 with model DatepartRegression in generation 0 of 3\n",
      "Model Number: 7 with model DatepartRegression in generation 0 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 8 with model DatepartRegression in generation 0 of 3\n",
      "Template Eval Error: ImportError('Tensorflow not available, install with pip install tensorflow.') in model 8 in generation 0: DatepartRegression\n",
      "Model Number: 9 with model ETS in generation 0 of 3\n",
      "Model Number: 10 with model ETS in generation 0 of 3\n",
      "Model Number: 11 with model GLM in generation 0 of 3\n",
      "Model Number: 12 with model GLM in generation 0 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:541: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 13 with model GLS in generation 0 of 3\n",
      "Model Number: 14 with model GLS in generation 0 of 3\n",
      "Model Number: 15 with model GluonTS in generation 0 of 3\n",
      "Template Eval Error: ImportError('GluonTS installation is incompatible with AutoTS. The numpy version is sometimes the issue, try 1.23.1 {as of 06-2023}') in model 15 in generation 0: GluonTS\n",
      "Model Number: 16 with model GluonTS in generation 0 of 3\n",
      "Template Eval Error: ImportError('GluonTS installation is incompatible with AutoTS. The numpy version is sometimes the issue, try 1.23.1 {as of 06-2023}') in model 16 in generation 0: GluonTS\n",
      "Model Number: 17 with model GluonTS in generation 0 of 3\n",
      "Template Eval Error: ImportError('GluonTS installation is incompatible with AutoTS. The numpy version is sometimes the issue, try 1.23.1 {as of 06-2023}') in model 17 in generation 0: GluonTS\n",
      "Model Number: 18 with model GluonTS in generation 0 of 3\n",
      "Template Eval Error: ImportError('GluonTS installation is incompatible with AutoTS. The numpy version is sometimes the issue, try 1.23.1 {as of 06-2023}') in model 18 in generation 0: GluonTS\n",
      "Model Number: 19 with model GluonTS in generation 0 of 3\n",
      "Template Eval Error: ImportError('GluonTS installation is incompatible with AutoTS. The numpy version is sometimes the issue, try 1.23.1 {as of 06-2023}') in model 19 in generation 0: GluonTS\n",
      "Model Number: 20 with model LastValueNaive in generation 0 of 3\n",
      "Model Number: 21 with model LastValueNaive in generation 0 of 3\n",
      "Model Number: 22 with model LastValueNaive in generation 0 of 3\n",
      "Model Number: 23 with model LastValueNaive in generation 0 of 3\n",
      "Model Number: 24 with model SeasonalNaive in generation 0 of 3\n",
      "Model Number: 25 with model SeasonalNaive in generation 0 of 3\n",
      "Model Number: 26 with model SeasonalNaive in generation 0 of 3\n",
      "Model Number: 27 with model UnobservedComponents in generation 0 of 3\n",
      "Model Number: 28 with model UnobservedComponents in generation 0 of 3\n",
      "Model Number: 29 with model UnobservedComponents in generation 0 of 3\n",
      "Model Number: 30 with model VAR in generation 0 of 3\n",
      "Template Eval Error: ValueError('Only gave one variable to VAR') in model 30 in generation 0: VAR\n",
      "Model Number: 31 with model VAR in generation 0 of 3\n",
      "Template Eval Error: ValueError('Only gave one variable to VAR') in model 31 in generation 0: VAR\n",
      "Model Number: 32 with model VECM in generation 0 of 3\n",
      "Template Eval Error: ValueError('Only gave one variable to VECM') in model 32 in generation 0: VECM\n",
      "Model Number: 33 with model VECM in generation 0 of 3\n",
      "Template Eval Error: ValueError('Only gave one variable to VECM') in model 33 in generation 0: VECM\n",
      "Model Number: 34 with model WindowRegression in generation 0 of 3\n",
      "Model Number: 35 with model ConstantNaive in generation 0 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18:59:56 - cmdstanpy - INFO - Chain [1] start processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 36 with model FBProphet in generation 0 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18:59:56 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 37 with model GluonTS in generation 0 of 3\n",
      "Template Eval Error: ImportError('GluonTS installation is incompatible with AutoTS. The numpy version is sometimes the issue, try 1.23.1 {as of 06-2023}') in model 37 in generation 0: GluonTS\n",
      "Model Number: 38 with model MultivariateRegression in generation 0 of 3\n",
      "Model Number: 39 with model MultivariateRegression in generation 0 of 3\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000034 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Model Number: 40 with model DatepartRegression in generation 0 of 3\n",
      "Model Number: 41 with model SeasonalNaive in generation 0 of 3\n",
      "Model Number: 42 with model DatepartRegression in generation 0 of 3\n",
      "Model Number: 43 with model UnobservedComponents in generation 0 of 3\n",
      "Model Number: 44 with model UnobservedComponents in generation 0 of 3\n",
      "Model Number: 45 with model ETS in generation 0 of 3\n",
      "Model Number: 46 with model VECM in generation 0 of 3\n",
      "Template Eval Error: ValueError('Only gave one variable to VECM') in model 46 in generation 0: VECM\n",
      "Model Number: 47 with model ARDL in generation 0 of 3\n",
      "Model Number: 48 with model MultivariateMotif in generation 0 of 3\n",
      "Model Number: 49 with model MultivariateMotif in generation 0 of 3\n",
      "Model Number: 50 with model UnivariateMotif in generation 0 of 3\n",
      "Template Eval Error: ValueError('kth(=10) out of bounds (1)') in model 50 in generation 0: UnivariateMotif\n",
      "Model Number: 51 with model UnivariateMotif in generation 0 of 3\n",
      "Model Number: 52 with model SectionalMotif in generation 0 of 3\n",
      "Model Number: 53 with model SectionalMotif in generation 0 of 3\n",
      "Model Number: 54 with model MultivariateRegression in generation 0 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18:59:59 - cmdstanpy - INFO - Chain [1] start processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 55 with model FBProphet in generation 0 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "19:00:21 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 56 with model SeasonalNaive in generation 0 of 3\n",
      "Model Number: 57 with model DatepartRegression in generation 0 of 3\n",
      "Model Number: 58 with model NVAR in generation 0 of 3\n",
      "Model Number: 59 with model Theta in generation 0 of 3\n",
      "Model Number: 60 with model UnivariateRegression in generation 0 of 3\n",
      "Template Eval Error: ValueError('Input X contains NaN.\\nDecisionTreeRegressor does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values') in model 60 in generation 0: UnivariateRegression\n",
      "Model Number: 61 with model ARCH in generation 0 of 3\n",
      "Template Eval Error: ImportError('`arch` package must be installed from pip') in model 61 in generation 0: ARCH\n",
      "Model Number: 62 with model ConstantNaive in generation 0 of 3\n",
      "Model Number: 63 with model LastValueNaive in generation 0 of 3\n",
      "Model Number: 64 with model AverageValueNaive in generation 0 of 3\n",
      "Model Number: 65 with model GLS in generation 0 of 3\n",
      "Model Number: 66 with model SeasonalNaive in generation 0 of 3\n",
      "Model Number: 67 with model GLM in generation 0 of 3\n",
      "Template Eval Error: ValueError('The first guess on the deviance function returned a nan.  This could be a boundary  problem and should be reported.') in model 67 in generation 0: GLM\n",
      "Model Number: 68 with model ETS in generation 0 of 3\n",
      "Model Number: 69 with model FBProphet in generation 0 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\statsmodels\\genmod\\families\\family.py:1367: ValueWarning: Negative binomial dispersion parameter alpha not set. Using default value alpha=1.0.\n",
      "  warnings.warn(\"Negative binomial dispersion parameter alpha not \"\n",
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\statsmodels\\genmod\\families\\family.py:1406: RuntimeWarning: invalid value encountered in log\n",
      "  resid_dev -= endog_alpha * np.log(endog_alpha / mu_alpha)\n",
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.380e+12, tolerance: 7.414e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "19:00:21 - cmdstanpy - INFO - Chain [1] start processing\n",
      "19:00:22 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 70 with model GluonTS in generation 0 of 3\n",
      "Template Eval Error: ImportError('GluonTS installation is incompatible with AutoTS. The numpy version is sometimes the issue, try 1.23.1 {as of 06-2023}') in model 70 in generation 0: GluonTS\n",
      "Model Number: 71 with model UnobservedComponents in generation 0 of 3\n",
      "Model Number: 72 with model VAR in generation 0 of 3\n",
      "Template Eval Error: ValueError('Only gave one variable to VAR') in model 72 in generation 0: VAR\n",
      "Model Number: 73 with model VECM in generation 0 of 3\n",
      "Template Eval Error: ValueError('Only gave one variable to VECM') in model 73 in generation 0: VECM\n",
      "Model Number: 74 with model ARIMA in generation 0 of 3\n",
      "Model Number: 75 with model WindowRegression in generation 0 of 3\n",
      "Model Number: 76 with model DatepartRegression in generation 0 of 3\n",
      "Model Number: 77 with model UnivariateRegression in generation 0 of 3\n",
      "Model Number: 78 with model MultivariateRegression in generation 0 of 3\n",
      "Model Number: 79 with model UnivariateMotif in generation 0 of 3\n",
      "Model Number: 80 with model MultivariateMotif in generation 0 of 3\n",
      "Template Eval Error: ValueError('kth(=100) out of bounds (51)') in model 80 in generation 0: MultivariateMotif\n",
      "Model Number: 81 with model SectionalMotif in generation 0 of 3\n",
      "Template Eval Error: ValueError(\"Model returned NaN due to a preprocessing transformer {'fillna': 'rolling_mean', 'transformations': {'0': 'SeasonalDifference', '1': 'AlignLastValue', '2': 'AlignLastValue', '3': 'EWMAFilter'}, 'transformation_params': {'0': {'lag_1': 7, 'method': 'LastValue'}, '1': {'rows': 1, 'lag': 1, 'method': 'multiplicative', 'strength': 1.0, 'first_value_only': False}, '2': {'rows': 1, 'lag': 1, 'method': 'additive', 'strength': 1.0, 'first_value_only': False}, '3': {'span': 12}}}. fail_on_forecast_nan=True\") in model 81 in generation 0: SectionalMotif\n",
      "Model Number: 82 with model NVAR in generation 0 of 3\n",
      "Model Number: 83 with model Theta in generation 0 of 3\n",
      "Model Number: 84 with model ARDL in generation 0 of 3\n",
      "Model Number: 85 with model ARCH in generation 0 of 3\n",
      "Template Eval Error: ImportError('`arch` package must be installed from pip') in model 85 in generation 0: ARCH\n",
      "Model Number: 86 with model MetricMotif in generation 0 of 3\n",
      "Model Number: 87 with model AverageValueNaive in generation 0 of 3\n",
      "Model Number: 88 with model UnobservedComponents in generation 0 of 3\n",
      "Model Number: 89 with model AverageValueNaive in generation 0 of 3\n",
      "Model Number: 90 with model LastValueNaive in generation 0 of 3\n",
      "Model Number: 91 with model ARDL in generation 0 of 3\n",
      "Model Number: 92 with model WindowRegression in generation 0 of 3\n",
      "Model Number: 93 with model ConstantNaive in generation 0 of 3\n",
      "Model Number: 94 with model SeasonalNaive in generation 0 of 3\n",
      "Model Number: 95 with model ARDL in generation 0 of 3\n",
      "Template Eval Error: ValueError(\"ARDL series NET_SALES failed with error ValueError('The number of regressors (178) including deterministics, lags of the endog, lags of the exogenous, and fixed regressors is larger than the sample available for estimation (69).') exog train             weekend  quarter      epoch  month_1  month_2  month_3  month_4  \\\\\\nMONTH                                                                         \\n2016-01-01        0        1  2457388.5      1.0      0.0      0.0      0.0   \\n2016-02-01        0        1  2457419.5      0.0      1.0      0.0      0.0   \\n2016-03-01        0        1  2457448.5      0.0      0.0      1.0      0.0   \\n2016-04-01        0        2  2457479.5      0.0      0.0      0.0      1.0   \\n2016-05-01        1        2  2457509.5      0.0      0.0      0.0      0.0   \\n...             ...      ...        ...      ...      ...      ...      ...   \\n2021-08-01        1        3  2459427.5      0.0      0.0      0.0      0.0   \\n2021-09-01        0        3  2459458.5      0.0      0.0      0.0      0.0   \\n2021-10-01        0        4  2459488.5      0.0      0.0      0.0      0.0   \\n2021-11-01        0        4  2459519.5      0.0      0.0      0.0      0.0   \\n2021-12-01        0        4  2459549.5      0.0      0.0      0.0      0.0   \\n\\n            month_5  month_6  month_7  ...  day_27  day_28  day_29  day_30  \\\\\\nMONTH                                  ...                                   \\n2016-01-01      0.0      0.0      0.0  ...     0.0     0.0     0.0     0.0   \\n2016-02-01      0.0      0.0      0.0  ...     0.0     0.0     0.0     0.0   \\n2016-03-01      0.0      0.0      0.0  ...     0.0     0.0     0.0     0.0   \\n2016-04-01      0.0      0.0      0.0  ...     0.0     0.0     0.0     0.0   \\n2016-05-01      1.0      0.0      0.0  ...     0.0     0.0     0.0     0.0   \\n...             ...      ...      ...  ...     ...     ...     ...     ...   \\n2021-08-01      0.0      0.0      0.0  ...     0.0     0.0     0.0     0.0   \\n2021-09-01      0.0      0.0      0.0  ...     0.0     0.0     0.0     0.0   \\n2021-10-01      0.0      0.0      0.0  ...     0.0     0.0     0.0     0.0   \\n2021-11-01      0.0      0.0      0.0  ...     0.0     0.0     0.0     0.0   \\n2021-12-01      0.0      0.0      0.0  ...     0.0     0.0     0.0     0.0   \\n\\n            day_31  weekdayofmonth_1  weekdayofmonth_2  weekdayofmonth_3  \\\\\\nMONTH                                                                      \\n2016-01-01     0.0               1.0               0.0               0.0   \\n2016-02-01     0.0               1.0               0.0               0.0   \\n2016-03-01     0.0               1.0               0.0               0.0   \\n2016-04-01     0.0               1.0               0.0               0.0   \\n2016-05-01     0.0               1.0               0.0               0.0   \\n...            ...               ...               ...               ...   \\n2021-08-01     0.0               1.0               0.0               0.0   \\n2021-09-01     0.0               1.0               0.0               0.0   \\n2021-10-01     0.0               1.0               0.0               0.0   \\n2021-11-01     0.0               1.0               0.0               0.0   \\n2021-12-01     0.0               1.0               0.0               0.0   \\n\\n            weekdayofmonth_4  weekdayofmonth_5  \\nMONTH                                           \\n2016-01-01               0.0               0.0  \\n2016-02-01               0.0               0.0  \\n2016-03-01               0.0               0.0  \\n2016-04-01               0.0               0.0  \\n2016-05-01               0.0               0.0  \\n...                      ...               ...  \\n2021-08-01               0.0               0.0  \\n2021-09-01               0.0               0.0  \\n2021-10-01               0.0               0.0  \\n2021-11-01               0.0               0.0  \\n2021-12-01               0.0               0.0  \\n\\n[72 rows x 58 columns] and predict             weekend  quarter      epoch  month_1  month_2  month_3  month_4  \\\\\\n2022-01-01        1        1  2459580.5      1.0      0.0      0.0      0.0   \\n2022-02-01        0        1  2459611.5      0.0      1.0      0.0      0.0   \\n2022-03-01        0        1  2459639.5      0.0      0.0      1.0      0.0   \\n2022-04-01        0        2  2459670.5      0.0      0.0      0.0      1.0   \\n2022-05-01        1        2  2459700.5      0.0      0.0      0.0      0.0   \\n2022-06-01        0        2  2459731.5      0.0      0.0      0.0      0.0   \\n2022-07-01        0        3  2459761.5      0.0      0.0      0.0      0.0   \\n2022-08-01        0        3  2459792.5      0.0      0.0      0.0      0.0   \\n2022-09-01        0        3  2459823.5      0.0      0.0      0.0      0.0   \\n2022-10-01        1        4  2459853.5      0.0      0.0      0.0      0.0   \\n2022-11-01        0        4  2459884.5      0.0      0.0      0.0      0.0   \\n2022-12-01        0        4  2459914.5      0.0      0.0      0.0      0.0   \\n\\n            month_5  month_6  month_7  ...  day_27  day_28  day_29  day_30  \\\\\\n2022-01-01      0.0      0.0      0.0  ...     0.0     0.0     0.0     0.0   \\n2022-02-01      0.0      0.0      0.0  ...     0.0     0.0     0.0     0.0   \\n2022-03-01      0.0      0.0      0.0  ...     0.0     0.0     0.0     0.0   \\n2022-04-01      0.0      0.0      0.0  ...     0.0     0.0     0.0     0.0   \\n2022-05-01      1.0      0.0      0.0  ...     0.0     0.0     0.0     0.0   \\n2022-06-01      0.0      1.0      0.0  ...     0.0     0.0     0.0     0.0   \\n2022-07-01      0.0      0.0      1.0  ...     0.0     0.0     0.0     0.0   \\n2022-08-01      0.0      0.0      0.0  ...     0.0     0.0     0.0     0.0   \\n2022-09-01      0.0      0.0      0.0  ...     0.0     0.0     0.0     0.0   \\n2022-10-01      0.0      0.0      0.0  ...     0.0     0.0     0.0     0.0   \\n2022-11-01      0.0      0.0      0.0  ...     0.0     0.0     0.0     0.0   \\n2022-12-01      0.0      0.0      0.0  ...     0.0     0.0     0.0     0.0   \\n\\n            day_31  weekdayofmonth_1  weekdayofmonth_2  weekdayofmonth_3  \\\\\\n2022-01-01     0.0               1.0               0.0               0.0   \\n2022-02-01     0.0               1.0               0.0               0.0   \\n2022-03-01     0.0               1.0               0.0               0.0   \\n2022-04-01     0.0               1.0               0.0               0.0   \\n2022-05-01     0.0               1.0               0.0               0.0   \\n2022-06-01     0.0               1.0               0.0               0.0   \\n2022-07-01     0.0               1.0               0.0               0.0   \\n2022-08-01     0.0               1.0               0.0               0.0   \\n2022-09-01     0.0               1.0               0.0               0.0   \\n2022-10-01     0.0               1.0               0.0               0.0   \\n2022-11-01     0.0               1.0               0.0               0.0   \\n2022-12-01     0.0               1.0               0.0               0.0   \\n\\n            weekdayofmonth_4  weekdayofmonth_5  \\n2022-01-01               0.0               0.0  \\n2022-02-01               0.0               0.0  \\n2022-03-01               0.0               0.0  \\n2022-04-01               0.0               0.0  \\n2022-05-01               0.0               0.0  \\n2022-06-01               0.0               0.0  \\n2022-07-01               0.0               0.0  \\n2022-08-01               0.0               0.0  \\n2022-09-01               0.0               0.0  \\n2022-10-01               0.0               0.0  \\n2022-11-01               0.0               0.0  \\n2022-12-01               0.0               0.0  \\n\\n[12 rows x 58 columns]\") in model 95 in generation 0: ARDL\n",
      "Model Number: 96 with model FBProphet in generation 0 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "19:00:24 - cmdstanpy - INFO - Chain [1] start processing\n",
      "19:00:24 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 97 with model ConstantNaive in generation 0 of 3\n",
      "Model Number: 98 with model ConstantNaive in generation 0 of 3\n",
      "Model Number: 99 with model UnobservedComponents in generation 0 of 3\n",
      "Model Number: 100 with model ConstantNaive in generation 0 of 3\n",
      "Model Number: 101 with model VAR in generation 0 of 3\n",
      "Template Eval Error: ValueError('Only gave one variable to VAR') in model 101 in generation 0: VAR\n",
      "Model Number: 102 with model ETS in generation 0 of 3\n",
      "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
      "ETS failed on NET_SALES with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
      "Model Number: 103 with model Theta in generation 0 of 3\n",
      "Model Number: 104 with model DatepartRegression in generation 0 of 3\n",
      "Template Eval Error: ValueError('Model DatepartRegression returned NaN for one or more series. fail_on_forecast_nan=True') in model 104 in generation 0: DatepartRegression\n",
      "Model Number: 105 with model GLM in generation 0 of 3\n",
      "Model Number: 106 with model ARCH in generation 0 of 3\n",
      "Template Eval Error: Exception('Transformer Detrend failed on fit') in model 106 in generation 0: ARCH\n",
      "Model Number: 107 with model AverageValueNaive in generation 0 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\neighbors\\_regression.py:494: UserWarning: One or more samples have no neighbors within specified radius; predicting NaN.\n",
      "  warnings.warn(empty_warning_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 108 with model MetricMotif in generation 0 of 3\n",
      "Model Number: 109 with model ETS in generation 0 of 3\n",
      "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
      "ETS failed on NET_SALES with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
      "Template Eval Error: Exception('Transformer DifferencedTransformer failed on inverse') in model 109 in generation 0: ETS\n",
      "Model Number: 110 with model ETS in generation 0 of 3\n",
      "ETS error ValueError('Cannot compute initial seasonals using heuristic method with less than two full seasonal cycles in the data.')\n",
      "ETS failed on NET_SALES with ValueError('Cannot compute initial seasonals using heuristic method with less than two full seasonal cycles in the data.')\n",
      "Template Eval Error: Exception('Transformer AlignLastValue failed on inverse') in model 110 in generation 0: ETS\n",
      "Model Number: 111 with model SeasonalNaive in generation 0 of 3\n",
      "Model Number: 112 with model ARCH in generation 0 of 3\n",
      "Template Eval Error: ImportError('`arch` package must be installed from pip') in model 112 in generation 0: ARCH\n",
      "Model Number: 113 with model SectionalMotif in generation 0 of 3\n",
      "Model Number: 114 with model SeasonalNaive in generation 0 of 3\n",
      "Model Number: 115 with model UnivariateRegression in generation 0 of 3\n",
      "Model Number: 116 with model VAR in generation 0 of 3\n",
      "Template Eval Error: ValueError('Only gave one variable to VAR') in model 116 in generation 0: VAR\n",
      "Model Number: 117 with model GluonTS in generation 0 of 3\n",
      "Template Eval Error: ImportError('GluonTS installation is incompatible with AutoTS. The numpy version is sometimes the issue, try 1.23.1 {as of 06-2023}') in model 117 in generation 0: GluonTS\n",
      "Model Number: 118 with model GLM in generation 0 of 3\n",
      "Template Eval Error: ValueError('NaN, inf or invalid value detected in weights, estimation infeasible.') in model 118 in generation 0: GLM\n",
      "Model Number: 119 with model MultivariateMotif in generation 0 of 3\n",
      "Model Number: 120 with model AverageValueNaive in generation 0 of 3\n",
      "Model Number: 121 with model ConstantNaive in generation 0 of 3\n",
      "Model Number: 122 with model ARCH in generation 0 of 3\n",
      "Template Eval Error: ImportError('`arch` package must be installed from pip') in model 122 in generation 0: ARCH\n",
      "Model Number: 123 with model GLS in generation 0 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\statsmodels\\genmod\\families\\family.py:1367: ValueWarning: Negative binomial dispersion parameter alpha not set. Using default value alpha=1.0.\n",
      "  warnings.warn(\"Negative binomial dispersion parameter alpha not \"\n",
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\statsmodels\\genmod\\families\\links.py:527: RuntimeWarning: overflow encountered in exp\n",
      "  return np.exp(z)\n",
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\statsmodels\\genmod\\families\\family.py:1402: RuntimeWarning: divide by zero encountered in divide\n",
      "  endog_mu = self._clean(endog / mu)\n",
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\statsmodels\\genmod\\families\\family.py:1406: RuntimeWarning: divide by zero encountered in log\n",
      "  resid_dev -= endog_alpha * np.log(endog_alpha / mu_alpha)\n",
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\statsmodels\\genmod\\families\\family.py:1406: RuntimeWarning: invalid value encountered in log\n",
      "  resid_dev -= endog_alpha * np.log(endog_alpha / mu_alpha)\n",
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\numpy\\core\\fromnumeric.py:86: RuntimeWarning: invalid value encountered in reduce\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n",
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\statsmodels\\genmod\\families\\family.py:143: RuntimeWarning: invalid value encountered in multiply\n",
      "  return 1. / (self.link.deriv(mu)**2 * self.variance(mu))\n",
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\statsmodels\\genmod\\generalized_linear_model.py:1243: RuntimeWarning: invalid value encountered in multiply\n",
      "  wlsendog = (lin_pred + self.family.link.deriv(mu) * (self.endog-mu)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 124 with model LastValueNaive in generation 0 of 3\n",
      "Template Eval Error: Exception('Transformer RegressionFilter failed on fit') in model 124 in generation 0: LastValueNaive\n",
      "Model Number: 125 with model UnobservedComponents in generation 0 of 3\n",
      "Model Number: 126 with model LastValueNaive in generation 0 of 3\n",
      "Model Number: 127 with model SectionalMotif in generation 0 of 3\n",
      "Template Eval Error: ValueError('Unknown Distance Metric: kulsinski') in model 127 in generation 0: SectionalMotif\n",
      "Model Number: 128 with model GLS in generation 0 of 3\n",
      "Model Number: 129 with model Theta in generation 0 of 3\n",
      "Model Number: 130 with model UnobservedComponents in generation 0 of 3\n",
      "Model Number: 131 with model WindowRegression in generation 0 of 3\n",
      "Template Eval Error: ValueError('Input X contains NaN.\\nBayesianRidge does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values') in model 131 in generation 0: WindowRegression\n",
      "Model Number: 132 with model NVAR in generation 0 of 3\n",
      "Model Number: 133 with model SeasonalNaive in generation 0 of 3\n",
      "Model Number: 134 with model UnobservedComponents in generation 0 of 3\n",
      "Template Eval Error: Exception('Transformer Detrend failed on fit') in model 134 in generation 0: UnobservedComponents\n",
      "Model Number: 135 with model GLS in generation 0 of 3\n",
      "Model Number: 136 with model MetricMotif in generation 0 of 3\n",
      "Model Number: 137 with model VAR in generation 0 of 3\n",
      "Template Eval Error: ValueError('Only gave one variable to VAR') in model 137 in generation 0: VAR\n",
      "Model Number: 138 with model WindowRegression in generation 0 of 3\n",
      "Template Eval Error: ImportError('Tensorflow not available, install with pip install tensorflow.') in model 138 in generation 0: WindowRegression\n",
      "Model Number: 139 with model GLM in generation 0 of 3\n",
      "Model Number: 140 with model NVAR in generation 0 of 3\n",
      "Model Number: 141 with model VAR in generation 0 of 3\n",
      "Template Eval Error: ValueError('Only gave one variable to VAR') in model 141 in generation 0: VAR\n",
      "Model Number: 142 with model DatepartRegression in generation 0 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\statsmodels\\genmod\\families\\links.py:198: RuntimeWarning: overflow encountered in exp\n",
      "  t = np.exp(-z)\n",
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\utils\\extmath.py:189: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\utils\\extmath.py:189: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Template Eval Error: ValueError('Solver produced non-finite parameter weights. The input data may contain large values and need to be preprocessed.') in model 142 in generation 0: DatepartRegression\n",
      "Model Number: 143 with model GLS in generation 0 of 3\n",
      "Model Number: 144 with model DatepartRegression in generation 0 of 3\n",
      "Template Eval Error: ValueError('Input X contains NaN.\\nExtraTreesRegressor does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values') in model 144 in generation 0: DatepartRegression\n",
      "Model Number: 145 with model VAR in generation 0 of 3\n",
      "Template Eval Error: ValueError('Only gave one variable to VAR') in model 145 in generation 0: VAR\n",
      "Model Number: 146 with model Theta in generation 0 of 3\n",
      "Model Number: 147 with model ETS in generation 0 of 3\n",
      "ETS error ValueError('Cannot compute initial seasonals using heuristic method with less than two full seasonal cycles in the data.')\n",
      "ETS failed on NET_SALES with ValueError('Cannot compute initial seasonals using heuristic method with less than two full seasonal cycles in the data.')\n",
      "Model Number: 148 with model ConstantNaive in generation 0 of 3\n",
      "Model Number: 149 with model ARDL in generation 0 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (250) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 150 with model SectionalMotif in generation 0 of 3\n",
      "Model Number: 151 with model VAR in generation 0 of 3\n",
      "Model Number: 152 with model DatepartRegression in generation 0 of 3\n",
      "Model Number: 153 with model Theta in generation 0 of 3\n",
      "Model Number: 154 with model MetricMotif in generation 0 of 3\n",
      "Model Number: 155 with model DatepartRegression in generation 0 of 3\n",
      "Model Number: 156 with model GLM in generation 0 of 3\n",
      "Model Number: 157 with model GluonTS in generation 0 of 3\n",
      "Template Eval Error: ImportError('GluonTS installation is incompatible with AutoTS. The numpy version is sometimes the issue, try 1.23.1 {as of 06-2023}') in model 157 in generation 0: GluonTS\n",
      "Model Number: 158 with model DatepartRegression in generation 0 of 3\n",
      "Template Eval Error: Exception('Transformer AlignLastValue failed on inverse') in model 158 in generation 0: DatepartRegression\n",
      "Model Number: 159 with model NVAR in generation 0 of 3\n",
      "Model Number: 160 with model GLS in generation 0 of 3\n",
      "Model Number: 161 with model SectionalMotif in generation 0 of 3\n",
      "Model Number: 162 with model FBProphet in generation 0 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\statsmodels\\genmod\\families\\links.py:198: RuntimeWarning: overflow encountered in exp\n",
      "  t = np.exp(-z)\n",
      "19:00:27 - cmdstanpy - INFO - Chain [1] start processing\n",
      "19:00:27 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 163 with model ETS in generation 0 of 3\n",
      "Model Number: 164 with model VAR in generation 0 of 3\n",
      "Template Eval Error: ValueError('Only gave one variable to VAR') in model 164 in generation 0: VAR\n",
      "Model Number: 165 with model MultivariateMotif in generation 0 of 3\n",
      "Model Number: 166 with model VAR in generation 0 of 3\n",
      "Template Eval Error: ValueError('Only gave one variable to VAR') in model 166 in generation 0: VAR\n",
      "Model Number: 167 with model ARIMA in generation 0 of 3\n",
      "Model Number: 168 with model UnobservedComponents in generation 0 of 3\n",
      "Model Number: 169 with model UnivariateMotif in generation 0 of 3\n",
      "Template Eval Error: ValueError('kth(=100) out of bounds (51)') in model 169 in generation 0: UnivariateMotif\n",
      "Model Number: 170 with model VAR in generation 0 of 3\n",
      "Template Eval Error: ValueError('Only gave one variable to VAR') in model 170 in generation 0: VAR\n",
      "Model Number: 171 with model Theta in generation 0 of 3\n",
      "Model Number: 172 with model MultivariateMotif in generation 0 of 3\n",
      "Model Number: 173 with model UnobservedComponents in generation 0 of 3\n",
      "Model Number: 174 with model WindowRegression in generation 0 of 3\n",
      "Model Number: 175 with model SeasonalNaive in generation 0 of 3\n",
      "Model Number: 176 with model ARDL in generation 0 of 3\n",
      "Model Number: 177 with model GLS in generation 0 of 3\n",
      "Model Number: 178 with model SectionalMotif in generation 0 of 3\n",
      "Model Number: 179 with model ARDL in generation 0 of 3\n",
      "Model Number: 180 with model MultivariateMotif in generation 0 of 3\n",
      "Model Number: 181 with model ARCH in generation 0 of 3\n",
      "Template Eval Error: ImportError('`arch` package must be installed from pip') in model 181 in generation 0: ARCH\n",
      "Model Number: 182 with model SectionalMotif in generation 0 of 3\n",
      "Model Number: 183 with model ARIMA in generation 0 of 3\n",
      "Model Number: 184 with model DatepartRegression in generation 0 of 3\n",
      "Model Number: 185 with model ETS in generation 0 of 3\n",
      "ETS error ValueError('Cannot compute initial seasonals using heuristic method with less than two full seasonal cycles in the data.')\n",
      "ETS failed on NET_SALES with ValueError('Cannot compute initial seasonals using heuristic method with less than two full seasonal cycles in the data.')\n",
      "Model Number: 186 with model VECM in generation 0 of 3\n",
      "Template Eval Error: ValueError('Only gave one variable to VECM') in model 186 in generation 0: VECM\n",
      "New Generation: 1 of 3\n",
      "Model Number: 187 with model GLS in generation 1 of 3\n",
      "Model Number: 188 with model AverageValueNaive in generation 1 of 3\n",
      "Model Number: 189 with model ConstantNaive in generation 1 of 3\n",
      "Model Number: 190 with model MultivariateMotif in generation 1 of 3\n",
      "Model Number: 191 with model SeasonalNaive in generation 1 of 3\n",
      "Model Number: 192 with model ARDL in generation 1 of 3\n",
      "Model Number: 193 with model SectionalMotif in generation 1 of 3\n",
      "Template Eval Error: Exception('Transformer Detrend failed on fit') in model 193 in generation 1: SectionalMotif\n",
      "Model Number: 194 with model MultivariateMotif in generation 1 of 3\n",
      "Model Number: 195 with model Theta in generation 1 of 3\n",
      "Model Number: 196 with model GLS in generation 1 of 3\n",
      "Model Number: 197 with model ConstantNaive in generation 1 of 3\n",
      "Model Number: 198 with model SeasonalNaive in generation 1 of 3\n",
      "Model Number: 199 with model DatepartRegression in generation 1 of 3\n",
      "Model Number: 200 with model MultivariateRegression in generation 1 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\autots\\tools\\probabilistic.py:67: RuntimeWarning: invalid value encountered in divide\n",
      "  (prior_mu / prior_sigma**2) + ((n * data_mu) / prior_sigma**2)\n",
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\autots\\tools\\probabilistic.py:68: RuntimeWarning: divide by zero encountered in divide\n",
      "  ) / ((1 / prior_sigma**2) + (n / prior_sigma**2))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 201 with model MetricMotif in generation 1 of 3\n",
      "Template Eval Error: Exception('Transformer ScipyFilter failed on fit') in model 201 in generation 1: MetricMotif\n",
      "Model Number: 202 with model FBProphet in generation 1 of 3\n",
      "Template Eval Error: Exception('Transformer RegressionFilter failed on fit') in model 202 in generation 1: FBProphet\n",
      "Model Number: 203 with model FBProphet in generation 1 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "19:00:30 - cmdstanpy - INFO - Chain [1] start processing\n",
      "19:00:51 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 204 with model GLS in generation 1 of 3\n",
      "Model Number: 205 with model AverageValueNaive in generation 1 of 3\n",
      "Model Number: 206 with model DatepartRegression in generation 1 of 3\n",
      "Model Number: 207 with model MultivariateRegression in generation 1 of 3\n",
      "Template Eval Error: XGBoostError('[19:00:53] C:\\\\buildkite-agent\\\\builds\\\\buildkite-windows-cpu-autoscaling-group-i-0fdc6d574b9c0d168-1\\\\xgboost\\\\xgboost-ci-windows\\\\src\\\\objective\\\\regression_obj.cu:340: PoissonRegression: label must be nonnegative') in model 207 in generation 1: MultivariateRegression\n",
      "Model Number: 208 with model ETS in generation 1 of 3\n",
      "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
      "ETS failed on NET_SALES with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
      "Model Number: 209 with model SectionalMotif in generation 1 of 3\n",
      "Model Number: 210 with model ConstantNaive in generation 1 of 3\n",
      "Model Number: 211 with model WindowRegression in generation 1 of 3\n",
      "Model Number: 212 with model ARIMA in generation 1 of 3\n",
      "Model Number: 213 with model DatepartRegression in generation 1 of 3\n",
      "Template Eval Error: ImportError('Tensorflow not available, install with pip install tensorflow.') in model 213 in generation 1: DatepartRegression\n",
      "Model Number: 214 with model ETS in generation 1 of 3\n",
      "Model Number: 215 with model Theta in generation 1 of 3\n",
      "Model Number: 216 with model MetricMotif in generation 1 of 3\n",
      "Model Number: 217 with model UnobservedComponents in generation 1 of 3\n",
      "Model Number: 218 with model LastValueNaive in generation 1 of 3\n",
      "Model Number: 219 with model ETS in generation 1 of 3\n",
      "ETS error ValueError('Can only dampen the trend component')\n",
      "ETS failed on NET_SALES with ValueError('Can only dampen the trend component')\n",
      "Model Number: 220 with model MultivariateRegression in generation 1 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 221 with model SeasonalNaive in generation 1 of 3\n",
      "Model Number: 222 with model UnivariateRegression in generation 1 of 3\n",
      "Model Number: 223 with model GLS in generation 1 of 3\n",
      "Model Number: 224 with model MultivariateRegression in generation 1 of 3\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000042 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Model Number: 225 with model SectionalMotif in generation 1 of 3\n",
      "Model Number: 226 with model SectionalMotif in generation 1 of 3\n",
      "Model Number: 227 with model ETS in generation 1 of 3\n",
      "Model Number: 228 with model GLM in generation 1 of 3\n",
      "Model Number: 229 with model GLM in generation 1 of 3\n",
      "Model Number: 230 with model DatepartRegression in generation 1 of 3\n",
      "Template Eval Error: Exception('Transformer AlignLastValue failed on inverse') in model 230 in generation 1: DatepartRegression\n",
      "Model Number: 231 with model UnobservedComponents in generation 1 of 3\n",
      "Model Number: 232 with model SectionalMotif in generation 1 of 3\n",
      "Model Number: 233 with model MultivariateRegression in generation 1 of 3\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000036 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Model Number: 234 with model DatepartRegression in generation 1 of 3\n",
      "Template Eval Error: ValueError('Model DatepartRegression returned NaN for one or more series. fail_on_forecast_nan=True') in model 234 in generation 1: DatepartRegression\n",
      "Model Number: 235 with model UnivariateMotif in generation 1 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\decomposition\\_fastica.py:708: FutureWarning: Starting in v1.3, whiten=True should be specified as whiten='arbitrary-variance' (its current behaviour). This behavior is deprecated in 1.1 and will raise ValueError in 1.3.\n",
      "  return self._fit_transform(X, compute_sources=True)\n",
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\neighbors\\_regression.py:494: UserWarning: One or more samples have no neighbors within specified radius; predicting NaN.\n",
      "  warnings.warn(empty_warning_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 236 with model AverageValueNaive in generation 1 of 3\n",
      "Template Eval Error: Exception('Transformer AlignLastValue failed on inverse') in model 236 in generation 1: AverageValueNaive\n",
      "Model Number: 237 with model WindowRegression in generation 1 of 3\n",
      "Model Number: 238 with model ARIMA in generation 1 of 3\n",
      "Model Number: 239 with model GLM in generation 1 of 3\n",
      "Model Number: 240 with model UnobservedComponents in generation 1 of 3\n",
      "Model Number: 241 with model MetricMotif in generation 1 of 3\n",
      "Model Number: 242 with model MultivariateRegression in generation 1 of 3\n",
      "Model Number: 243 with model Theta in generation 1 of 3\n",
      "Model Number: 244 with model MultivariateMotif in generation 1 of 3\n",
      "Model Number: 245 with model VAR in generation 1 of 3\n",
      "Template Eval Error: ValueError('Only gave one variable to VAR') in model 245 in generation 1: VAR\n",
      "Model Number: 246 with model ETS in generation 1 of 3\n",
      "Template Eval Error: Exception('Transformer Detrend failed on fit') in model 246 in generation 1: ETS\n",
      "Model Number: 247 with model NVAR in generation 1 of 3\n",
      "Model Number: 248 with model ARDL in generation 1 of 3\n",
      "Model Number: 249 with model SectionalMotif in generation 1 of 3\n",
      "Model Number: 250 with model ARIMA in generation 1 of 3\n",
      "Model Number: 251 with model ETS in generation 1 of 3\n",
      "Model Number: 252 with model SeasonalNaive in generation 1 of 3\n",
      "Model Number: 253 with model ARDL in generation 1 of 3\n",
      "Model Number: 254 with model MultivariateRegression in generation 1 of 3\n",
      "Template Eval Error: XGBoostError('[19:00:57] C:\\\\buildkite-agent\\\\builds\\\\buildkite-windows-cpu-autoscaling-group-i-0fdc6d574b9c0d168-1\\\\xgboost\\\\xgboost-ci-windows\\\\src\\\\objective\\\\regression_obj.cu:340: PoissonRegression: label must be nonnegative') in model 254 in generation 1: MultivariateRegression\n",
      "Model Number: 255 with model GLM in generation 1 of 3\n",
      "Model Number: 256 with model SectionalMotif in generation 1 of 3\n",
      "Model Number: 257 with model LastValueNaive in generation 1 of 3\n",
      "Model Number: 258 with model LastValueNaive in generation 1 of 3\n",
      "Model Number: 259 with model Theta in generation 1 of 3\n",
      "Model Number: 260 with model WindowRegression in generation 1 of 3\n",
      "Model Number: 261 with model MultivariateMotif in generation 1 of 3\n",
      "Model Number: 262 with model SectionalMotif in generation 1 of 3\n",
      "Template Eval Error: ValueError('kth(=10) out of bounds (6)') in model 262 in generation 1: SectionalMotif\n",
      "Model Number: 263 with model DatepartRegression in generation 1 of 3\n",
      "Model Number: 264 with model ETS in generation 1 of 3\n",
      "Template Eval Error: Exception('Transformer Cointegration failed on fit') in model 264 in generation 1: ETS\n",
      "Model Number: 265 with model ConstantNaive in generation 1 of 3\n",
      "Model Number: 266 with model WindowRegression in generation 1 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\decomposition\\_fastica.py:583: UserWarning: Ignoring n_components with whiten=False.\n",
      "  warnings.warn(\"Ignoring n_components with whiten=False.\")\n",
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\decomposition\\_fastica.py:123: ConvergenceWarning: FastICA did not converge. Consider increasing tolerance or the maximum number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 267 with model Theta in generation 1 of 3\n",
      "Model Number: 268 with model NVAR in generation 1 of 3\n",
      "Model Number: 269 with model SectionalMotif in generation 1 of 3\n",
      "Model Number: 270 with model ARIMA in generation 1 of 3\n",
      "Model Number: 271 with model FBProphet in generation 1 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "19:00:59 - cmdstanpy - INFO - Chain [1] start processing\n",
      "19:00:59 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 272 with model AverageValueNaive in generation 1 of 3\n",
      "Model Number: 273 with model UnobservedComponents in generation 1 of 3\n",
      "Template Eval Error: Exception('Transformer Cointegration failed on fit') in model 273 in generation 1: UnobservedComponents\n",
      "Model Number: 274 with model SeasonalNaive in generation 1 of 3\n",
      "Model Number: 275 with model MultivariateMotif in generation 1 of 3\n",
      "Model Number: 276 with model UnivariateMotif in generation 1 of 3\n",
      "Model Number: 277 with model Theta in generation 1 of 3\n",
      "Model Number: 278 with model MultivariateRegression in generation 1 of 3\n",
      "Model Number: 279 with model LastValueNaive in generation 1 of 3\n",
      "Model Number: 280 with model WindowRegression in generation 1 of 3\n",
      "Model Number: 281 with model SeasonalNaive in generation 1 of 3\n",
      "Model Number: 282 with model DatepartRegression in generation 1 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 283 with model GLM in generation 1 of 3\n",
      "Model Number: 284 with model UnobservedComponents in generation 1 of 3\n",
      "Model Number: 285 with model UnivariateMotif in generation 1 of 3\n",
      "Model Number: 286 with model DatepartRegression in generation 1 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\linear_model\\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.48343e-24): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 287 with model SeasonalNaive in generation 1 of 3\n",
      "Model Number: 288 with model ETS in generation 1 of 3\n",
      "Template Eval Error: Exception('Transformer RegressionFilter failed on fit') in model 288 in generation 1: ETS\n",
      "Model Number: 289 with model ARDL in generation 1 of 3\n",
      "Model Number: 290 with model DatepartRegression in generation 1 of 3\n",
      "Model Number: 291 with model SectionalMotif in generation 1 of 3\n",
      "Model Number: 292 with model MultivariateMotif in generation 1 of 3\n",
      "Model Number: 293 with model LastValueNaive in generation 1 of 3\n",
      "Model Number: 294 with model ARDL in generation 1 of 3\n",
      "Model Number: 295 with model UnobservedComponents in generation 1 of 3\n",
      "Template Eval Error: LinAlgError('Singular matrix') in model 295 in generation 1: UnobservedComponents\n",
      "Model Number: 296 with model ETS in generation 1 of 3\n",
      "Model Number: 297 with model MetricMotif in generation 1 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\decomposition\\_fastica.py:583: UserWarning: Ignoring n_components with whiten=False.\n",
      "  warnings.warn(\"Ignoring n_components with whiten=False.\")\n",
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\decomposition\\_fastica.py:123: ConvergenceWarning: FastICA did not converge. Consider increasing tolerance or the maximum number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 298 with model SeasonalNaive in generation 1 of 3\n",
      "Template Eval Error: Exception('Transformer Detrend failed on fit') in model 298 in generation 1: SeasonalNaive\n",
      "Model Number: 299 with model GLS in generation 1 of 3\n",
      "Model Number: 300 with model DatepartRegression in generation 1 of 3\n",
      "Model Number: 301 with model SeasonalNaive in generation 1 of 3\n",
      "Model Number: 302 with model UnivariateRegression in generation 1 of 3\n",
      "Model Number: 303 with model DatepartRegression in generation 1 of 3\n",
      "Model Number: 304 with model ETS in generation 1 of 3\n",
      "Model Number: 305 with model GLS in generation 1 of 3\n",
      "Model Number: 306 with model ARIMA in generation 1 of 3\n",
      "Model Number: 307 with model MultivariateRegression in generation 1 of 3\n",
      "Model Number: 308 with model GLM in generation 1 of 3\n",
      "Model Number: 309 with model UnobservedComponents in generation 1 of 3\n",
      "Model Number: 310 with model FBProphet in generation 1 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\statsmodels\\genmod\\families\\links.py:198: RuntimeWarning: overflow encountered in exp\n",
      "  t = np.exp(-z)\n",
      "19:01:03 - cmdstanpy - INFO - Chain [1] start processing\n",
      "19:01:03 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 311 with model SectionalMotif in generation 1 of 3\n",
      "New Generation: 2 of 3\n",
      "Model Number: 312 with model GLS in generation 2 of 3\n",
      "Model Number: 313 with model SeasonalNaive in generation 2 of 3\n",
      "Model Number: 314 with model MultivariateRegression in generation 2 of 3\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000024 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Model Number: 315 with model MultivariateMotif in generation 2 of 3\n",
      "Model Number: 316 with model MetricMotif in generation 2 of 3\n",
      "Model Number: 317 with model ETS in generation 2 of 3\n",
      "Model Number: 318 with model ETS in generation 2 of 3\n",
      "Model Number: 319 with model GLM in generation 2 of 3\n",
      "Model Number: 320 with model ARDL in generation 2 of 3\n",
      "Template Eval Error: ValueError(\"ARDL series NET_SALES failed with error ValueError('The number of regressors (120) including deterministics, lags of the endog, lags of the exogenous, and fixed regressors is larger than the sample available for estimation (69).') exog train             weekend  quarter      epoch  month_1  month_2  month_3  month_4  \\\\\\nMONTH                                                                         \\n2016-01-01        0        1  2457388.5      1.0      0.0      0.0      0.0   \\n2016-02-01        0        1  2457419.5      0.0      1.0      0.0      0.0   \\n2016-03-01        0        1  2457448.5      0.0      0.0      1.0      0.0   \\n2016-04-01        0        2  2457479.5      0.0      0.0      0.0      1.0   \\n2016-05-01        1        2  2457509.5      0.0      0.0      0.0      0.0   \\n...             ...      ...        ...      ...      ...      ...      ...   \\n2021-08-01        1        3  2459427.5      0.0      0.0      0.0      0.0   \\n2021-09-01        0        3  2459458.5      0.0      0.0      0.0      0.0   \\n2021-10-01        0        4  2459488.5      0.0      0.0      0.0      0.0   \\n2021-11-01        0        4  2459519.5      0.0      0.0      0.0      0.0   \\n2021-12-01        0        4  2459549.5      0.0      0.0      0.0      0.0   \\n\\n            month_5  month_6  month_7  ...  day_27  day_28  day_29  day_30  \\\\\\nMONTH                                  ...                                   \\n2016-01-01      0.0      0.0      0.0  ...     0.0     0.0     0.0     0.0   \\n2016-02-01      0.0      0.0      0.0  ...     0.0     0.0     0.0     0.0   \\n2016-03-01      0.0      0.0      0.0  ...     0.0     0.0     0.0     0.0   \\n2016-04-01      0.0      0.0      0.0  ...     0.0     0.0     0.0     0.0   \\n2016-05-01      1.0      0.0      0.0  ...     0.0     0.0     0.0     0.0   \\n...             ...      ...      ...  ...     ...     ...     ...     ...   \\n2021-08-01      0.0      0.0      0.0  ...     0.0     0.0     0.0     0.0   \\n2021-09-01      0.0      0.0      0.0  ...     0.0     0.0     0.0     0.0   \\n2021-10-01      0.0      0.0      0.0  ...     0.0     0.0     0.0     0.0   \\n2021-11-01      0.0      0.0      0.0  ...     0.0     0.0     0.0     0.0   \\n2021-12-01      0.0      0.0      0.0  ...     0.0     0.0     0.0     0.0   \\n\\n            day_31  weekdayofmonth_1  weekdayofmonth_2  weekdayofmonth_3  \\\\\\nMONTH                                                                      \\n2016-01-01     0.0               1.0               0.0               0.0   \\n2016-02-01     0.0               1.0               0.0               0.0   \\n2016-03-01     0.0               1.0               0.0               0.0   \\n2016-04-01     0.0               1.0               0.0               0.0   \\n2016-05-01     0.0               1.0               0.0               0.0   \\n...            ...               ...               ...               ...   \\n2021-08-01     0.0               1.0               0.0               0.0   \\n2021-09-01     0.0               1.0               0.0               0.0   \\n2021-10-01     0.0               1.0               0.0               0.0   \\n2021-11-01     0.0               1.0               0.0               0.0   \\n2021-12-01     0.0               1.0               0.0               0.0   \\n\\n            weekdayofmonth_4  weekdayofmonth_5  \\nMONTH                                           \\n2016-01-01               0.0               0.0  \\n2016-02-01               0.0               0.0  \\n2016-03-01               0.0               0.0  \\n2016-04-01               0.0               0.0  \\n2016-05-01               0.0               0.0  \\n...                      ...               ...  \\n2021-08-01               0.0               0.0  \\n2021-09-01               0.0               0.0  \\n2021-10-01               0.0               0.0  \\n2021-11-01               0.0               0.0  \\n2021-12-01               0.0               0.0  \\n\\n[72 rows x 58 columns] and predict             weekend  quarter      epoch  month_1  month_2  month_3  month_4  \\\\\\n2022-01-01        1        1  2459580.5      1.0      0.0      0.0      0.0   \\n2022-02-01        0        1  2459611.5      0.0      1.0      0.0      0.0   \\n2022-03-01        0        1  2459639.5      0.0      0.0      1.0      0.0   \\n2022-04-01        0        2  2459670.5      0.0      0.0      0.0      1.0   \\n2022-05-01        1        2  2459700.5      0.0      0.0      0.0      0.0   \\n2022-06-01        0        2  2459731.5      0.0      0.0      0.0      0.0   \\n2022-07-01        0        3  2459761.5      0.0      0.0      0.0      0.0   \\n2022-08-01        0        3  2459792.5      0.0      0.0      0.0      0.0   \\n2022-09-01        0        3  2459823.5      0.0      0.0      0.0      0.0   \\n2022-10-01        1        4  2459853.5      0.0      0.0      0.0      0.0   \\n2022-11-01        0        4  2459884.5      0.0      0.0      0.0      0.0   \\n2022-12-01        0        4  2459914.5      0.0      0.0      0.0      0.0   \\n\\n            month_5  month_6  month_7  ...  day_27  day_28  day_29  day_30  \\\\\\n2022-01-01      0.0      0.0      0.0  ...     0.0     0.0     0.0     0.0   \\n2022-02-01      0.0      0.0      0.0  ...     0.0     0.0     0.0     0.0   \\n2022-03-01      0.0      0.0      0.0  ...     0.0     0.0     0.0     0.0   \\n2022-04-01      0.0      0.0      0.0  ...     0.0     0.0     0.0     0.0   \\n2022-05-01      1.0      0.0      0.0  ...     0.0     0.0     0.0     0.0   \\n2022-06-01      0.0      1.0      0.0  ...     0.0     0.0     0.0     0.0   \\n2022-07-01      0.0      0.0      1.0  ...     0.0     0.0     0.0     0.0   \\n2022-08-01      0.0      0.0      0.0  ...     0.0     0.0     0.0     0.0   \\n2022-09-01      0.0      0.0      0.0  ...     0.0     0.0     0.0     0.0   \\n2022-10-01      0.0      0.0      0.0  ...     0.0     0.0     0.0     0.0   \\n2022-11-01      0.0      0.0      0.0  ...     0.0     0.0     0.0     0.0   \\n2022-12-01      0.0      0.0      0.0  ...     0.0     0.0     0.0     0.0   \\n\\n            day_31  weekdayofmonth_1  weekdayofmonth_2  weekdayofmonth_3  \\\\\\n2022-01-01     0.0               1.0               0.0               0.0   \\n2022-02-01     0.0               1.0               0.0               0.0   \\n2022-03-01     0.0               1.0               0.0               0.0   \\n2022-04-01     0.0               1.0               0.0               0.0   \\n2022-05-01     0.0               1.0               0.0               0.0   \\n2022-06-01     0.0               1.0               0.0               0.0   \\n2022-07-01     0.0               1.0               0.0               0.0   \\n2022-08-01     0.0               1.0               0.0               0.0   \\n2022-09-01     0.0               1.0               0.0               0.0   \\n2022-10-01     0.0               1.0               0.0               0.0   \\n2022-11-01     0.0               1.0               0.0               0.0   \\n2022-12-01     0.0               1.0               0.0               0.0   \\n\\n            weekdayofmonth_4  weekdayofmonth_5  \\n2022-01-01               0.0               0.0  \\n2022-02-01               0.0               0.0  \\n2022-03-01               0.0               0.0  \\n2022-04-01               0.0               0.0  \\n2022-05-01               0.0               0.0  \\n2022-06-01               0.0               0.0  \\n2022-07-01               0.0               0.0  \\n2022-08-01               0.0               0.0  \\n2022-09-01               0.0               0.0  \\n2022-10-01               0.0               0.0  \\n2022-11-01               0.0               0.0  \\n2022-12-01               0.0               0.0  \\n\\n[12 rows x 58 columns]\") in model 320 in generation 2: ARDL\n",
      "Model Number: 321 with model ConstantNaive in generation 2 of 3\n",
      "Template Eval Error: Exception('Transformer Detrend failed on fit') in model 321 in generation 2: ConstantNaive\n",
      "Model Number: 322 with model ARDL in generation 2 of 3\n",
      "Model Number: 323 with model MetricMotif in generation 2 of 3\n",
      "Model Number: 324 with model MultivariateMotif in generation 2 of 3\n",
      "Template Eval Error: Exception('Transformer AlignLastValue failed on inverse') in model 324 in generation 2: MultivariateMotif\n",
      "Model Number: 325 with model GLM in generation 2 of 3\n",
      "Model Number: 326 with model MultivariateMotif in generation 2 of 3\n",
      "Model Number: 327 with model SectionalMotif in generation 2 of 3\n",
      "Model Number: 328 with model SectionalMotif in generation 2 of 3\n",
      "Model Number: 329 with model WindowRegression in generation 2 of 3\n",
      "Model Number: 330 with model GLS in generation 2 of 3\n",
      "Model Number: 331 with model UnobservedComponents in generation 2 of 3\n",
      "Model Number: 332 with model SeasonalNaive in generation 2 of 3\n",
      "Model Number: 333 with model AverageValueNaive in generation 2 of 3\n",
      "Model Number: 334 with model Theta in generation 2 of 3\n",
      "Model Number: 335 with model ETS in generation 2 of 3\n",
      "Model Number: 336 with model SectionalMotif in generation 2 of 3\n",
      "Model Number: 337 with model ETS in generation 2 of 3\n",
      "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
      "ETS failed on NET_SALES with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
      "Model Number: 338 with model ARIMA in generation 2 of 3\n",
      "Model Number: 339 with model GLS in generation 2 of 3\n",
      "Model Number: 340 with model MultivariateRegression in generation 2 of 3\n",
      "Model Number: 341 with model SectionalMotif in generation 2 of 3\n",
      "Model Number: 342 with model MultivariateRegression in generation 2 of 3\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000037 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "Model Number: 343 with model UnobservedComponents in generation 2 of 3\n",
      "Model Number: 344 with model ARIMA in generation 2 of 3\n",
      "Model Number: 345 with model GLS in generation 2 of 3\n",
      "Model Number: 346 with model MultivariateMotif in generation 2 of 3\n",
      "Model Number: 347 with model LastValueNaive in generation 2 of 3\n",
      "Template Eval Error: Exception('Transformer Detrend failed on fit') in model 347 in generation 2: LastValueNaive\n",
      "Model Number: 348 with model AverageValueNaive in generation 2 of 3\n",
      "Model Number: 349 with model ARDL in generation 2 of 3\n",
      "Model Number: 350 with model MetricMotif in generation 2 of 3\n",
      "Model Number: 351 with model GLS in generation 2 of 3\n",
      "Model Number: 352 with model MetricMotif in generation 2 of 3\n",
      "Model Number: 353 with model WindowRegression in generation 2 of 3\n",
      "Model Number: 354 with model MultivariateRegression in generation 2 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\linear_model\\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.48343e-24): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 355 with model AverageValueNaive in generation 2 of 3\n",
      "Model Number: 356 with model UnobservedComponents in generation 2 of 3\n",
      "Model Number: 357 with model GLM in generation 2 of 3\n",
      "Model Number: 358 with model UnivariateRegression in generation 2 of 3\n",
      "Model Number: 359 with model DatepartRegression in generation 2 of 3\n",
      "Model Number: 360 with model ETS in generation 2 of 3\n",
      "Model Number: 361 with model GLM in generation 2 of 3\n",
      "Model Number: 362 with model AverageValueNaive in generation 2 of 3\n",
      "Model Number: 363 with model Theta in generation 2 of 3\n",
      "Model Number: 364 with model UnivariateMotif in generation 2 of 3\n",
      "Model Number: 365 with model GLS in generation 2 of 3\n",
      "Model Number: 366 with model UnivariateMotif in generation 2 of 3\n",
      "Template Eval Error: Exception('Transformer BTCD failed on fit') in model 366 in generation 2: UnivariateMotif\n",
      "Model Number: 367 with model MultivariateMotif in generation 2 of 3\n",
      "Model Number: 368 with model DatepartRegression in generation 2 of 3\n",
      "Model Number: 369 with model SectionalMotif in generation 2 of 3\n",
      "Model Number: 370 with model NVAR in generation 2 of 3\n",
      "Model Number: 371 with model SectionalMotif in generation 2 of 3\n",
      "Model Number: 372 with model ETS in generation 2 of 3\n",
      "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
      "ETS failed on NET_SALES with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
      "Model Number: 373 with model SectionalMotif in generation 2 of 3\n",
      "Template Eval Error: Exception('Transformer AlignLastValue failed on inverse') in model 373 in generation 2: SectionalMotif\n",
      "Model Number: 374 with model SeasonalNaive in generation 2 of 3\n",
      "Model Number: 375 with model SeasonalNaive in generation 2 of 3\n",
      "Model Number: 376 with model ARDL in generation 2 of 3\n",
      "Model Number: 377 with model UnivariateMotif in generation 2 of 3\n",
      "Model Number: 378 with model WindowRegression in generation 2 of 3\n",
      "Model Number: 379 with model ARIMA in generation 2 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 380 with model LastValueNaive in generation 2 of 3\n",
      "Model Number: 381 with model GLM in generation 2 of 3\n",
      "Model Number: 382 with model MetricMotif in generation 2 of 3\n",
      "Model Number: 383 with model ETS in generation 2 of 3\n",
      "Model Number: 384 with model WindowRegression in generation 2 of 3\n",
      "Model Number: 385 with model WindowRegression in generation 2 of 3\n",
      "Model Number: 386 with model UnivariateMotif in generation 2 of 3\n",
      "Model Number: 387 with model ETS in generation 2 of 3\n",
      "Template Eval Error: Exception('Transformer RegressionFilter failed on fit') in model 387 in generation 2: ETS\n",
      "Model Number: 388 with model ARDL in generation 2 of 3\n",
      "Model Number: 389 with model ARDL in generation 2 of 3\n",
      "Model Number: 390 with model UnobservedComponents in generation 2 of 3\n",
      "Model Number: 391 with model Theta in generation 2 of 3\n",
      "Model Number: 392 with model SeasonalNaive in generation 2 of 3\n",
      "Model Number: 393 with model ARIMA in generation 2 of 3\n",
      "Model Number: 394 with model GLS in generation 2 of 3\n",
      "Model Number: 395 with model MultivariateRegression in generation 2 of 3\n",
      "Model Number: 396 with model Theta in generation 2 of 3\n",
      "Model Number: 397 with model WindowRegression in generation 2 of 3\n",
      "Model Number: 398 with model ARIMA in generation 2 of 3\n",
      "Model Number: 399 with model SeasonalNaive in generation 2 of 3\n",
      "Model Number: 400 with model GLS in generation 2 of 3\n",
      "Model Number: 401 with model ARIMA in generation 2 of 3\n",
      "Model Number: 402 with model ARDL in generation 2 of 3\n",
      "Model Number: 403 with model AverageValueNaive in generation 2 of 3\n",
      "Model Number: 404 with model UnobservedComponents in generation 2 of 3\n",
      "Template Eval Error: LinAlgError('Singular matrix') in model 404 in generation 2: UnobservedComponents\n",
      "Model Number: 405 with model SectionalMotif in generation 2 of 3\n",
      "Model Number: 406 with model LastValueNaive in generation 2 of 3\n",
      "Template Eval Error: Exception('Transformer Detrend failed on fit') in model 406 in generation 2: LastValueNaive\n",
      "Model Number: 407 with model MultivariateMotif in generation 2 of 3\n",
      "Model Number: 408 with model MultivariateRegression in generation 2 of 3\n",
      "Model Number: 409 with model MetricMotif in generation 2 of 3\n",
      "Model Number: 410 with model GLM in generation 2 of 3\n",
      "Model Number: 411 with model AverageValueNaive in generation 2 of 3\n",
      "Model Number: 412 with model ETS in generation 2 of 3\n",
      "Model Number: 413 with model LastValueNaive in generation 2 of 3\n",
      "Model Number: 414 with model SeasonalNaive in generation 2 of 3\n",
      "Model Number: 415 with model UnivariateMotif in generation 2 of 3\n",
      "Model Number: 416 with model MetricMotif in generation 2 of 3\n",
      "Model Number: 417 with model ConstantNaive in generation 2 of 3\n",
      "Model Number: 418 with model UnobservedComponents in generation 2 of 3\n",
      "Model Number: 419 with model ARIMA in generation 2 of 3\n",
      "Model Number: 420 with model GLM in generation 2 of 3\n",
      "Model Number: 421 with model ARIMA in generation 2 of 3\n",
      "Model Number: 422 with model WindowRegression in generation 2 of 3\n",
      "Model Number: 423 with model GLS in generation 2 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\decomposition\\_fastica.py:708: FutureWarning: Starting in v1.3, whiten=True should be specified as whiten='arbitrary-variance' (its current behaviour). This behavior is deprecated in 1.1 and will raise ValueError in 1.3.\n",
      "  return self._fit_transform(X, compute_sources=True)\n",
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\autots\\tools\\probabilistic.py:67: RuntimeWarning: invalid value encountered in divide\n",
      "  (prior_mu / prior_sigma**2) + ((n * data_mu) / prior_sigma**2)\n",
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\autots\\tools\\probabilistic.py:68: RuntimeWarning: divide by zero encountered in divide\n",
      "  ) / ((1 / prior_sigma**2) + (n / prior_sigma**2))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 424 with model WindowRegression in generation 2 of 3\n",
      "Model Number: 425 with model ARDL in generation 2 of 3\n",
      "Model Number: 426 with model DatepartRegression in generation 2 of 3\n",
      "Template Eval Error: ImportError('Tensorflow not available, install with pip install tensorflow.') in model 426 in generation 2: DatepartRegression\n",
      "Model Number: 427 with model MetricMotif in generation 2 of 3\n",
      "Model Number: 428 with model FBProphet in generation 2 of 3\n",
      "Template Eval Error: Exception('Transformer BTCD failed on fit') in model 428 in generation 2: FBProphet\n",
      "Model Number: 429 with model WindowRegression in generation 2 of 3\n",
      "Model Number: 430 with model MultivariateMotif in generation 2 of 3\n",
      "Model Number: 431 with model Theta in generation 2 of 3\n",
      "Model Number: 432 with model ETS in generation 2 of 3\n",
      "Template Eval Error: Exception('Transformer BTCD failed on fit') in model 432 in generation 2: ETS\n",
      "Model Number: 433 with model ARDL in generation 2 of 3\n",
      "Model Number: 434 with model Theta in generation 2 of 3\n",
      "Model Number: 435 with model ConstantNaive in generation 2 of 3\n",
      "Model Number: 436 with model MetricMotif in generation 2 of 3\n",
      "New Generation: 3 of 3\n",
      "Model Number: 437 with model MultivariateRegression in generation 3 of 3\n",
      "Model Number: 438 with model ARDL in generation 3 of 3\n",
      "Model Number: 439 with model SectionalMotif in generation 3 of 3\n",
      "Model Number: 440 with model SectionalMotif in generation 3 of 3\n",
      "Model Number: 441 with model ETS in generation 3 of 3\n",
      "Model Number: 442 with model ConstantNaive in generation 3 of 3\n",
      "Model Number: 443 with model MultivariateMotif in generation 3 of 3\n",
      "Model Number: 444 with model GLM in generation 3 of 3\n",
      "Template Eval Error: Exception('Transformer RegressionFilter failed on fit') in model 444 in generation 3: GLM\n",
      "Model Number: 445 with model GLM in generation 3 of 3\n",
      "Model Number: 446 with model ETS in generation 3 of 3\n",
      "ETS error ValueError('Can only dampen the trend component')\n",
      "ETS failed on NET_SALES with ValueError('Can only dampen the trend component')\n",
      "Model Number: 447 with model ARIMA in generation 3 of 3\n",
      "Template Eval Error: Exception('Transformer BTCD failed on fit') in model 447 in generation 3: ARIMA\n",
      "Model Number: 448 with model UnivariateRegression in generation 3 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\autots\\tools\\probabilistic.py:67: RuntimeWarning: invalid value encountered in divide\n",
      "  (prior_mu / prior_sigma**2) + ((n * data_mu) / prior_sigma**2)\n",
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\autots\\tools\\probabilistic.py:68: RuntimeWarning: divide by zero encountered in divide\n",
      "  ) / ((1 / prior_sigma**2) + (n / prior_sigma**2))\n",
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\statsmodels\\genmod\\families\\family.py:1367: ValueWarning: Negative binomial dispersion parameter alpha not set. Using default value alpha=1.0.\n",
      "  warnings.warn(\"Negative binomial dispersion parameter alpha not \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 449 with model MultivariateMotif in generation 3 of 3\n",
      "Model Number: 450 with model ARIMA in generation 3 of 3\n",
      "Model Number: 451 with model SeasonalNaive in generation 3 of 3\n",
      "Model Number: 452 with model UnivariateMotif in generation 3 of 3\n",
      "Model Number: 453 with model GLS in generation 3 of 3\n",
      "Model Number: 454 with model GLM in generation 3 of 3\n",
      "Model Number: 455 with model SeasonalNaive in generation 3 of 3\n",
      "Model Number: 456 with model ARIMA in generation 3 of 3\n",
      "Model Number: 457 with model UnobservedComponents in generation 3 of 3\n",
      "Model Number: 458 with model SectionalMotif in generation 3 of 3\n",
      "Model Number: 459 with model UnivariateRegression in generation 3 of 3\n",
      "Model Number: 460 with model NVAR in generation 3 of 3\n",
      "Model Number: 461 with model ARDL in generation 3 of 3\n",
      "Model Number: 462 with model ConstantNaive in generation 3 of 3\n",
      "Model Number: 463 with model ARIMA in generation 3 of 3\n",
      "Model Number: 464 with model DatepartRegression in generation 3 of 3\n",
      "Model Number: 465 with model Theta in generation 3 of 3\n",
      "Model Number: 466 with model MultivariateRegression in generation 3 of 3\n",
      "Model Number: 467 with model MetricMotif in generation 3 of 3\n",
      "Template Eval Error: Exception('Transformer AlignLastValue failed on inverse') in model 467 in generation 3: MetricMotif\n",
      "Model Number: 468 with model Theta in generation 3 of 3\n",
      "Model Number: 469 with model ETS in generation 3 of 3\n",
      "Model Number: 470 with model SeasonalNaive in generation 3 of 3\n",
      "Model Number: 471 with model Theta in generation 3 of 3\n",
      "Model Number: 472 with model UnobservedComponents in generation 3 of 3\n",
      "Model Number: 473 with model ETS in generation 3 of 3\n",
      "Model Number: 474 with model DatepartRegression in generation 3 of 3\n",
      "Model Number: 475 with model MultivariateRegression in generation 3 of 3\n",
      "Model Number: 476 with model DatepartRegression in generation 3 of 3\n",
      "Model Number: 477 with model SectionalMotif in generation 3 of 3\n",
      "Model Number: 478 with model DatepartRegression in generation 3 of 3\n",
      "Model Number: 479 with model UnobservedComponents in generation 3 of 3\n",
      "Model Number: 480 with model UnivariateMotif in generation 3 of 3\n",
      "Model Number: 481 with model SeasonalNaive in generation 3 of 3\n",
      "Model Number: 482 with model SeasonalNaive in generation 3 of 3\n",
      "Model Number: 483 with model MultivariateRegression in generation 3 of 3\n",
      "Model Number: 484 with model Theta in generation 3 of 3\n",
      "Model Number: 485 with model UnobservedComponents in generation 3 of 3\n",
      "Model Number: 486 with model UnivariateMotif in generation 3 of 3\n",
      "Model Number: 487 with model UnobservedComponents in generation 3 of 3\n",
      "Model Number: 488 with model MultivariateRegression in generation 3 of 3\n",
      "Model Number: 489 with model UnobservedComponents in generation 3 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "19:01:31 - cmdstanpy - INFO - Chain [1] start processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 490 with model FBProphet in generation 3 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "19:01:31 - cmdstanpy - INFO - Chain [1] done processing\n",
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\statsmodels\\genmod\\families\\family.py:445: RuntimeWarning: divide by zero encountered in divide\n",
      "  endog_mu = self._clean(endog / mu)\n",
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\statsmodels\\genmod\\families\\family.py:143: RuntimeWarning: divide by zero encountered in divide\n",
      "  return 1. / (self.link.deriv(mu)**2 * self.variance(mu))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 491 with model GLM in generation 3 of 3\n",
      "Template Eval Error: ValueError('NaN, inf or invalid value detected in weights, estimation infeasible.') in model 491 in generation 3: GLM\n",
      "Model Number: 492 with model MultivariateRegression in generation 3 of 3\n",
      "Model Number: 493 with model SectionalMotif in generation 3 of 3\n",
      "Model Number: 494 with model GLM in generation 3 of 3\n",
      "Model Number: 495 with model WindowRegression in generation 3 of 3\n",
      "Model Number: 496 with model GLS in generation 3 of 3\n",
      "Model Number: 497 with model GLM in generation 3 of 3\n",
      "Model Number: 498 with model MetricMotif in generation 3 of 3\n",
      "Model Number: 499 with model SectionalMotif in generation 3 of 3\n",
      "Model Number: 500 with model DatepartRegression in generation 3 of 3\n",
      "Model Number: 501 with model MetricMotif in generation 3 of 3\n",
      "Model Number: 502 with model VAR in generation 3 of 3\n",
      "Template Eval Error: ValueError('Only gave one variable to VAR') in model 502 in generation 3: VAR\n",
      "Model Number: 503 with model LastValueNaive in generation 3 of 3\n",
      "Model Number: 504 with model ARDL in generation 3 of 3\n",
      "Model Number: 505 with model MultivariateRegression in generation 3 of 3\n",
      "Template Eval Error: XGBoostError('[19:01:33] C:\\\\buildkite-agent\\\\builds\\\\buildkite-windows-cpu-autoscaling-group-i-0fdc6d574b9c0d168-1\\\\xgboost\\\\xgboost-ci-windows\\\\src\\\\objective\\\\regression_obj.cu:340: PoissonRegression: label must be nonnegative') in model 505 in generation 3: MultivariateRegression\n",
      "Model Number: 506 with model DatepartRegression in generation 3 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\decomposition\\_fastica.py:708: FutureWarning: Starting in v1.3, whiten=True should be specified as whiten='arbitrary-variance' (its current behaviour). This behavior is deprecated in 1.1 and will raise ValueError in 1.3.\n",
      "  return self._fit_transform(X, compute_sources=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 507 with model SeasonalNaive in generation 3 of 3\n",
      "Template Eval Error: Exception('Transformer Cointegration failed on fit') in model 507 in generation 3: SeasonalNaive\n",
      "Model Number: 508 with model ETS in generation 3 of 3\n",
      "Model Number: 509 with model AverageValueNaive in generation 3 of 3\n",
      "Model Number: 510 with model MultivariateRegression in generation 3 of 3\n",
      "Model Number: 511 with model UnobservedComponents in generation 3 of 3\n",
      "Model Number: 512 with model Theta in generation 3 of 3\n",
      "Model Number: 513 with model DatepartRegression in generation 3 of 3\n",
      "Model Number: 514 with model Theta in generation 3 of 3\n",
      "Model Number: 515 with model MultivariateMotif in generation 3 of 3\n",
      "Model Number: 516 with model ARDL in generation 3 of 3\n",
      "Model Number: 517 with model ARIMA in generation 3 of 3\n",
      "Model Number: 518 with model SeasonalNaive in generation 3 of 3\n",
      "Model Number: 519 with model SectionalMotif in generation 3 of 3\n",
      "Model Number: 520 with model WindowRegression in generation 3 of 3\n",
      "Model Number: 521 with model GLS in generation 3 of 3\n",
      "Model Number: 522 with model ETS in generation 3 of 3\n",
      "Model Number: 523 with model ARIMA in generation 3 of 3\n",
      "Model Number: 524 with model ETS in generation 3 of 3\n",
      "ETS error ValueError('Can only dampen the trend component')\n",
      "ETS failed on NET_SALES with ValueError('Can only dampen the trend component')\n",
      "Model Number: 525 with model ARIMA in generation 3 of 3\n",
      "Model Number: 526 with model SectionalMotif in generation 3 of 3\n",
      "Model Number: 527 with model SeasonalNaive in generation 3 of 3\n",
      "Template Eval Error: Exception('Transformer Cointegration failed on fit') in model 527 in generation 3: SeasonalNaive\n",
      "Model Number: 528 with model ARDL in generation 3 of 3\n",
      "Model Number: 529 with model MetricMotif in generation 3 of 3\n",
      "Model Number: 530 with model MultivariateRegression in generation 3 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 531 with model ETS in generation 3 of 3\n",
      "Model Number: 532 with model MetricMotif in generation 3 of 3\n",
      "Model Number: 533 with model ETS in generation 3 of 3\n",
      "Model Number: 534 with model SeasonalNaive in generation 3 of 3\n",
      "Model Number: 535 with model SectionalMotif in generation 3 of 3\n",
      "Model Number: 536 with model SectionalMotif in generation 3 of 3\n",
      "Model Number: 537 with model WindowRegression in generation 3 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 538 with model NVAR in generation 3 of 3\n",
      "Model Number: 539 with model Theta in generation 3 of 3\n",
      "Model Number: 540 with model WindowRegression in generation 3 of 3\n",
      "Model Number: 541 with model ARDL in generation 3 of 3\n",
      "Model Number: 542 with model AverageValueNaive in generation 3 of 3\n",
      "Model Number: 543 with model UnivariateMotif in generation 3 of 3\n",
      "Model Number: 544 with model MultivariateRegression in generation 3 of 3\n",
      "Model Number: 545 with model MultivariateRegression in generation 3 of 3\n",
      "Model Number: 546 with model ETS in generation 3 of 3\n",
      "Model Number: 547 with model DatepartRegression in generation 3 of 3\n",
      "Model Number: 548 with model MultivariateMotif in generation 3 of 3\n",
      "Model Number: 549 with model LastValueNaive in generation 3 of 3\n",
      "Model Number: 550 with model WindowRegression in generation 3 of 3\n",
      "Model Number: 551 with model GLS in generation 3 of 3\n",
      "Model Number: 552 with model WindowRegression in generation 3 of 3\n",
      "Model Number: 553 with model MetricMotif in generation 3 of 3\n",
      "Model Number: 554 with model SeasonalNaive in generation 3 of 3\n",
      "Model Number: 555 with model DatepartRegression in generation 3 of 3\n",
      "Model Number: 556 with model SeasonalNaive in generation 3 of 3\n",
      "Model Number: 557 with model UnobservedComponents in generation 3 of 3\n",
      "Model Number: 558 with model ETS in generation 3 of 3\n",
      "Model Number: 559 with model WindowRegression in generation 3 of 3\n",
      "Model Number: 560 with model GLM in generation 3 of 3\n",
      "Model Number: 561 with model WindowRegression in generation 3 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\statsmodels\\genmod\\families\\family.py:1367: ValueWarning: Negative binomial dispersion parameter alpha not set. Using default value alpha=1.0.\n",
      "  warnings.warn(\"Negative binomial dispersion parameter alpha not \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TotalRuntime missing in 4!\n",
      "Validation Round: 1\n",
      "Model Number: 1 of 84 with model DatepartRegression for Validation 1\n",
      "📈 1 - DatepartRegression with avg smape 36.45: \n",
      "Model Number: 2 of 84 with model ARDL for Validation 1\n",
      "📈 2 - ARDL with avg smape 28.37: \n",
      "Model Number: 3 of 84 with model DatepartRegression for Validation 1\n",
      "3 - DatepartRegression with avg smape 32.33: \n",
      "Model Number: 4 of 84 with model DatepartRegression for Validation 1\n",
      "4 - DatepartRegression with avg smape 42.53: \n",
      "Model Number: 5 of 84 with model SeasonalNaive for Validation 1\n",
      "📈 5 - SeasonalNaive with avg smape 19.25: \n",
      "Model Number: 6 of 84 with model WindowRegression for Validation 1\n",
      "6 - WindowRegression with avg smape 63.02: \n",
      "Model Number: 7 of 84 with model DatepartRegression for Validation 1\n",
      "7 - DatepartRegression with avg smape 54.65: \n",
      "Model Number: 8 of 84 with model WindowRegression for Validation 1\n",
      "8 - WindowRegression with avg smape 26.2: \n",
      "Model Number: 9 of 84 with model ARIMA for Validation 1\n",
      "9 - ARIMA with avg smape 109.73: \n",
      "Model Number: 10 of 84 with model DatepartRegression for Validation 1\n",
      "10 - DatepartRegression with avg smape 39.06: \n",
      "Model Number: 11 of 84 with model ARIMA for Validation 1\n",
      "11 - ARIMA with avg smape 109.03: \n",
      "Model Number: 12 of 84 with model ARIMA for Validation 1\n",
      "12 - ARIMA with avg smape 113.19: \n",
      "Model Number: 13 of 84 with model ARIMA for Validation 1\n",
      "13 - ARIMA with avg smape 113.19: \n",
      "Model Number: 14 of 84 with model MetricMotif for Validation 1\n",
      "14 - MetricMotif with avg smape 48.54: \n",
      "Model Number: 15 of 84 with model ARIMA for Validation 1\n",
      "15 - ARIMA with avg smape 80.31: \n",
      "Model Number: 16 of 84 with model ETS for Validation 1\n",
      "16 - ETS with avg smape 19.85: \n",
      "Model Number: 17 of 84 with model MultivariateRegression for Validation 1\n",
      "17 - MultivariateRegression with avg smape 26.75: \n",
      "Model Number: 18 of 84 with model ARDL for Validation 1\n",
      "18 - ARDL with avg smape 21.55: \n",
      "Model Number: 19 of 84 with model ARDL for Validation 1\n",
      "19 - ARDL with avg smape 26.9: \n",
      "Model Number: 20 of 84 with model ARDL for Validation 1\n",
      "20 - ARDL with avg smape 20.77: \n",
      "Model Number: 21 of 84 with model Theta for Validation 1\n",
      "21 - Theta with avg smape 23.9: \n",
      "Model Number: 22 of 84 with model SectionalMotif for Validation 1\n",
      "22 - SectionalMotif with avg smape 29.93: \n",
      "Model Number: 23 of 84 with model ARDL for Validation 1\n",
      "23 - ARDL with avg smape 20.45: \n",
      "Model Number: 24 of 84 with model MultivariateRegression for Validation 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24 - MultivariateRegression with avg smape 23.3: \n",
      "Model Number: 25 of 84 with model MetricMotif for Validation 1\n",
      "25 - MetricMotif with avg smape 23.31: \n",
      "Model Number: 26 of 84 with model ETS for Validation 1\n",
      "26 - ETS with avg smape 38.95: \n",
      "Model Number: 27 of 84 with model ETS for Validation 1\n",
      "27 - ETS with avg smape 38.96: \n",
      "Model Number: 28 of 84 with model SeasonalNaive for Validation 1\n",
      "28 - SeasonalNaive with avg smape 38.85: \n",
      "Model Number: 29 of 84 with model MultivariateRegression for Validation 1\n",
      "29 - MultivariateRegression with avg smape 20.56: \n",
      "Model Number: 30 of 84 with model SeasonalNaive for Validation 1\n",
      "30 - SeasonalNaive with avg smape 35.79: \n",
      "Model Number: 31 of 84 with model MetricMotif for Validation 1\n",
      "31 - MetricMotif with avg smape 22.62: \n",
      "Model Number: 32 of 84 with model ETS for Validation 1\n",
      "32 - ETS with avg smape 36.56: \n",
      "Model Number: 33 of 84 with model MultivariateRegression for Validation 1\n",
      "33 - MultivariateRegression with avg smape 47.12: \n",
      "Model Number: 34 of 84 with model SeasonalNaive for Validation 1\n",
      "34 - SeasonalNaive with avg smape 31.34: \n",
      "Model Number: 35 of 84 with model SectionalMotif for Validation 1\n",
      "35 - SectionalMotif with avg smape 25.51: \n",
      "Model Number: 36 of 84 with model MultivariateRegression for Validation 1\n",
      "36 - MultivariateRegression with avg smape 60.89: \n",
      "Model Number: 37 of 84 with model GLS for Validation 1\n",
      "37 - GLS with avg smape 22.71: \n",
      "Model Number: 38 of 84 with model UnobservedComponents for Validation 1\n",
      "38 - UnobservedComponents with avg smape 42.57: \n",
      "Model Number: 39 of 84 with model ETS for Validation 1\n",
      "ETS error ValueError('Can only dampen the trend component')\n",
      "ETS failed on NET_SALES with ValueError('Can only dampen the trend component')\n",
      "39 - ETS with avg smape 42.57: \n",
      "Model Number: 40 of 84 with model SeasonalNaive for Validation 1\n",
      "40 - SeasonalNaive with avg smape 39.79: \n",
      "Model Number: 41 of 84 with model UnobservedComponents for Validation 1\n",
      "41 - UnobservedComponents with avg smape 48.8: \n",
      "Model Number: 42 of 84 with model GLS for Validation 1\n",
      "42 - GLS with avg smape 22.74: \n",
      "Model Number: 43 of 84 with model MetricMotif for Validation 1\n",
      "43 - MetricMotif with avg smape 45.97: \n",
      "Model Number: 44 of 84 with model MetricMotif for Validation 1\n",
      "44 - MetricMotif with avg smape 38.45: \n",
      "Model Number: 45 of 84 with model UnobservedComponents for Validation 1\n",
      "45 - UnobservedComponents with avg smape 42.57: \n",
      "Model Number: 46 of 84 with model GLS for Validation 1\n",
      "46 - GLS with avg smape 21.81: \n",
      "Model Number: 47 of 84 with model GLM for Validation 1\n",
      "47 - GLM with avg smape 23.99: \n",
      "Model Number: 48 of 84 with model GLM for Validation 1\n",
      "48 - GLM with avg smape 23.87: \n",
      "Model Number: 49 of 84 with model GLM for Validation 1\n",
      "49 - GLM with avg smape 23.39: \n",
      "Model Number: 50 of 84 with model GLM for Validation 1\n",
      "50 - GLM with avg smape 23.39: \n",
      "Model Number: 51 of 84 with model GLM for Validation 1\n",
      "51 - GLM with avg smape 21.96: \n",
      "Model Number: 52 of 84 with model GLS for Validation 1\n",
      "52 - GLS with avg smape 21.52: \n",
      "Model Number: 53 of 84 with model WindowRegression for Validation 1\n",
      "53 - WindowRegression with avg smape 27.05: \n",
      "Model Number: 54 of 84 with model UnobservedComponents for Validation 1\n",
      "54 - UnobservedComponents with avg smape 52.88: \n",
      "Model Number: 55 of 84 with model SectionalMotif for Validation 1\n",
      "55 - SectionalMotif with avg smape 21.78: \n",
      "Model Number: 56 of 84 with model GLS for Validation 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\statsmodels\\genmod\\families\\family.py:1367: ValueWarning: Negative binomial dispersion parameter alpha not set. Using default value alpha=1.0.\n",
      "  warnings.warn(\"Negative binomial dispersion parameter alpha not \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56 - GLS with avg smape 21.16: \n",
      "Model Number: 57 of 84 with model SectionalMotif for Validation 1\n",
      "57 - SectionalMotif with avg smape 21.49: \n",
      "Model Number: 58 of 84 with model WindowRegression for Validation 1\n",
      "58 - WindowRegression with avg smape 52.65: \n",
      "Model Number: 59 of 84 with model WindowRegression for Validation 1\n",
      "59 - WindowRegression with avg smape 53.28: \n",
      "Model Number: 60 of 84 with model MultivariateMotif for Validation 1\n",
      "60 - MultivariateMotif with avg smape 23.39: \n",
      "Model Number: 61 of 84 with model SectionalMotif for Validation 1\n",
      "61 - SectionalMotif with avg smape 22.73: \n",
      "Model Number: 62 of 84 with model UnivariateMotif for Validation 1\n",
      "62 - UnivariateMotif with avg smape 29.96: \n",
      "Model Number: 63 of 84 with model UnivariateMotif for Validation 1\n",
      "63 - UnivariateMotif with avg smape 24.09: \n",
      "Model Number: 64 of 84 with model AverageValueNaive for Validation 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64 - AverageValueNaive with avg smape 25.69: \n",
      "Model Number: 65 of 84 with model UnobservedComponents for Validation 1\n",
      "65 - UnobservedComponents with avg smape 45.64: \n",
      "Model Number: 66 of 84 with model MultivariateMotif for Validation 1\n",
      "66 - MultivariateMotif with avg smape 24.28: \n",
      "Model Number: 67 of 84 with model Theta for Validation 1\n",
      "67 - Theta with avg smape 32.05: \n",
      "Model Number: 68 of 84 with model AverageValueNaive for Validation 1\n",
      "68 - AverageValueNaive with avg smape 25.2: \n",
      "Model Number: 69 of 84 with model MultivariateMotif for Validation 1\n",
      "69 - MultivariateMotif with avg smape 27.91: \n",
      "Model Number: 70 of 84 with model AverageValueNaive for Validation 1\n",
      "70 - AverageValueNaive with avg smape 21.05: \n",
      "Model Number: 71 of 84 with model AverageValueNaive for Validation 1\n",
      "71 - AverageValueNaive with avg smape 20.72: \n",
      "Model Number: 72 of 84 with model LastValueNaive for Validation 1\n",
      "72 - LastValueNaive with avg smape 108.78: \n",
      "Model Number: 73 of 84 with model MultivariateMotif for Validation 1\n",
      "73 - MultivariateMotif with avg smape 26.0: \n",
      "Model Number: 74 of 84 with model Theta for Validation 1\n",
      "74 - Theta with avg smape 28.71: \n",
      "Model Number: 75 of 84 with model Theta for Validation 1\n",
      "75 - Theta with avg smape 28.62: \n",
      "Model Number: 76 of 84 with model UnivariateMotif for Validation 1\n",
      "76 - UnivariateMotif with avg smape 77.92: \n",
      "Model Number: 77 of 84 with model AverageValueNaive for Validation 1\n",
      "77 - AverageValueNaive with avg smape 21.96: \n",
      "Model Number: 78 of 84 with model LastValueNaive for Validation 1\n",
      "78 - LastValueNaive with avg smape 108.78: \n",
      "Model Number: 79 of 84 with model LastValueNaive for Validation 1\n",
      "79 - LastValueNaive with avg smape 108.78: \n",
      "Model Number: 80 of 84 with model Theta for Validation 1\n",
      "80 - Theta with avg smape 32.65: \n",
      "Model Number: 81 of 84 with model MultivariateMotif for Validation 1\n",
      "81 - MultivariateMotif with avg smape 22.11: \n",
      "Model Number: 82 of 84 with model LastValueNaive for Validation 1\n",
      "82 - LastValueNaive with avg smape 108.77: \n",
      "Model Number: 83 of 84 with model UnivariateMotif for Validation 1\n",
      "83 - UnivariateMotif with avg smape 22.82: \n",
      "Model Number: 84 of 84 with model UnivariateMotif for Validation 1\n",
      "84 - UnivariateMotif with avg smape 24.99: \n",
      "Validation Round: 2\n",
      "Model Number: 1 of 84 with model DatepartRegression for Validation 2\n",
      "📈 1 - DatepartRegression with avg smape 45.85: \n",
      "Model Number: 2 of 84 with model ARDL for Validation 2\n",
      "📈 2 - ARDL with avg smape 43.07: \n",
      "Model Number: 3 of 84 with model DatepartRegression for Validation 2\n",
      "3 - DatepartRegression with avg smape 45.58: \n",
      "Model Number: 4 of 84 with model DatepartRegression for Validation 2\n",
      "4 - DatepartRegression with avg smape 46.07: \n",
      "Model Number: 5 of 84 with model SeasonalNaive for Validation 2\n",
      "📈 5 - SeasonalNaive with avg smape 30.03: \n",
      "Model Number: 6 of 84 with model WindowRegression for Validation 2\n",
      "6 - WindowRegression with avg smape 50.06: \n",
      "Model Number: 7 of 84 with model DatepartRegression for Validation 2\n",
      "7 - DatepartRegression with avg smape 57.0: \n",
      "Model Number: 8 of 84 with model WindowRegression for Validation 2\n",
      "8 - WindowRegression with avg smape 45.95: \n",
      "Model Number: 9 of 84 with model ARIMA for Validation 2\n",
      "9 - ARIMA with avg smape 39.26: \n",
      "Model Number: 10 of 84 with model DatepartRegression for Validation 2\n",
      "10 - DatepartRegression with avg smape 44.73: \n",
      "Model Number: 11 of 84 with model ARIMA for Validation 2\n",
      "11 - ARIMA with avg smape 41.92: \n",
      "Model Number: 12 of 84 with model ARIMA for Validation 2\n",
      "12 - ARIMA with avg smape 42.08: \n",
      "Model Number: 13 of 84 with model ARIMA for Validation 2\n",
      "13 - ARIMA with avg smape 42.08: \n",
      "Model Number: 14 of 84 with model MetricMotif for Validation 2\n",
      "14 - MetricMotif with avg smape 46.22: \n",
      "Model Number: 15 of 84 with model ARIMA for Validation 2\n",
      "15 - ARIMA with avg smape 31.78: \n",
      "Model Number: 16 of 84 with model ETS for Validation 2\n",
      "16 - ETS with avg smape 32.81: \n",
      "Model Number: 17 of 84 with model MultivariateRegression for Validation 2\n",
      "17 - MultivariateRegression with avg smape 52.11: \n",
      "Model Number: 18 of 84 with model ARDL for Validation 2\n",
      "18 - ARDL with avg smape 53.95: \n",
      "Model Number: 19 of 84 with model ARDL for Validation 2\n",
      "19 - ARDL with avg smape 58.1: \n",
      "Model Number: 20 of 84 with model ARDL for Validation 2\n",
      "20 - ARDL with avg smape 43.09: \n",
      "Model Number: 21 of 84 with model Theta for Validation 2\n",
      "21 - Theta with avg smape 37.39: \n",
      "Model Number: 22 of 84 with model SectionalMotif for Validation 2\n",
      "📈 22 - SectionalMotif with avg smape 24.37: \n",
      "Model Number: 23 of 84 with model ARDL for Validation 2\n",
      "23 - ARDL with avg smape 44.42: \n",
      "Model Number: 24 of 84 with model MultivariateRegression for Validation 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24 - MultivariateRegression with avg smape 55.06: \n",
      "Model Number: 25 of 84 with model MetricMotif for Validation 2\n",
      "25 - MetricMotif with avg smape 39.11: \n",
      "Model Number: 26 of 84 with model ETS for Validation 2\n",
      "26 - ETS with avg smape 45.27: \n",
      "Model Number: 27 of 84 with model ETS for Validation 2\n",
      "27 - ETS with avg smape 45.28: \n",
      "Model Number: 28 of 84 with model SeasonalNaive for Validation 2\n",
      "28 - SeasonalNaive with avg smape 46.76: \n",
      "Model Number: 29 of 84 with model MultivariateRegression for Validation 2\n",
      "29 - MultivariateRegression with avg smape 58.76: \n",
      "Model Number: 30 of 84 with model SeasonalNaive for Validation 2\n",
      "30 - SeasonalNaive with avg smape 43.63: \n",
      "Model Number: 31 of 84 with model MetricMotif for Validation 2\n",
      "31 - MetricMotif with avg smape 45.86: \n",
      "Model Number: 32 of 84 with model ETS for Validation 2\n",
      "32 - ETS with avg smape 45.63: \n",
      "Model Number: 33 of 84 with model MultivariateRegression for Validation 2\n",
      "33 - MultivariateRegression with avg smape 47.07: \n",
      "Model Number: 34 of 84 with model SeasonalNaive for Validation 2\n",
      "34 - SeasonalNaive with avg smape 33.14: \n",
      "Model Number: 35 of 84 with model SectionalMotif for Validation 2\n",
      "35 - SectionalMotif with avg smape 54.54: \n",
      "Model Number: 36 of 84 with model MultivariateRegression for Validation 2\n",
      "36 - MultivariateRegression with avg smape 54.16: \n",
      "Model Number: 37 of 84 with model GLS for Validation 2\n",
      "37 - GLS with avg smape 48.26: \n",
      "Model Number: 38 of 84 with model UnobservedComponents for Validation 2\n",
      "38 - UnobservedComponents with avg smape 44.98: \n",
      "Model Number: 39 of 84 with model ETS for Validation 2\n",
      "ETS error ValueError('Can only dampen the trend component')\n",
      "ETS failed on NET_SALES with ValueError('Can only dampen the trend component')\n",
      "39 - ETS with avg smape 44.98: \n",
      "Model Number: 40 of 84 with model SeasonalNaive for Validation 2\n",
      "40 - SeasonalNaive with avg smape 39.45: \n",
      "Model Number: 41 of 84 with model UnobservedComponents for Validation 2\n",
      "41 - UnobservedComponents with avg smape 48.84: \n",
      "Model Number: 42 of 84 with model GLS for Validation 2\n",
      "42 - GLS with avg smape 48.93: \n",
      "Model Number: 43 of 84 with model MetricMotif for Validation 2\n",
      "43 - MetricMotif with avg smape 46.5: \n",
      "Model Number: 44 of 84 with model MetricMotif for Validation 2\n",
      "44 - MetricMotif with avg smape 58.3: \n",
      "Model Number: 45 of 84 with model UnobservedComponents for Validation 2\n",
      "45 - UnobservedComponents with avg smape 44.98: \n",
      "Model Number: 46 of 84 with model GLS for Validation 2\n",
      "46 - GLS with avg smape 44.76: \n",
      "Model Number: 47 of 84 with model GLM for Validation 2\n",
      "47 - GLM with avg smape 56.32: \n",
      "Model Number: 48 of 84 with model GLM for Validation 2\n",
      "48 - GLM with avg smape 56.96: \n",
      "Model Number: 49 of 84 with model GLM for Validation 2\n",
      "49 - GLM with avg smape 60.43: \n",
      "Model Number: 50 of 84 with model GLM for Validation 2\n",
      "50 - GLM with avg smape 60.43: \n",
      "Model Number: 51 of 84 with model GLM for Validation 2\n",
      "51 - GLM with avg smape 58.37: \n",
      "Model Number: 52 of 84 with model GLS for Validation 2\n",
      "52 - GLS with avg smape 44.76: \n",
      "Model Number: 53 of 84 with model WindowRegression for Validation 2\n",
      "53 - WindowRegression with avg smape 63.41: \n",
      "Model Number: 54 of 84 with model UnobservedComponents for Validation 2\n",
      "54 - UnobservedComponents with avg smape 46.73: \n",
      "Model Number: 55 of 84 with model SectionalMotif for Validation 2\n",
      "55 - SectionalMotif with avg smape 49.79: \n",
      "Model Number: 56 of 84 with model GLS for Validation 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\statsmodels\\genmod\\families\\family.py:1367: ValueWarning: Negative binomial dispersion parameter alpha not set. Using default value alpha=1.0.\n",
      "  warnings.warn(\"Negative binomial dispersion parameter alpha not \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56 - GLS with avg smape 41.94: \n",
      "Model Number: 57 of 84 with model SectionalMotif for Validation 2\n",
      "57 - SectionalMotif with avg smape 47.79: \n",
      "Model Number: 58 of 84 with model WindowRegression for Validation 2\n",
      "58 - WindowRegression with avg smape 42.83: \n",
      "Model Number: 59 of 84 with model WindowRegression for Validation 2\n",
      "59 - WindowRegression with avg smape 42.83: \n",
      "Model Number: 60 of 84 with model MultivariateMotif for Validation 2\n",
      "60 - MultivariateMotif with avg smape 48.43: \n",
      "Model Number: 61 of 84 with model SectionalMotif for Validation 2\n",
      "61 - SectionalMotif with avg smape 44.35: \n",
      "Model Number: 62 of 84 with model UnivariateMotif for Validation 2\n",
      "62 - UnivariateMotif with avg smape 47.17: \n",
      "Model Number: 63 of 84 with model UnivariateMotif for Validation 2\n",
      "63 - UnivariateMotif with avg smape 51.71: \n",
      "Model Number: 64 of 84 with model AverageValueNaive for Validation 2\n",
      "64 - AverageValueNaive with avg smape 47.66: \n",
      "Model Number: 65 of 84 with model UnobservedComponents for Validation 2\n",
      "65 - UnobservedComponents with avg smape 49.81: \n",
      "Model Number: 66 of 84 with model MultivariateMotif for Validation 2\n",
      "66 - MultivariateMotif with avg smape 45.9: \n",
      "Model Number: 67 of 84 with model Theta for Validation 2\n",
      "67 - Theta with avg smape 68.2: \n",
      "Model Number: 68 of 84 with model AverageValueNaive for Validation 2\n",
      "68 - AverageValueNaive with avg smape 47.46: \n",
      "Model Number: 69 of 84 with model MultivariateMotif for Validation 2\n",
      "69 - MultivariateMotif with avg smape 54.21: \n",
      "Model Number: 70 of 84 with model AverageValueNaive for Validation 2\n",
      "70 - AverageValueNaive with avg smape 38.86: \n",
      "Model Number: 71 of 84 with model AverageValueNaive for Validation 2\n",
      "71 - AverageValueNaive with avg smape 52.66: \n",
      "Model Number: 72 of 84 with model LastValueNaive for Validation 2\n",
      "72 - LastValueNaive with avg smape 29.62: \n",
      "Model Number: 73 of 84 with model MultivariateMotif for Validation 2\n",
      "73 - MultivariateMotif with avg smape 53.36: \n",
      "Model Number: 74 of 84 with model Theta for Validation 2\n",
      "74 - Theta with avg smape 60.11: \n",
      "Model Number: 75 of 84 with model Theta for Validation 2\n",
      "75 - Theta with avg smape 50.49: \n",
      "Model Number: 76 of 84 with model UnivariateMotif for Validation 2\n",
      "76 - UnivariateMotif with avg smape 50.37: \n",
      "Model Number: 77 of 84 with model AverageValueNaive for Validation 2\n",
      "77 - AverageValueNaive with avg smape 40.14: \n",
      "Model Number: 78 of 84 with model LastValueNaive for Validation 2\n",
      "78 - LastValueNaive with avg smape 29.62: \n",
      "Model Number: 79 of 84 with model LastValueNaive for Validation 2\n",
      "79 - LastValueNaive with avg smape 29.62: \n",
      "Model Number: 80 of 84 with model Theta for Validation 2\n",
      "80 - Theta with avg smape 52.03: \n",
      "Model Number: 81 of 84 with model MultivariateMotif for Validation 2\n",
      "81 - MultivariateMotif with avg smape 47.48: \n",
      "Model Number: 82 of 84 with model LastValueNaive for Validation 2\n",
      "82 - LastValueNaive with avg smape 29.65: \n",
      "Model Number: 83 of 84 with model UnivariateMotif for Validation 2\n",
      "83 - UnivariateMotif with avg smape 43.59: \n",
      "Model Number: 84 of 84 with model UnivariateMotif for Validation 2\n",
      "84 - UnivariateMotif with avg smape 43.65: \n",
      "Validation Round: 3\n",
      "Model Number: 1 of 84 with model DatepartRegression for Validation 3\n",
      "📈 1 - DatepartRegression with avg smape 10.25: \n",
      "Model Number: 2 of 84 with model ARDL for Validation 3\n",
      "2 - ARDL with avg smape 33.84: \n",
      "Model Number: 3 of 84 with model DatepartRegression for Validation 3\n",
      "3 - DatepartRegression with avg smape 10.29: \n",
      "Model Number: 4 of 84 with model DatepartRegression for Validation 3\n",
      "4 - DatepartRegression with avg smape 11.84: \n",
      "Model Number: 5 of 84 with model SeasonalNaive for Validation 3\n",
      "5 - SeasonalNaive with avg smape 14.05: \n",
      "Model Number: 6 of 84 with model WindowRegression for Validation 3\n",
      "6 - WindowRegression with avg smape 30.38: \n",
      "Model Number: 7 of 84 with model DatepartRegression for Validation 3\n",
      "7 - DatepartRegression with avg smape 20.72: \n",
      "Model Number: 8 of 84 with model WindowRegression for Validation 3\n",
      "8 - WindowRegression with avg smape 18.29: \n",
      "Model Number: 9 of 84 with model ARIMA for Validation 3\n",
      "9 - ARIMA with avg smape 17.42: \n",
      "Model Number: 10 of 84 with model DatepartRegression for Validation 3\n",
      "Template Eval Error: Exception('Transformer RegressionFilter failed on fit') in model 10 in generation 0: DatepartRegression\n",
      "Model Number: 11 of 84 with model ARIMA for Validation 3\n",
      "📈 11 - ARIMA with avg smape 8.77: \n",
      "Model Number: 12 of 84 with model ARIMA for Validation 3\n",
      "📈 12 - ARIMA with avg smape 8.32: \n",
      "Model Number: 13 of 84 with model ARIMA for Validation 3\n",
      "13 - ARIMA with avg smape 8.32: \n",
      "Model Number: 14 of 84 with model MetricMotif for Validation 3\n",
      "14 - MetricMotif with avg smape 23.92: \n",
      "Model Number: 15 of 84 with model ARIMA for Validation 3\n",
      "15 - ARIMA with avg smape 13.0: \n",
      "Model Number: 16 of 84 with model ETS for Validation 3\n",
      "16 - ETS with avg smape 10.89: \n",
      "Model Number: 17 of 84 with model MultivariateRegression for Validation 3\n",
      "17 - MultivariateRegression with avg smape 13.08: \n",
      "Model Number: 18 of 84 with model ARDL for Validation 3\n",
      "Template Eval Error: Exception('Transformer RegressionFilter failed on fit') in model 18 in generation 0: ARDL\n",
      "Model Number: 19 of 84 with model ARDL for Validation 3\n",
      "Template Eval Error: Exception('Transformer RegressionFilter failed on fit') in model 19 in generation 0: ARDL\n",
      "Model Number: 20 of 84 with model ARDL for Validation 3\n",
      "20 - ARDL with avg smape 12.06: \n",
      "Model Number: 21 of 84 with model Theta for Validation 3\n",
      "21 - Theta with avg smape 13.16: \n",
      "Model Number: 22 of 84 with model SectionalMotif for Validation 3\n",
      "Template Eval Error: Exception('Transformer RegressionFilter failed on fit') in model 22 in generation 0: SectionalMotif\n",
      "Model Number: 23 of 84 with model ARDL for Validation 3\n",
      "Template Eval Error: Exception('Transformer RegressionFilter failed on fit') in model 23 in generation 0: ARDL\n",
      "Model Number: 24 of 84 with model MultivariateRegression for Validation 3\n",
      "Template Eval Error: Exception('Transformer Detrend failed on fit') in model 24 in generation 0: MultivariateRegression\n",
      "Model Number: 25 of 84 with model MetricMotif for Validation 3\n",
      "25 - MetricMotif with avg smape 13.98: \n",
      "Model Number: 26 of 84 with model ETS for Validation 3\n",
      "26 - ETS with avg smape 8.44: \n",
      "Model Number: 27 of 84 with model ETS for Validation 3\n",
      "27 - ETS with avg smape 8.45: \n",
      "Model Number: 28 of 84 with model SeasonalNaive for Validation 3\n",
      "28 - SeasonalNaive with avg smape 9.86: \n",
      "Model Number: 29 of 84 with model MultivariateRegression for Validation 3\n",
      "29 - MultivariateRegression with avg smape 15.33: \n",
      "Model Number: 30 of 84 with model SeasonalNaive for Validation 3\n",
      "30 - SeasonalNaive with avg smape 14.21: \n",
      "Model Number: 31 of 84 with model MetricMotif for Validation 3\n",
      "31 - MetricMotif with avg smape 17.5: \n",
      "Model Number: 32 of 84 with model ETS for Validation 3\n",
      "📈 32 - ETS with avg smape 8.18: \n",
      "Model Number: 33 of 84 with model MultivariateRegression for Validation 3\n",
      "33 - MultivariateRegression with avg smape 19.46: \n",
      "Model Number: 34 of 84 with model SeasonalNaive for Validation 3\n",
      "34 - SeasonalNaive with avg smape 16.13: \n",
      "Model Number: 35 of 84 with model SectionalMotif for Validation 3\n",
      "35 - SectionalMotif with avg smape 15.3: \n",
      "Model Number: 36 of 84 with model MultivariateRegression for Validation 3\n",
      "36 - MultivariateRegression with avg smape 25.81: \n",
      "Model Number: 37 of 84 with model GLS for Validation 3\n",
      "37 - GLS with avg smape 9.59: \n",
      "Model Number: 38 of 84 with model UnobservedComponents for Validation 3\n",
      "38 - UnobservedComponents with avg smape 16.3: \n",
      "Model Number: 39 of 84 with model ETS for Validation 3\n",
      "ETS error ValueError('Can only dampen the trend component')\n",
      "ETS failed on NET_SALES with ValueError('Can only dampen the trend component')\n",
      "39 - ETS with avg smape 16.3: \n",
      "Model Number: 40 of 84 with model SeasonalNaive for Validation 3\n",
      "40 - SeasonalNaive with avg smape 11.59: \n",
      "Model Number: 41 of 84 with model UnobservedComponents for Validation 3\n",
      "41 - UnobservedComponents with avg smape 20.79: \n",
      "Model Number: 42 of 84 with model GLS for Validation 3\n",
      "42 - GLS with avg smape 9.67: \n",
      "Model Number: 43 of 84 with model MetricMotif for Validation 3\n",
      "43 - MetricMotif with avg smape 22.17: \n",
      "Model Number: 44 of 84 with model MetricMotif for Validation 3\n",
      "44 - MetricMotif with avg smape 23.9: \n",
      "Model Number: 45 of 84 with model UnobservedComponents for Validation 3\n",
      "45 - UnobservedComponents with avg smape 16.3: \n",
      "Model Number: 46 of 84 with model GLS for Validation 3\n",
      "46 - GLS with avg smape 10.57: \n",
      "Model Number: 47 of 84 with model GLM for Validation 3\n",
      "47 - GLM with avg smape 14.09: \n",
      "Model Number: 48 of 84 with model GLM for Validation 3\n",
      "48 - GLM with avg smape 15.23: \n",
      "Model Number: 49 of 84 with model GLM for Validation 3\n",
      "49 - GLM with avg smape 27.79: \n",
      "Model Number: 50 of 84 with model GLM for Validation 3\n",
      "50 - GLM with avg smape 27.79: \n",
      "Model Number: 51 of 84 with model GLM for Validation 3\n",
      "51 - GLM with avg smape 20.64: \n",
      "Model Number: 52 of 84 with model GLS for Validation 3\n",
      "52 - GLS with avg smape 10.25: \n",
      "Model Number: 53 of 84 with model WindowRegression for Validation 3\n",
      "53 - WindowRegression with avg smape 39.42: \n",
      "Model Number: 54 of 84 with model UnobservedComponents for Validation 3\n",
      "54 - UnobservedComponents with avg smape 19.29: \n",
      "Model Number: 55 of 84 with model SectionalMotif for Validation 3\n",
      "55 - SectionalMotif with avg smape 25.45: \n",
      "Model Number: 56 of 84 with model GLS for Validation 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\statsmodels\\genmod\\families\\family.py:1367: ValueWarning: Negative binomial dispersion parameter alpha not set. Using default value alpha=1.0.\n",
      "  warnings.warn(\"Negative binomial dispersion parameter alpha not \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56 - GLS with avg smape 11.12: \n",
      "Model Number: 57 of 84 with model SectionalMotif for Validation 3\n",
      "57 - SectionalMotif with avg smape 20.32: \n",
      "Model Number: 58 of 84 with model WindowRegression for Validation 3\n",
      "58 - WindowRegression with avg smape 40.54: \n",
      "Model Number: 59 of 84 with model WindowRegression for Validation 3\n",
      "59 - WindowRegression with avg smape 40.54: \n",
      "Model Number: 60 of 84 with model MultivariateMotif for Validation 3\n",
      "60 - MultivariateMotif with avg smape 15.61: \n",
      "Model Number: 61 of 84 with model SectionalMotif for Validation 3\n",
      "61 - SectionalMotif with avg smape 17.72: \n",
      "Model Number: 62 of 84 with model UnivariateMotif for Validation 3\n",
      "62 - UnivariateMotif with avg smape 19.74: \n",
      "Model Number: 63 of 84 with model UnivariateMotif for Validation 3\n",
      "63 - UnivariateMotif with avg smape 19.53: \n",
      "Model Number: 64 of 84 with model AverageValueNaive for Validation 3\n",
      "64 - AverageValueNaive with avg smape 8.47: \n",
      "Model Number: 65 of 84 with model UnobservedComponents for Validation 3\n",
      "65 - UnobservedComponents with avg smape 14.86: \n",
      "Model Number: 66 of 84 with model MultivariateMotif for Validation 3\n",
      "Template Eval Error: Exception('Transformer RegressionFilter failed on fit') in model 66 in generation 0: MultivariateMotif\n",
      "Model Number: 67 of 84 with model Theta for Validation 3\n",
      "67 - Theta with avg smape 9.51: \n",
      "Model Number: 68 of 84 with model AverageValueNaive for Validation 3\n",
      "68 - AverageValueNaive with avg smape 9.18: \n",
      "Model Number: 69 of 84 with model MultivariateMotif for Validation 3\n",
      "69 - MultivariateMotif with avg smape 28.97: \n",
      "Model Number: 70 of 84 with model AverageValueNaive for Validation 3\n",
      "70 - AverageValueNaive with avg smape 11.84: \n",
      "Model Number: 71 of 84 with model AverageValueNaive for Validation 3\n",
      "71 - AverageValueNaive with avg smape 9.88: \n",
      "Model Number: 72 of 84 with model LastValueNaive for Validation 3\n",
      "72 - LastValueNaive with avg smape 11.61: \n",
      "Model Number: 73 of 84 with model MultivariateMotif for Validation 3\n",
      "73 - MultivariateMotif with avg smape 11.94: \n",
      "Model Number: 74 of 84 with model Theta for Validation 3\n",
      "74 - Theta with avg smape 14.63: \n",
      "Model Number: 75 of 84 with model Theta for Validation 3\n",
      "75 - Theta with avg smape 11.09: \n",
      "Model Number: 76 of 84 with model UnivariateMotif for Validation 3\n",
      "Template Eval Error: Exception('Transformer RegressionFilter failed on fit') in model 76 in generation 0: UnivariateMotif\n",
      "Model Number: 77 of 84 with model AverageValueNaive for Validation 3\n",
      "77 - AverageValueNaive with avg smape 12.81: \n",
      "Model Number: 78 of 84 with model LastValueNaive for Validation 3\n",
      "78 - LastValueNaive with avg smape 11.61: \n",
      "Model Number: 79 of 84 with model LastValueNaive for Validation 3\n",
      "79 - LastValueNaive with avg smape 11.61: \n",
      "Model Number: 80 of 84 with model Theta for Validation 3\n",
      "80 - Theta with avg smape 12.7: \n",
      "Model Number: 81 of 84 with model MultivariateMotif for Validation 3\n",
      "Template Eval Error: ValueError('window shape cannot be larger than input array shape') in model 81 in generation 0: MultivariateMotif\n",
      "Model Number: 82 of 84 with model LastValueNaive for Validation 3\n",
      "82 - LastValueNaive with avg smape 11.51: \n",
      "Model Number: 83 of 84 with model UnivariateMotif for Validation 3\n",
      "83 - UnivariateMotif with avg smape 16.62: \n",
      "Model Number: 84 of 84 with model UnivariateMotif for Validation 3\n",
      "Template Eval Error: Exception('Transformer RegressionFilter failed on fit') in model 84 in generation 0: UnivariateMotif\n",
      "TotalRuntime missing in 5!\n",
      "Validation Round: 1\n",
      "TotalRuntime missing in 0!\n",
      "Validation Round: 2\n",
      "TotalRuntime missing in 0!\n",
      "Validation Round: 3\n",
      "TotalRuntime missing in 0!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\crudek\\AppData\\Local\\Temp\\ipykernel_11000\\1533679110.py:63: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  all_predictions = all_predictions.append(temp_fcasts_ni)\n",
      " 14%|█▍        | 2/14 [05:04<30:39, 153.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 6 cpus for n_jobs.\n",
      "Data frequency is: MS, used frequency is: MS\n",
      "Model Number: 1 with model ARIMA in generation 0 of 3\n",
      "Model Number: 2 with model AverageValueNaive in generation 0 of 3\n",
      "Model Number: 3 with model AverageValueNaive in generation 0 of 3\n",
      "Model Number: 4 with model AverageValueNaive in generation 0 of 3\n",
      "Model Number: 5 with model DatepartRegression in generation 0 of 3\n",
      "Model Number: 6 with model DatepartRegression in generation 0 of 3\n",
      "Model Number: 7 with model DatepartRegression in generation 0 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 8 with model DatepartRegression in generation 0 of 3\n",
      "Template Eval Error: ImportError('Tensorflow not available, install with pip install tensorflow.') in model 8 in generation 0: DatepartRegression\n",
      "Model Number: 9 with model ETS in generation 0 of 3\n",
      "Model Number: 10 with model ETS in generation 0 of 3\n",
      "Model Number: 11 with model GLM in generation 0 of 3\n",
      "Model Number: 12 with model GLM in generation 0 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:541: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 13 with model GLS in generation 0 of 3\n",
      "Model Number: 14 with model GLS in generation 0 of 3\n",
      "Model Number: 15 with model GluonTS in generation 0 of 3\n",
      "Template Eval Error: ImportError('GluonTS installation is incompatible with AutoTS. The numpy version is sometimes the issue, try 1.23.1 {as of 06-2023}') in model 15 in generation 0: GluonTS\n",
      "Model Number: 16 with model GluonTS in generation 0 of 3\n",
      "Template Eval Error: ImportError('GluonTS installation is incompatible with AutoTS. The numpy version is sometimes the issue, try 1.23.1 {as of 06-2023}') in model 16 in generation 0: GluonTS\n",
      "Model Number: 17 with model GluonTS in generation 0 of 3\n",
      "Template Eval Error: ImportError('GluonTS installation is incompatible with AutoTS. The numpy version is sometimes the issue, try 1.23.1 {as of 06-2023}') in model 17 in generation 0: GluonTS\n",
      "Model Number: 18 with model GluonTS in generation 0 of 3\n",
      "Template Eval Error: ImportError('GluonTS installation is incompatible with AutoTS. The numpy version is sometimes the issue, try 1.23.1 {as of 06-2023}') in model 18 in generation 0: GluonTS\n",
      "Model Number: 19 with model GluonTS in generation 0 of 3\n",
      "Template Eval Error: ImportError('GluonTS installation is incompatible with AutoTS. The numpy version is sometimes the issue, try 1.23.1 {as of 06-2023}') in model 19 in generation 0: GluonTS\n",
      "Model Number: 20 with model LastValueNaive in generation 0 of 3\n",
      "Model Number: 21 with model LastValueNaive in generation 0 of 3\n",
      "Model Number: 22 with model LastValueNaive in generation 0 of 3\n",
      "Model Number: 23 with model LastValueNaive in generation 0 of 3\n",
      "Model Number: 24 with model SeasonalNaive in generation 0 of 3\n",
      "Model Number: 25 with model SeasonalNaive in generation 0 of 3\n",
      "Model Number: 26 with model SeasonalNaive in generation 0 of 3\n",
      "Model Number: 27 with model UnobservedComponents in generation 0 of 3\n",
      "Model Number: 28 with model UnobservedComponents in generation 0 of 3\n",
      "Model Number: 29 with model UnobservedComponents in generation 0 of 3\n",
      "Model Number: 30 with model VAR in generation 0 of 3\n",
      "Template Eval Error: ValueError('Only gave one variable to VAR') in model 30 in generation 0: VAR\n",
      "Model Number: 31 with model VAR in generation 0 of 3\n",
      "Template Eval Error: ValueError('Only gave one variable to VAR') in model 31 in generation 0: VAR\n",
      "Model Number: 32 with model VECM in generation 0 of 3\n",
      "Template Eval Error: ValueError('Only gave one variable to VECM') in model 32 in generation 0: VECM\n",
      "Model Number: 33 with model VECM in generation 0 of 3\n",
      "Template Eval Error: ValueError('Only gave one variable to VECM') in model 33 in generation 0: VECM\n",
      "Model Number: 34 with model WindowRegression in generation 0 of 3\n",
      "Model Number: 35 with model ConstantNaive in generation 0 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "19:02:33 - cmdstanpy - INFO - Chain [1] start processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 36 with model FBProphet in generation 0 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "19:02:33 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 37 with model GluonTS in generation 0 of 3\n",
      "Template Eval Error: ImportError('GluonTS installation is incompatible with AutoTS. The numpy version is sometimes the issue, try 1.23.1 {as of 06-2023}') in model 37 in generation 0: GluonTS\n",
      "Model Number: 38 with model MultivariateRegression in generation 0 of 3\n",
      "Model Number: 39 with model MultivariateRegression in generation 0 of 3\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000030 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Model Number: 40 with model DatepartRegression in generation 0 of 3\n",
      "Model Number: 41 with model SeasonalNaive in generation 0 of 3\n",
      "Model Number: 42 with model DatepartRegression in generation 0 of 3\n",
      "Model Number: 43 with model UnobservedComponents in generation 0 of 3\n",
      "Model Number: 44 with model UnobservedComponents in generation 0 of 3\n",
      "Model Number: 45 with model ETS in generation 0 of 3\n",
      "Model Number: 46 with model VECM in generation 0 of 3\n",
      "Template Eval Error: ValueError('Only gave one variable to VECM') in model 46 in generation 0: VECM\n",
      "Model Number: 47 with model ARDL in generation 0 of 3\n",
      "Model Number: 48 with model MultivariateMotif in generation 0 of 3\n",
      "Model Number: 49 with model MultivariateMotif in generation 0 of 3\n",
      "Model Number: 50 with model UnivariateMotif in generation 0 of 3\n",
      "Template Eval Error: ValueError('kth(=10) out of bounds (1)') in model 50 in generation 0: UnivariateMotif\n",
      "Model Number: 51 with model UnivariateMotif in generation 0 of 3\n",
      "Model Number: 52 with model SectionalMotif in generation 0 of 3\n",
      "Model Number: 53 with model SectionalMotif in generation 0 of 3\n",
      "Model Number: 54 with model MultivariateRegression in generation 0 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "19:02:36 - cmdstanpy - INFO - Chain [1] start processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 55 with model FBProphet in generation 0 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "19:02:57 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 56 with model SeasonalNaive in generation 0 of 3\n",
      "Model Number: 57 with model DatepartRegression in generation 0 of 3\n",
      "Model Number: 58 with model NVAR in generation 0 of 3\n",
      "Model Number: 59 with model Theta in generation 0 of 3\n",
      "Model Number: 60 with model UnivariateRegression in generation 0 of 3\n",
      "Template Eval Error: ValueError('Input X contains NaN.\\nDecisionTreeRegressor does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values') in model 60 in generation 0: UnivariateRegression\n",
      "Model Number: 61 with model ARCH in generation 0 of 3\n",
      "Template Eval Error: ImportError('`arch` package must be installed from pip') in model 61 in generation 0: ARCH\n",
      "Model Number: 62 with model ConstantNaive in generation 0 of 3\n",
      "Model Number: 63 with model LastValueNaive in generation 0 of 3\n",
      "Model Number: 64 with model AverageValueNaive in generation 0 of 3\n",
      "Model Number: 65 with model GLS in generation 0 of 3\n",
      "Model Number: 66 with model SeasonalNaive in generation 0 of 3\n",
      "Model Number: 67 with model GLM in generation 0 of 3\n",
      "Template Eval Error: ValueError('The first guess on the deviance function returned a nan.  This could be a boundary  problem and should be reported.') in model 67 in generation 0: GLM\n",
      "Model Number: 68 with model ETS in generation 0 of 3\n",
      "Model Number: 69 with model FBProphet in generation 0 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\statsmodels\\genmod\\families\\family.py:1367: ValueWarning: Negative binomial dispersion parameter alpha not set. Using default value alpha=1.0.\n",
      "  warnings.warn(\"Negative binomial dispersion parameter alpha not \"\n",
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\statsmodels\\genmod\\families\\family.py:1406: RuntimeWarning: invalid value encountered in log\n",
      "  resid_dev -= endog_alpha * np.log(endog_alpha / mu_alpha)\n",
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.394e+12, tolerance: 1.997e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "19:02:58 - cmdstanpy - INFO - Chain [1] start processing\n",
      "19:02:59 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 70 with model GluonTS in generation 0 of 3\n",
      "Template Eval Error: ImportError('GluonTS installation is incompatible with AutoTS. The numpy version is sometimes the issue, try 1.23.1 {as of 06-2023}') in model 70 in generation 0: GluonTS\n",
      "Model Number: 71 with model UnobservedComponents in generation 0 of 3\n",
      "Model Number: 72 with model VAR in generation 0 of 3\n",
      "Template Eval Error: ValueError('Only gave one variable to VAR') in model 72 in generation 0: VAR\n",
      "Model Number: 73 with model VECM in generation 0 of 3\n",
      "Template Eval Error: ValueError('Only gave one variable to VECM') in model 73 in generation 0: VECM\n",
      "Model Number: 74 with model ARIMA in generation 0 of 3\n",
      "Model Number: 75 with model WindowRegression in generation 0 of 3\n",
      "Model Number: 76 with model DatepartRegression in generation 0 of 3\n",
      "Model Number: 77 with model UnivariateRegression in generation 0 of 3\n",
      "Model Number: 78 with model MultivariateRegression in generation 0 of 3\n",
      "Model Number: 79 with model UnivariateMotif in generation 0 of 3\n",
      "Model Number: 80 with model MultivariateMotif in generation 0 of 3\n",
      "Template Eval Error: ValueError('kth(=100) out of bounds (51)') in model 80 in generation 0: MultivariateMotif\n",
      "Model Number: 81 with model SectionalMotif in generation 0 of 3\n",
      "Template Eval Error: ValueError(\"Model returned NaN due to a preprocessing transformer {'fillna': 'rolling_mean', 'transformations': {'0': 'SeasonalDifference', '1': 'AlignLastValue', '2': 'AlignLastValue', '3': 'EWMAFilter'}, 'transformation_params': {'0': {'lag_1': 7, 'method': 'LastValue'}, '1': {'rows': 1, 'lag': 1, 'method': 'multiplicative', 'strength': 1.0, 'first_value_only': False}, '2': {'rows': 1, 'lag': 1, 'method': 'additive', 'strength': 1.0, 'first_value_only': False}, '3': {'span': 12}}}. fail_on_forecast_nan=True\") in model 81 in generation 0: SectionalMotif\n",
      "Model Number: 82 with model NVAR in generation 0 of 3\n",
      "Model Number: 83 with model Theta in generation 0 of 3\n",
      "Model Number: 84 with model ARDL in generation 0 of 3\n",
      "Model Number: 85 with model ARCH in generation 0 of 3\n",
      "Template Eval Error: ImportError('`arch` package must be installed from pip') in model 85 in generation 0: ARCH\n",
      "Model Number: 86 with model MetricMotif in generation 0 of 3\n",
      "Model Number: 87 with model AverageValueNaive in generation 0 of 3\n",
      "Model Number: 88 with model UnobservedComponents in generation 0 of 3\n",
      "Model Number: 89 with model AverageValueNaive in generation 0 of 3\n",
      "Model Number: 90 with model LastValueNaive in generation 0 of 3\n",
      "Model Number: 91 with model ARDL in generation 0 of 3\n",
      "Model Number: 92 with model WindowRegression in generation 0 of 3\n",
      "Model Number: 93 with model ConstantNaive in generation 0 of 3\n",
      "Model Number: 94 with model SeasonalNaive in generation 0 of 3\n",
      "Model Number: 95 with model ARDL in generation 0 of 3\n",
      "Template Eval Error: ValueError(\"ARDL series NET_SALES failed with error ValueError('The number of regressors (178) including deterministics, lags of the endog, lags of the exogenous, and fixed regressors is larger than the sample available for estimation (69).') exog train             weekend  quarter      epoch  month_1  month_2  month_3  month_4  \\\\\\nMONTH                                                                         \\n2016-01-01        0        1  2457388.5      1.0      0.0      0.0      0.0   \\n2016-02-01        0        1  2457419.5      0.0      1.0      0.0      0.0   \\n2016-03-01        0        1  2457448.5      0.0      0.0      1.0      0.0   \\n2016-04-01        0        2  2457479.5      0.0      0.0      0.0      1.0   \\n2016-05-01        1        2  2457509.5      0.0      0.0      0.0      0.0   \\n...             ...      ...        ...      ...      ...      ...      ...   \\n2021-08-01        1        3  2459427.5      0.0      0.0      0.0      0.0   \\n2021-09-01        0        3  2459458.5      0.0      0.0      0.0      0.0   \\n2021-10-01        0        4  2459488.5      0.0      0.0      0.0      0.0   \\n2021-11-01        0        4  2459519.5      0.0      0.0      0.0      0.0   \\n2021-12-01        0        4  2459549.5      0.0      0.0      0.0      0.0   \\n\\n            month_5  month_6  month_7  ...  day_27  day_28  day_29  day_30  \\\\\\nMONTH                                  ...                                   \\n2016-01-01      0.0      0.0      0.0  ...     0.0     0.0     0.0     0.0   \\n2016-02-01      0.0      0.0      0.0  ...     0.0     0.0     0.0     0.0   \\n2016-03-01      0.0      0.0      0.0  ...     0.0     0.0     0.0     0.0   \\n2016-04-01      0.0      0.0      0.0  ...     0.0     0.0     0.0     0.0   \\n2016-05-01      1.0      0.0      0.0  ...     0.0     0.0     0.0     0.0   \\n...             ...      ...      ...  ...     ...     ...     ...     ...   \\n2021-08-01      0.0      0.0      0.0  ...     0.0     0.0     0.0     0.0   \\n2021-09-01      0.0      0.0      0.0  ...     0.0     0.0     0.0     0.0   \\n2021-10-01      0.0      0.0      0.0  ...     0.0     0.0     0.0     0.0   \\n2021-11-01      0.0      0.0      0.0  ...     0.0     0.0     0.0     0.0   \\n2021-12-01      0.0      0.0      0.0  ...     0.0     0.0     0.0     0.0   \\n\\n            day_31  weekdayofmonth_1  weekdayofmonth_2  weekdayofmonth_3  \\\\\\nMONTH                                                                      \\n2016-01-01     0.0               1.0               0.0               0.0   \\n2016-02-01     0.0               1.0               0.0               0.0   \\n2016-03-01     0.0               1.0               0.0               0.0   \\n2016-04-01     0.0               1.0               0.0               0.0   \\n2016-05-01     0.0               1.0               0.0               0.0   \\n...            ...               ...               ...               ...   \\n2021-08-01     0.0               1.0               0.0               0.0   \\n2021-09-01     0.0               1.0               0.0               0.0   \\n2021-10-01     0.0               1.0               0.0               0.0   \\n2021-11-01     0.0               1.0               0.0               0.0   \\n2021-12-01     0.0               1.0               0.0               0.0   \\n\\n            weekdayofmonth_4  weekdayofmonth_5  \\nMONTH                                           \\n2016-01-01               0.0               0.0  \\n2016-02-01               0.0               0.0  \\n2016-03-01               0.0               0.0  \\n2016-04-01               0.0               0.0  \\n2016-05-01               0.0               0.0  \\n...                      ...               ...  \\n2021-08-01               0.0               0.0  \\n2021-09-01               0.0               0.0  \\n2021-10-01               0.0               0.0  \\n2021-11-01               0.0               0.0  \\n2021-12-01               0.0               0.0  \\n\\n[72 rows x 58 columns] and predict             weekend  quarter      epoch  month_1  month_2  month_3  month_4  \\\\\\n2022-01-01        1        1  2459580.5      1.0      0.0      0.0      0.0   \\n2022-02-01        0        1  2459611.5      0.0      1.0      0.0      0.0   \\n2022-03-01        0        1  2459639.5      0.0      0.0      1.0      0.0   \\n2022-04-01        0        2  2459670.5      0.0      0.0      0.0      1.0   \\n2022-05-01        1        2  2459700.5      0.0      0.0      0.0      0.0   \\n2022-06-01        0        2  2459731.5      0.0      0.0      0.0      0.0   \\n2022-07-01        0        3  2459761.5      0.0      0.0      0.0      0.0   \\n2022-08-01        0        3  2459792.5      0.0      0.0      0.0      0.0   \\n2022-09-01        0        3  2459823.5      0.0      0.0      0.0      0.0   \\n2022-10-01        1        4  2459853.5      0.0      0.0      0.0      0.0   \\n2022-11-01        0        4  2459884.5      0.0      0.0      0.0      0.0   \\n2022-12-01        0        4  2459914.5      0.0      0.0      0.0      0.0   \\n\\n            month_5  month_6  month_7  ...  day_27  day_28  day_29  day_30  \\\\\\n2022-01-01      0.0      0.0      0.0  ...     0.0     0.0     0.0     0.0   \\n2022-02-01      0.0      0.0      0.0  ...     0.0     0.0     0.0     0.0   \\n2022-03-01      0.0      0.0      0.0  ...     0.0     0.0     0.0     0.0   \\n2022-04-01      0.0      0.0      0.0  ...     0.0     0.0     0.0     0.0   \\n2022-05-01      1.0      0.0      0.0  ...     0.0     0.0     0.0     0.0   \\n2022-06-01      0.0      1.0      0.0  ...     0.0     0.0     0.0     0.0   \\n2022-07-01      0.0      0.0      1.0  ...     0.0     0.0     0.0     0.0   \\n2022-08-01      0.0      0.0      0.0  ...     0.0     0.0     0.0     0.0   \\n2022-09-01      0.0      0.0      0.0  ...     0.0     0.0     0.0     0.0   \\n2022-10-01      0.0      0.0      0.0  ...     0.0     0.0     0.0     0.0   \\n2022-11-01      0.0      0.0      0.0  ...     0.0     0.0     0.0     0.0   \\n2022-12-01      0.0      0.0      0.0  ...     0.0     0.0     0.0     0.0   \\n\\n            day_31  weekdayofmonth_1  weekdayofmonth_2  weekdayofmonth_3  \\\\\\n2022-01-01     0.0               1.0               0.0               0.0   \\n2022-02-01     0.0               1.0               0.0               0.0   \\n2022-03-01     0.0               1.0               0.0               0.0   \\n2022-04-01     0.0               1.0               0.0               0.0   \\n2022-05-01     0.0               1.0               0.0               0.0   \\n2022-06-01     0.0               1.0               0.0               0.0   \\n2022-07-01     0.0               1.0               0.0               0.0   \\n2022-08-01     0.0               1.0               0.0               0.0   \\n2022-09-01     0.0               1.0               0.0               0.0   \\n2022-10-01     0.0               1.0               0.0               0.0   \\n2022-11-01     0.0               1.0               0.0               0.0   \\n2022-12-01     0.0               1.0               0.0               0.0   \\n\\n            weekdayofmonth_4  weekdayofmonth_5  \\n2022-01-01               0.0               0.0  \\n2022-02-01               0.0               0.0  \\n2022-03-01               0.0               0.0  \\n2022-04-01               0.0               0.0  \\n2022-05-01               0.0               0.0  \\n2022-06-01               0.0               0.0  \\n2022-07-01               0.0               0.0  \\n2022-08-01               0.0               0.0  \\n2022-09-01               0.0               0.0  \\n2022-10-01               0.0               0.0  \\n2022-11-01               0.0               0.0  \\n2022-12-01               0.0               0.0  \\n\\n[12 rows x 58 columns]\") in model 95 in generation 0: ARDL\n",
      "Model Number: 96 with model FBProphet in generation 0 of 3\n",
      "No anomalies detected.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "19:03:01 - cmdstanpy - INFO - Chain [1] start processing\n",
      "19:03:01 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 97 with model ConstantNaive in generation 0 of 3\n",
      "Model Number: 98 with model ConstantNaive in generation 0 of 3\n",
      "Model Number: 99 with model UnobservedComponents in generation 0 of 3\n",
      "Model Number: 100 with model ConstantNaive in generation 0 of 3\n",
      "Model Number: 101 with model VAR in generation 0 of 3\n",
      "Template Eval Error: ValueError('Only gave one variable to VAR') in model 101 in generation 0: VAR\n",
      "Model Number: 102 with model ETS in generation 0 of 3\n",
      "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
      "ETS failed on NET_SALES with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
      "Model Number: 103 with model Theta in generation 0 of 3\n",
      "Model Number: 104 with model DatepartRegression in generation 0 of 3\n",
      "Template Eval Error: ValueError('Model DatepartRegression returned NaN for one or more series. fail_on_forecast_nan=True') in model 104 in generation 0: DatepartRegression\n",
      "Model Number: 105 with model GLM in generation 0 of 3\n",
      "Model Number: 106 with model ARCH in generation 0 of 3\n",
      "Template Eval Error: Exception('Transformer Detrend failed on fit') in model 106 in generation 0: ARCH\n",
      "Model Number: 107 with model AverageValueNaive in generation 0 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\neighbors\\_regression.py:494: UserWarning: One or more samples have no neighbors within specified radius; predicting NaN.\n",
      "  warnings.warn(empty_warning_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 108 with model MetricMotif in generation 0 of 3\n",
      "Model Number: 109 with model ETS in generation 0 of 3\n",
      "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
      "ETS failed on NET_SALES with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
      "Template Eval Error: Exception('Transformer DifferencedTransformer failed on inverse') in model 109 in generation 0: ETS\n",
      "Model Number: 110 with model ETS in generation 0 of 3\n",
      "ETS error ValueError('Cannot compute initial seasonals using heuristic method with less than two full seasonal cycles in the data.')\n",
      "ETS failed on NET_SALES with ValueError('Cannot compute initial seasonals using heuristic method with less than two full seasonal cycles in the data.')\n",
      "Template Eval Error: Exception('Transformer AlignLastValue failed on inverse') in model 110 in generation 0: ETS\n",
      "Model Number: 111 with model SeasonalNaive in generation 0 of 3\n",
      "Model Number: 112 with model ARCH in generation 0 of 3\n",
      "Template Eval Error: ImportError('`arch` package must be installed from pip') in model 112 in generation 0: ARCH\n",
      "Model Number: 113 with model SectionalMotif in generation 0 of 3\n",
      "Model Number: 114 with model SeasonalNaive in generation 0 of 3\n",
      "Model Number: 115 with model UnivariateRegression in generation 0 of 3\n",
      "Model Number: 116 with model VAR in generation 0 of 3\n",
      "Template Eval Error: ValueError('Only gave one variable to VAR') in model 116 in generation 0: VAR\n",
      "Model Number: 117 with model GluonTS in generation 0 of 3\n",
      "Template Eval Error: ImportError('GluonTS installation is incompatible with AutoTS. The numpy version is sometimes the issue, try 1.23.1 {as of 06-2023}') in model 117 in generation 0: GluonTS\n",
      "Model Number: 118 with model GLM in generation 0 of 3\n",
      "Template Eval Error: ValueError('The first guess on the deviance function returned a nan.  This could be a boundary  problem and should be reported.') in model 118 in generation 0: GLM\n",
      "Model Number: 119 with model MultivariateMotif in generation 0 of 3\n",
      "Model Number: 120 with model AverageValueNaive in generation 0 of 3\n",
      "Model Number: 121 with model ConstantNaive in generation 0 of 3\n",
      "Model Number: 122 with model ARCH in generation 0 of 3\n",
      "Template Eval Error: ImportError('`arch` package must be installed from pip') in model 122 in generation 0: ARCH\n",
      "Model Number: 123 with model GLS in generation 0 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\statsmodels\\genmod\\families\\family.py:1367: ValueWarning: Negative binomial dispersion parameter alpha not set. Using default value alpha=1.0.\n",
      "  warnings.warn(\"Negative binomial dispersion parameter alpha not \"\n",
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\statsmodels\\genmod\\families\\family.py:1406: RuntimeWarning: invalid value encountered in log\n",
      "  resid_dev -= endog_alpha * np.log(endog_alpha / mu_alpha)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 124 with model LastValueNaive in generation 0 of 3\n",
      "Template Eval Error: Exception('Transformer RegressionFilter failed on fit') in model 124 in generation 0: LastValueNaive\n",
      "Model Number: 125 with model UnobservedComponents in generation 0 of 3\n",
      "Model Number: 126 with model LastValueNaive in generation 0 of 3\n",
      "Model Number: 127 with model SectionalMotif in generation 0 of 3\n",
      "Template Eval Error: ValueError('Unknown Distance Metric: kulsinski') in model 127 in generation 0: SectionalMotif\n",
      "Model Number: 128 with model GLS in generation 0 of 3\n",
      "Model Number: 129 with model Theta in generation 0 of 3\n",
      "Model Number: 130 with model UnobservedComponents in generation 0 of 3\n",
      "Model Number: 131 with model WindowRegression in generation 0 of 3\n",
      "Template Eval Error: ValueError('Input X contains NaN.\\nBayesianRidge does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values') in model 131 in generation 0: WindowRegression\n",
      "Model Number: 132 with model NVAR in generation 0 of 3\n",
      "Model Number: 133 with model SeasonalNaive in generation 0 of 3\n",
      "Model Number: 134 with model UnobservedComponents in generation 0 of 3\n",
      "Template Eval Error: Exception('Transformer Detrend failed on fit') in model 134 in generation 0: UnobservedComponents\n",
      "Model Number: 135 with model GLS in generation 0 of 3\n",
      "Model Number: 136 with model MetricMotif in generation 0 of 3\n",
      "Model Number: 137 with model VAR in generation 0 of 3\n",
      "Template Eval Error: ValueError('Only gave one variable to VAR') in model 137 in generation 0: VAR\n",
      "Model Number: 138 with model WindowRegression in generation 0 of 3\n",
      "Template Eval Error: ImportError('Tensorflow not available, install with pip install tensorflow.') in model 138 in generation 0: WindowRegression\n",
      "Model Number: 139 with model GLM in generation 0 of 3\n",
      "Model Number: 140 with model NVAR in generation 0 of 3\n",
      "Model Number: 141 with model VAR in generation 0 of 3\n",
      "Template Eval Error: ValueError('Only gave one variable to VAR') in model 141 in generation 0: VAR\n",
      "Model Number: 142 with model DatepartRegression in generation 0 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\statsmodels\\genmod\\families\\links.py:198: RuntimeWarning: overflow encountered in exp\n",
      "  t = np.exp(-z)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 143 with model GLS in generation 0 of 3\n",
      "Model Number: 144 with model DatepartRegression in generation 0 of 3\n",
      "Template Eval Error: ValueError('Input X contains NaN.\\nExtraTreesRegressor does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values') in model 144 in generation 0: DatepartRegression\n",
      "Model Number: 145 with model VAR in generation 0 of 3\n",
      "Template Eval Error: ValueError('Only gave one variable to VAR') in model 145 in generation 0: VAR\n",
      "Model Number: 146 with model Theta in generation 0 of 3\n",
      "Model Number: 147 with model ETS in generation 0 of 3\n",
      "ETS error ValueError('Cannot compute initial seasonals using heuristic method with less than two full seasonal cycles in the data.')\n",
      "ETS failed on NET_SALES with ValueError('Cannot compute initial seasonals using heuristic method with less than two full seasonal cycles in the data.')\n",
      "Model Number: 148 with model ConstantNaive in generation 0 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 149 with model ARDL in generation 0 of 3\n",
      "Model Number: 150 with model SectionalMotif in generation 0 of 3\n",
      "Model Number: 151 with model VAR in generation 0 of 3\n",
      "Model Number: 152 with model DatepartRegression in generation 0 of 3\n",
      "Model Number: 153 with model Theta in generation 0 of 3\n",
      "Model Number: 154 with model MetricMotif in generation 0 of 3\n",
      "Model Number: 155 with model DatepartRegression in generation 0 of 3\n",
      "Model Number: 156 with model GLM in generation 0 of 3\n",
      "Model Number: 157 with model GluonTS in generation 0 of 3\n",
      "Template Eval Error: ImportError('GluonTS installation is incompatible with AutoTS. The numpy version is sometimes the issue, try 1.23.1 {as of 06-2023}') in model 157 in generation 0: GluonTS\n",
      "Model Number: 158 with model DatepartRegression in generation 0 of 3\n",
      "Template Eval Error: Exception('Transformer AlignLastValue failed on inverse') in model 158 in generation 0: DatepartRegression\n",
      "Model Number: 159 with model NVAR in generation 0 of 3\n",
      "Model Number: 160 with model GLS in generation 0 of 3\n",
      "Model Number: 161 with model SectionalMotif in generation 0 of 3\n",
      "Model Number: 162 with model FBProphet in generation 0 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\statsmodels\\genmod\\families\\links.py:198: RuntimeWarning: overflow encountered in exp\n",
      "  t = np.exp(-z)\n",
      "19:03:04 - cmdstanpy - INFO - Chain [1] start processing\n",
      "19:03:04 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 163 with model ETS in generation 0 of 3\n",
      "Model Number: 164 with model VAR in generation 0 of 3\n",
      "Template Eval Error: ValueError('Only gave one variable to VAR') in model 164 in generation 0: VAR\n",
      "Model Number: 165 with model MultivariateMotif in generation 0 of 3\n",
      "Model Number: 166 with model VAR in generation 0 of 3\n",
      "Template Eval Error: ValueError('Only gave one variable to VAR') in model 166 in generation 0: VAR\n",
      "Model Number: 167 with model ARIMA in generation 0 of 3\n",
      "Model Number: 168 with model UnobservedComponents in generation 0 of 3\n",
      "Model Number: 169 with model UnivariateMotif in generation 0 of 3\n",
      "Template Eval Error: ValueError('kth(=100) out of bounds (51)') in model 169 in generation 0: UnivariateMotif\n",
      "Model Number: 170 with model VAR in generation 0 of 3\n",
      "Template Eval Error: ValueError('Only gave one variable to VAR') in model 170 in generation 0: VAR\n",
      "Model Number: 171 with model Theta in generation 0 of 3\n",
      "Model Number: 172 with model MultivariateMotif in generation 0 of 3\n",
      "Model Number: 173 with model UnobservedComponents in generation 0 of 3\n",
      "Model Number: 174 with model WindowRegression in generation 0 of 3\n",
      "Model Number: 175 with model SeasonalNaive in generation 0 of 3\n",
      "Model Number: 176 with model ARDL in generation 0 of 3\n",
      "Model Number: 177 with model GLS in generation 0 of 3\n",
      "Model Number: 178 with model SectionalMotif in generation 0 of 3\n",
      "Model Number: 179 with model ARDL in generation 0 of 3\n",
      "Model Number: 180 with model MultivariateMotif in generation 0 of 3\n",
      "Model Number: 181 with model ARCH in generation 0 of 3\n",
      "Template Eval Error: ImportError('`arch` package must be installed from pip') in model 181 in generation 0: ARCH\n",
      "Model Number: 182 with model SectionalMotif in generation 0 of 3\n",
      "Model Number: 183 with model ARIMA in generation 0 of 3\n",
      "Model Number: 184 with model DatepartRegression in generation 0 of 3\n",
      "Model Number: 185 with model ETS in generation 0 of 3\n",
      "ETS error ValueError('Cannot compute initial seasonals using heuristic method with less than two full seasonal cycles in the data.')\n",
      "ETS failed on NET_SALES with ValueError('Cannot compute initial seasonals using heuristic method with less than two full seasonal cycles in the data.')\n",
      "Model Number: 186 with model VECM in generation 0 of 3\n",
      "Template Eval Error: ValueError('Only gave one variable to VECM') in model 186 in generation 0: VECM\n",
      "New Generation: 1 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.105e-01, tolerance: 7.008e-04\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 187 with model ETS in generation 1 of 3\n",
      "Model Number: 188 with model WindowRegression in generation 1 of 3\n",
      "Model Number: 189 with model MultivariateMotif in generation 1 of 3\n",
      "Model Number: 190 with model ARDL in generation 1 of 3\n",
      "Model Number: 191 with model MultivariateMotif in generation 1 of 3\n",
      "Model Number: 192 with model GLS in generation 1 of 3\n",
      "Model Number: 193 with model WindowRegression in generation 1 of 3\n",
      "Template Eval Error: Exception('Transformer AlignLastValue failed on inverse') in model 193 in generation 1: WindowRegression\n",
      "Model Number: 194 with model SeasonalNaive in generation 1 of 3\n",
      "Model Number: 195 with model ARDL in generation 1 of 3\n",
      "Model Number: 196 with model UnivariateMotif in generation 1 of 3\n",
      "Model Number: 197 with model Theta in generation 1 of 3\n",
      "Model Number: 198 with model Theta in generation 1 of 3\n",
      "Model Number: 199 with model ConstantNaive in generation 1 of 3\n",
      "Model Number: 200 with model ETS in generation 1 of 3\n",
      "Model Number: 201 with model ARIMA in generation 1 of 3\n",
      "Model Number: 202 with model MultivariateRegression in generation 1 of 3\n",
      "Model Number: 203 with model ConstantNaive in generation 1 of 3\n",
      "Model Number: 204 with model MultivariateRegression in generation 1 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\numpy\\lib\\function_base.py:2845: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  c = cov(x, y, rowvar, dtype=dtype)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Template Eval Error: ValueError('Input X contains NaN.\\nRandomForestRegressor does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values') in model 204 in generation 1: MultivariateRegression\n",
      "Model Number: 205 with model GLM in generation 1 of 3\n",
      "Model Number: 206 with model VAR in generation 1 of 3\n",
      "Template Eval Error: Exception('Transformer MinMaxScaler failed on inverse') in model 206 in generation 1: VAR\n",
      "Model Number: 207 with model ETS in generation 1 of 3\n",
      "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
      "ETS failed on NET_SALES with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
      "Model Number: 208 with model LastValueNaive in generation 1 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\numpy\\lib\\function_base.py:2845: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  c = cov(x, y, rowvar, dtype=dtype)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 209 with model ARIMA in generation 1 of 3\n",
      "Model Number: 210 with model SeasonalNaive in generation 1 of 3\n",
      "Model Number: 211 with model SectionalMotif in generation 1 of 3\n",
      "Model Number: 212 with model WindowRegression in generation 1 of 3\n",
      "Template Eval Error: ImportError('Tensorflow not available, install with pip install tensorflow.') in model 212 in generation 1: WindowRegression\n",
      "Model Number: 213 with model GLS in generation 1 of 3\n",
      "Model Number: 214 with model SectionalMotif in generation 1 of 3\n",
      "Model Number: 215 with model NVAR in generation 1 of 3\n",
      "Model Number: 216 with model MultivariateRegression in generation 1 of 3\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000035 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Model Number: 217 with model ARIMA in generation 1 of 3\n",
      "Model Number: 218 with model UnivariateRegression in generation 1 of 3\n",
      "Model Number: 219 with model UnobservedComponents in generation 1 of 3\n",
      "Model Number: 220 with model DatepartRegression in generation 1 of 3\n",
      "Model Number: 221 with model MultivariateMotif in generation 1 of 3\n",
      "Model Number: 222 with model ETS in generation 1 of 3\n",
      "Template Eval Error: Exception('Transformer BTCD failed on fit') in model 222 in generation 1: ETS\n",
      "Model Number: 223 with model SeasonalNaive in generation 1 of 3\n",
      "Model Number: 224 with model SectionalMotif in generation 1 of 3\n",
      "Model Number: 225 with model MetricMotif in generation 1 of 3\n",
      "Model Number: 226 with model WindowRegression in generation 1 of 3\n",
      "Model Number: 227 with model SeasonalNaive in generation 1 of 3\n",
      "Model Number: 228 with model ARDL in generation 1 of 3\n",
      "Model Number: 229 with model SectionalMotif in generation 1 of 3\n",
      "Model Number: 230 with model LastValueNaive in generation 1 of 3\n",
      "Model Number: 231 with model ARDL in generation 1 of 3\n",
      "Model Number: 232 with model FBProphet in generation 1 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "19:03:11 - cmdstanpy - INFO - Chain [1] start processing\n",
      "19:03:11 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 233 with model UnobservedComponents in generation 1 of 3\n",
      "Model Number: 234 with model GLS in generation 1 of 3\n",
      "Model Number: 235 with model ETS in generation 1 of 3\n",
      "Model Number: 236 with model DatepartRegression in generation 1 of 3\n",
      "Template Eval Error: Exception('Transformer AlignLastValue failed on inverse') in model 236 in generation 1: DatepartRegression\n",
      "Model Number: 237 with model UnobservedComponents in generation 1 of 3\n",
      "Template Eval Error: LinAlgError('Singular matrix') in model 237 in generation 1: UnobservedComponents\n",
      "Model Number: 238 with model GLS in generation 1 of 3\n",
      "Model Number: 239 with model GLS in generation 1 of 3\n",
      "Model Number: 240 with model UnobservedComponents in generation 1 of 3\n",
      "Model Number: 241 with model MultivariateMotif in generation 1 of 3\n",
      "Model Number: 242 with model LastValueNaive in generation 1 of 3\n",
      "Model Number: 243 with model MultivariateMotif in generation 1 of 3\n",
      "Model Number: 244 with model ARDL in generation 1 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\decomposition\\_fastica.py:708: FutureWarning: Starting in v1.3, whiten=True should be specified as whiten='arbitrary-variance' (its current behaviour). This behavior is deprecated in 1.1 and will raise ValueError in 1.3.\n",
      "  return self._fit_transform(X, compute_sources=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 245 with model SeasonalNaive in generation 1 of 3\n",
      "Model Number: 246 with model GLM in generation 1 of 3\n",
      "Template Eval Error: ValueError('The first guess on the deviance function returned a nan.  This could be a boundary  problem and should be reported.') in model 246 in generation 1: GLM\n",
      "Model Number: 247 with model ConstantNaive in generation 1 of 3\n",
      "Model Number: 248 with model NVAR in generation 1 of 3\n",
      "Model Number: 249 with model SeasonalNaive in generation 1 of 3\n",
      "Model Number: 250 with model FBProphet in generation 1 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\statsmodels\\genmod\\families\\family.py:1367: ValueWarning: Negative binomial dispersion parameter alpha not set. Using default value alpha=1.0.\n",
      "  warnings.warn(\"Negative binomial dispersion parameter alpha not \"\n",
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\statsmodels\\genmod\\families\\family.py:1406: RuntimeWarning: invalid value encountered in log\n",
      "  resid_dev -= endog_alpha * np.log(endog_alpha / mu_alpha)\n",
      "19:03:12 - cmdstanpy - INFO - Chain [1] start processing\n",
      "19:03:13 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 251 with model UnobservedComponents in generation 1 of 3\n",
      "Model Number: 252 with model AverageValueNaive in generation 1 of 3\n",
      "Model Number: 253 with model NVAR in generation 1 of 3\n",
      "Model Number: 254 with model GLM in generation 1 of 3\n",
      "Model Number: 255 with model SectionalMotif in generation 1 of 3\n",
      "Template Eval Error: ValueError('kth(=10) out of bounds (6)') in model 255 in generation 1: SectionalMotif\n",
      "Model Number: 256 with model UnobservedComponents in generation 1 of 3\n",
      "Model Number: 257 with model SectionalMotif in generation 1 of 3\n",
      "Model Number: 258 with model WindowRegression in generation 1 of 3\n",
      "Model Number: 259 with model MetricMotif in generation 1 of 3\n",
      "Template Eval Error: Exception('Transformer Detrend failed on fit') in model 259 in generation 1: MetricMotif\n",
      "Model Number: 260 with model UnobservedComponents in generation 1 of 3\n",
      "Model Number: 261 with model DatepartRegression in generation 1 of 3\n",
      "Model Number: 262 with model DatepartRegression in generation 1 of 3\n",
      "Model Number: 263 with model DatepartRegression in generation 1 of 3\n",
      "Template Eval Error: ValueError('Model DatepartRegression returned NaN for one or more series. fail_on_forecast_nan=True') in model 263 in generation 1: DatepartRegression\n",
      "Model Number: 264 with model NVAR in generation 1 of 3\n",
      "Model Number: 265 with model UnivariateMotif in generation 1 of 3\n",
      "Model Number: 266 with model UnivariateMotif in generation 1 of 3\n",
      "Model Number: 267 with model Theta in generation 1 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\neighbors\\_regression.py:494: UserWarning: One or more samples have no neighbors within specified radius; predicting NaN.\n",
      "  warnings.warn(empty_warning_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 268 with model SeasonalNaive in generation 1 of 3\n",
      "Model Number: 269 with model ARIMA in generation 1 of 3\n",
      "Model Number: 270 with model MetricMotif in generation 1 of 3\n",
      "Model Number: 271 with model GLM in generation 1 of 3\n",
      "Model Number: 272 with model GLM in generation 1 of 3\n",
      "Model Number: 273 with model NVAR in generation 1 of 3\n",
      "Model Number: 274 with model MultivariateMotif in generation 1 of 3\n",
      "Model Number: 275 with model GLS in generation 1 of 3\n",
      "Model Number: 276 with model GLM in generation 1 of 3\n",
      "Model Number: 277 with model MetricMotif in generation 1 of 3\n",
      "Model Number: 278 with model UnivariateRegression in generation 1 of 3\n",
      "Model Number: 279 with model UnobservedComponents in generation 1 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\statsmodels\\genmod\\families\\family.py:1367: ValueWarning: Negative binomial dispersion parameter alpha not set. Using default value alpha=1.0.\n",
      "  warnings.warn(\"Negative binomial dispersion parameter alpha not \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 280 with model DatepartRegression in generation 1 of 3\n",
      "Model Number: 281 with model DatepartRegression in generation 1 of 3\n",
      "Model Number: 282 with model GLS in generation 1 of 3\n",
      "Model Number: 283 with model SeasonalNaive in generation 1 of 3\n",
      "Model Number: 284 with model ETS in generation 1 of 3\n",
      "Model Number: 285 with model MetricMotif in generation 1 of 3\n",
      "Model Number: 286 with model UnivariateRegression in generation 1 of 3\n",
      "Model Number: 287 with model MultivariateRegression in generation 1 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 288 with model MultivariateMotif in generation 1 of 3\n",
      "Template Eval Error: Exception('Transformer AlignLastValue failed on inverse') in model 288 in generation 1: MultivariateMotif\n",
      "Model Number: 289 with model SectionalMotif in generation 1 of 3\n",
      "Model Number: 290 with model DatepartRegression in generation 1 of 3\n",
      "Model Number: 291 with model UnobservedComponents in generation 1 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\decomposition\\_fastica.py:708: FutureWarning: Starting in v1.3, whiten=True should be specified as whiten='arbitrary-variance' (its current behaviour). This behavior is deprecated in 1.1 and will raise ValueError in 1.3.\n",
      "  return self._fit_transform(X, compute_sources=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 292 with model ETS in generation 1 of 3\n",
      "Model Number: 293 with model LastValueNaive in generation 1 of 3\n",
      "Model Number: 294 with model UnobservedComponents in generation 1 of 3\n",
      "Model Number: 295 with model MultivariateMotif in generation 1 of 3\n",
      "Model Number: 296 with model WindowRegression in generation 1 of 3\n",
      "Model Number: 297 with model AverageValueNaive in generation 1 of 3\n",
      "Model Number: 298 with model UnobservedComponents in generation 1 of 3\n",
      "Model Number: 299 with model ARDL in generation 1 of 3\n",
      "Model Number: 300 with model GLM in generation 1 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 301 with model SeasonalNaive in generation 1 of 3\n",
      "Model Number: 302 with model ConstantNaive in generation 1 of 3\n",
      "Model Number: 303 with model GLS in generation 1 of 3\n",
      "Model Number: 304 with model SectionalMotif in generation 1 of 3\n",
      "Model Number: 305 with model FBProphet in generation 1 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "19:03:16 - cmdstanpy - INFO - Chain [1] start processing\n",
      "19:03:17 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 306 with model MetricMotif in generation 1 of 3\n",
      "Template Eval Error: Exception('Transformer Detrend failed on fit') in model 306 in generation 1: MetricMotif\n",
      "Model Number: 307 with model FBProphet in generation 1 of 3\n",
      "Template Eval Error: Exception('Transformer RegressionFilter failed on fit') in model 307 in generation 1: FBProphet\n",
      "Model Number: 308 with model SeasonalNaive in generation 1 of 3\n",
      "Model Number: 309 with model MetricMotif in generation 1 of 3\n",
      "Model Number: 310 with model AverageValueNaive in generation 1 of 3\n",
      "Model Number: 311 with model SectionalMotif in generation 1 of 3\n",
      "New Generation: 2 of 3\n",
      "Model Number: 312 with model GLM in generation 2 of 3\n",
      "Model Number: 313 with model GLM in generation 2 of 3\n",
      "Model Number: 314 with model AverageValueNaive in generation 2 of 3\n",
      "Model Number: 315 with model VAR in generation 2 of 3\n",
      "Template Eval Error: ValueError('Only gave one variable to VAR') in model 315 in generation 2: VAR\n",
      "Model Number: 316 with model DatepartRegression in generation 2 of 3\n",
      "Model Number: 317 with model GLM in generation 2 of 3\n",
      "Template Eval Error: ValueError('The first guess on the deviance function returned a nan.  This could be a boundary  problem and should be reported.') in model 317 in generation 2: GLM\n",
      "Model Number: 318 with model MetricMotif in generation 2 of 3\n",
      "Model Number: 319 with model UnivariateRegression in generation 2 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\statsmodels\\genmod\\generalized_linear_model.py:307: DomainWarning: The InversePower link function does not respect the domain of the Gamma family.\n",
      "  warnings.warn((f\"The {type(family.link).__name__} link function \"\n",
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\statsmodels\\genmod\\families\\family.py:188: RuntimeWarning: invalid value encountered in divide\n",
      "  return np.sum(resid_dev * freq_weights * var_weights / scale)\n",
      "19:03:18 - cmdstanpy - INFO - Chain [1] start processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Template Eval Error: ValueError('Input X contains NaN.\\nLinearRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values') in model 319 in generation 2: UnivariateRegression\n",
      "Model Number: 320 with model FBProphet in generation 2 of 3\n",
      "No anomalies detected.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "19:03:18 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 321 with model DatepartRegression in generation 2 of 3\n",
      "Model Number: 322 with model AverageValueNaive in generation 2 of 3\n",
      "Model Number: 323 with model UnobservedComponents in generation 2 of 3\n",
      "Model Number: 324 with model GLM in generation 2 of 3\n",
      "Model Number: 325 with model Theta in generation 2 of 3\n",
      "Model Number: 326 with model MetricMotif in generation 2 of 3\n",
      "Model Number: 327 with model ARDL in generation 2 of 3\n",
      "Model Number: 328 with model NVAR in generation 2 of 3\n",
      "Model Number: 329 with model UnivariateRegression in generation 2 of 3\n",
      "Model Number: 330 with model MultivariateMotif in generation 2 of 3\n",
      "Model Number: 331 with model UnobservedComponents in generation 2 of 3\n",
      "Model Number: 332 with model AverageValueNaive in generation 2 of 3\n",
      "Model Number: 333 with model UnivariateMotif in generation 2 of 3\n",
      "Model Number: 334 with model WindowRegression in generation 2 of 3\n",
      "Model Number: 335 with model ARDL in generation 2 of 3\n",
      "Model Number: 336 with model MultivariateRegression in generation 2 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\linear_model\\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.48343e-24): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 337 with model SeasonalNaive in generation 2 of 3\n",
      "Model Number: 338 with model SectionalMotif in generation 2 of 3\n",
      "Model Number: 339 with model SectionalMotif in generation 2 of 3\n",
      "Model Number: 340 with model UnobservedComponents in generation 2 of 3\n",
      "Model Number: 341 with model WindowRegression in generation 2 of 3\n",
      "Model Number: 342 with model UnobservedComponents in generation 2 of 3\n",
      "Model Number: 343 with model ConstantNaive in generation 2 of 3\n",
      "Model Number: 344 with model SeasonalNaive in generation 2 of 3\n",
      "Model Number: 345 with model GLS in generation 2 of 3\n",
      "Model Number: 346 with model GLS in generation 2 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:541: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 347 with model GLM in generation 2 of 3\n",
      "Model Number: 348 with model MultivariateMotif in generation 2 of 3\n",
      "Template Eval Error: Exception('Transformer AlignLastValue failed on inverse') in model 348 in generation 2: MultivariateMotif\n",
      "Model Number: 349 with model GLS in generation 2 of 3\n",
      "Model Number: 350 with model MetricMotif in generation 2 of 3\n",
      "Model Number: 351 with model MultivariateRegression in generation 2 of 3\n",
      "Model Number: 352 with model SectionalMotif in generation 2 of 3\n",
      "Model Number: 353 with model SeasonalNaive in generation 2 of 3\n",
      "Model Number: 354 with model ARDL in generation 2 of 3\n",
      "Model Number: 355 with model DatepartRegression in generation 2 of 3\n",
      "Template Eval Error: ValueError('Model DatepartRegression returned NaN for one or more series. fail_on_forecast_nan=True') in model 355 in generation 2: DatepartRegression\n",
      "Model Number: 356 with model GLS in generation 2 of 3\n",
      "Model Number: 357 with model UnivariateMotif in generation 2 of 3\n",
      "Template Eval Error: ValueError('kth(=100) out of bounds (51)') in model 357 in generation 2: UnivariateMotif\n",
      "Model Number: 358 with model Theta in generation 2 of 3\n",
      "Model Number: 359 with model SeasonalNaive in generation 2 of 3\n",
      "Model Number: 360 with model WindowRegression in generation 2 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\neighbors\\_regression.py:494: UserWarning: One or more samples have no neighbors within specified radius; predicting NaN.\n",
      "  warnings.warn(empty_warning_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 361 with model ConstantNaive in generation 2 of 3\n",
      "Model Number: 362 with model MetricMotif in generation 2 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:541: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 363 with model GLM in generation 2 of 3\n",
      "Template Eval Error: ValueError('NaN, inf or invalid value detected in weights, estimation infeasible.') in model 363 in generation 2: GLM\n",
      "Model Number: 364 with model GLM in generation 2 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\decomposition\\_fastica.py:708: FutureWarning: Starting in v1.3, whiten=True should be specified as whiten='arbitrary-variance' (its current behaviour). This behavior is deprecated in 1.1 and will raise ValueError in 1.3.\n",
      "  return self._fit_transform(X, compute_sources=True)\n",
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\statsmodels\\genmod\\families\\links.py:527: RuntimeWarning: overflow encountered in exp\n",
      "  return np.exp(z)\n",
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\statsmodels\\genmod\\families\\family.py:445: RuntimeWarning: divide by zero encountered in divide\n",
      "  endog_mu = self._clean(endog / mu)\n",
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\statsmodels\\genmod\\families\\family.py:143: RuntimeWarning: invalid value encountered in multiply\n",
      "  return 1. / (self.link.deriv(mu)**2 * self.variance(mu))\n",
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\statsmodels\\genmod\\families\\family.py:143: RuntimeWarning: divide by zero encountered in divide\n",
      "  return 1. / (self.link.deriv(mu)**2 * self.variance(mu))\n",
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\statsmodels\\genmod\\generalized_linear_model.py:1243: RuntimeWarning: invalid value encountered in multiply\n",
      "  wlsendog = (lin_pred + self.family.link.deriv(mu) * (self.endog-mu)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 365 with model Theta in generation 2 of 3\n",
      "Model Number: 366 with model MultivariateMotif in generation 2 of 3\n",
      "Model Number: 367 with model GLM in generation 2 of 3\n",
      "Model Number: 368 with model ConstantNaive in generation 2 of 3\n",
      "Model Number: 369 with model MultivariateRegression in generation 2 of 3\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000025 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Model Number: 370 with model SectionalMotif in generation 2 of 3\n",
      "Model Number: 371 with model UnobservedComponents in generation 2 of 3\n",
      "Model Number: 372 with model AverageValueNaive in generation 2 of 3\n",
      "Model Number: 373 with model SectionalMotif in generation 2 of 3\n",
      "Model Number: 374 with model ARDL in generation 2 of 3\n",
      "Model Number: 375 with model SectionalMotif in generation 2 of 3\n",
      "Model Number: 376 with model GLS in generation 2 of 3\n",
      "Model Number: 377 with model MultivariateMotif in generation 2 of 3\n",
      "Model Number: 378 with model ETS in generation 2 of 3\n",
      "Model Number: 379 with model NVAR in generation 2 of 3\n",
      "Model Number: 380 with model LastValueNaive in generation 2 of 3\n",
      "Model Number: 381 with model ETS in generation 2 of 3\n",
      "Model Number: 382 with model MetricMotif in generation 2 of 3\n",
      "Model Number: 383 with model SectionalMotif in generation 2 of 3\n",
      "Model Number: 384 with model SeasonalNaive in generation 2 of 3\n",
      "Model Number: 385 with model NVAR in generation 2 of 3\n",
      "Model Number: 386 with model WindowRegression in generation 2 of 3\n",
      "Model Number: 387 with model ETS in generation 2 of 3\n",
      "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
      "ETS failed on NET_SALES with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
      "Model Number: 388 with model UnivariateMotif in generation 2 of 3\n",
      "Model Number: 389 with model DatepartRegression in generation 2 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\autots\\tools\\probabilistic.py:67: RuntimeWarning: invalid value encountered in divide\n",
      "  (prior_mu / prior_sigma**2) + ((n * data_mu) / prior_sigma**2)\n",
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\autots\\tools\\probabilistic.py:68: RuntimeWarning: divide by zero encountered in divide\n",
      "  ) / ((1 / prior_sigma**2) + (n / prior_sigma**2))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 390 with model UnivariateRegression in generation 2 of 3\n",
      "Model Number: 391 with model LastValueNaive in generation 2 of 3\n",
      "Model Number: 392 with model WindowRegression in generation 2 of 3\n",
      "Model Number: 393 with model ARDL in generation 2 of 3\n",
      "Model Number: 394 with model GLS in generation 2 of 3\n",
      "Model Number: 395 with model SectionalMotif in generation 2 of 3\n",
      "Model Number: 396 with model SectionalMotif in generation 2 of 3\n",
      "Model Number: 397 with model DatepartRegression in generation 2 of 3\n",
      "Model Number: 398 with model GLS in generation 2 of 3\n",
      "Model Number: 399 with model SectionalMotif in generation 2 of 3\n",
      "Model Number: 400 with model ARDL in generation 2 of 3\n",
      "Model Number: 401 with model UnivariateMotif in generation 2 of 3\n",
      "Template Eval Error: Exception('Transformer LocalLinearTrend failed on fit') in model 401 in generation 2: UnivariateMotif\n",
      "Model Number: 402 with model Theta in generation 2 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\linear_model\\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.48343e-24): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 403 with model ARDL in generation 2 of 3\n",
      "Model Number: 404 with model DatepartRegression in generation 2 of 3\n",
      "Model Number: 405 with model GLM in generation 2 of 3\n",
      "Template Eval Error: ValueError('The first guess on the deviance function returned a nan.  This could be a boundary  problem and should be reported.') in model 405 in generation 2: GLM\n",
      "Model Number: 406 with model DatepartRegression in generation 2 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\statsmodels\\genmod\\families\\family.py:1367: ValueWarning: Negative binomial dispersion parameter alpha not set. Using default value alpha=1.0.\n",
      "  warnings.warn(\"Negative binomial dispersion parameter alpha not \"\n",
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\statsmodels\\genmod\\families\\family.py:1406: RuntimeWarning: invalid value encountered in log\n",
      "  resid_dev -= endog_alpha * np.log(endog_alpha / mu_alpha)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 407 with model GLS in generation 2 of 3\n",
      "Model Number: 408 with model MultivariateRegression in generation 2 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\autots\\tools\\probabilistic.py:67: RuntimeWarning: invalid value encountered in divide\n",
      "  (prior_mu / prior_sigma**2) + ((n * data_mu) / prior_sigma**2)\n",
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\autots\\tools\\probabilistic.py:68: RuntimeWarning: divide by zero encountered in divide\n",
      "  ) / ((1 / prior_sigma**2) + (n / prior_sigma**2))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 409 with model UnivariateMotif in generation 2 of 3\n",
      "Model Number: 410 with model AverageValueNaive in generation 2 of 3\n",
      "Model Number: 411 with model WindowRegression in generation 2 of 3\n",
      "Model Number: 412 with model ARIMA in generation 2 of 3\n",
      "Model Number: 413 with model MetricMotif in generation 2 of 3\n",
      "Model Number: 414 with model MultivariateRegression in generation 2 of 3\n",
      "Model Number: 415 with model MultivariateRegression in generation 2 of 3\n",
      "Model Number: 416 with model GLM in generation 2 of 3\n",
      "Model Number: 417 with model ETS in generation 2 of 3\n",
      "Model Number: 418 with model MultivariateRegression in generation 2 of 3\n",
      "Model Number: 419 with model UnivariateRegression in generation 2 of 3\n",
      "Template Eval Error: ValueError('Input X contains NaN.\\nLinearRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values') in model 419 in generation 2: UnivariateRegression\n",
      "Model Number: 420 with model ARDL in generation 2 of 3\n",
      "Model Number: 421 with model LastValueNaive in generation 2 of 3\n",
      "Model Number: 422 with model NVAR in generation 2 of 3\n",
      "Model Number: 423 with model UnivariateMotif in generation 2 of 3\n",
      "Model Number: 424 with model GLS in generation 2 of 3\n",
      "Model Number: 425 with model DatepartRegression in generation 2 of 3\n",
      "Model Number: 426 with model WindowRegression in generation 2 of 3\n",
      "Template Eval Error: Exception('Transformer AlignLastValue failed on inverse') in model 426 in generation 2: WindowRegression\n",
      "Model Number: 427 with model SectionalMotif in generation 2 of 3\n",
      "Model Number: 428 with model UnobservedComponents in generation 2 of 3\n",
      "Model Number: 429 with model GLM in generation 2 of 3\n",
      "Template Eval Error: ValueError('NaN, inf or invalid value detected in weights, estimation infeasible.') in model 429 in generation 2: GLM\n",
      "Model Number: 430 with model ARDL in generation 2 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\linear_model\\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.48343e-24): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\statsmodels\\genmod\\families\\links.py:527: RuntimeWarning: overflow encountered in exp\n",
      "  return np.exp(z)\n",
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\statsmodels\\genmod\\families\\family.py:143: RuntimeWarning: invalid value encountered in multiply\n",
      "  return 1. / (self.link.deriv(mu)**2 * self.variance(mu))\n",
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\statsmodels\\genmod\\generalized_linear_model.py:1243: RuntimeWarning: invalid value encountered in multiply\n",
      "  wlsendog = (lin_pred + self.family.link.deriv(mu) * (self.endog-mu)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 431 with model UnivariateMotif in generation 2 of 3\n",
      "Template Eval Error: Exception('Transformer LocalLinearTrend failed on fit') in model 431 in generation 2: UnivariateMotif\n",
      "Model Number: 432 with model SeasonalNaive in generation 2 of 3\n",
      "Model Number: 433 with model FBProphet in generation 2 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.116e+13, tolerance: 5.397e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "19:03:29 - cmdstanpy - INFO - Chain [1] start processing\n",
      "19:03:29 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 434 with model ARIMA in generation 2 of 3\n",
      "Model Number: 435 with model NVAR in generation 2 of 3\n",
      "Model Number: 436 with model MetricMotif in generation 2 of 3\n",
      "New Generation: 3 of 3\n",
      "Model Number: 437 with model UnobservedComponents in generation 3 of 3\n",
      "Template Eval Error: Exception('Transformer Cointegration failed on fit') in model 437 in generation 3: UnobservedComponents\n",
      "Model Number: 438 with model WindowRegression in generation 3 of 3\n",
      "Template Eval Error: Exception('Transformer Cointegration failed on fit') in model 438 in generation 3: WindowRegression\n",
      "Model Number: 439 with model SeasonalNaive in generation 3 of 3\n",
      "Model Number: 440 with model MetricMotif in generation 3 of 3\n",
      "Model Number: 441 with model GLM in generation 3 of 3\n",
      "Model Number: 442 with model AverageValueNaive in generation 3 of 3\n",
      "Model Number: 443 with model NVAR in generation 3 of 3\n",
      "Model Number: 444 with model GLS in generation 3 of 3\n",
      "Model Number: 445 with model GLM in generation 3 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\statsmodels\\genmod\\families\\family.py:1367: ValueWarning: Negative binomial dispersion parameter alpha not set. Using default value alpha=1.0.\n",
      "  warnings.warn(\"Negative binomial dispersion parameter alpha not \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 446 with model MetricMotif in generation 3 of 3\n",
      "Model Number: 447 with model ETS in generation 3 of 3\n",
      "Model Number: 448 with model SectionalMotif in generation 3 of 3\n",
      "Model Number: 449 with model MultivariateRegression in generation 3 of 3\n",
      "Model Number: 450 with model SeasonalNaive in generation 3 of 3\n",
      "Model Number: 451 with model AverageValueNaive in generation 3 of 3\n",
      "Template Eval Error: Exception('Transformer BTCD failed on fit') in model 451 in generation 3: AverageValueNaive\n",
      "Model Number: 452 with model GLS in generation 3 of 3\n",
      "Model Number: 453 with model ARIMA in generation 3 of 3\n",
      "Model Number: 454 with model ARIMA in generation 3 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\autots\\tools\\probabilistic.py:67: RuntimeWarning: invalid value encountered in divide\n",
      "  (prior_mu / prior_sigma**2) + ((n * data_mu) / prior_sigma**2)\n",
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\autots\\tools\\probabilistic.py:68: RuntimeWarning: divide by zero encountered in divide\n",
      "  ) / ((1 / prior_sigma**2) + (n / prior_sigma**2))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 455 with model WindowRegression in generation 3 of 3\n",
      "Model Number: 456 with model SectionalMotif in generation 3 of 3\n",
      "Template Eval Error: ValueError('The number of observations (7) is too small; the covariance matrix is singular. For observations with 10 dimensions, at least 11 observations are required.') in model 456 in generation 3: SectionalMotif\n",
      "Model Number: 457 with model MetricMotif in generation 3 of 3\n",
      "Model Number: 458 with model GLM in generation 3 of 3\n",
      "Model Number: 459 with model ETS in generation 3 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 460 with model ARDL in generation 3 of 3\n",
      "Model Number: 461 with model MultivariateMotif in generation 3 of 3\n",
      "Model Number: 462 with model LastValueNaive in generation 3 of 3\n",
      "Model Number: 463 with model UnobservedComponents in generation 3 of 3\n",
      "Model Number: 464 with model UnobservedComponents in generation 3 of 3\n",
      "Model Number: 465 with model ARDL in generation 3 of 3\n",
      "Model Number: 466 with model MultivariateMotif in generation 3 of 3\n",
      "Model Number: 467 with model MetricMotif in generation 3 of 3\n",
      "Model Number: 468 with model GLM in generation 3 of 3\n",
      "Template Eval Error: Exception('Transformer BTCD failed on fit') in model 468 in generation 3: GLM\n",
      "Model Number: 469 with model UnobservedComponents in generation 3 of 3\n",
      "Template Eval Error: LinAlgError('Singular matrix') in model 469 in generation 3: UnobservedComponents\n",
      "Model Number: 470 with model MetricMotif in generation 3 of 3\n",
      "Model Number: 471 with model SeasonalNaive in generation 3 of 3\n",
      "Model Number: 472 with model UnivariateMotif in generation 3 of 3\n",
      "Template Eval Error: ValueError('kth(=100) out of bounds (47)') in model 472 in generation 3: UnivariateMotif\n",
      "Model Number: 473 with model UnobservedComponents in generation 3 of 3\n",
      "Model Number: 474 with model ARDL in generation 3 of 3\n",
      "Model Number: 475 with model MultivariateMotif in generation 3 of 3\n",
      "Model Number: 476 with model GLS in generation 3 of 3\n",
      "Model Number: 477 with model ConstantNaive in generation 3 of 3\n",
      "Model Number: 478 with model GLM in generation 3 of 3\n",
      "Template Eval Error: Exception('Transformer Cointegration failed on fit') in model 478 in generation 3: GLM\n",
      "Model Number: 479 with model ARDL in generation 3 of 3\n",
      "Model Number: 480 with model AverageValueNaive in generation 3 of 3\n",
      "Model Number: 481 with model MetricMotif in generation 3 of 3\n",
      "Model Number: 482 with model GLS in generation 3 of 3\n",
      "Model Number: 483 with model FBProphet in generation 3 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "19:03:37 - cmdstanpy - INFO - Chain [1] start processing\n",
      "19:03:37 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 484 with model MetricMotif in generation 3 of 3\n",
      "Model Number: 485 with model UnivariateMotif in generation 3 of 3\n",
      "Template Eval Error: Exception('Transformer AlignLastValue failed on inverse') in model 485 in generation 3: UnivariateMotif\n",
      "Model Number: 486 with model SectionalMotif in generation 3 of 3\n",
      "Model Number: 487 with model NVAR in generation 3 of 3\n",
      "Model Number: 488 with model GLS in generation 3 of 3\n",
      "Template Eval Error: Exception('Transformer Cointegration failed on fit') in model 488 in generation 3: GLS\n",
      "Model Number: 489 with model MultivariateRegression in generation 3 of 3\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000028 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Model Number: 490 with model UnivariateMotif in generation 3 of 3\n",
      "Model Number: 491 with model UnobservedComponents in generation 3 of 3\n",
      "Model Number: 492 with model SectionalMotif in generation 3 of 3\n",
      "Model Number: 493 with model SectionalMotif in generation 3 of 3\n",
      "Model Number: 494 with model ARDL in generation 3 of 3\n",
      "Model Number: 495 with model UnobservedComponents in generation 3 of 3\n",
      "Model Number: 496 with model MultivariateMotif in generation 3 of 3\n",
      "Model Number: 497 with model Theta in generation 3 of 3\n",
      "Model Number: 498 with model AverageValueNaive in generation 3 of 3\n",
      "Model Number: 499 with model ETS in generation 3 of 3\n",
      "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
      "ETS failed on NET_SALES with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
      "Model Number: 500 with model NVAR in generation 3 of 3\n",
      "Model Number: 501 with model MultivariateMotif in generation 3 of 3\n",
      "Model Number: 502 with model MultivariateRegression in generation 3 of 3\n",
      "Model Number: 503 with model UnobservedComponents in generation 3 of 3\n",
      "Model Number: 504 with model GLS in generation 3 of 3\n",
      "Model Number: 505 with model GLS in generation 3 of 3\n",
      "Template Eval Error: Exception('Transformer RegressionFilter failed on fit') in model 505 in generation 3: GLS\n",
      "Model Number: 506 with model ARDL in generation 3 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\autots\\tools\\probabilistic.py:67: RuntimeWarning: invalid value encountered in divide\n",
      "  (prior_mu / prior_sigma**2) + ((n * data_mu) / prior_sigma**2)\n",
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\autots\\tools\\probabilistic.py:68: RuntimeWarning: divide by zero encountered in divide\n",
      "  ) / ((1 / prior_sigma**2) + (n / prior_sigma**2))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 507 with model ETS in generation 3 of 3\n",
      "Model Number: 508 with model ConstantNaive in generation 3 of 3\n",
      "Model Number: 509 with model ETS in generation 3 of 3\n",
      "Model Number: 510 with model AverageValueNaive in generation 3 of 3\n",
      "Template Eval Error: Exception('Transformer BTCD failed on fit') in model 510 in generation 3: AverageValueNaive\n",
      "Model Number: 511 with model DatepartRegression in generation 3 of 3\n",
      "Template Eval Error: ImportError('Tensorflow not available, install with pip install tensorflow.') in model 511 in generation 3: DatepartRegression\n",
      "Model Number: 512 with model GLM in generation 3 of 3\n",
      "Template Eval Error: ValueError('NaN, inf or invalid value detected in weights, estimation infeasible.') in model 512 in generation 3: GLM\n",
      "Model Number: 513 with model SeasonalNaive in generation 3 of 3\n",
      "Model Number: 514 with model DatepartRegression in generation 3 of 3\n",
      "Model Number: 515 with model GLM in generation 3 of 3\n",
      "Model Number: 516 with model DatepartRegression in generation 3 of 3\n",
      "Model Number: 517 with model Theta in generation 3 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\statsmodels\\genmod\\families\\family.py:445: RuntimeWarning: divide by zero encountered in divide\n",
      "  endog_mu = self._clean(endog / mu)\n",
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\statsmodels\\genmod\\families\\family.py:143: RuntimeWarning: divide by zero encountered in divide\n",
      "  return 1. / (self.link.deriv(mu)**2 * self.variance(mu))\n",
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 518 with model ARDL in generation 3 of 3\n",
      "Model Number: 519 with model WindowRegression in generation 3 of 3\n",
      "Model Number: 520 with model LastValueNaive in generation 3 of 3\n",
      "Model Number: 521 with model DatepartRegression in generation 3 of 3\n",
      "Model Number: 522 with model SeasonalNaive in generation 3 of 3\n",
      "Model Number: 523 with model GLS in generation 3 of 3\n",
      "Model Number: 524 with model MultivariateRegression in generation 3 of 3\n",
      "Model Number: 525 with model GLM in generation 3 of 3\n",
      "Model Number: 526 with model UnobservedComponents in generation 3 of 3\n",
      "Model Number: 527 with model UnivariateMotif in generation 3 of 3\n",
      "Template Eval Error: Exception('Transformer AlignLastValue failed on inverse') in model 527 in generation 3: UnivariateMotif\n",
      "Model Number: 528 with model SeasonalNaive in generation 3 of 3\n",
      "Model Number: 529 with model SectionalMotif in generation 3 of 3\n",
      "Template Eval Error: ValueError('kth(=10) out of bounds (4)') in model 529 in generation 3: SectionalMotif\n",
      "Model Number: 530 with model LastValueNaive in generation 3 of 3\n",
      "Model Number: 531 with model UnivariateMotif in generation 3 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\statsmodels\\genmod\\families\\family.py:1367: ValueWarning: Negative binomial dispersion parameter alpha not set. Using default value alpha=1.0.\n",
      "  warnings.warn(\"Negative binomial dispersion parameter alpha not \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 532 with model SeasonalNaive in generation 3 of 3\n",
      "Model Number: 533 with model GLM in generation 3 of 3\n",
      "Model Number: 534 with model UnivariateMotif in generation 3 of 3\n",
      "Template Eval Error: ValueError('kth(=100) out of bounds (47)') in model 534 in generation 3: UnivariateMotif\n",
      "Model Number: 535 with model Theta in generation 3 of 3\n",
      "Model Number: 536 with model MetricMotif in generation 3 of 3\n",
      "Template Eval Error: ValueError('kth(=99) out of bounds (63)') in model 536 in generation 3: MetricMotif\n",
      "Model Number: 537 with model LastValueNaive in generation 3 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\statsmodels\\genmod\\families\\links.py:198: RuntimeWarning: overflow encountered in exp\n",
      "  t = np.exp(-z)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 538 with model SeasonalNaive in generation 3 of 3\n",
      "Model Number: 539 with model ARDL in generation 3 of 3\n",
      "Model Number: 540 with model UnivariateMotif in generation 3 of 3\n",
      "Model Number: 541 with model UnobservedComponents in generation 3 of 3\n",
      "Model Number: 542 with model FBProphet in generation 3 of 3\n",
      "No anomalies detected.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "19:03:42 - cmdstanpy - INFO - Chain [1] start processing\n",
      "19:03:42 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 543 with model WindowRegression in generation 3 of 3\n",
      "Template Eval Error: ValueError('Found array with 0 sample(s) (shape=(0, 0)) while a minimum of 1 is required by BayesianRidge.') in model 543 in generation 3: WindowRegression\n",
      "Model Number: 544 with model SectionalMotif in generation 3 of 3\n",
      "Model Number: 545 with model MetricMotif in generation 3 of 3\n",
      "Model Number: 546 with model GLM in generation 3 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\statsmodels\\genmod\\families\\family.py:1367: ValueWarning: Negative binomial dispersion parameter alpha not set. Using default value alpha=1.0.\n",
      "  warnings.warn(\"Negative binomial dispersion parameter alpha not \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 547 with model MultivariateRegression in generation 3 of 3\n",
      "Model Number: 548 with model ARDL in generation 3 of 3\n",
      "Template Eval Error: Exception('Transformer AlignLastValue failed on inverse') in model 548 in generation 3: ARDL\n",
      "Model Number: 549 with model AverageValueNaive in generation 3 of 3\n",
      "Model Number: 550 with model SectionalMotif in generation 3 of 3\n",
      "Model Number: 551 with model GLM in generation 3 of 3\n",
      "Template Eval Error: ValueError('NaN, inf or invalid value detected in weights, estimation infeasible.') in model 551 in generation 3: GLM\n",
      "Model Number: 552 with model SectionalMotif in generation 3 of 3\n",
      "Model Number: 553 with model MultivariateMotif in generation 3 of 3\n",
      "Model Number: 554 with model NVAR in generation 3 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\statsmodels\\genmod\\families\\family.py:445: RuntimeWarning: divide by zero encountered in divide\n",
      "  endog_mu = self._clean(endog / mu)\n",
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\statsmodels\\genmod\\families\\family.py:143: RuntimeWarning: divide by zero encountered in divide\n",
      "  return 1. / (self.link.deriv(mu)**2 * self.variance(mu))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 555 with model SectionalMotif in generation 3 of 3\n",
      "Model Number: 556 with model AverageValueNaive in generation 3 of 3\n",
      "Model Number: 557 with model WindowRegression in generation 3 of 3\n",
      "Model Number: 558 with model ARDL in generation 3 of 3\n",
      "Model Number: 559 with model DatepartRegression in generation 3 of 3\n",
      "Model Number: 560 with model DatepartRegression in generation 3 of 3\n",
      "Model Number: 561 with model WindowRegression in generation 3 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:541: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TotalRuntime missing in 4!\n",
      "Validation Round: 1\n",
      "Model Number: 1 of 85 with model SectionalMotif for Validation 1\n",
      "📈 1 - SectionalMotif with avg smape 34.06: \n",
      "Model Number: 2 of 85 with model UnobservedComponents for Validation 1\n",
      "📈 2 - UnobservedComponents with avg smape 31.81: \n",
      "Model Number: 3 of 85 with model MetricMotif for Validation 1\n",
      "📈 3 - MetricMotif with avg smape 24.5: \n",
      "Model Number: 4 of 85 with model ARDL for Validation 1\n",
      "4 - ARDL with avg smape 31.68: \n",
      "Model Number: 5 of 85 with model MetricMotif for Validation 1\n",
      "5 - MetricMotif with avg smape 31.08: \n",
      "Model Number: 6 of 85 with model MetricMotif for Validation 1\n",
      "6 - MetricMotif with avg smape 59.01: \n",
      "Model Number: 7 of 85 with model MetricMotif for Validation 1\n",
      "7 - MetricMotif with avg smape 46.65: \n",
      "Model Number: 8 of 85 with model SectionalMotif for Validation 1\n",
      "8 - SectionalMotif with avg smape 40.34: \n",
      "Model Number: 9 of 85 with model MetricMotif for Validation 1\n",
      "9 - MetricMotif with avg smape 30.67: \n",
      "Model Number: 10 of 85 with model WindowRegression for Validation 1\n",
      "10 - WindowRegression with avg smape 46.1: \n",
      "Model Number: 11 of 85 with model UnivariateMotif for Validation 1\n",
      "11 - UnivariateMotif with avg smape 32.71: \n",
      "Model Number: 12 of 85 with model SectionalMotif for Validation 1\n",
      "12 - SectionalMotif with avg smape 35.45: \n",
      "Model Number: 13 of 85 with model UnivariateMotif for Validation 1\n",
      "13 - UnivariateMotif with avg smape 30.03: \n",
      "Model Number: 14 of 85 with model GLS for Validation 1\n",
      "14 - GLS with avg smape 31.7: \n",
      "Model Number: 15 of 85 with model SectionalMotif for Validation 1\n",
      "15 - SectionalMotif with avg smape 42.31: \n",
      "Model Number: 16 of 85 with model WindowRegression for Validation 1\n",
      "16 - WindowRegression with avg smape 24.88: \n",
      "Model Number: 17 of 85 with model SectionalMotif for Validation 1\n",
      "17 - SectionalMotif with avg smape 36.32: \n",
      "Model Number: 18 of 85 with model UnobservedComponents for Validation 1\n",
      "18 - UnobservedComponents with avg smape 33.65: \n",
      "Model Number: 19 of 85 with model GLS for Validation 1\n",
      "19 - GLS with avg smape 38.31: \n",
      "Model Number: 20 of 85 with model DatepartRegression for Validation 1\n",
      "20 - DatepartRegression with avg smape 33.3: \n",
      "Model Number: 21 of 85 with model MultivariateMotif for Validation 1\n",
      "Template Eval Error: ValueError('The number of observations (22) is too small; the covariance matrix is singular. For observations with 28 dimensions, at least 29 observations are required.') in model 21 in generation 0: MultivariateMotif\n",
      "Model Number: 22 of 85 with model AverageValueNaive for Validation 1\n",
      "22 - AverageValueNaive with avg smape 35.21: \n",
      "Model Number: 23 of 85 with model UnobservedComponents for Validation 1\n",
      "23 - UnobservedComponents with avg smape 35.86: \n",
      "Model Number: 24 of 85 with model UnobservedComponents for Validation 1\n",
      "24 - UnobservedComponents with avg smape 35.86: \n",
      "Model Number: 25 of 85 with model AverageValueNaive for Validation 1\n",
      "25 - AverageValueNaive with avg smape 35.86: \n",
      "Model Number: 26 of 85 with model WindowRegression for Validation 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26 - WindowRegression with avg smape 42.33: \n",
      "Model Number: 27 of 85 with model GLM for Validation 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\statsmodels\\genmod\\families\\family.py:1367: ValueWarning: Negative binomial dispersion parameter alpha not set. Using default value alpha=1.0.\n",
      "  warnings.warn(\"Negative binomial dispersion parameter alpha not \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27 - GLM with avg smape 31.17: \n",
      "Model Number: 28 of 85 with model ARIMA for Validation 1\n",
      "28 - ARIMA with avg smape 25.04: \n",
      "Model Number: 29 of 85 with model GLM for Validation 1\n",
      "📈 29 - GLM with avg smape 24.16: \n",
      "Model Number: 30 of 85 with model GLM for Validation 1\n",
      "30 - GLM with avg smape 31.8: \n",
      "Model Number: 31 of 85 with model ETS for Validation 1\n",
      "31 - ETS with avg smape 28.13: \n",
      "Model Number: 32 of 85 with model WindowRegression for Validation 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:541: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32 - WindowRegression with avg smape 56.88: \n",
      "Model Number: 33 of 85 with model MultivariateRegression for Validation 1\n",
      "33 - MultivariateRegression with avg smape 51.85: \n",
      "Model Number: 34 of 85 with model UnivariateMotif for Validation 1\n",
      "34 - UnivariateMotif with avg smape 41.92: \n",
      "Model Number: 35 of 85 with model SeasonalNaive for Validation 1\n",
      "35 - SeasonalNaive with avg smape 26.99: \n",
      "Model Number: 36 of 85 with model SeasonalNaive for Validation 1\n",
      "36 - SeasonalNaive with avg smape 31.44: \n",
      "Model Number: 37 of 85 with model GLM for Validation 1\n",
      "37 - GLM with avg smape 31.06: \n",
      "Model Number: 38 of 85 with model UnivariateMotif for Validation 1\n",
      "38 - UnivariateMotif with avg smape 32.37: \n",
      "Model Number: 39 of 85 with model ARDL for Validation 1\n",
      "39 - ARDL with avg smape 31.12: \n",
      "Model Number: 40 of 85 with model UnobservedComponents for Validation 1\n",
      "40 - UnobservedComponents with avg smape 31.37: \n",
      "Model Number: 41 of 85 with model GLM for Validation 1\n",
      "41 - GLM with avg smape 36.63: \n",
      "Model Number: 42 of 85 with model ARDL for Validation 1\n",
      "42 - ARDL with avg smape 31.46: \n",
      "Model Number: 43 of 85 with model ARDL for Validation 1\n",
      "43 - ARDL with avg smape 36.77: \n",
      "Model Number: 44 of 85 with model GLS for Validation 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\statsmodels\\genmod\\families\\family.py:1367: ValueWarning: Negative binomial dispersion parameter alpha not set. Using default value alpha=1.0.\n",
      "  warnings.warn(\"Negative binomial dispersion parameter alpha not \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44 - GLS with avg smape 36.0: \n",
      "Model Number: 45 of 85 with model ARDL for Validation 1\n",
      "45 - ARDL with avg smape 32.94: \n",
      "Model Number: 46 of 85 with model MultivariateMotif for Validation 1\n",
      "📈 46 - MultivariateMotif with avg smape 23.18: \n",
      "Model Number: 47 of 85 with model MultivariateMotif for Validation 1\n",
      "47 - MultivariateMotif with avg smape 23.18: \n",
      "Model Number: 48 of 85 with model DatepartRegression for Validation 1\n",
      "📈 48 - DatepartRegression with avg smape 22.93: \n",
      "Model Number: 49 of 85 with model MultivariateRegression for Validation 1\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000023 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "49 - MultivariateRegression with avg smape 37.63: \n",
      "Model Number: 50 of 85 with model GLS for Validation 1\n",
      "50 - GLS with avg smape 35.97: \n",
      "Model Number: 51 of 85 with model SeasonalNaive for Validation 1\n",
      "51 - SeasonalNaive with avg smape 28.02: \n",
      "Model Number: 52 of 85 with model DatepartRegression for Validation 1\n",
      "52 - DatepartRegression with avg smape 28.55: \n",
      "Model Number: 53 of 85 with model GLS for Validation 1\n",
      "53 - GLS with avg smape 34.11: \n",
      "Model Number: 54 of 85 with model MultivariateMotif for Validation 1\n",
      "54 - MultivariateMotif with avg smape 23.76: \n",
      "Model Number: 55 of 85 with model DatepartRegression for Validation 1\n",
      "55 - DatepartRegression with avg smape 43.8: \n",
      "Model Number: 56 of 85 with model DatepartRegression for Validation 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56 - DatepartRegression with avg smape 28.4: \n",
      "Model Number: 57 of 85 with model NVAR for Validation 1\n",
      "57 - NVAR with avg smape 38.7: \n",
      "Model Number: 58 of 85 with model AverageValueNaive for Validation 1\n",
      "58 - AverageValueNaive with avg smape 27.63: \n",
      "Model Number: 59 of 85 with model AverageValueNaive for Validation 1\n",
      "59 - AverageValueNaive with avg smape 26.75: \n",
      "Model Number: 60 of 85 with model AverageValueNaive for Validation 1\n",
      "60 - AverageValueNaive with avg smape 26.75: \n",
      "Model Number: 61 of 85 with model WindowRegression for Validation 1\n",
      "61 - WindowRegression with avg smape 91.54: \n",
      "Model Number: 62 of 85 with model SeasonalNaive for Validation 1\n",
      "62 - SeasonalNaive with avg smape 30.43: \n",
      "Model Number: 63 of 85 with model ETS for Validation 1\n",
      "📈 63 - ETS with avg smape 21.91: \n",
      "Model Number: 64 of 85 with model ConstantNaive for Validation 1\n",
      "64 - ConstantNaive with avg smape 35.86: \n",
      "Model Number: 65 of 85 with model ConstantNaive for Validation 1\n",
      "65 - ConstantNaive with avg smape 35.86: \n",
      "Model Number: 66 of 85 with model SeasonalNaive for Validation 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66 - SeasonalNaive with avg smape 30.35: \n",
      "Model Number: 67 of 85 with model MultivariateRegression for Validation 1\n",
      "67 - MultivariateRegression with avg smape 39.26: \n",
      "Model Number: 68 of 85 with model NVAR for Validation 1\n",
      "68 - NVAR with avg smape 30.83: \n",
      "Model Number: 69 of 85 with model NVAR for Validation 1\n",
      "69 - NVAR with avg smape 30.83: \n",
      "Model Number: 70 of 85 with model NVAR for Validation 1\n",
      "70 - NVAR with avg smape 30.83: \n",
      "Model Number: 71 of 85 with model MultivariateMotif for Validation 1\n",
      "71 - MultivariateMotif with avg smape 29.44: \n",
      "Model Number: 72 of 85 with model NVAR for Validation 1\n",
      "72 - NVAR with avg smape 35.67: \n",
      "Model Number: 73 of 85 with model MultivariateRegression for Validation 1\n",
      "73 - MultivariateRegression with avg smape 29.38: \n",
      "Model Number: 74 of 85 with model ETS for Validation 1\n",
      "74 - ETS with avg smape 33.9: \n",
      "Model Number: 75 of 85 with model MultivariateRegression for Validation 1\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000040 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "75 - MultivariateRegression with avg smape 40.28: \n",
      "Model Number: 76 of 85 with model UnivariateMotif for Validation 1\n",
      "76 - UnivariateMotif with avg smape 42.46: \n",
      "Model Number: 77 of 85 with model ETS for Validation 1\n",
      "77 - ETS with avg smape 38.76: \n",
      "Model Number: 78 of 85 with model ETS for Validation 1\n",
      "78 - ETS with avg smape 21.95: \n",
      "Model Number: 79 of 85 with model Theta for Validation 1\n",
      "79 - Theta with avg smape 25.93: \n",
      "Model Number: 80 of 85 with model Theta for Validation 1\n",
      "80 - Theta with avg smape 25.93: \n",
      "Model Number: 81 of 85 with model Theta for Validation 1\n",
      "81 - Theta with avg smape 25.74: \n",
      "Model Number: 82 of 85 with model ARIMA for Validation 1\n",
      "82 - ARIMA with avg smape 34.48: \n",
      "Model Number: 83 of 85 with model Theta for Validation 1\n",
      "83 - Theta with avg smape 25.06: \n",
      "Model Number: 84 of 85 with model FBProphet for Validation 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "19:03:53 - cmdstanpy - INFO - Chain [1] start processing\n",
      "19:03:54 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84 - FBProphet with avg smape 33.39: \n",
      "Model Number: 85 of 85 with model UnivariateRegression for Validation 1\n",
      "85 - UnivariateRegression with avg smape 71.22: \n",
      "Validation Round: 2\n",
      "Model Number: 1 of 85 with model SectionalMotif for Validation 2\n",
      "Template Eval Error: ValueError('kth(=10) out of bounds (7)') in model 1 in generation 0: SectionalMotif\n",
      "Model Number: 2 of 85 with model UnobservedComponents for Validation 2\n",
      "📈 2 - UnobservedComponents with avg smape 47.27: \n",
      "Model Number: 3 of 85 with model MetricMotif for Validation 2\n",
      "3 - MetricMotif with avg smape 52.33: \n",
      "Model Number: 4 of 85 with model ARDL for Validation 2\n",
      "📈 4 - ARDL with avg smape 47.22: \n",
      "Model Number: 5 of 85 with model MetricMotif for Validation 2\n",
      "5 - MetricMotif with avg smape 54.38: \n",
      "Model Number: 6 of 85 with model MetricMotif for Validation 2\n",
      "6 - MetricMotif with avg smape 52.82: \n",
      "Model Number: 7 of 85 with model MetricMotif for Validation 2\n",
      "7 - MetricMotif with avg smape 50.89: \n",
      "Model Number: 8 of 85 with model SectionalMotif for Validation 2\n",
      "8 - SectionalMotif with avg smape 55.25: \n",
      "Model Number: 9 of 85 with model MetricMotif for Validation 2\n",
      "9 - MetricMotif with avg smape 48.78: \n",
      "Model Number: 10 of 85 with model WindowRegression for Validation 2\n",
      "10 - WindowRegression with avg smape 60.52: \n",
      "Model Number: 11 of 85 with model UnivariateMotif for Validation 2\n",
      "11 - UnivariateMotif with avg smape 54.51: \n",
      "Model Number: 12 of 85 with model SectionalMotif for Validation 2\n",
      "Template Eval Error: ValueError('kth(=3) out of bounds (3)') in model 12 in generation 0: SectionalMotif\n",
      "Model Number: 13 of 85 with model UnivariateMotif for Validation 2\n",
      "13 - UnivariateMotif with avg smape 52.26: \n",
      "Model Number: 14 of 85 with model GLS for Validation 2\n",
      "14 - GLS with avg smape 47.69: \n",
      "Model Number: 15 of 85 with model SectionalMotif for Validation 2\n",
      "Template Eval Error: ValueError('kth(=3) out of bounds (3)') in model 15 in generation 0: SectionalMotif\n",
      "Model Number: 16 of 85 with model WindowRegression for Validation 2\n",
      "16 - WindowRegression with avg smape 51.03: \n",
      "Model Number: 17 of 85 with model SectionalMotif for Validation 2\n",
      "Template Eval Error: ValueError('kth(=3) out of bounds (3)') in model 17 in generation 0: SectionalMotif\n",
      "Model Number: 18 of 85 with model UnobservedComponents for Validation 2\n",
      "18 - UnobservedComponents with avg smape 55.64: \n",
      "Model Number: 19 of 85 with model GLS for Validation 2\n",
      "19 - GLS with avg smape 50.33: \n",
      "Model Number: 20 of 85 with model DatepartRegression for Validation 2\n",
      "📈 20 - DatepartRegression with avg smape 45.21: \n",
      "Model Number: 21 of 85 with model MultivariateMotif for Validation 2\n",
      "Template Eval Error: ValueError('The number of observations (10) is too small; the covariance matrix is singular. For observations with 28 dimensions, at least 29 observations are required.') in model 21 in generation 0: MultivariateMotif\n",
      "Model Number: 22 of 85 with model AverageValueNaive for Validation 2\n",
      "22 - AverageValueNaive with avg smape 50.73: \n",
      "Model Number: 23 of 85 with model UnobservedComponents for Validation 2\n",
      "23 - UnobservedComponents with avg smape 50.85: \n",
      "Model Number: 24 of 85 with model UnobservedComponents for Validation 2\n",
      "24 - UnobservedComponents with avg smape 50.85: \n",
      "Model Number: 25 of 85 with model AverageValueNaive for Validation 2\n",
      "25 - AverageValueNaive with avg smape 50.85: \n",
      "Model Number: 26 of 85 with model WindowRegression for Validation 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26 - WindowRegression with avg smape 55.36: \n",
      "Model Number: 27 of 85 with model GLM for Validation 2\n",
      "27 - GLM with avg smape 48.13: \n",
      "Model Number: 28 of 85 with model ARIMA for Validation 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\statsmodels\\genmod\\families\\family.py:1367: ValueWarning: Negative binomial dispersion parameter alpha not set. Using default value alpha=1.0.\n",
      "  warnings.warn(\"Negative binomial dispersion parameter alpha not \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28 - ARIMA with avg smape 54.67: \n",
      "Model Number: 29 of 85 with model GLM for Validation 2\n",
      "29 - GLM with avg smape 47.54: \n",
      "Model Number: 30 of 85 with model GLM for Validation 2\n",
      "30 - GLM with avg smape 50.36: \n",
      "Model Number: 31 of 85 with model ETS for Validation 2\n",
      "31 - ETS with avg smape 54.26: \n",
      "Model Number: 32 of 85 with model WindowRegression for Validation 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:541: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32 - WindowRegression with avg smape 59.84: \n",
      "Model Number: 33 of 85 with model MultivariateRegression for Validation 2\n",
      "33 - MultivariateRegression with avg smape 53.85: \n",
      "Model Number: 34 of 85 with model UnivariateMotif for Validation 2\n",
      "34 - UnivariateMotif with avg smape 56.49: \n",
      "Model Number: 35 of 85 with model SeasonalNaive for Validation 2\n",
      "35 - SeasonalNaive with avg smape 49.41: \n",
      "Model Number: 36 of 85 with model SeasonalNaive for Validation 2\n",
      "📈 36 - SeasonalNaive with avg smape 44.31: \n",
      "Model Number: 37 of 85 with model GLM for Validation 2\n",
      "37 - GLM with avg smape 46.37: \n",
      "Model Number: 38 of 85 with model UnivariateMotif for Validation 2\n",
      "38 - UnivariateMotif with avg smape 50.44: \n",
      "Model Number: 39 of 85 with model ARDL for Validation 2\n",
      "39 - ARDL with avg smape 48.04: \n",
      "Model Number: 40 of 85 with model UnobservedComponents for Validation 2\n",
      "40 - UnobservedComponents with avg smape 49.23: \n",
      "Model Number: 41 of 85 with model GLM for Validation 2\n",
      "41 - GLM with avg smape 51.95: \n",
      "Model Number: 42 of 85 with model ARDL for Validation 2\n",
      "42 - ARDL with avg smape 49.07: \n",
      "Model Number: 43 of 85 with model ARDL for Validation 2\n",
      "43 - ARDL with avg smape 51.26: \n",
      "Model Number: 44 of 85 with model GLS for Validation 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\statsmodels\\genmod\\families\\family.py:1367: ValueWarning: Negative binomial dispersion parameter alpha not set. Using default value alpha=1.0.\n",
      "  warnings.warn(\"Negative binomial dispersion parameter alpha not \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44 - GLS with avg smape 51.5: \n",
      "Model Number: 45 of 85 with model ARDL for Validation 2\n",
      "45 - ARDL with avg smape 47.05: \n",
      "Model Number: 46 of 85 with model MultivariateMotif for Validation 2\n",
      "46 - MultivariateMotif with avg smape 59.85: \n",
      "Model Number: 47 of 85 with model MultivariateMotif for Validation 2\n",
      "47 - MultivariateMotif with avg smape 59.85: \n",
      "Model Number: 48 of 85 with model DatepartRegression for Validation 2\n",
      "48 - DatepartRegression with avg smape 47.67: \n",
      "Model Number: 49 of 85 with model MultivariateRegression for Validation 2\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000032 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "49 - MultivariateRegression with avg smape 74.64: \n",
      "Model Number: 50 of 85 with model GLS for Validation 2\n",
      "50 - GLS with avg smape 51.47: \n",
      "Model Number: 51 of 85 with model SeasonalNaive for Validation 2\n",
      "51 - SeasonalNaive with avg smape 49.67: \n",
      "Model Number: 52 of 85 with model DatepartRegression for Validation 2\n",
      "52 - DatepartRegression with avg smape 49.82: \n",
      "Model Number: 53 of 85 with model GLS for Validation 2\n",
      "53 - GLS with avg smape 58.16: \n",
      "Model Number: 54 of 85 with model MultivariateMotif for Validation 2\n",
      "54 - MultivariateMotif with avg smape 67.24: \n",
      "Model Number: 55 of 85 with model DatepartRegression for Validation 2\n",
      "55 - DatepartRegression with avg smape 50.47: \n",
      "Model Number: 56 of 85 with model DatepartRegression for Validation 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56 - DatepartRegression with avg smape 49.81: \n",
      "Model Number: 57 of 85 with model NVAR for Validation 2\n",
      "57 - NVAR with avg smape 51.43: \n",
      "Model Number: 58 of 85 with model AverageValueNaive for Validation 2\n",
      "58 - AverageValueNaive with avg smape 49.57: \n",
      "Model Number: 59 of 85 with model AverageValueNaive for Validation 2\n",
      "59 - AverageValueNaive with avg smape 47.4: \n",
      "Model Number: 60 of 85 with model AverageValueNaive for Validation 2\n",
      "60 - AverageValueNaive with avg smape 47.4: \n",
      "Model Number: 61 of 85 with model WindowRegression for Validation 2\n",
      "📈 61 - WindowRegression with avg smape 41.24: \n",
      "Model Number: 62 of 85 with model SeasonalNaive for Validation 2\n",
      "62 - SeasonalNaive with avg smape 46.54: \n",
      "Model Number: 63 of 85 with model ETS for Validation 2\n",
      "63 - ETS with avg smape 52.85: \n",
      "Model Number: 64 of 85 with model ConstantNaive for Validation 2\n",
      "64 - ConstantNaive with avg smape 50.85: \n",
      "Model Number: 65 of 85 with model ConstantNaive for Validation 2\n",
      "65 - ConstantNaive with avg smape 50.85: \n",
      "Model Number: 66 of 85 with model SeasonalNaive for Validation 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66 - SeasonalNaive with avg smape 46.82: \n",
      "Model Number: 67 of 85 with model MultivariateRegression for Validation 2\n",
      "67 - MultivariateRegression with avg smape 56.96: \n",
      "Model Number: 68 of 85 with model NVAR for Validation 2\n",
      "68 - NVAR with avg smape 53.12: \n",
      "Model Number: 69 of 85 with model NVAR for Validation 2\n",
      "69 - NVAR with avg smape 53.12: \n",
      "Model Number: 70 of 85 with model NVAR for Validation 2\n",
      "70 - NVAR with avg smape 53.12: \n",
      "Model Number: 71 of 85 with model MultivariateMotif for Validation 2\n",
      "71 - MultivariateMotif with avg smape 59.38: \n",
      "Model Number: 72 of 85 with model NVAR for Validation 2\n",
      "72 - NVAR with avg smape 55.25: \n",
      "Model Number: 73 of 85 with model MultivariateRegression for Validation 2\n",
      "73 - MultivariateRegression with avg smape 55.13: \n",
      "Model Number: 74 of 85 with model ETS for Validation 2\n",
      "74 - ETS with avg smape 50.78: \n",
      "Model Number: 75 of 85 with model MultivariateRegression for Validation 2\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000026 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "75 - MultivariateRegression with avg smape 44.28: \n",
      "Model Number: 76 of 85 with model UnivariateMotif for Validation 2\n",
      "Template Eval Error: ValueError('kth(=20) out of bounds (9)') in model 76 in generation 0: UnivariateMotif\n",
      "Model Number: 77 of 85 with model ETS for Validation 2\n",
      "77 - ETS with avg smape 54.88: \n",
      "Model Number: 78 of 85 with model ETS for Validation 2\n",
      "78 - ETS with avg smape 51.38: \n",
      "Model Number: 79 of 85 with model Theta for Validation 2\n",
      "79 - Theta with avg smape 49.92: \n",
      "Model Number: 80 of 85 with model Theta for Validation 2\n",
      "80 - Theta with avg smape 49.92: \n",
      "Model Number: 81 of 85 with model Theta for Validation 2\n",
      "81 - Theta with avg smape 48.1: \n",
      "Model Number: 82 of 85 with model ARIMA for Validation 2\n",
      "82 - ARIMA with avg smape 49.86: \n",
      "Model Number: 83 of 85 with model Theta for Validation 2\n",
      "83 - Theta with avg smape 48.44: \n",
      "Model Number: 84 of 85 with model FBProphet for Validation 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "19:04:02 - cmdstanpy - INFO - Chain [1] start processing\n",
      "19:04:26 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84 - FBProphet with avg smape 50.09: \n",
      "Model Number: 85 of 85 with model UnivariateRegression for Validation 2\n",
      "85 - UnivariateRegression with avg smape 41.8: \n",
      "Validation Round: 3\n",
      "Model Number: 1 of 85 with model SectionalMotif for Validation 3\n",
      "Template Eval Error: ValueError('zero-size array to reduction operation fmax which has no identity') in model 1 in generation 0: SectionalMotif\n",
      "Model Number: 2 of 85 with model UnobservedComponents for Validation 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\autots\\models\\basics.py:1911: RuntimeWarning: Mean of empty slice\n",
      "  forecast = np.nanmean(results, axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📈 2 - UnobservedComponents with avg smape 8.56: \n",
      "Model Number: 3 of 85 with model MetricMotif for Validation 3\n",
      "Template Eval Error: Exception('Transformer RegressionFilter failed on fit') in model 3 in generation 0: MetricMotif\n",
      "Model Number: 4 of 85 with model ARDL for Validation 3\n",
      "4 - ARDL with avg smape 9.19: \n",
      "Model Number: 5 of 85 with model MetricMotif for Validation 3\n",
      "Template Eval Error: Exception('Transformer RegressionFilter failed on fit') in model 5 in generation 0: MetricMotif\n",
      "Model Number: 6 of 85 with model MetricMotif for Validation 3\n",
      "Template Eval Error: Exception('Transformer RegressionFilter failed on fit') in model 6 in generation 0: MetricMotif\n",
      "Model Number: 7 of 85 with model MetricMotif for Validation 3\n",
      "Template Eval Error: Exception('Transformer RegressionFilter failed on fit') in model 7 in generation 0: MetricMotif\n",
      "Model Number: 8 of 85 with model SectionalMotif for Validation 3\n",
      "8 - SectionalMotif with avg smape 19.47: \n",
      "Model Number: 9 of 85 with model MetricMotif for Validation 3\n",
      "Template Eval Error: Exception('Transformer RegressionFilter failed on fit') in model 9 in generation 0: MetricMotif\n",
      "Model Number: 10 of 85 with model WindowRegression for Validation 3\n",
      "10 - WindowRegression with avg smape 16.45: \n",
      "Model Number: 11 of 85 with model UnivariateMotif for Validation 3\n",
      "Template Eval Error: ValueError('kth(=20) out of bounds (11)') in model 11 in generation 0: UnivariateMotif\n",
      "Model Number: 12 of 85 with model SectionalMotif for Validation 3\n",
      "Template Eval Error: ValueError('kth(=3) out of bounds (2)') in model 12 in generation 0: SectionalMotif\n",
      "Model Number: 13 of 85 with model UnivariateMotif for Validation 3\n",
      "13 - UnivariateMotif with avg smape 19.85: \n",
      "Model Number: 14 of 85 with model GLS for Validation 3\n",
      "📈 14 - GLS with avg smape 8.01: \n",
      "Model Number: 15 of 85 with model SectionalMotif for Validation 3\n",
      "Template Eval Error: ValueError('kth(=3) out of bounds (2)') in model 15 in generation 0: SectionalMotif\n",
      "Model Number: 16 of 85 with model WindowRegression for Validation 3\n",
      "Template Eval Error: Exception('Transformer RegressionFilter failed on fit') in model 16 in generation 0: WindowRegression\n",
      "Model Number: 17 of 85 with model SectionalMotif for Validation 3\n",
      "Template Eval Error: ValueError('kth(=3) out of bounds (2)') in model 17 in generation 0: SectionalMotif\n",
      "Model Number: 18 of 85 with model UnobservedComponents for Validation 3\n",
      "Template Eval Error: Exception('Transformer RegressionFilter failed on fit') in model 18 in generation 0: UnobservedComponents\n",
      "Model Number: 19 of 85 with model GLS for Validation 3\n",
      "19 - GLS with avg smape 9.84: \n",
      "Model Number: 20 of 85 with model DatepartRegression for Validation 3\n",
      "20 - DatepartRegression with avg smape 25.29: \n",
      "Model Number: 21 of 85 with model MultivariateMotif for Validation 3\n",
      "Template Eval Error: ValueError('window shape cannot be larger than input array shape') in model 21 in generation 0: MultivariateMotif\n",
      "Model Number: 22 of 85 with model AverageValueNaive for Validation 3\n",
      "22 - AverageValueNaive with avg smape 20.24: \n",
      "Model Number: 23 of 85 with model UnobservedComponents for Validation 3\n",
      "23 - UnobservedComponents with avg smape 19.99: \n",
      "Model Number: 24 of 85 with model UnobservedComponents for Validation 3\n",
      "24 - UnobservedComponents with avg smape 19.99: \n",
      "Model Number: 25 of 85 with model AverageValueNaive for Validation 3\n",
      "25 - AverageValueNaive with avg smape 19.99: \n",
      "Model Number: 26 of 85 with model WindowRegression for Validation 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26 - WindowRegression with avg smape 18.51: \n",
      "Model Number: 27 of 85 with model GLM for Validation 3\n",
      "27 - GLM with avg smape 21.16: \n",
      "Model Number: 28 of 85 with model ARIMA for Validation 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\statsmodels\\genmod\\families\\family.py:1367: ValueWarning: Negative binomial dispersion parameter alpha not set. Using default value alpha=1.0.\n",
      "  warnings.warn(\"Negative binomial dispersion parameter alpha not \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28 - ARIMA with avg smape 19.9: \n",
      "Model Number: 29 of 85 with model GLM for Validation 3\n",
      "29 - GLM with avg smape 20.75: \n",
      "Model Number: 30 of 85 with model GLM for Validation 3\n",
      "30 - GLM with avg smape 19.98: \n",
      "Model Number: 31 of 85 with model ETS for Validation 3\n",
      "31 - ETS with avg smape 19.07: \n",
      "Model Number: 32 of 85 with model WindowRegression for Validation 3\n",
      "32 - WindowRegression with avg smape 26.17: \n",
      "Model Number: 33 of 85 with model MultivariateRegression for Validation 3\n",
      "33 - MultivariateRegression with avg smape 8.7: \n",
      "Model Number: 34 of 85 with model UnivariateMotif for Validation 3\n",
      "Template Eval Error: ValueError('kth(=20) out of bounds (11)') in model 34 in generation 0: UnivariateMotif\n",
      "Model Number: 35 of 85 with model SeasonalNaive for Validation 3\n",
      "35 - SeasonalNaive with avg smape 22.04: \n",
      "Model Number: 36 of 85 with model SeasonalNaive for Validation 3\n",
      "36 - SeasonalNaive with avg smape 32.41: \n",
      "Model Number: 37 of 85 with model GLM for Validation 3\n",
      "37 - GLM with avg smape 25.87: \n",
      "Model Number: 38 of 85 with model UnivariateMotif for Validation 3\n",
      "Template Eval Error: Exception('Transformer RegressionFilter failed on fit') in model 38 in generation 0: UnivariateMotif\n",
      "Model Number: 39 of 85 with model ARDL for Validation 3\n",
      "39 - ARDL with avg smape 22.96: \n",
      "Model Number: 40 of 85 with model UnobservedComponents for Validation 3\n",
      "40 - UnobservedComponents with avg smape 17.19: \n",
      "Model Number: 41 of 85 with model GLM for Validation 3\n",
      "41 - GLM with avg smape 19.88: \n",
      "Model Number: 42 of 85 with model ARDL for Validation 3\n",
      "42 - ARDL with avg smape 9.56: \n",
      "Model Number: 43 of 85 with model ARDL for Validation 3\n",
      "43 - ARDL with avg smape 21.81: \n",
      "Model Number: 44 of 85 with model GLS for Validation 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\statsmodels\\genmod\\families\\family.py:1367: ValueWarning: Negative binomial dispersion parameter alpha not set. Using default value alpha=1.0.\n",
      "  warnings.warn(\"Negative binomial dispersion parameter alpha not \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44 - GLS with avg smape 19.99: \n",
      "Model Number: 45 of 85 with model ARDL for Validation 3\n",
      "45 - ARDL with avg smape 21.82: \n",
      "Model Number: 46 of 85 with model MultivariateMotif for Validation 3\n",
      "46 - MultivariateMotif with avg smape 23.57: \n",
      "Model Number: 47 of 85 with model MultivariateMotif for Validation 3\n",
      "47 - MultivariateMotif with avg smape 23.57: \n",
      "Model Number: 48 of 85 with model DatepartRegression for Validation 3\n",
      "48 - DatepartRegression with avg smape 25.24: \n",
      "Model Number: 49 of 85 with model MultivariateRegression for Validation 3\n",
      "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "49 - MultivariateRegression with avg smape 25.44: \n",
      "Model Number: 50 of 85 with model GLS for Validation 3\n",
      "50 - GLS with avg smape 20.01: \n",
      "Model Number: 51 of 85 with model SeasonalNaive for Validation 3\n",
      "51 - SeasonalNaive with avg smape 9.9: \n",
      "Model Number: 52 of 85 with model DatepartRegression for Validation 3\n",
      "52 - DatepartRegression with avg smape 15.69: \n",
      "Model Number: 53 of 85 with model GLS for Validation 3\n",
      "53 - GLS with avg smape 20.09: \n",
      "Model Number: 54 of 85 with model MultivariateMotif for Validation 3\n",
      "54 - MultivariateMotif with avg smape 33.16: \n",
      "Model Number: 55 of 85 with model DatepartRegression for Validation 3\n",
      "55 - DatepartRegression with avg smape 22.77: \n",
      "Model Number: 56 of 85 with model DatepartRegression for Validation 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\autots\\tools\\probabilistic.py:67: RuntimeWarning: invalid value encountered in divide\n",
      "  (prior_mu / prior_sigma**2) + ((n * data_mu) / prior_sigma**2)\n",
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\autots\\tools\\probabilistic.py:68: RuntimeWarning: divide by zero encountered in divide\n",
      "  ) / ((1 / prior_sigma**2) + (n / prior_sigma**2))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56 - DatepartRegression with avg smape 15.68: \n",
      "Model Number: 57 of 85 with model NVAR for Validation 3\n",
      "57 - NVAR with avg smape 21.0: \n",
      "Model Number: 58 of 85 with model AverageValueNaive for Validation 3\n",
      "Template Eval Error: Exception('Transformer RegressionFilter failed on fit') in model 58 in generation 0: AverageValueNaive\n",
      "Model Number: 59 of 85 with model AverageValueNaive for Validation 3\n",
      "59 - AverageValueNaive with avg smape 23.14: \n",
      "Model Number: 60 of 85 with model AverageValueNaive for Validation 3\n",
      "60 - AverageValueNaive with avg smape 23.14: \n",
      "Model Number: 61 of 85 with model WindowRegression for Validation 3\n",
      "Template Eval Error: Exception('Transformer RegressionFilter failed on fit') in model 61 in generation 0: WindowRegression\n",
      "Model Number: 62 of 85 with model SeasonalNaive for Validation 3\n",
      "62 - SeasonalNaive with avg smape 25.71: \n",
      "Model Number: 63 of 85 with model ETS for Validation 3\n",
      "63 - ETS with avg smape 18.65: \n",
      "Model Number: 64 of 85 with model ConstantNaive for Validation 3\n",
      "64 - ConstantNaive with avg smape 19.99: \n",
      "Model Number: 65 of 85 with model ConstantNaive for Validation 3\n",
      "65 - ConstantNaive with avg smape 19.99: \n",
      "Model Number: 66 of 85 with model SeasonalNaive for Validation 3\n",
      "Template Eval Error: Exception('Transformer RegressionFilter failed on fit') in model 66 in generation 0: SeasonalNaive\n",
      "Model Number: 67 of 85 with model MultivariateRegression for Validation 3\n",
      "Template Eval Error: Exception('Transformer RegressionFilter failed on fit') in model 67 in generation 0: MultivariateRegression\n",
      "Model Number: 68 of 85 with model NVAR for Validation 3\n",
      "68 - NVAR with avg smape 19.65: \n",
      "Model Number: 69 of 85 with model NVAR for Validation 3\n",
      "69 - NVAR with avg smape 19.64: \n",
      "Model Number: 70 of 85 with model NVAR for Validation 3\n",
      "70 - NVAR with avg smape 19.64: \n",
      "Model Number: 71 of 85 with model MultivariateMotif for Validation 3\n",
      "Template Eval Error: ValueError('kth(=20) out of bounds (15)') in model 71 in generation 0: MultivariateMotif\n",
      "Model Number: 72 of 85 with model NVAR for Validation 3\n",
      "72 - NVAR with avg smape 22.88: \n",
      "Model Number: 73 of 85 with model MultivariateRegression for Validation 3\n",
      "Template Eval Error: Exception('Transformer RegressionFilter failed on fit') in model 73 in generation 0: MultivariateRegression\n",
      "Model Number: 74 of 85 with model ETS for Validation 3\n",
      "74 - ETS with avg smape 12.7: \n",
      "Model Number: 75 of 85 with model MultivariateRegression for Validation 3\n",
      "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "75 - MultivariateRegression with avg smape 25.28: \n",
      "Model Number: 76 of 85 with model UnivariateMotif for Validation 3\n",
      "Template Eval Error: ValueError('window shape cannot be larger than input array shape') in model 76 in generation 0: UnivariateMotif\n",
      "Model Number: 77 of 85 with model ETS for Validation 3\n",
      "77 - ETS with avg smape 18.34: \n",
      "Model Number: 78 of 85 with model ETS for Validation 3\n",
      "78 - ETS with avg smape 20.27: \n",
      "Model Number: 79 of 85 with model Theta for Validation 3\n",
      "79 - Theta with avg smape 42.42: \n",
      "Model Number: 80 of 85 with model Theta for Validation 3\n",
      "80 - Theta with avg smape 42.42: \n",
      "Model Number: 81 of 85 with model Theta for Validation 3\n",
      "81 - Theta with avg smape 34.03: \n",
      "Model Number: 82 of 85 with model ARIMA for Validation 3\n",
      "82 - ARIMA with avg smape 23.08: \n",
      "Model Number: 83 of 85 with model Theta for Validation 3\n",
      "83 - Theta with avg smape 42.06: \n",
      "Model Number: 84 of 85 with model FBProphet for Validation 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "19:04:33 - cmdstanpy - INFO - Chain [1] start processing\n",
      "19:04:53 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84 - FBProphet with avg smape 12.8: \n",
      "Model Number: 85 of 85 with model UnivariateRegression for Validation 3\n",
      "85 - UnivariateRegression with avg smape 18.07: \n",
      "TotalRuntime missing in 5!\n",
      "Validation Round: 1\n",
      "TotalRuntime missing in 0!\n",
      "Validation Round: 2\n",
      "TotalRuntime missing in 0!\n",
      "Validation Round: 3\n",
      "TotalRuntime missing in 0!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\crudek\\AppData\\Local\\Temp\\ipykernel_11000\\1533679110.py:63: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  all_predictions = all_predictions.append(temp_fcasts_ni)\n",
      " 21%|██▏       | 3/14 [07:27<27:15, 148.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 6 cpus for n_jobs.\n",
      "Data frequency is: MS, used frequency is: MS\n",
      "Model Number: 1 with model ARIMA in generation 0 of 3\n",
      "Model Number: 2 with model AverageValueNaive in generation 0 of 3\n",
      "Model Number: 3 with model AverageValueNaive in generation 0 of 3\n",
      "Model Number: 4 with model AverageValueNaive in generation 0 of 3\n",
      "Model Number: 5 with model DatepartRegression in generation 0 of 3\n",
      "Model Number: 6 with model DatepartRegression in generation 0 of 3\n",
      "Model Number: 7 with model DatepartRegression in generation 0 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 8 with model DatepartRegression in generation 0 of 3\n",
      "Template Eval Error: ImportError('Tensorflow not available, install with pip install tensorflow.') in model 8 in generation 0: DatepartRegression\n",
      "Model Number: 9 with model ETS in generation 0 of 3\n",
      "Model Number: 10 with model ETS in generation 0 of 3\n",
      "Model Number: 11 with model GLM in generation 0 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:541: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 12 with model GLM in generation 0 of 3\n",
      "Model Number: 13 with model GLS in generation 0 of 3\n",
      "Model Number: 14 with model GLS in generation 0 of 3\n",
      "Model Number: 15 with model GluonTS in generation 0 of 3\n",
      "Template Eval Error: ImportError('GluonTS installation is incompatible with AutoTS. The numpy version is sometimes the issue, try 1.23.1 {as of 06-2023}') in model 15 in generation 0: GluonTS\n",
      "Model Number: 16 with model GluonTS in generation 0 of 3\n",
      "Template Eval Error: ImportError('GluonTS installation is incompatible with AutoTS. The numpy version is sometimes the issue, try 1.23.1 {as of 06-2023}') in model 16 in generation 0: GluonTS\n",
      "Model Number: 17 with model GluonTS in generation 0 of 3\n",
      "Template Eval Error: ImportError('GluonTS installation is incompatible with AutoTS. The numpy version is sometimes the issue, try 1.23.1 {as of 06-2023}') in model 17 in generation 0: GluonTS\n",
      "Model Number: 18 with model GluonTS in generation 0 of 3\n",
      "Template Eval Error: ImportError('GluonTS installation is incompatible with AutoTS. The numpy version is sometimes the issue, try 1.23.1 {as of 06-2023}') in model 18 in generation 0: GluonTS\n",
      "Model Number: 19 with model GluonTS in generation 0 of 3\n",
      "Template Eval Error: ImportError('GluonTS installation is incompatible with AutoTS. The numpy version is sometimes the issue, try 1.23.1 {as of 06-2023}') in model 19 in generation 0: GluonTS\n",
      "Model Number: 20 with model LastValueNaive in generation 0 of 3\n",
      "Model Number: 21 with model LastValueNaive in generation 0 of 3\n",
      "Model Number: 22 with model LastValueNaive in generation 0 of 3\n",
      "Model Number: 23 with model LastValueNaive in generation 0 of 3\n",
      "Model Number: 24 with model SeasonalNaive in generation 0 of 3\n",
      "Model Number: 25 with model SeasonalNaive in generation 0 of 3\n",
      "Model Number: 26 with model SeasonalNaive in generation 0 of 3\n",
      "Model Number: 27 with model UnobservedComponents in generation 0 of 3\n",
      "Model Number: 28 with model UnobservedComponents in generation 0 of 3\n",
      "Model Number: 29 with model UnobservedComponents in generation 0 of 3\n",
      "Model Number: 30 with model VAR in generation 0 of 3\n",
      "Template Eval Error: ValueError('Only gave one variable to VAR') in model 30 in generation 0: VAR\n",
      "Model Number: 31 with model VAR in generation 0 of 3\n",
      "Template Eval Error: ValueError('Only gave one variable to VAR') in model 31 in generation 0: VAR\n",
      "Model Number: 32 with model VECM in generation 0 of 3\n",
      "Template Eval Error: ValueError('Only gave one variable to VECM') in model 32 in generation 0: VECM\n",
      "Model Number: 33 with model VECM in generation 0 of 3\n",
      "Template Eval Error: ValueError('Only gave one variable to VECM') in model 33 in generation 0: VECM\n",
      "Model Number: 34 with model WindowRegression in generation 0 of 3\n",
      "Model Number: 35 with model ConstantNaive in generation 0 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:541: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "19:04:56 - cmdstanpy - INFO - Chain [1] start processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 36 with model FBProphet in generation 0 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "19:04:56 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 37 with model GluonTS in generation 0 of 3\n",
      "Template Eval Error: ImportError('GluonTS installation is incompatible with AutoTS. The numpy version is sometimes the issue, try 1.23.1 {as of 06-2023}') in model 37 in generation 0: GluonTS\n",
      "Model Number: 38 with model MultivariateRegression in generation 0 of 3\n",
      "Model Number: 39 with model MultivariateRegression in generation 0 of 3\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000031 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Model Number: 40 with model DatepartRegression in generation 0 of 3\n",
      "Model Number: 41 with model SeasonalNaive in generation 0 of 3\n",
      "Model Number: 42 with model DatepartRegression in generation 0 of 3\n",
      "Model Number: 43 with model UnobservedComponents in generation 0 of 3\n",
      "Model Number: 44 with model UnobservedComponents in generation 0 of 3\n",
      "Model Number: 45 with model ETS in generation 0 of 3\n",
      "Model Number: 46 with model VECM in generation 0 of 3\n",
      "Template Eval Error: ValueError('Only gave one variable to VECM') in model 46 in generation 0: VECM\n",
      "Model Number: 47 with model ARDL in generation 0 of 3\n",
      "Model Number: 48 with model MultivariateMotif in generation 0 of 3\n",
      "Model Number: 49 with model MultivariateMotif in generation 0 of 3\n",
      "Model Number: 50 with model UnivariateMotif in generation 0 of 3\n",
      "Template Eval Error: ValueError('kth(=10) out of bounds (1)') in model 50 in generation 0: UnivariateMotif\n",
      "Model Number: 51 with model UnivariateMotif in generation 0 of 3\n",
      "Model Number: 52 with model SectionalMotif in generation 0 of 3\n",
      "Model Number: 53 with model SectionalMotif in generation 0 of 3\n",
      "Model Number: 54 with model MultivariateRegression in generation 0 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "19:04:59 - cmdstanpy - INFO - Chain [1] start processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 55 with model FBProphet in generation 0 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "19:05:20 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 56 with model SeasonalNaive in generation 0 of 3\n",
      "Model Number: 57 with model DatepartRegression in generation 0 of 3\n",
      "Model Number: 58 with model NVAR in generation 0 of 3\n",
      "Model Number: 59 with model Theta in generation 0 of 3\n",
      "Model Number: 60 with model UnivariateRegression in generation 0 of 3\n",
      "Template Eval Error: ValueError('Input X contains NaN.\\nDecisionTreeRegressor does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values') in model 60 in generation 0: UnivariateRegression\n",
      "Model Number: 61 with model ARCH in generation 0 of 3\n",
      "Template Eval Error: ImportError('`arch` package must be installed from pip') in model 61 in generation 0: ARCH\n",
      "Model Number: 62 with model ConstantNaive in generation 0 of 3\n",
      "Model Number: 63 with model LastValueNaive in generation 0 of 3\n",
      "Model Number: 64 with model AverageValueNaive in generation 0 of 3\n",
      "Model Number: 65 with model GLS in generation 0 of 3\n",
      "Model Number: 66 with model SeasonalNaive in generation 0 of 3\n",
      "Model Number: 67 with model GLM in generation 0 of 3\n",
      "Template Eval Error: ValueError('The first guess on the deviance function returned a nan.  This could be a boundary  problem and should be reported.') in model 67 in generation 0: GLM\n",
      "Model Number: 68 with model ETS in generation 0 of 3\n",
      "Model Number: 69 with model FBProphet in generation 0 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\statsmodels\\genmod\\families\\family.py:1367: ValueWarning: Negative binomial dispersion parameter alpha not set. Using default value alpha=1.0.\n",
      "  warnings.warn(\"Negative binomial dispersion parameter alpha not \"\n",
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\statsmodels\\genmod\\families\\family.py:1406: RuntimeWarning: invalid value encountered in log\n",
      "  resid_dev -= endog_alpha * np.log(endog_alpha / mu_alpha)\n",
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.146e+11, tolerance: 4.879e+07\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "19:05:21 - cmdstanpy - INFO - Chain [1] start processing\n",
      "19:05:21 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 70 with model GluonTS in generation 0 of 3\n",
      "Template Eval Error: ImportError('GluonTS installation is incompatible with AutoTS. The numpy version is sometimes the issue, try 1.23.1 {as of 06-2023}') in model 70 in generation 0: GluonTS\n",
      "Model Number: 71 with model UnobservedComponents in generation 0 of 3\n",
      "Model Number: 72 with model VAR in generation 0 of 3\n",
      "Template Eval Error: ValueError('Only gave one variable to VAR') in model 72 in generation 0: VAR\n",
      "Model Number: 73 with model VECM in generation 0 of 3\n",
      "Template Eval Error: ValueError('Only gave one variable to VECM') in model 73 in generation 0: VECM\n",
      "Model Number: 74 with model ARIMA in generation 0 of 3\n",
      "Model Number: 75 with model WindowRegression in generation 0 of 3\n",
      "Model Number: 76 with model DatepartRegression in generation 0 of 3\n",
      "Model Number: 77 with model UnivariateRegression in generation 0 of 3\n",
      "Model Number: 78 with model MultivariateRegression in generation 0 of 3\n",
      "Model Number: 79 with model UnivariateMotif in generation 0 of 3\n",
      "Model Number: 80 with model MultivariateMotif in generation 0 of 3\n",
      "Template Eval Error: ValueError('kth(=100) out of bounds (51)') in model 80 in generation 0: MultivariateMotif\n",
      "Model Number: 81 with model SectionalMotif in generation 0 of 3\n",
      "Template Eval Error: ValueError(\"Model returned NaN due to a preprocessing transformer {'fillna': 'rolling_mean', 'transformations': {'0': 'SeasonalDifference', '1': 'AlignLastValue', '2': 'AlignLastValue', '3': 'EWMAFilter'}, 'transformation_params': {'0': {'lag_1': 7, 'method': 'LastValue'}, '1': {'rows': 1, 'lag': 1, 'method': 'multiplicative', 'strength': 1.0, 'first_value_only': False}, '2': {'rows': 1, 'lag': 1, 'method': 'additive', 'strength': 1.0, 'first_value_only': False}, '3': {'span': 12}}}. fail_on_forecast_nan=True\") in model 81 in generation 0: SectionalMotif\n",
      "Model Number: 82 with model NVAR in generation 0 of 3\n",
      "Model Number: 83 with model Theta in generation 0 of 3\n",
      "Model Number: 84 with model ARDL in generation 0 of 3\n",
      "Model Number: 85 with model ARCH in generation 0 of 3\n",
      "Template Eval Error: ImportError('`arch` package must be installed from pip') in model 85 in generation 0: ARCH\n",
      "Model Number: 86 with model MetricMotif in generation 0 of 3\n",
      "Model Number: 87 with model AverageValueNaive in generation 0 of 3\n",
      "Model Number: 88 with model UnobservedComponents in generation 0 of 3\n",
      "Model Number: 89 with model AverageValueNaive in generation 0 of 3\n",
      "Model Number: 90 with model LastValueNaive in generation 0 of 3\n",
      "Model Number: 91 with model ARDL in generation 0 of 3\n",
      "Model Number: 92 with model WindowRegression in generation 0 of 3\n",
      "Model Number: 93 with model ConstantNaive in generation 0 of 3\n",
      "Model Number: 94 with model SeasonalNaive in generation 0 of 3\n",
      "Model Number: 95 with model ARDL in generation 0 of 3\n",
      "Template Eval Error: ValueError(\"ARDL series NET_SALES failed with error ValueError('The number of regressors (178) including deterministics, lags of the endog, lags of the exogenous, and fixed regressors is larger than the sample available for estimation (69).') exog train             weekend  quarter      epoch  month_1  month_2  month_3  month_4  \\\\\\nMONTH                                                                         \\n2016-01-01        0        1  2457388.5      1.0      0.0      0.0      0.0   \\n2016-02-01        0        1  2457419.5      0.0      1.0      0.0      0.0   \\n2016-03-01        0        1  2457448.5      0.0      0.0      1.0      0.0   \\n2016-04-01        0        2  2457479.5      0.0      0.0      0.0      1.0   \\n2016-05-01        1        2  2457509.5      0.0      0.0      0.0      0.0   \\n...             ...      ...        ...      ...      ...      ...      ...   \\n2021-08-01        1        3  2459427.5      0.0      0.0      0.0      0.0   \\n2021-09-01        0        3  2459458.5      0.0      0.0      0.0      0.0   \\n2021-10-01        0        4  2459488.5      0.0      0.0      0.0      0.0   \\n2021-11-01        0        4  2459519.5      0.0      0.0      0.0      0.0   \\n2021-12-01        0        4  2459549.5      0.0      0.0      0.0      0.0   \\n\\n            month_5  month_6  month_7  ...  day_27  day_28  day_29  day_30  \\\\\\nMONTH                                  ...                                   \\n2016-01-01      0.0      0.0      0.0  ...     0.0     0.0     0.0     0.0   \\n2016-02-01      0.0      0.0      0.0  ...     0.0     0.0     0.0     0.0   \\n2016-03-01      0.0      0.0      0.0  ...     0.0     0.0     0.0     0.0   \\n2016-04-01      0.0      0.0      0.0  ...     0.0     0.0     0.0     0.0   \\n2016-05-01      1.0      0.0      0.0  ...     0.0     0.0     0.0     0.0   \\n...             ...      ...      ...  ...     ...     ...     ...     ...   \\n2021-08-01      0.0      0.0      0.0  ...     0.0     0.0     0.0     0.0   \\n2021-09-01      0.0      0.0      0.0  ...     0.0     0.0     0.0     0.0   \\n2021-10-01      0.0      0.0      0.0  ...     0.0     0.0     0.0     0.0   \\n2021-11-01      0.0      0.0      0.0  ...     0.0     0.0     0.0     0.0   \\n2021-12-01      0.0      0.0      0.0  ...     0.0     0.0     0.0     0.0   \\n\\n            day_31  weekdayofmonth_1  weekdayofmonth_2  weekdayofmonth_3  \\\\\\nMONTH                                                                      \\n2016-01-01     0.0               1.0               0.0               0.0   \\n2016-02-01     0.0               1.0               0.0               0.0   \\n2016-03-01     0.0               1.0               0.0               0.0   \\n2016-04-01     0.0               1.0               0.0               0.0   \\n2016-05-01     0.0               1.0               0.0               0.0   \\n...            ...               ...               ...               ...   \\n2021-08-01     0.0               1.0               0.0               0.0   \\n2021-09-01     0.0               1.0               0.0               0.0   \\n2021-10-01     0.0               1.0               0.0               0.0   \\n2021-11-01     0.0               1.0               0.0               0.0   \\n2021-12-01     0.0               1.0               0.0               0.0   \\n\\n            weekdayofmonth_4  weekdayofmonth_5  \\nMONTH                                           \\n2016-01-01               0.0               0.0  \\n2016-02-01               0.0               0.0  \\n2016-03-01               0.0               0.0  \\n2016-04-01               0.0               0.0  \\n2016-05-01               0.0               0.0  \\n...                      ...               ...  \\n2021-08-01               0.0               0.0  \\n2021-09-01               0.0               0.0  \\n2021-10-01               0.0               0.0  \\n2021-11-01               0.0               0.0  \\n2021-12-01               0.0               0.0  \\n\\n[72 rows x 58 columns] and predict             weekend  quarter      epoch  month_1  month_2  month_3  month_4  \\\\\\n2022-01-01        1        1  2459580.5      1.0      0.0      0.0      0.0   \\n2022-02-01        0        1  2459611.5      0.0      1.0      0.0      0.0   \\n2022-03-01        0        1  2459639.5      0.0      0.0      1.0      0.0   \\n2022-04-01        0        2  2459670.5      0.0      0.0      0.0      1.0   \\n2022-05-01        1        2  2459700.5      0.0      0.0      0.0      0.0   \\n2022-06-01        0        2  2459731.5      0.0      0.0      0.0      0.0   \\n2022-07-01        0        3  2459761.5      0.0      0.0      0.0      0.0   \\n2022-08-01        0        3  2459792.5      0.0      0.0      0.0      0.0   \\n2022-09-01        0        3  2459823.5      0.0      0.0      0.0      0.0   \\n2022-10-01        1        4  2459853.5      0.0      0.0      0.0      0.0   \\n2022-11-01        0        4  2459884.5      0.0      0.0      0.0      0.0   \\n2022-12-01        0        4  2459914.5      0.0      0.0      0.0      0.0   \\n\\n            month_5  month_6  month_7  ...  day_27  day_28  day_29  day_30  \\\\\\n2022-01-01      0.0      0.0      0.0  ...     0.0     0.0     0.0     0.0   \\n2022-02-01      0.0      0.0      0.0  ...     0.0     0.0     0.0     0.0   \\n2022-03-01      0.0      0.0      0.0  ...     0.0     0.0     0.0     0.0   \\n2022-04-01      0.0      0.0      0.0  ...     0.0     0.0     0.0     0.0   \\n2022-05-01      1.0      0.0      0.0  ...     0.0     0.0     0.0     0.0   \\n2022-06-01      0.0      1.0      0.0  ...     0.0     0.0     0.0     0.0   \\n2022-07-01      0.0      0.0      1.0  ...     0.0     0.0     0.0     0.0   \\n2022-08-01      0.0      0.0      0.0  ...     0.0     0.0     0.0     0.0   \\n2022-09-01      0.0      0.0      0.0  ...     0.0     0.0     0.0     0.0   \\n2022-10-01      0.0      0.0      0.0  ...     0.0     0.0     0.0     0.0   \\n2022-11-01      0.0      0.0      0.0  ...     0.0     0.0     0.0     0.0   \\n2022-12-01      0.0      0.0      0.0  ...     0.0     0.0     0.0     0.0   \\n\\n            day_31  weekdayofmonth_1  weekdayofmonth_2  weekdayofmonth_3  \\\\\\n2022-01-01     0.0               1.0               0.0               0.0   \\n2022-02-01     0.0               1.0               0.0               0.0   \\n2022-03-01     0.0               1.0               0.0               0.0   \\n2022-04-01     0.0               1.0               0.0               0.0   \\n2022-05-01     0.0               1.0               0.0               0.0   \\n2022-06-01     0.0               1.0               0.0               0.0   \\n2022-07-01     0.0               1.0               0.0               0.0   \\n2022-08-01     0.0               1.0               0.0               0.0   \\n2022-09-01     0.0               1.0               0.0               0.0   \\n2022-10-01     0.0               1.0               0.0               0.0   \\n2022-11-01     0.0               1.0               0.0               0.0   \\n2022-12-01     0.0               1.0               0.0               0.0   \\n\\n            weekdayofmonth_4  weekdayofmonth_5  \\n2022-01-01               0.0               0.0  \\n2022-02-01               0.0               0.0  \\n2022-03-01               0.0               0.0  \\n2022-04-01               0.0               0.0  \\n2022-05-01               0.0               0.0  \\n2022-06-01               0.0               0.0  \\n2022-07-01               0.0               0.0  \\n2022-08-01               0.0               0.0  \\n2022-09-01               0.0               0.0  \\n2022-10-01               0.0               0.0  \\n2022-11-01               0.0               0.0  \\n2022-12-01               0.0               0.0  \\n\\n[12 rows x 58 columns]\") in model 95 in generation 0: ARDL\n",
      "Model Number: 96 with model FBProphet in generation 0 of 3\n",
      "No anomalies detected.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "19:05:23 - cmdstanpy - INFO - Chain [1] start processing\n",
      "19:05:23 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 97 with model ConstantNaive in generation 0 of 3\n",
      "Model Number: 98 with model ConstantNaive in generation 0 of 3\n",
      "Model Number: 99 with model UnobservedComponents in generation 0 of 3\n",
      "Model Number: 100 with model ConstantNaive in generation 0 of 3\n",
      "Model Number: 101 with model VAR in generation 0 of 3\n",
      "Template Eval Error: ValueError('Only gave one variable to VAR') in model 101 in generation 0: VAR\n",
      "Model Number: 102 with model ETS in generation 0 of 3\n",
      "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
      "ETS failed on NET_SALES with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
      "Model Number: 103 with model Theta in generation 0 of 3\n",
      "Model Number: 104 with model DatepartRegression in generation 0 of 3\n",
      "Template Eval Error: ValueError('Model DatepartRegression returned NaN for one or more series. fail_on_forecast_nan=True') in model 104 in generation 0: DatepartRegression\n",
      "Model Number: 105 with model GLM in generation 0 of 3\n",
      "Model Number: 106 with model ARCH in generation 0 of 3\n",
      "Template Eval Error: Exception('Transformer Detrend failed on fit') in model 106 in generation 0: ARCH\n",
      "Model Number: 107 with model AverageValueNaive in generation 0 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\neighbors\\_regression.py:494: UserWarning: One or more samples have no neighbors within specified radius; predicting NaN.\n",
      "  warnings.warn(empty_warning_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 108 with model MetricMotif in generation 0 of 3\n",
      "Model Number: 109 with model ETS in generation 0 of 3\n",
      "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
      "ETS failed on NET_SALES with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
      "Template Eval Error: Exception('Transformer DifferencedTransformer failed on inverse') in model 109 in generation 0: ETS\n",
      "Model Number: 110 with model ETS in generation 0 of 3\n",
      "ETS error ValueError('Cannot compute initial seasonals using heuristic method with less than two full seasonal cycles in the data.')\n",
      "ETS failed on NET_SALES with ValueError('Cannot compute initial seasonals using heuristic method with less than two full seasonal cycles in the data.')\n",
      "Template Eval Error: Exception('Transformer AlignLastValue failed on inverse') in model 110 in generation 0: ETS\n",
      "Model Number: 111 with model SeasonalNaive in generation 0 of 3\n",
      "Model Number: 112 with model ARCH in generation 0 of 3\n",
      "Template Eval Error: ImportError('`arch` package must be installed from pip') in model 112 in generation 0: ARCH\n",
      "Model Number: 113 with model SectionalMotif in generation 0 of 3\n",
      "Model Number: 114 with model SeasonalNaive in generation 0 of 3\n",
      "Model Number: 115 with model UnivariateRegression in generation 0 of 3\n",
      "Model Number: 116 with model VAR in generation 0 of 3\n",
      "Template Eval Error: ValueError('Only gave one variable to VAR') in model 116 in generation 0: VAR\n",
      "Model Number: 117 with model GluonTS in generation 0 of 3\n",
      "Template Eval Error: ImportError('GluonTS installation is incompatible with AutoTS. The numpy version is sometimes the issue, try 1.23.1 {as of 06-2023}') in model 117 in generation 0: GluonTS\n",
      "Model Number: 118 with model GLM in generation 0 of 3\n",
      "Template Eval Error: ValueError('NaN, inf or invalid value detected in weights, estimation infeasible.') in model 118 in generation 0: GLM\n",
      "Model Number: 119 with model MultivariateMotif in generation 0 of 3\n",
      "Model Number: 120 with model AverageValueNaive in generation 0 of 3\n",
      "Model Number: 121 with model ConstantNaive in generation 0 of 3\n",
      "Model Number: 122 with model ARCH in generation 0 of 3"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\statsmodels\\genmod\\families\\family.py:1367: ValueWarning: Negative binomial dispersion parameter alpha not set. Using default value alpha=1.0.\n",
      "  warnings.warn(\"Negative binomial dispersion parameter alpha not \"\n",
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\statsmodels\\genmod\\families\\family.py:1402: RuntimeWarning: divide by zero encountered in divide\n",
      "  endog_mu = self._clean(endog / mu)\n",
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\statsmodels\\genmod\\families\\family.py:1406: RuntimeWarning: invalid value encountered in log\n",
      "  resid_dev -= endog_alpha * np.log(endog_alpha / mu_alpha)\n",
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\statsmodels\\genmod\\families\\links.py:527: RuntimeWarning: overflow encountered in exp\n",
      "  return np.exp(z)\n",
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\statsmodels\\genmod\\families\\family.py:1406: RuntimeWarning: divide by zero encountered in log\n",
      "  resid_dev -= endog_alpha * np.log(endog_alpha / mu_alpha)\n",
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\numpy\\core\\fromnumeric.py:86: RuntimeWarning: invalid value encountered in reduce\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n",
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\statsmodels\\genmod\\families\\family.py:143: RuntimeWarning: invalid value encountered in multiply\n",
      "  return 1. / (self.link.deriv(mu)**2 * self.variance(mu))\n",
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\statsmodels\\genmod\\generalized_linear_model.py:1243: RuntimeWarning: invalid value encountered in multiply\n",
      "  wlsendog = (lin_pred + self.family.link.deriv(mu) * (self.endog-mu)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Template Eval Error: ImportError('`arch` package must be installed from pip') in model 122 in generation 0: ARCH\n",
      "Model Number: 123 with model GLS in generation 0 of 3\n",
      "Model Number: 124 with model LastValueNaive in generation 0 of 3\n",
      "Template Eval Error: Exception('Transformer RegressionFilter failed on fit') in model 124 in generation 0: LastValueNaive\n",
      "Model Number: 125 with model UnobservedComponents in generation 0 of 3\n",
      "Model Number: 126 with model LastValueNaive in generation 0 of 3\n",
      "Model Number: 127 with model SectionalMotif in generation 0 of 3\n",
      "Template Eval Error: ValueError('Unknown Distance Metric: kulsinski') in model 127 in generation 0: SectionalMotif\n",
      "Model Number: 128 with model GLS in generation 0 of 3\n",
      "Model Number: 129 with model Theta in generation 0 of 3\n",
      "Model Number: 130 with model UnobservedComponents in generation 0 of 3\n",
      "Model Number: 131 with model WindowRegression in generation 0 of 3\n",
      "Template Eval Error: ValueError('Input X contains NaN.\\nBayesianRidge does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values') in model 131 in generation 0: WindowRegression\n",
      "Model Number: 132 with model NVAR in generation 0 of 3\n",
      "Model Number: 133 with model SeasonalNaive in generation 0 of 3\n",
      "Model Number: 134 with model UnobservedComponents in generation 0 of 3\n",
      "Template Eval Error: Exception('Transformer Detrend failed on fit') in model 134 in generation 0: UnobservedComponents\n",
      "Model Number: 135 with model GLS in generation 0 of 3\n",
      "Model Number: 136 with model MetricMotif in generation 0 of 3\n",
      "Model Number: 137 with model VAR in generation 0 of 3\n",
      "Template Eval Error: ValueError('Only gave one variable to VAR') in model 137 in generation 0: VAR\n",
      "Model Number: 138 with model WindowRegression in generation 0 of 3\n",
      "Template Eval Error: ImportError('Tensorflow not available, install with pip install tensorflow.') in model 138 in generation 0: WindowRegression\n",
      "Model Number: 139 with model GLM in generation 0 of 3\n",
      "Model Number: 140 with model NVAR in generation 0 of 3\n",
      "Model Number: 141 with model VAR in generation 0 of 3\n",
      "Template Eval Error: ValueError('Only gave one variable to VAR') in model 141 in generation 0: VAR\n",
      "Model Number: 142 with model DatepartRegression in generation 0 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\statsmodels\\genmod\\families\\links.py:198: RuntimeWarning: overflow encountered in exp\n",
      "  t = np.exp(-z)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 143 with model GLS in generation 0 of 3\n",
      "Model Number: 144 with model DatepartRegression in generation 0 of 3\n",
      "Template Eval Error: ValueError('Input X contains NaN.\\nExtraTreesRegressor does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values') in model 144 in generation 0: DatepartRegression\n",
      "Model Number: 145 with model VAR in generation 0 of 3\n",
      "Template Eval Error: ValueError('Only gave one variable to VAR') in model 145 in generation 0: VAR\n",
      "Model Number: 146 with model Theta in generation 0 of 3\n",
      "Model Number: 147 with model ETS in generation 0 of 3\n",
      "ETS error ValueError('Cannot compute initial seasonals using heuristic method with less than two full seasonal cycles in the data.')\n",
      "ETS failed on NET_SALES with ValueError('Cannot compute initial seasonals using heuristic method with less than two full seasonal cycles in the data.')\n",
      "Model Number: 148 with model ConstantNaive in generation 0 of 3\n",
      "Model Number: 149 with model ARDL in generation 0 of 3\n",
      "Model Number: 150 with model SectionalMotif in generation 0 of 3\n",
      "Model Number: 151 with model VAR in generation 0 of 3\n",
      "Model Number: 152 with model DatepartRegression in generation 0 of 3\n",
      "Model Number: 153 with model Theta in generation 0 of 3\n",
      "Model Number: 154 with model MetricMotif in generation 0 of 3\n",
      "Model Number: 155 with model DatepartRegression in generation 0 of 3\n",
      "Model Number: 156 with model GLM in generation 0 of 3\n",
      "Model Number: 157 with model GluonTS in generation 0 of 3\n",
      "Template Eval Error: ImportError('GluonTS installation is incompatible with AutoTS. The numpy version is sometimes the issue, try 1.23.1 {as of 06-2023}') in model 157 in generation 0: GluonTS\n",
      "Model Number: 158 with model DatepartRegression in generation 0 of 3\n",
      "Template Eval Error: Exception('Transformer AlignLastValue failed on inverse') in model 158 in generation 0: DatepartRegression\n",
      "Model Number: 159 with model NVAR in generation 0 of 3\n",
      "Model Number: 160 with model GLS in generation 0 of 3\n",
      "Model Number: 161 with model SectionalMotif in generation 0 of 3\n",
      "Model Number: 162 with model FBProphet in generation 0 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\statsmodels\\genmod\\families\\links.py:198: RuntimeWarning: overflow encountered in exp\n",
      "  t = np.exp(-z)\n",
      "19:05:26 - cmdstanpy - INFO - Chain [1] start processing\n",
      "19:05:27 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 163 with model ETS in generation 0 of 3\n",
      "Model Number: 164 with model VAR in generation 0 of 3\n",
      "Template Eval Error: ValueError('Only gave one variable to VAR') in model 164 in generation 0: VAR\n",
      "Model Number: 165 with model MultivariateMotif in generation 0 of 3\n",
      "Model Number: 166 with model VAR in generation 0 of 3\n",
      "Template Eval Error: ValueError('Only gave one variable to VAR') in model 166 in generation 0: VAR\n",
      "Model Number: 167 with model ARIMA in generation 0 of 3\n",
      "Model Number: 168 with model UnobservedComponents in generation 0 of 3\n",
      "Model Number: 169 with model UnivariateMotif in generation 0 of 3\n",
      "Template Eval Error: ValueError('kth(=100) out of bounds (51)') in model 169 in generation 0: UnivariateMotif\n",
      "Model Number: 170 with model VAR in generation 0 of 3\n",
      "Template Eval Error: ValueError('Only gave one variable to VAR') in model 170 in generation 0: VAR\n",
      "Model Number: 171 with model Theta in generation 0 of 3\n",
      "Model Number: 172 with model MultivariateMotif in generation 0 of 3\n",
      "Model Number: 173 with model UnobservedComponents in generation 0 of 3\n",
      "Model Number: 174 with model WindowRegression in generation 0 of 3\n",
      "Model Number: 175 with model SeasonalNaive in generation 0 of 3\n",
      "Model Number: 176 with model ARDL in generation 0 of 3\n",
      "Model Number: 177 with model GLS in generation 0 of 3\n",
      "Model Number: 178 with model SectionalMotif in generation 0 of 3\n",
      "Model Number: 179 with model ARDL in generation 0 of 3\n",
      "Model Number: 180 with model MultivariateMotif in generation 0 of 3\n",
      "Model Number: 181 with model ARCH in generation 0 of 3\n",
      "Template Eval Error: ImportError('`arch` package must be installed from pip') in model 181 in generation 0: ARCH\n",
      "Model Number: 182 with model SectionalMotif in generation 0 of 3\n",
      "Model Number: 183 with model ARIMA in generation 0 of 3\n",
      "Model Number: 184 with model DatepartRegression in generation 0 of 3\n",
      "Model Number: 185 with model ETS in generation 0 of 3\n",
      "ETS error ValueError('Cannot compute initial seasonals using heuristic method with less than two full seasonal cycles in the data.')\n",
      "ETS failed on NET_SALES with ValueError('Cannot compute initial seasonals using heuristic method with less than two full seasonal cycles in the data.')\n",
      "Model Number: 186 with model VECM in generation 0 of 3\n",
      "Template Eval Error: ValueError('Only gave one variable to VECM') in model 186 in generation 0: VECM\n",
      "New Generation: 1 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.588e-02, tolerance: 9.014e-04\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 187 with model ConstantNaive in generation 1 of 3\n",
      "Model Number: 188 with model MetricMotif in generation 1 of 3\n",
      "Model Number: 189 with model GLS in generation 1 of 3\n",
      "Model Number: 190 with model NVAR in generation 1 of 3\n",
      "Model Number: 191 with model SeasonalNaive in generation 1 of 3\n",
      "Model Number: 192 with model UnivariateRegression in generation 1 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\decomposition\\_fastica.py:708: FutureWarning: Starting in v1.3, whiten=True should be specified as whiten='arbitrary-variance' (its current behaviour). This behavior is deprecated in 1.1 and will raise ValueError in 1.3.\n",
      "  return self._fit_transform(X, compute_sources=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 193 with model NVAR in generation 1 of 3\n",
      "Model Number: 194 with model NVAR in generation 1 of 3\n",
      "Model Number: 195 with model FBProphet in generation 1 of 3\n",
      "Template Eval Error: Exception('Transformer BTCD failed on fit') in model 195 in generation 1: FBProphet\n",
      "Model Number: 196 with model MetricMotif in generation 1 of 3\n",
      "Model Number: 197 with model AverageValueNaive in generation 1 of 3\n",
      "Model Number: 198 with model ConstantNaive in generation 1 of 3\n",
      "Model Number: 199 with model UnobservedComponents in generation 1 of 3\n",
      "Model Number: 200 with model ConstantNaive in generation 1 of 3\n",
      "Template Eval Error: Exception('Transformer PowerTransformer failed on fit') in model 200 in generation 1: ConstantNaive\n",
      "Model Number: 201 with model AverageValueNaive in generation 1 of 3\n",
      "Model Number: 202 with model NVAR in generation 1 of 3\n",
      "Model Number: 203 with model ETS in generation 1 of 3\n",
      "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
      "ETS failed on NET_SALES with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
      "Model Number: 204 with model SectionalMotif in generation 1 of 3\n",
      "Model Number: 205 with model UnobservedComponents in generation 1 of 3\n",
      "Model Number: 206 with model WindowRegression in generation 1 of 3\n",
      "Model Number: 207 with model Theta in generation 1 of 3\n",
      "Model Number: 208 with model SectionalMotif in generation 1 of 3\n",
      "Model Number: 209 with model UnobservedComponents in generation 1 of 3\n",
      "Model Number: 210 with model GLS in generation 1 of 3\n",
      "Model Number: 211 with model Theta in generation 1 of 3\n",
      "Model Number: 212 with model UnivariateMotif in generation 1 of 3\n",
      "Model Number: 213 with model LastValueNaive in generation 1 of 3\n",
      "Model Number: 214 with model DatepartRegression in generation 1 of 3\n",
      "Model Number: 215 with model FBProphet in generation 1 of 3\n",
      "No anomalies detected.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "19:05:30 - cmdstanpy - INFO - Chain [1] start processing\n",
      "19:05:30 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 216 with model SeasonalNaive in generation 1 of 3\n",
      "Model Number: 217 with model DatepartRegression in generation 1 of 3\n",
      "Template Eval Error: ValueError('Model DatepartRegression returned NaN for one or more series. fail_on_forecast_nan=True') in model 217 in generation 1: DatepartRegression\n",
      "Model Number: 218 with model ConstantNaive in generation 1 of 3\n",
      "Model Number: 219 with model GLM in generation 1 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\neighbors\\_regression.py:494: UserWarning: One or more samples have no neighbors within specified radius; predicting NaN.\n",
      "  warnings.warn(empty_warning_msg)\n",
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\decomposition\\_fastica.py:708: FutureWarning: Starting in v1.3, whiten=True should be specified as whiten='arbitrary-variance' (its current behaviour). This behavior is deprecated in 1.1 and will raise ValueError in 1.3.\n",
      "  return self._fit_transform(X, compute_sources=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 220 with model MultivariateRegression in generation 1 of 3\n",
      "Template Eval Error: ValueError(\"loss='poisson' requires non-negative y and sum(y) > 0.\") in model 220 in generation 1: MultivariateRegression\n",
      "Model Number: 221 with model ConstantNaive in generation 1 of 3\n",
      "Model Number: 222 with model ARDL in generation 1 of 3\n",
      "Model Number: 223 with model WindowRegression in generation 1 of 3\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000036 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Model Number: 224 with model SeasonalNaive in generation 1 of 3\n",
      "Model Number: 225 with model SectionalMotif in generation 1 of 3\n",
      "Model Number: 226 with model SeasonalNaive in generation 1 of 3\n",
      "Model Number: 227 with model GLM in generation 1 of 3\n",
      "Template Eval Error: Exception('Transformer AlignLastValue failed on inverse') in model 227 in generation 1: GLM\n",
      "Model Number: 228 with model DatepartRegression in generation 1 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\linear_model\\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.48343e-24): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\statsmodels\\genmod\\families\\links.py:198: RuntimeWarning: overflow encountered in exp\n",
      "  t = np.exp(-z)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 229 with model ConstantNaive in generation 1 of 3\n",
      "Model Number: 230 with model SeasonalNaive in generation 1 of 3\n",
      "Model Number: 231 with model MultivariateMotif in generation 1 of 3\n",
      "Model Number: 232 with model UnobservedComponents in generation 1 of 3\n",
      "Template Eval Error: Exception('Transformer BTCD failed on fit') in model 232 in generation 1: UnobservedComponents\n",
      "Model Number: 233 with model ETS in generation 1 of 3\n",
      "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
      "ETS failed on NET_SALES with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
      "Model Number: 234 with model MultivariateMotif in generation 1 of 3\n",
      "Model Number: 235 with model LastValueNaive in generation 1 of 3\n",
      "Model Number: 236 with model UnobservedComponents in generation 1 of 3\n",
      "Model Number: 237 with model GLS in generation 1 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\decomposition\\_fastica.py:708: FutureWarning: Starting in v1.3, whiten=True should be specified as whiten='arbitrary-variance' (its current behaviour). This behavior is deprecated in 1.1 and will raise ValueError in 1.3.\n",
      "  return self._fit_transform(X, compute_sources=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 238 with model ARDL in generation 1 of 3\n",
      "Model Number: 239 with model NVAR in generation 1 of 3\n",
      "Model Number: 240 with model MultivariateRegression in generation 1 of 3\n",
      "Model Number: 241 with model SeasonalNaive in generation 1 of 3\n",
      "Template Eval Error: Exception('Transformer AlignLastValue failed on inverse') in model 241 in generation 1: SeasonalNaive\n",
      "Model Number: 242 with model ARDL in generation 1 of 3\n",
      "Model Number: 243 with model SectionalMotif in generation 1 of 3\n",
      "Model Number: 244 with model UnobservedComponents in generation 1 of 3\n",
      "Model Number: 245 with model LastValueNaive in generation 1 of 3\n",
      "Template Eval Error: Exception('Transformer Cointegration failed on fit') in model 245 in generation 1: LastValueNaive\n",
      "Model Number: 246 with model ETS in generation 1 of 3\n",
      "Model Number: 247 with model ARIMA in generation 1 of 3\n",
      "Model Number: 248 with model SectionalMotif in generation 1 of 3\n",
      "Template Eval Error: ValueError('kth(=3) out of bounds (2)') in model 248 in generation 1: SectionalMotif\n",
      "Model Number: 249 with model MetricMotif in generation 1 of 3\n",
      "Model Number: 250 with model ETS in generation 1 of 3\n",
      "ETS error ValueError('Cannot compute initial seasonals using heuristic method with less than two full seasonal cycles in the data.')\n",
      "ETS failed on NET_SALES with ValueError('Cannot compute initial seasonals using heuristic method with less than two full seasonal cycles in the data.')\n",
      "Model Number: 251 with model AverageValueNaive in generation 1 of 3\n",
      "Model Number: 252 with model MetricMotif in generation 1 of 3\n",
      "Model Number: 253 with model SeasonalNaive in generation 1 of 3\n",
      "Model Number: 254 with model ETS in generation 1 of 3\n",
      "ETS error ValueError('Cannot compute initial seasonals using heuristic method with less than two full seasonal cycles in the data.')\n",
      "ETS failed on NET_SALES with ValueError('Cannot compute initial seasonals using heuristic method with less than two full seasonal cycles in the data.')\n",
      "Model Number: 255 with model DatepartRegression in generation 1 of 3\n",
      "Model Number: 256 with model DatepartRegression in generation 1 of 3\n",
      "Template Eval Error: Exception('Transformer BTCD failed on fit') in model 256 in generation 1: DatepartRegression\n",
      "Model Number: 257 with model LastValueNaive in generation 1 of 3\n",
      "Model Number: 258 with model ARDL in generation 1 of 3\n",
      "Model Number: 259 with model ARIMA in generation 1 of 3\n",
      "Model Number: 260 with model Theta in generation 1 of 3\n",
      "Model Number: 261 with model GLS in generation 1 of 3\n",
      "Model Number: 262 with model UnobservedComponents in generation 1 of 3\n",
      "Model Number: 263 with model NVAR in generation 1 of 3\n",
      "Model Number: 264 with model SectionalMotif in generation 1 of 3\n",
      "Template Eval Error: ValueError('kth(=100) out of bounds (51)') in model 264 in generation 1: SectionalMotif\n",
      "Model Number: 265 with model UnobservedComponents in generation 1 of 3\n",
      "Model Number: 266 with model FBProphet in generation 1 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.532e+11, tolerance: 8.799e+07\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "19:05:33 - cmdstanpy - INFO - Chain [1] start processing\n",
      "19:05:34 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 267 with model UnobservedComponents in generation 1 of 3\n",
      "Model Number: 268 with model GLM in generation 1 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\statsmodels\\genmod\\families\\links.py:198: RuntimeWarning: overflow encountered in exp\n",
      "  t = np.exp(-z)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 269 with model MetricMotif in generation 1 of 3\n",
      "Model Number: 270 with model UnobservedComponents in generation 1 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\linear_model\\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.48343e-24): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Template Eval Error: ValueError('Model UnobservedComponents returned NaN for one or more series. fail_on_forecast_nan=True') in model 270 in generation 1: UnobservedComponents\n",
      "Model Number: 271 with model UnobservedComponents in generation 1 of 3\n",
      "Model Number: 272 with model SectionalMotif in generation 1 of 3\n",
      "Template Eval Error: ValueError('kth(=10) out of bounds (6)') in model 272 in generation 1: SectionalMotif\n",
      "Model Number: 273 with model UnivariateMotif in generation 1 of 3\n",
      "Model Number: 274 with model DatepartRegression in generation 1 of 3\n",
      "Template Eval Error: ImportError('Tensorflow not available, install with pip install tensorflow.') in model 274 in generation 1: DatepartRegression\n",
      "Model Number: 275 with model SectionalMotif in generation 1 of 3\n",
      "Model Number: 276 with model SectionalMotif in generation 1 of 3\n",
      "Template Eval Error: ValueError('kth(=20) out of bounds (6)') in model 276 in generation 1: SectionalMotif\n",
      "Model Number: 277 with model SeasonalNaive in generation 1 of 3\n",
      "Model Number: 278 with model Theta in generation 1 of 3\n",
      "Model Number: 279 with model LastValueNaive in generation 1 of 3\n",
      "Model Number: 280 with model MultivariateMotif in generation 1 of 3\n",
      "Model Number: 281 with model GLM in generation 1 of 3\n",
      "Model Number: 282 with model MetricMotif in generation 1 of 3\n",
      "Model Number: 283 with model ETS in generation 1 of 3\n",
      "Model Number: 284 with model GLS in generation 1 of 3\n",
      "Model Number: 285 with model SeasonalNaive in generation 1 of 3\n",
      "Template Eval Error: Exception('Transformer Detrend failed on fit') in model 285 in generation 1: SeasonalNaive\n",
      "Model Number: 286 with model DatepartRegression in generation 1 of 3\n",
      "Model Number: 287 with model WindowRegression in generation 1 of 3\n",
      "Model Number: 288 with model ConstantNaive in generation 1 of 3\n",
      "Model Number: 289 with model GLS in generation 1 of 3\n",
      "Template Eval Error: Exception('Transformer AlignLastValue failed on inverse') in model 289 in generation 1: GLS\n",
      "Model Number: 290 with model DatepartRegression in generation 1 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 291 with model ARDL in generation 1 of 3\n",
      "Model Number: 292 with model MetricMotif in generation 1 of 3\n",
      "Model Number: 293 with model DatepartRegression in generation 1 of 3\n",
      "Model Number: 294 with model MultivariateRegression in generation 1 of 3\n",
      "Model Number: 295 with model ARIMA in generation 1 of 3\n",
      "Model Number: 296 with model WindowRegression in generation 1 of 3\n",
      "Model Number: 297 with model Theta in generation 1 of 3\n",
      "Model Number: 298 with model GLS in generation 1 of 3\n",
      "Model Number: 299 with model ETS in generation 1 of 3\n",
      "Model Number: 300 with model SeasonalNaive in generation 1 of 3\n",
      "Template Eval Error: Exception('Transformer AlignLastValue failed on inverse') in model 300 in generation 1: SeasonalNaive\n",
      "Model Number: 301 with model MultivariateMotif in generation 1 of 3\n",
      "Model Number: 302 with model SeasonalNaive in generation 1 of 3\n",
      "Model Number: 303 with model SectionalMotif in generation 1 of 3\n",
      "Model Number: 304 with model LastValueNaive in generation 1 of 3\n",
      "Model Number: 305 with model MultivariateMotif in generation 1 of 3\n",
      "Template Eval Error: LinAlgError('Singular matrix') in model 305 in generation 1: MultivariateMotif\n",
      "Model Number: 306 with model SectionalMotif in generation 1 of 3\n",
      "Template Eval Error: ValueError('kth(=100) out of bounds (51)') in model 306 in generation 1: SectionalMotif\n",
      "Model Number: 307 with model DatepartRegression in generation 1 of 3\n",
      "Model Number: 308 with model UnobservedComponents in generation 1 of 3\n",
      "Model Number: 309 with model UnivariateMotif in generation 1 of 3\n",
      "Model Number: 310 with model DatepartRegression in generation 1 of 3\n",
      "Model Number: 311 with model SeasonalNaive in generation 1 of 3\n",
      "New Generation: 2 of 3\n",
      "Model Number: 312 with model NVAR in generation 2 of 3\n",
      "Model Number: 313 with model UnivariateRegression in generation 2 of 3\n",
      "Template Eval Error: Exception('Transformer AlignLastValue failed on inverse') in model 313 in generation 2: UnivariateRegression\n",
      "Model Number: 314 with model ETS in generation 2 of 3\n",
      "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
      "ETS failed on NET_SALES with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
      "Model Number: 315 with model GLS in generation 2 of 3\n",
      "Model Number: 316 with model DatepartRegression in generation 2 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:2418: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.97398578701635, tolerance: 0.01801897428711782\n",
      "  ) = cd_fast.enet_coordinate_descent_multi_task(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 317 with model GLS in generation 2 of 3\n",
      "Model Number: 318 with model ETS in generation 2 of 3\n",
      "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
      "ETS failed on NET_SALES with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
      "Model Number: 319 with model ConstantNaive in generation 2 of 3\n",
      "Model Number: 320 with model UnobservedComponents in generation 2 of 3\n",
      "Model Number: 321 with model MultivariateRegression in generation 2 of 3\n",
      "Template Eval Error: Exception('Transformer BTCD failed on fit') in model 321 in generation 2: MultivariateRegression\n",
      "Model Number: 322 with model GLM in generation 2 of 3\n",
      "Model Number: 323 with model UnivariateRegression in generation 2 of 3\n",
      "Model Number: 324 with model AverageValueNaive in generation 2 of 3\n",
      "Model Number: 325 with model GLM in generation 2 of 3\n",
      "Template Eval Error: ValueError('The first guess on the deviance function returned a nan.  This could be a boundary  problem and should be reported.') in model 325 in generation 2: GLM\n",
      "Model Number: 326 with model MetricMotif in generation 2 of 3\n",
      "Model Number: 327 with model GLS in generation 2 of 3\n",
      "Model Number: 328 with model GLS in generation 2 of 3\n",
      "Model Number: 329 with model DatepartRegression in generation 2 of 3\n",
      "Model Number: 330 with model ARIMA in generation 2 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\statsmodels\\genmod\\families\\family.py:1367: ValueWarning: Negative binomial dispersion parameter alpha not set. Using default value alpha=1.0.\n",
      "  warnings.warn(\"Negative binomial dispersion parameter alpha not \"\n",
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\statsmodels\\genmod\\families\\family.py:1406: RuntimeWarning: invalid value encountered in log\n",
      "  resid_dev -= endog_alpha * np.log(endog_alpha / mu_alpha)\n",
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.392e+08, tolerance: 2.013e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 331 with model MultivariateMotif in generation 2 of 3\n",
      "Model Number: 332 with model ETS in generation 2 of 3\n",
      "Model Number: 333 with model UnobservedComponents in generation 2 of 3\n",
      "Model Number: 334 with model GLS in generation 2 of 3\n",
      "Model Number: 335 with model GLS in generation 2 of 3\n",
      "Model Number: 336 with model GLM in generation 2 of 3\n",
      "Model Number: 337 with model ConstantNaive in generation 2 of 3\n",
      "Model Number: 338 with model SeasonalNaive in generation 2 of 3\n",
      "Model Number: 339 with model LastValueNaive in generation 2 of 3\n",
      "Template Eval Error: Exception('Transformer AlignLastValue failed on inverse') in model 339 in generation 2: LastValueNaive\n",
      "Model Number: 340 with model LastValueNaive in generation 2 of 3\n",
      "Model Number: 341 with model DatepartRegression in generation 2 of 3\n",
      "Model Number: 342 with model UnobservedComponents in generation 2 of 3\n",
      "Model Number: 343 with model ETS in generation 2 of 3\n",
      "Model Number: 344 with model LastValueNaive in generation 2 of 3\n",
      "Model Number: 345 with model NVAR in generation 2 of 3\n",
      "Model Number: 346 with model SectionalMotif in generation 2 of 3\n",
      "Model Number: 347 with model ETS in generation 2 of 3\n",
      "Model Number: 348 with model MetricMotif in generation 2 of 3\n",
      "Model Number: 349 with model UnobservedComponents in generation 2 of 3\n",
      "Model Number: 350 with model UnobservedComponents in generation 2 of 3\n",
      "Model Number: 351 with model LastValueNaive in generation 2 of 3\n",
      "Model Number: 352 with model ETS in generation 2 of 3\n",
      "ETS error ValueError('Cannot compute initial seasonals using heuristic method with less than two full seasonal cycles in the data.')\n",
      "ETS failed on NET_SALES with ValueError('Cannot compute initial seasonals using heuristic method with less than two full seasonal cycles in the data.')\n",
      "Model Number: 353 with model DatepartRegression in generation 2 of 3\n",
      "Template Eval Error: Exception('Transformer BTCD failed on fit') in model 353 in generation 2: DatepartRegression\n",
      "Model Number: 354 with model ETS in generation 2 of 3\n",
      "Model Number: 355 with model SectionalMotif in generation 2 of 3\n",
      "Model Number: 356 with model AverageValueNaive in generation 2 of 3\n",
      "Model Number: 357 with model GLS in generation 2 of 3\n",
      "Model Number: 358 with model ConstantNaive in generation 2 of 3\n",
      "Model Number: 359 with model GLS in generation 2 of 3\n",
      "Model Number: 360 with model LastValueNaive in generation 2 of 3\n",
      "Template Eval Error: Exception('Transformer BTCD failed on fit') in model 360 in generation 2: LastValueNaive\n",
      "Model Number: 361 with model Theta in generation 2 of 3\n",
      "Model Number: 362 with model DatepartRegression in generation 2 of 3\n",
      "Model Number: 363 with model WindowRegression in generation 2 of 3\n",
      "Model Number: 364 with model MultivariateRegression in generation 2 of 3\n",
      "Template Eval Error: Exception('Transformer BTCD failed on fit') in model 364 in generation 2: MultivariateRegression\n",
      "Model Number: 365 with model ARIMA in generation 2 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\decomposition\\_fastica.py:708: FutureWarning: Starting in v1.3, whiten=True should be specified as whiten='arbitrary-variance' (its current behaviour). This behavior is deprecated in 1.1 and will raise ValueError in 1.3.\n",
      "  return self._fit_transform(X, compute_sources=True)\n",
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\linear_model\\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.48343e-24): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 366 with model GLM in generation 2 of 3\n",
      "Model Number: 367 with model SectionalMotif in generation 2 of 3\n",
      "Template Eval Error: Exception('Transformer AlignLastValue failed on inverse') in model 367 in generation 2: SectionalMotif\n",
      "Model Number: 368 with model UnobservedComponents in generation 2 of 3\n",
      "Model Number: 369 with model MetricMotif in generation 2 of 3\n",
      "Model Number: 370 with model ConstantNaive in generation 2 of 3\n",
      "Model Number: 371 with model UnivariateMotif in generation 2 of 3\n",
      "Model Number: 372 with model Theta in generation 2 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\statsmodels\\genmod\\families\\links.py:198: RuntimeWarning: overflow encountered in exp\n",
      "  t = np.exp(-z)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 373 with model UnobservedComponents in generation 2 of 3\n",
      "Model Number: 374 with model SeasonalNaive in generation 2 of 3\n",
      "Model Number: 375 with model DatepartRegression in generation 2 of 3\n",
      "Model Number: 376 with model UnobservedComponents in generation 2 of 3\n",
      "Model Number: 377 with model MultivariateRegression in generation 2 of 3\n",
      "Model Number: 378 with model SeasonalNaive in generation 2 of 3\n",
      "Model Number: 379 with model ARIMA in generation 2 of 3\n",
      "Model Number: 380 with model WindowRegression in generation 2 of 3\n",
      "Model Number: 381 with model GLM in generation 2 of 3\n",
      "Model Number: 382 with model DatepartRegression in generation 2 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\statsmodels\\genmod\\families\\links.py:198: RuntimeWarning: overflow encountered in exp\n",
      "  t = np.exp(-z)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Template Eval Error: Exception('Transformer AlignLastValue failed on inverse') in model 382 in generation 2: DatepartRegression\n",
      "Model Number: 383 with model ARIMA in generation 2 of 3\n",
      "Model Number: 384 with model MetricMotif in generation 2 of 3\n",
      "Model Number: 385 with model SectionalMotif in generation 2 of 3\n",
      "Model Number: 386 with model SectionalMotif in generation 2 of 3\n",
      "Model Number: 387 with model AverageValueNaive in generation 2 of 3\n",
      "Model Number: 388 with model ARDL in generation 2 of 3\n",
      "Template Eval Error: Exception('Transformer Detrend failed on fit') in model 388 in generation 2: ARDL\n",
      "Model Number: 389 with model AverageValueNaive in generation 2 of 3\n",
      "Model Number: 390 with model ConstantNaive in generation 2 of 3\n",
      "Model Number: 391 with model SectionalMotif in generation 2 of 3\n",
      "Template Eval Error: Exception('Transformer AlignLastValue failed on inverse') in model 391 in generation 2: SectionalMotif\n",
      "Model Number: 392 with model SeasonalNaive in generation 2 of 3\n",
      "Model Number: 393 with model LastValueNaive in generation 2 of 3\n",
      "Model Number: 394 with model SectionalMotif in generation 2 of 3\n",
      "Model Number: 395 with model MultivariateMotif in generation 2 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\decomposition\\_fastica.py:708: FutureWarning: Starting in v1.3, whiten=True should be specified as whiten='arbitrary-variance' (its current behaviour). This behavior is deprecated in 1.1 and will raise ValueError in 1.3.\n",
      "  return self._fit_transform(X, compute_sources=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 396 with model MetricMotif in generation 2 of 3\n",
      "Model Number: 397 with model Theta in generation 2 of 3\n",
      "Model Number: 398 with model AverageValueNaive in generation 2 of 3\n",
      "Model Number: 399 with model ARDL in generation 2 of 3\n",
      "Model Number: 400 with model SeasonalNaive in generation 2 of 3\n",
      "Model Number: 401 with model ARDL in generation 2 of 3\n",
      "Model Number: 402 with model SectionalMotif in generation 2 of 3\n",
      "Template Eval Error: ValueError('kth(=100) out of bounds (11)') in model 402 in generation 2: SectionalMotif\n",
      "Model Number: 403 with model ETS in generation 2 of 3\n",
      "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
      "ETS failed on NET_SALES with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
      "Model Number: 404 with model ConstantNaive in generation 2 of 3\n",
      "Model Number: 405 with model SeasonalNaive in generation 2 of 3\n",
      "Model Number: 406 with model GLS in generation 2 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\decomposition\\_fastica.py:708: FutureWarning: Starting in v1.3, whiten=True should be specified as whiten='arbitrary-variance' (its current behaviour). This behavior is deprecated in 1.1 and will raise ValueError in 1.3.\n",
      "  return self._fit_transform(X, compute_sources=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 407 with model AverageValueNaive in generation 2 of 3\n",
      "Template Eval Error: Exception('Transformer AlignLastValue failed on inverse') in model 407 in generation 2: AverageValueNaive\n",
      "Model Number: 408 with model FBProphet in generation 2 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "19:05:47 - cmdstanpy - INFO - Chain [1] start processing\n",
      "19:05:47 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 409 with model ConstantNaive in generation 2 of 3\n",
      "Model Number: 410 with model UnobservedComponents in generation 2 of 3\n",
      "Model Number: 411 with model Theta in generation 2 of 3\n",
      "Model Number: 412 with model SeasonalNaive in generation 2 of 3\n",
      "Model Number: 413 with model FBProphet in generation 2 of 3\n",
      "No anomalies detected.\n",
      "Model Number: 414 with model MultivariateMotif in generation 2 of 3\n",
      "Model Number: 415 with model SectionalMotif in generation 2 of 3\n",
      "Model Number: 416 with model UnivariateMotif in generation 2 of 3\n",
      "Model Number: 417 with model AverageValueNaive in generation 2 of 3\n",
      "Model Number: 418 with model NVAR in generation 2 of 3\n",
      "Model Number: 419 with model ConstantNaive in generation 2 of 3\n",
      "Model Number: 420 with model UnobservedComponents in generation 2 of 3\n",
      "Model Number: 421 with model ARDL in generation 2 of 3\n",
      "Model Number: 422 with model NVAR in generation 2 of 3\n",
      "Model Number: 423 with model UnobservedComponents in generation 2 of 3\n",
      "Model Number: 424 with model WindowRegression in generation 2 of 3\n",
      "Model Number: 425 with model SectionalMotif in generation 2 of 3\n",
      "Model Number: 426 with model GLM in generation 2 of 3\n",
      "Template Eval Error: Exception('Transformer AlignLastValue failed on inverse') in model 426 in generation 2: GLM\n",
      "Model Number: 427 with model Theta in generation 2 of 3\n",
      "Model Number: 428 with model UnivariateRegression in generation 2 of 3\n",
      "Model Number: 429 with model ARDL in generation 2 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:541: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 430 with model LastValueNaive in generation 2 of 3\n",
      "Model Number: 431 with model GLM in generation 2 of 3\n",
      "Model Number: 432 with model UnobservedComponents in generation 2 of 3\n",
      "Model Number: 433 with model GLS in generation 2 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\statsmodels\\genmod\\families\\links.py:198: RuntimeWarning: overflow encountered in exp\n",
      "  t = np.exp(-z)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 434 with model ARDL in generation 2 of 3\n",
      "Template Eval Error: ValueError(\"ARDL series NET_SALES failed with error ValueError('The number of regressors (97) including deterministics, lags of the endog, lags of the exogenous, and fixed regressors is larger than the sample available for estimation (68).') exog train             weekend  quarter      epoch  month_1  month_2  month_3  month_4  \\\\\\nMONTH                                                                         \\n2016-01-01        0        1  2457388.5      1.0      0.0      0.0      0.0   \\n2016-02-01        0        1  2457419.5      0.0      1.0      0.0      0.0   \\n2016-03-01        0        1  2457448.5      0.0      0.0      1.0      0.0   \\n2016-04-01        0        2  2457479.5      0.0      0.0      0.0      1.0   \\n2016-05-01        1        2  2457509.5      0.0      0.0      0.0      0.0   \\n...             ...      ...        ...      ...      ...      ...      ...   \\n2021-08-01        1        3  2459427.5      0.0      0.0      0.0      0.0   \\n2021-09-01        0        3  2459458.5      0.0      0.0      0.0      0.0   \\n2021-10-01        0        4  2459488.5      0.0      0.0      0.0      0.0   \\n2021-11-01        0        4  2459519.5      0.0      0.0      0.0      0.0   \\n2021-12-01        0        4  2459549.5      0.0      0.0      0.0      0.0   \\n\\n            month_5  month_6  month_7  ...  month_11  month_12  weekday_0  \\\\\\nMONTH                                  ...                                  \\n2016-01-01      0.0      0.0      0.0  ...       0.0       0.0        0.0   \\n2016-02-01      0.0      0.0      0.0  ...       0.0       0.0        1.0   \\n2016-03-01      0.0      0.0      0.0  ...       0.0       0.0        0.0   \\n2016-04-01      0.0      0.0      0.0  ...       0.0       0.0        0.0   \\n2016-05-01      1.0      0.0      0.0  ...       0.0       0.0        0.0   \\n...             ...      ...      ...  ...       ...       ...        ...   \\n2021-08-01      0.0      0.0      0.0  ...       0.0       0.0        0.0   \\n2021-09-01      0.0      0.0      0.0  ...       0.0       0.0        0.0   \\n2021-10-01      0.0      0.0      0.0  ...       0.0       0.0        0.0   \\n2021-11-01      0.0      0.0      0.0  ...       1.0       0.0        1.0   \\n2021-12-01      0.0      0.0      0.0  ...       0.0       1.0        0.0   \\n\\n            weekday_1  weekday_2  weekday_3  weekday_4  weekday_5  weekday_6  \\\\\\nMONTH                                                                          \\n2016-01-01        0.0        0.0        0.0        1.0        0.0        0.0   \\n2016-02-01        0.0        0.0        0.0        0.0        0.0        0.0   \\n2016-03-01        1.0        0.0        0.0        0.0        0.0        0.0   \\n2016-04-01        0.0        0.0        0.0        1.0        0.0        0.0   \\n2016-05-01        0.0        0.0        0.0        0.0        0.0        1.0   \\n...               ...        ...        ...        ...        ...        ...   \\n2021-08-01        0.0        0.0        0.0        0.0        0.0        1.0   \\n2021-09-01        0.0        1.0        0.0        0.0        0.0        0.0   \\n2021-10-01        0.0        0.0        0.0        1.0        0.0        0.0   \\n2021-11-01        0.0        0.0        0.0        0.0        0.0        0.0   \\n2021-12-01        0.0        1.0        0.0        0.0        0.0        0.0   \\n\\n               phase  \\nMONTH                 \\n2016-01-01  0.547495  \\n2016-02-01  0.442910  \\n2016-03-01  0.520471  \\n2016-04-01  0.381729  \\n2016-05-01  0.321422  \\n...              ...  \\n2021-08-01  0.387780  \\n2021-09-01  0.273881  \\n2021-10-01  0.247126  \\n2021-11-01  0.130043  \\n2021-12-01  0.093069  \\n\\n[72 rows x 23 columns] and predict             weekend  quarter      epoch  month_1  month_2  month_3  month_4  \\\\\\n2022-01-01        1        1  2459580.5      1.0      0.0      0.0      0.0   \\n2022-02-01        0        1  2459611.5      0.0      1.0      0.0      0.0   \\n2022-03-01        0        1  2459639.5      0.0      0.0      1.0      0.0   \\n2022-04-01        0        2  2459670.5      0.0      0.0      0.0      1.0   \\n2022-05-01        1        2  2459700.5      0.0      0.0      0.0      0.0   \\n2022-06-01        0        2  2459731.5      0.0      0.0      0.0      0.0   \\n2022-07-01        0        3  2459761.5      0.0      0.0      0.0      0.0   \\n2022-08-01        0        3  2459792.5      0.0      0.0      0.0      0.0   \\n2022-09-01        0        3  2459823.5      0.0      0.0      0.0      0.0   \\n2022-10-01        1        4  2459853.5      0.0      0.0      0.0      0.0   \\n2022-11-01        0        4  2459884.5      0.0      0.0      0.0      0.0   \\n2022-12-01        0        4  2459914.5      0.0      0.0      0.0      0.0   \\n\\n            month_5  month_6  month_7  ...  month_11  month_12  weekday_0  \\\\\\n2022-01-01      0.0      0.0      0.0  ...       0.0       0.0        0.0   \\n2022-02-01      0.0      0.0      0.0  ...       0.0       0.0        0.0   \\n2022-03-01      0.0      0.0      0.0  ...       0.0       0.0        0.0   \\n2022-04-01      0.0      0.0      0.0  ...       0.0       0.0        0.0   \\n2022-05-01      1.0      0.0      0.0  ...       0.0       0.0        0.0   \\n2022-06-01      0.0      1.0      0.0  ...       0.0       0.0        0.0   \\n2022-07-01      0.0      0.0      1.0  ...       0.0       0.0        0.0   \\n2022-08-01      0.0      0.0      0.0  ...       0.0       0.0        1.0   \\n2022-09-01      0.0      0.0      0.0  ...       0.0       0.0        0.0   \\n2022-10-01      0.0      0.0      0.0  ...       0.0       0.0        0.0   \\n2022-11-01      0.0      0.0      0.0  ...       1.0       0.0        0.0   \\n2022-12-01      0.0      0.0      0.0  ...       0.0       1.0        0.0   \\n\\n            weekday_1  weekday_2  weekday_3  weekday_4  weekday_5  weekday_6  \\\\\\n2022-01-01        0.0        0.0        0.0        0.0        1.0        0.0   \\n2022-02-01        1.0        0.0        0.0        0.0        0.0        0.0   \\n2022-03-01        1.0        0.0        0.0        0.0        0.0        0.0   \\n2022-04-01        0.0        0.0        0.0        1.0        0.0        0.0   \\n2022-05-01        0.0        0.0        0.0        0.0        0.0        1.0   \\n2022-06-01        0.0        1.0        0.0        0.0        0.0        0.0   \\n2022-07-01        0.0        0.0        0.0        1.0        0.0        0.0   \\n2022-08-01        0.0        0.0        0.0        0.0        0.0        0.0   \\n2022-09-01        0.0        0.0        1.0        0.0        0.0        0.0   \\n2022-10-01        0.0        0.0        0.0        0.0        1.0        0.0   \\n2022-11-01        1.0        0.0        0.0        0.0        0.0        0.0   \\n2022-12-01        0.0        0.0        1.0        0.0        0.0        0.0   \\n\\n               phase  \\n2022-01-01  0.014061  \\n2022-02-01  0.004344  \\n2022-03-01  0.011285  \\n2022-04-01  0.002806  \\n2022-05-01  0.008211  \\n2022-06-01  0.047322  \\n2022-07-01  0.063280  \\n2022-08-01  0.151187  \\n2022-09-01  0.292373  \\n2022-10-01  0.367633  \\n2022-11-01  0.561603  \\n2022-12-01  0.628538  \\n\\n[12 rows x 23 columns]\") in model 434 in generation 2: ARDL\n",
      "Model Number: 435 with model GLS in generation 2 of 3\n",
      "Model Number: 436 with model ARDL in generation 2 of 3\n",
      "New Generation: 3 of 3\n",
      "Model Number: 437 with model GLS in generation 3 of 3\n",
      "Model Number: 438 with model GLS in generation 3 of 3\n",
      "Model Number: 439 with model ARDL in generation 3 of 3\n",
      "Template Eval Error: Exception('Transformer Detrend failed on fit') in model 439 in generation 3: ARDL\n",
      "Model Number: 440 with model UnobservedComponents in generation 3 of 3\n",
      "Model Number: 441 with model GLS in generation 3 of 3\n",
      "Model Number: 442 with model UnivariateRegression in generation 3 of 3\n",
      "Model Number: 443 with model SeasonalNaive in generation 3 of 3\n",
      "Model Number: 444 with model AverageValueNaive in generation 3 of 3\n",
      "Model Number: 445 with model MetricMotif in generation 3 of 3\n",
      "Model Number: 446 with model ETS in generation 3 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\autots\\tools\\probabilistic.py:67: RuntimeWarning: invalid value encountered in divide\n",
      "  (prior_mu / prior_sigma**2) + ((n * data_mu) / prior_sigma**2)\n",
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\autots\\tools\\probabilistic.py:68: RuntimeWarning: divide by zero encountered in divide\n",
      "  ) / ((1 / prior_sigma**2) + (n / prior_sigma**2))\n",
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\decomposition\\_fastica.py:708: FutureWarning: Starting in v1.3, whiten=True should be specified as whiten='arbitrary-variance' (its current behaviour). This behavior is deprecated in 1.1 and will raise ValueError in 1.3.\n",
      "  return self._fit_transform(X, compute_sources=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 447 with model ETS in generation 3 of 3\n",
      "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
      "ETS failed on NET_SALES with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
      "Model Number: 448 with model ConstantNaive in generation 3 of 3\n",
      "Template Eval Error: Exception('Transformer AlignLastValue failed on inverse') in model 448 in generation 3: ConstantNaive\n",
      "Model Number: 449 with model ARDL in generation 3 of 3\n",
      "Model Number: 450 with model DatepartRegression in generation 3 of 3\n",
      "Model Number: 451 with model ETS in generation 3 of 3\n",
      "ETS error ValueError('Cannot compute initial seasonals using heuristic method with less than two full seasonal cycles in the data.')\n",
      "ETS failed on NET_SALES with ValueError('Cannot compute initial seasonals using heuristic method with less than two full seasonal cycles in the data.')\n",
      "Model Number: 452 with model UnobservedComponents in generation 3 of 3\n",
      "Model Number: 453 with model MultivariateRegression in generation 3 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\decomposition\\_fastica.py:708: FutureWarning: Starting in v1.3, whiten=True should be specified as whiten='arbitrary-variance' (its current behaviour). This behavior is deprecated in 1.1 and will raise ValueError in 1.3.\n",
      "  return self._fit_transform(X, compute_sources=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 454 with model GLS in generation 3 of 3\n",
      "Model Number: 455 with model LastValueNaive in generation 3 of 3\n",
      "Model Number: 456 with model MultivariateRegression in generation 3 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 457 with model LastValueNaive in generation 3 of 3\n",
      "Model Number: 458 with model MetricMotif in generation 3 of 3\n",
      "Model Number: 459 with model GLS in generation 3 of 3\n",
      "Template Eval Error: Exception('Transformer BTCD failed on fit') in model 459 in generation 3: GLS\n",
      "Model Number: 460 with model WindowRegression in generation 3 of 3\n",
      "Model Number: 461 with model DatepartRegression in generation 3 of 3\n",
      "Template Eval Error: ValueError('Input X contains NaN.\\nRadiusNeighborsRegressor does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values') in model 461 in generation 3: DatepartRegression\n",
      "Model Number: 462 with model NVAR in generation 3 of 3\n",
      "Model Number: 463 with model ARDL in generation 3 of 3\n",
      "Model Number: 464 with model MetricMotif in generation 3 of 3\n",
      "Model Number: 465 with model UnobservedComponents in generation 3 of 3\n",
      "Model Number: 466 with model UnivariateMotif in generation 3 of 3\n",
      "Model Number: 467 with model GLS in generation 3 of 3\n",
      "Model Number: 468 with model ETS in generation 3 of 3\n",
      "Model Number: 469 with model FBProphet in generation 3 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "19:05:52 - cmdstanpy - INFO - Chain [1] start processing\n",
      "19:05:52 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 470 with model ConstantNaive in generation 3 of 3\n",
      "Model Number: 471 with model MultivariateMotif in generation 3 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "19:05:52 - cmdstanpy - INFO - Chain [1] start processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 472 with model FBProphet in generation 3 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "19:05:52 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 473 with model MetricMotif in generation 3 of 3\n",
      "Model Number: 474 with model GLS in generation 3 of 3\n",
      "Model Number: 475 with model MultivariateRegression in generation 3 of 3\n",
      "Model Number: 476 with model LastValueNaive in generation 3 of 3\n",
      "Template Eval Error: Exception('Transformer AlignLastValue failed on inverse') in model 476 in generation 3: LastValueNaive\n",
      "Model Number: 477 with model LastValueNaive in generation 3 of 3\n",
      "Model Number: 478 with model ConstantNaive in generation 3 of 3\n",
      "Model Number: 479 with model UnobservedComponents in generation 3 of 3\n",
      "Model Number: 480 with model AverageValueNaive in generation 3 of 3\n",
      "Model Number: 481 with model GLS in generation 3 of 3\n",
      "Model Number: 482 with model SectionalMotif in generation 3 of 3\n",
      "Template Eval Error: ValueError('kth(=10) out of bounds (6)') in model 482 in generation 3: SectionalMotif\n",
      "Model Number: 483 with model ARIMA in generation 3 of 3\n",
      "Model Number: 484 with model GLS in generation 3 of 3\n",
      "Model Number: 485 with model NVAR in generation 3 of 3\n",
      "Model Number: 486 with model Theta in generation 3 of 3\n",
      "Model Number: 487 with model DatepartRegression in generation 3 of 3\n",
      "Model Number: 488 with model UnivariateRegression in generation 3 of 3\n",
      "Model Number: 489 with model GLM in generation 3 of 3\n",
      "Model Number: 490 with model UnivariateRegression in generation 3 of 3\n",
      "Model Number: 491 with model ConstantNaive in generation 3 of 3\n",
      "Model Number: 492 with model UnobservedComponents in generation 3 of 3\n",
      "Model Number: 493 with model SeasonalNaive in generation 3 of 3\n",
      "Model Number: 494 with model AverageValueNaive in generation 3 of 3\n",
      "Model Number: 495 with model MultivariateMotif in generation 3 of 3\n",
      "Model Number: 496 with model FBProphet in generation 3 of 3\n",
      "Model Number: 497 with model ETS in generation 3 of 3\n",
      "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
      "ETS failed on NET_SALES with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
      "Model Number: 498 with model Theta in generation 3 of 3\n",
      "Model Number: 499 with model NVAR in generation 3 of 3\n",
      "Model Number: 500 with model UnobservedComponents in generation 3 of 3\n",
      "Model Number: 501 with model NVAR in generation 3 of 3\n",
      "Model Number: 502 with model ConstantNaive in generation 3 of 3\n",
      "Model Number: 503 with model UnobservedComponents in generation 3 of 3\n",
      "Model Number: 504 with model ConstantNaive in generation 3 of 3\n",
      "Model Number: 505 with model Theta in generation 3 of 3\n",
      "Model Number: 506 with model UnobservedComponents in generation 3 of 3\n",
      "Model Number: 507 with model SectionalMotif in generation 3 of 3\n",
      "Template Eval Error: ValueError('kth(=10) out of bounds (6)') in model 507 in generation 3: SectionalMotif\n",
      "Model Number: 508 with model SectionalMotif in generation 3 of 3\n",
      "Model Number: 509 with model NVAR in generation 3 of 3\n",
      "Model Number: 510 with model DatepartRegression in generation 3 of 3\n",
      "Model Number: 511 with model UnivariateRegression in generation 3 of 3\n",
      "Template Eval Error: ValueError('Input X contains NaN.\\nRidge does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values') in model 511 in generation 3: UnivariateRegression\n",
      "Model Number: 512 with model SectionalMotif in generation 3 of 3\n",
      "Model Number: 513 with model MetricMotif in generation 3 of 3\n",
      "Model Number: 514 with model DatepartRegression in generation 3 of 3\n",
      "Model Number: 515 with model SeasonalNaive in generation 3 of 3\n",
      "Model Number: 516 with model ETS in generation 3 of 3\n",
      "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
      "ETS failed on NET_SALES with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
      "Model Number: 517 with model MetricMotif in generation 3 of 3\n",
      "Template Eval Error: Exception('Transformer AlignLastValue failed on inverse') in model 517 in generation 3: MetricMotif\n",
      "Model Number: 518 with model ARIMA in generation 3 of 3\n",
      "Model Number: 519 with model LastValueNaive in generation 3 of 3\n",
      "Model Number: 520 with model SeasonalNaive in generation 3 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\decomposition\\_fastica.py:708: FutureWarning: Starting in v1.3, whiten=True should be specified as whiten='arbitrary-variance' (its current behaviour). This behavior is deprecated in 1.1 and will raise ValueError in 1.3.\n",
      "  return self._fit_transform(X, compute_sources=True)\n",
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\decomposition\\_fastica.py:708: FutureWarning: Starting in v1.3, whiten=True should be specified as whiten='arbitrary-variance' (its current behaviour). This behavior is deprecated in 1.1 and will raise ValueError in 1.3.\n",
      "  return self._fit_transform(X, compute_sources=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 521 with model ETS in generation 3 of 3\n",
      "Model Number: 522 with model UnivariateMotif in generation 3 of 3\n",
      "Model Number: 523 with model ETS in generation 3 of 3\n",
      "Model Number: 524 with model AverageValueNaive in generation 3 of 3\n",
      "Model Number: 525 with model GLS in generation 3 of 3\n",
      "Model Number: 526 with model ARIMA in generation 3 of 3\n",
      "Model Number: 527 with model GLS in generation 3 of 3\n",
      "Model Number: 528 with model GLM in generation 3 of 3\n",
      "Model Number: 529 with model SectionalMotif in generation 3 of 3\n",
      "Model Number: 530 with model UnivariateRegression in generation 3 of 3\n",
      "Model Number: 531 with model DatepartRegression in generation 3 of 3\n",
      "Model Number: 532 with model UnivariateRegression in generation 3 of 3\n",
      "Model Number: 533 with model LastValueNaive in generation 3 of 3\n",
      "Model Number: 534 with model GLM in generation 3 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\autots\\tools\\probabilistic.py:67: RuntimeWarning: invalid value encountered in divide\n",
      "  (prior_mu / prior_sigma**2) + ((n * data_mu) / prior_sigma**2)\n",
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\autots\\tools\\probabilistic.py:68: RuntimeWarning: divide by zero encountered in divide\n",
      "  ) / ((1 / prior_sigma**2) + (n / prior_sigma**2))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 535 with model ARIMA in generation 3 of 3\n",
      "Model Number: 536 with model AverageValueNaive in generation 3 of 3\n",
      "Model Number: 537 with model UnivariateMotif in generation 3 of 3\n",
      "Model Number: 538 with model MultivariateRegression in generation 3 of 3\n",
      "Model Number: 539 with model UnobservedComponents in generation 3 of 3\n",
      "Model Number: 540 with model GLS in generation 3 of 3\n",
      "Template Eval Error: Exception('Transformer AlignLastValue failed on inverse') in model 540 in generation 3: GLS\n",
      "Model Number: 541 with model ConstantNaive in generation 3 of 3\n",
      "Model Number: 542 with model UnobservedComponents in generation 3 of 3\n",
      "Model Number: 543 with model ARDL in generation 3 of 3\n",
      "Model Number: 544 with model GLM in generation 3 of 3\n",
      "Model Number: 545 with model AverageValueNaive in generation 3 of 3\n",
      "Model Number: 546 with model ARIMA in generation 3 of 3\n",
      "Model Number: 547 with model DatepartRegression in generation 3 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\decomposition\\_fastica.py:708: FutureWarning: Starting in v1.3, whiten=True should be specified as whiten='arbitrary-variance' (its current behaviour). This behavior is deprecated in 1.1 and will raise ValueError in 1.3.\n",
      "  return self._fit_transform(X, compute_sources=True)\n",
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\statsmodels\\genmod\\generalized_linear_model.py:307: DomainWarning: The InversePower link function does not respect the domain of the Gamma family.\n",
      "  warnings.warn((f\"The {type(family.link).__name__} link function \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 548 with model SeasonalNaive in generation 3 of 3\n",
      "Model Number: 549 with model ConstantNaive in generation 3 of 3\n",
      "Model Number: 550 with model UnivariateMotif in generation 3 of 3\n",
      "Model Number: 551 with model WindowRegression in generation 3 of 3\n",
      "Model Number: 552 with model FBProphet in generation 3 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.146e+11, tolerance: 4.879e+07\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "19:05:58 - cmdstanpy - INFO - Chain [1] start processing\n",
      "19:05:59 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 553 with model GLM in generation 3 of 3\n",
      "Model Number: 554 with model DatepartRegression in generation 3 of 3\n",
      "Model Number: 555 with model ARIMA in generation 3 of 3\n",
      "Model Number: 556 with model UnivariateMotif in generation 3 of 3\n",
      "Model Number: 557 with model LastValueNaive in generation 3 of 3\n",
      "Model Number: 558 with model SectionalMotif in generation 3 of 3\n",
      "Template Eval Error: ValueError('kth(=10) out of bounds (6)') in model 558 in generation 3: SectionalMotif\n",
      "Model Number: 559 with model LastValueNaive in generation 3 of 3\n",
      "Template Eval Error: Exception('Transformer AlignLastValue failed on inverse') in model 559 in generation 3: LastValueNaive\n",
      "Model Number: 560 with model UnivariateRegression in generation 3 of 3\n",
      "Model Number: 561 with model NVAR in generation 3 of 3\n",
      "TotalRuntime missing in 4!\n",
      "Validation Round: 1\n",
      "Model Number: 1 of 84 with model NVAR for Validation 1\n",
      "📈 1 - NVAR with avg smape 54.17: \n",
      "Model Number: 2 of 84 with model ConstantNaive for Validation 1\n",
      "2 - ConstantNaive with avg smape 78.73: \n",
      "Model Number: 3 of 84 with model ConstantNaive for Validation 1\n",
      "3 - ConstantNaive with avg smape 67.3: \n",
      "Model Number: 4 of 84 with model ConstantNaive for Validation 1\n",
      "4 - ConstantNaive with avg smape 67.3: \n",
      "Model Number: 5 of 84 with model ConstantNaive for Validation 1\n",
      "5 - ConstantNaive with avg smape 67.3: \n",
      "Model Number: 6 of 84 with model ARIMA for Validation 1\n",
      "6 - ARIMA with avg smape 57.89: \n",
      "Model Number: 7 of 84 with model ConstantNaive for Validation 1\n",
      "7 - ConstantNaive with avg smape 65.56: \n",
      "Model Number: 8 of 84 with model GLM for Validation 1\n",
      "8 - GLM with avg smape 73.53: \n",
      "Model Number: 9 of 84 with model GLS for Validation 1\n",
      "9 - GLS with avg smape 65.55: \n",
      "Model Number: 10 of 84 with model LastValueNaive for Validation 1\n",
      "📈 10 - LastValueNaive with avg smape 31.91: \n",
      "Model Number: 11 of 84 with model AverageValueNaive for Validation 1\n",
      "11 - AverageValueNaive with avg smape 67.2: \n",
      "Model Number: 12 of 84 with model AverageValueNaive for Validation 1\n",
      "12 - AverageValueNaive with avg smape 67.2: \n",
      "Model Number: 13 of 84 with model UnobservedComponents for Validation 1\n",
      "13 - UnobservedComponents with avg smape 65.56: \n",
      "Model Number: 14 of 84 with model ETS for Validation 1\n",
      "ETS error ValueError('Cannot compute initial seasonals using heuristic method with less than two full seasonal cycles in the data.')\n",
      "ETS failed on NET_SALES with ValueError('Cannot compute initial seasonals using heuristic method with less than two full seasonal cycles in the data.')\n",
      "14 - ETS with avg smape 67.3: \n",
      "Model Number: 15 of 84 with model ETS for Validation 1\n",
      "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
      "ETS failed on NET_SALES with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
      "15 - ETS with avg smape 65.56: \n",
      "Model Number: 16 of 84 with model ETS for Validation 1\n",
      "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
      "ETS failed on NET_SALES with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
      "16 - ETS with avg smape 67.3: \n",
      "Model Number: 17 of 84 with model ETS for Validation 1\n",
      "ETS error ValueError('Cannot compute initial seasonals using heuristic method with less than two full seasonal cycles in the data.')\n",
      "ETS failed on NET_SALES with ValueError('Cannot compute initial seasonals using heuristic method with less than two full seasonal cycles in the data.')\n",
      "17 - ETS with avg smape 65.56: \n",
      "Model Number: 18 of 84 with model GLS for Validation 1\n",
      "18 - GLS with avg smape 65.56: \n",
      "Model Number: 19 of 84 with model GLS for Validation 1\n",
      "19 - GLS with avg smape 65.56: \n",
      "Model Number: 20 of 84 with model AverageValueNaive for Validation 1\n",
      "20 - AverageValueNaive with avg smape 86.99: \n",
      "Model Number: 21 of 84 with model AverageValueNaive for Validation 1\n",
      "21 - AverageValueNaive with avg smape 86.99: \n",
      "Model Number: 22 of 84 with model DatepartRegression for Validation 1\n",
      "22 - DatepartRegression with avg smape 61.76: \n",
      "Model Number: 23 of 84 with model DatepartRegression for Validation 1\n",
      "23 - DatepartRegression with avg smape 61.76: \n",
      "Model Number: 24 of 84 with model UnobservedComponents for Validation 1\n",
      "24 - UnobservedComponents with avg smape 71.8: \n",
      "Model Number: 25 of 84 with model GLS for Validation 1\n",
      "25 - GLS with avg smape 84.35: \n",
      "Model Number: 26 of 84 with model GLS for Validation 1\n",
      "26 - GLS with avg smape 86.03: \n",
      "Model Number: 27 of 84 with model SeasonalNaive for Validation 1\n",
      "27 - SeasonalNaive with avg smape 76.19: \n",
      "Model Number: 28 of 84 with model UnobservedComponents for Validation 1\n",
      "28 - UnobservedComponents with avg smape 67.68: \n",
      "Model Number: 29 of 84 with model ARIMA for Validation 1\n",
      "29 - ARIMA with avg smape 43.03: \n",
      "Model Number: 30 of 84 with model AverageValueNaive for Validation 1\n",
      "30 - AverageValueNaive with avg smape 78.55: \n",
      "Model Number: 31 of 84 with model UnobservedComponents for Validation 1\n",
      "31 - UnobservedComponents with avg smape 67.73: \n",
      "Model Number: 32 of 84 with model UnobservedComponents for Validation 1\n",
      "32 - UnobservedComponents with avg smape 67.73: \n",
      "Model Number: 33 of 84 with model DatepartRegression for Validation 1\n",
      "33 - DatepartRegression with avg smape 64.11: \n",
      "Model Number: 34 of 84 with model SeasonalNaive for Validation 1\n",
      "34 - SeasonalNaive with avg smape 77.39: \n",
      "Model Number: 35 of 84 with model GLM for Validation 1\n",
      "35 - GLM with avg smape 62.41: \n",
      "Model Number: 36 of 84 with model ARIMA for Validation 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\linear_model\\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.78051e-24): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36 - ARIMA with avg smape 52.62: \n",
      "Model Number: 37 of 84 with model ETS for Validation 1\n",
      "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
      "ETS failed on NET_SALES with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
      "37 - ETS with avg smape 52.33: \n",
      "Model Number: 38 of 84 with model ARDL for Validation 1\n",
      "38 - ARDL with avg smape 35.63: \n",
      "Model Number: 39 of 84 with model SectionalMotif for Validation 1\n",
      "Template Eval Error: ValueError('kth(=5) out of bounds (4)') in model 39 in generation 0: SectionalMotif\n",
      "Model Number: 40 of 84 with model SeasonalNaive for Validation 1\n",
      "40 - SeasonalNaive with avg smape 79.17: \n",
      "Model Number: 41 of 84 with model GLM for Validation 1\n",
      "41 - GLM with avg smape 54.95: \n",
      "Model Number: 42 of 84 with model GLM for Validation 1\n",
      "42 - GLM with avg smape 62.57: \n",
      "Model Number: 43 of 84 with model SeasonalNaive for Validation 1\n",
      "43 - SeasonalNaive with avg smape 72.55: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\decomposition\\_fastica.py:708: FutureWarning: Starting in v1.3, whiten=True should be specified as whiten='arbitrary-variance' (its current behaviour). This behavior is deprecated in 1.1 and will raise ValueError in 1.3.\n",
      "  return self._fit_transform(X, compute_sources=True)\n",
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\decomposition\\_fastica.py:708: FutureWarning: Starting in v1.3, whiten=True should be specified as whiten='arbitrary-variance' (its current behaviour). This behavior is deprecated in 1.1 and will raise ValueError in 1.3.\n",
      "  return self._fit_transform(X, compute_sources=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 44 of 84 with model SeasonalNaive for Validation 1\n",
      "44 - SeasonalNaive with avg smape 73.78: \n",
      "Model Number: 45 of 84 with model GLM for Validation 1\n",
      "45 - GLM with avg smape 57.69: \n",
      "Model Number: 46 of 84 with model SectionalMotif for Validation 1\n",
      "46 - SectionalMotif with avg smape 101.89: \n",
      "Model Number: 47 of 84 with model SectionalMotif for Validation 1\n",
      "47 - SectionalMotif with avg smape 85.57: \n",
      "Model Number: 48 of 84 with model MetricMotif for Validation 1\n",
      "48 - MetricMotif with avg smape 44.43: \n",
      "Model Number: 49 of 84 with model SectionalMotif for Validation 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\decomposition\\_fastica.py:708: FutureWarning: Starting in v1.3, whiten=True should be specified as whiten='arbitrary-variance' (its current behaviour). This behavior is deprecated in 1.1 and will raise ValueError in 1.3.\n",
      "  return self._fit_transform(X, compute_sources=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49 - SectionalMotif with avg smape 49.45: \n",
      "Model Number: 50 of 84 with model ARDL for Validation 1\n",
      "📈 50 - ARDL with avg smape 29.78: \n",
      "Model Number: 51 of 84 with model UnivariateRegression for Validation 1\n",
      "51 - UnivariateRegression with avg smape 48.08: \n",
      "Model Number: 52 of 84 with model UnivariateRegression for Validation 1\n",
      "52 - UnivariateRegression with avg smape 30.18: \n",
      "Model Number: 53 of 84 with model NVAR for Validation 1\n",
      "53 - NVAR with avg smape 38.23: \n",
      "Model Number: 54 of 84 with model LastValueNaive for Validation 1\n",
      "54 - LastValueNaive with avg smape 32.68: \n",
      "Model Number: 55 of 84 with model LastValueNaive for Validation 1\n",
      "55 - LastValueNaive with avg smape 32.68: \n",
      "Model Number: 56 of 84 with model LastValueNaive for Validation 1\n",
      "56 - LastValueNaive with avg smape 30.59: \n",
      "Model Number: 57 of 84 with model UnivariateRegression for Validation 1\n",
      "57 - UnivariateRegression with avg smape 43.4: \n",
      "Model Number: 58 of 84 with model SectionalMotif for Validation 1\n",
      "58 - SectionalMotif with avg smape 48.12: \n",
      "Model Number: 59 of 84 with model UnivariateRegression for Validation 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\autots\\tools\\probabilistic.py:67: RuntimeWarning: invalid value encountered in divide\n",
      "  (prior_mu / prior_sigma**2) + ((n * data_mu) / prior_sigma**2)\n",
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\autots\\tools\\probabilistic.py:68: RuntimeWarning: divide by zero encountered in divide\n",
      "  ) / ((1 / prior_sigma**2) + (n / prior_sigma**2))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59 - UnivariateRegression with avg smape 43.11: \n",
      "Model Number: 60 of 84 with model ARIMA for Validation 1\n",
      "60 - ARIMA with avg smape 33.81: \n",
      "Model Number: 61 of 84 with model UnivariateRegression for Validation 1\n",
      "61 - UnivariateRegression with avg smape 50.8: \n",
      "Model Number: 62 of 84 with model DatepartRegression for Validation 1\n",
      "62 - DatepartRegression with avg smape 40.37: \n",
      "Model Number: 63 of 84 with model ARDL for Validation 1\n",
      "63 - ARDL with avg smape 45.94: \n",
      "Model Number: 64 of 84 with model MultivariateMotif for Validation 1\n",
      "64 - MultivariateMotif with avg smape 37.57: \n",
      "Model Number: 65 of 84 with model MultivariateMotif for Validation 1\n",
      "65 - MultivariateMotif with avg smape 37.59: \n",
      "Model Number: 66 of 84 with model ARIMA for Validation 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.235e-02, tolerance: 5.369e-04\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66 - ARIMA with avg smape 38.95: \n",
      "Model Number: 67 of 84 with model DatepartRegression for Validation 1\n",
      "67 - DatepartRegression with avg smape 31.31: \n",
      "Model Number: 68 of 84 with model UnivariateMotif for Validation 1\n",
      "68 - UnivariateMotif with avg smape 44.91: \n",
      "Model Number: 69 of 84 with model ARDL for Validation 1\n",
      "📈 69 - ARDL with avg smape 28.68: \n",
      "Model Number: 70 of 84 with model ARDL for Validation 1\n",
      "70 - ARDL with avg smape 28.68: \n",
      "Model Number: 71 of 84 with model MetricMotif for Validation 1\n",
      "71 - MetricMotif with avg smape 38.69: \n",
      "Model Number: 72 of 84 with model MetricMotif for Validation 1\n",
      "72 - MetricMotif with avg smape 36.57: \n",
      "Model Number: 73 of 84 with model MetricMotif for Validation 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\decomposition\\_fastica.py:708: FutureWarning: Starting in v1.3, whiten=True should be specified as whiten='arbitrary-variance' (its current behaviour). This behavior is deprecated in 1.1 and will raise ValueError in 1.3.\n",
      "  return self._fit_transform(X, compute_sources=True)\n",
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\linear_model\\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.78051e-24): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73 - MetricMotif with avg smape 40.3: \n",
      "Model Number: 74 of 84 with model MetricMotif for Validation 1\n",
      "74 - MetricMotif with avg smape 38.48: \n",
      "Model Number: 75 of 84 with model LastValueNaive for Validation 1\n",
      "75 - LastValueNaive with avg smape 44.55: \n",
      "Model Number: 76 of 84 with model NVAR for Validation 1\n",
      "76 - NVAR with avg smape 85.14: \n",
      "Model Number: 77 of 84 with model UnivariateMotif for Validation 1\n",
      "77 - UnivariateMotif with avg smape 67.49: \n",
      "Model Number: 78 of 84 with model Theta for Validation 1\n",
      "78 - Theta with avg smape 125.13: \n",
      "Model Number: 79 of 84 with model Theta for Validation 1\n",
      "79 - Theta with avg smape 125.13: \n",
      "Model Number: 80 of 84 with model Theta for Validation 1\n",
      "80 - Theta with avg smape 124.78: \n",
      "Model Number: 81 of 84 with model NVAR for Validation 1\n",
      "Template Eval Error: Exception('Transformer StandardScaler failed on inverse') in model 81 in generation 0: NVAR\n",
      "Model Number: 82 of 84 with model NVAR for Validation 1\n",
      "82 - NVAR with avg smape 30.67: \n",
      "Model Number: 83 of 84 with model MultivariateRegression for Validation 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\pandas\\core\\internals\\blocks.py:351: RuntimeWarning: overflow encountered in exp\n",
      "  result = func(self.values, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83 - MultivariateRegression with avg smape 30.95: \n",
      "Model Number: 84 of 84 with model MultivariateRegression for Validation 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84 - MultivariateRegression with avg smape 30.95: \n",
      "Validation Round: 2\n",
      "Model Number: 1 of 84 with model NVAR for Validation 2\n",
      "📈 1 - NVAR with avg smape 74.52: \n",
      "Model Number: 2 of 84 with model ConstantNaive for Validation 2\n",
      "2 - ConstantNaive with avg smape 99.87: \n",
      "Model Number: 3 of 84 with model ConstantNaive for Validation 2\n",
      "3 - ConstantNaive with avg smape 84.43: \n",
      "Model Number: 4 of 84 with model ConstantNaive for Validation 2\n",
      "4 - ConstantNaive with avg smape 84.43: \n",
      "Model Number: 5 of 84 with model ConstantNaive for Validation 2\n",
      "5 - ConstantNaive with avg smape 84.43: \n",
      "Model Number: 6 of 84 with model ARIMA for Validation 2\n",
      "6 - ARIMA with avg smape 79.03: \n",
      "Model Number: 7 of 84 with model ConstantNaive for Validation 2\n",
      "7 - ConstantNaive with avg smape 83.17: \n",
      "Model Number: 8 of 84 with model GLM for Validation 2\n",
      "8 - GLM with avg smape 92.1: \n",
      "Model Number: 9 of 84 with model GLS for Validation 2\n",
      "9 - GLS with avg smape 83.17: \n",
      "Model Number: 10 of 84 with model LastValueNaive for Validation 2\n",
      "📈 10 - LastValueNaive with avg smape 57.93: \n",
      "Model Number: 11 of 84 with model AverageValueNaive for Validation 2\n",
      "11 - AverageValueNaive with avg smape 84.37: \n",
      "Model Number: 12 of 84 with model AverageValueNaive for Validation 2\n",
      "12 - AverageValueNaive with avg smape 84.37: \n",
      "Model Number: 13 of 84 with model UnobservedComponents for Validation 2\n",
      "13 - UnobservedComponents with avg smape 83.17: \n",
      "Model Number: 14 of 84 with model ETS for Validation 2\n",
      "ETS error ValueError('Cannot compute initial seasonals using heuristic method with less than two full seasonal cycles in the data.')\n",
      "ETS failed on NET_SALES with ValueError('Cannot compute initial seasonals using heuristic method with less than two full seasonal cycles in the data.')\n",
      "14 - ETS with avg smape 84.43: \n",
      "Model Number: 15 of 84 with model ETS for Validation 2\n",
      "15 - ETS with avg smape 59.45: \n",
      "Model Number: 16 of 84 with model ETS for Validation 2\n",
      "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
      "ETS failed on NET_SALES with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
      "16 - ETS with avg smape 84.43: \n",
      "Model Number: 17 of 84 with model ETS for Validation 2\n",
      "ETS error ValueError('Cannot compute initial seasonals using heuristic method with less than two full seasonal cycles in the data.')\n",
      "ETS failed on NET_SALES with ValueError('Cannot compute initial seasonals using heuristic method with less than two full seasonal cycles in the data.')\n",
      "17 - ETS with avg smape 83.17: \n",
      "Model Number: 18 of 84 with model GLS for Validation 2\n",
      "18 - GLS with avg smape 83.17: \n",
      "Model Number: 19 of 84 with model GLS for Validation 2\n",
      "19 - GLS with avg smape 83.17: \n",
      "Model Number: 20 of 84 with model AverageValueNaive for Validation 2\n",
      "20 - AverageValueNaive with avg smape 120.18: \n",
      "Model Number: 21 of 84 with model AverageValueNaive for Validation 2\n",
      "21 - AverageValueNaive with avg smape 120.18: \n",
      "Model Number: 22 of 84 with model DatepartRegression for Validation 2\n",
      "22 - DatepartRegression with avg smape 80.07: \n",
      "Model Number: 23 of 84 with model DatepartRegression for Validation 2\n",
      "23 - DatepartRegression with avg smape 80.07: \n",
      "Model Number: 24 of 84 with model UnobservedComponents for Validation 2\n",
      "24 - UnobservedComponents with avg smape 89.06: \n",
      "Model Number: 25 of 84 with model GLS for Validation 2\n",
      "25 - GLS with avg smape 116.12: \n",
      "Model Number: 26 of 84 with model GLS for Validation 2\n",
      "26 - GLS with avg smape 119.23: \n",
      "Model Number: 27 of 84 with model SeasonalNaive for Validation 2\n",
      "27 - SeasonalNaive with avg smape 90.98: \n",
      "Model Number: 28 of 84 with model UnobservedComponents for Validation 2\n",
      "28 - UnobservedComponents with avg smape 88.8: \n",
      "Model Number: 29 of 84 with model ARIMA for Validation 2\n",
      "29 - ARIMA with avg smape 83.17: \n",
      "Model Number: 30 of 84 with model AverageValueNaive for Validation 2\n",
      "30 - AverageValueNaive with avg smape 83.98: \n",
      "Model Number: 31 of 84 with model UnobservedComponents for Validation 2\n",
      "31 - UnobservedComponents with avg smape 140.32: \n",
      "Model Number: 32 of 84 with model UnobservedComponents for Validation 2\n",
      "32 - UnobservedComponents with avg smape 140.32: \n",
      "Model Number: 33 of 84 with model DatepartRegression for Validation 2\n",
      "33 - DatepartRegression with avg smape 89.07: \n",
      "Model Number: 34 of 84 with model SeasonalNaive for Validation 2\n",
      "34 - SeasonalNaive with avg smape 114.27: \n",
      "Model Number: 35 of 84 with model GLM for Validation 2\n",
      "35 - GLM with avg smape 80.69: \n",
      "Model Number: 36 of 84 with model ARIMA for Validation 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\linear_model\\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.22635e-24): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36 - ARIMA with avg smape 68.59: \n",
      "Model Number: 37 of 84 with model ETS for Validation 2\n",
      "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
      "ETS failed on NET_SALES with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
      "37 - ETS with avg smape 114.21: \n",
      "Model Number: 38 of 84 with model ARDL for Validation 2\n",
      "📈 38 - ARDL with avg smape 41.29: \n",
      "Model Number: 39 of 84 with model SectionalMotif for Validation 2\n",
      "Template Eval Error: ValueError('kth(=5) out of bounds (3)') in model 39 in generation 0: SectionalMotif\n",
      "Model Number: 40 of 84 with model SeasonalNaive for Validation 2\n",
      "40 - SeasonalNaive with avg smape 94.1: \n",
      "Model Number: 41 of 84 with model GLM for Validation 2\n",
      "41 - GLM with avg smape 73.38: \n",
      "Model Number: 42 of 84 with model GLM for Validation 2\n",
      "42 - GLM with avg smape 80.5: \n",
      "Model Number: 43 of 84 with model SeasonalNaive for Validation 2\n",
      "43 - SeasonalNaive with avg smape 84.81: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\decomposition\\_fastica.py:708: FutureWarning: Starting in v1.3, whiten=True should be specified as whiten='arbitrary-variance' (its current behaviour). This behavior is deprecated in 1.1 and will raise ValueError in 1.3.\n",
      "  return self._fit_transform(X, compute_sources=True)\n",
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\statsmodels\\genmod\\families\\links.py:198: RuntimeWarning: overflow encountered in exp\n",
      "  t = np.exp(-z)\n",
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\decomposition\\_fastica.py:708: FutureWarning: Starting in v1.3, whiten=True should be specified as whiten='arbitrary-variance' (its current behaviour). This behavior is deprecated in 1.1 and will raise ValueError in 1.3.\n",
      "  return self._fit_transform(X, compute_sources=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 44 of 84 with model SeasonalNaive for Validation 2\n",
      "44 - SeasonalNaive with avg smape 85.45: \n",
      "Model Number: 45 of 84 with model GLM for Validation 2\n",
      "45 - GLM with avg smape 78.49: \n",
      "Model Number: 46 of 84 with model SectionalMotif for Validation 2\n",
      "Template Eval Error: ValueError('kth(=3) out of bounds (3)') in model 46 in generation 0: SectionalMotif\n",
      "Model Number: 47 of 84 with model SectionalMotif for Validation 2\n",
      "Template Eval Error: ValueError('kth(=3) out of bounds (3)') in model 47 in generation 0: SectionalMotif\n",
      "Model Number: 48 of 84 with model MetricMotif for Validation 2\n",
      "48 - MetricMotif with avg smape 46.86: \n",
      "Model Number: 49 of 84 with model SectionalMotif for Validation 2\n",
      "49 - SectionalMotif with avg smape 49.95: \n",
      "Model Number: 50 of 84 with model ARDL for Validation 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\decomposition\\_fastica.py:708: FutureWarning: Starting in v1.3, whiten=True should be specified as whiten='arbitrary-variance' (its current behaviour). This behavior is deprecated in 1.1 and will raise ValueError in 1.3.\n",
      "  return self._fit_transform(X, compute_sources=True)\n",
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\statsmodels\\genmod\\families\\links.py:198: RuntimeWarning: overflow encountered in exp\n",
      "  t = np.exp(-z)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📈 50 - ARDL with avg smape 38.12: \n",
      "Model Number: 51 of 84 with model UnivariateRegression for Validation 2\n",
      "51 - UnivariateRegression with avg smape 72.98: \n",
      "Model Number: 52 of 84 with model UnivariateRegression for Validation 2\n",
      "📈 52 - UnivariateRegression with avg smape 35.02: \n",
      "Model Number: 53 of 84 with model NVAR for Validation 2\n",
      "53 - NVAR with avg smape 61.24: \n",
      "Model Number: 54 of 84 with model LastValueNaive for Validation 2\n",
      "54 - LastValueNaive with avg smape 82.87: \n",
      "Model Number: 55 of 84 with model LastValueNaive for Validation 2\n",
      "55 - LastValueNaive with avg smape 82.68: \n",
      "Model Number: 56 of 84 with model LastValueNaive for Validation 2\n",
      "56 - LastValueNaive with avg smape 40.61: \n",
      "Model Number: 57 of 84 with model UnivariateRegression for Validation 2\n",
      "57 - UnivariateRegression with avg smape 55.13: \n",
      "Model Number: 58 of 84 with model SectionalMotif for Validation 2\n",
      "58 - SectionalMotif with avg smape 48.65: \n",
      "Model Number: 59 of 84 with model UnivariateRegression for Validation 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\autots\\tools\\probabilistic.py:67: RuntimeWarning: invalid value encountered in divide\n",
      "  (prior_mu / prior_sigma**2) + ((n * data_mu) / prior_sigma**2)\n",
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\autots\\tools\\probabilistic.py:68: RuntimeWarning: divide by zero encountered in divide\n",
      "  ) / ((1 / prior_sigma**2) + (n / prior_sigma**2))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59 - UnivariateRegression with avg smape 36.95: \n",
      "Model Number: 60 of 84 with model ARIMA for Validation 2\n",
      "60 - ARIMA with avg smape 47.44: \n",
      "Model Number: 61 of 84 with model UnivariateRegression for Validation 2\n",
      "61 - UnivariateRegression with avg smape 76.86: \n",
      "Model Number: 62 of 84 with model DatepartRegression for Validation 2\n",
      "62 - DatepartRegression with avg smape 54.16: \n",
      "Model Number: 63 of 84 with model ARDL for Validation 2\n",
      "63 - ARDL with avg smape 49.55: \n",
      "Model Number: 64 of 84 with model MultivariateMotif for Validation 2\n",
      "64 - MultivariateMotif with avg smape 126.5: \n",
      "Model Number: 65 of 84 with model MultivariateMotif for Validation 2\n",
      "65 - MultivariateMotif with avg smape 126.51: \n",
      "Model Number: 66 of 84 with model ARIMA for Validation 2\n",
      "66 - ARIMA with avg smape 60.29: \n",
      "Model Number: 67 of 84 with model DatepartRegression for Validation 2\n",
      "67 - DatepartRegression with avg smape 39.17: \n",
      "Model Number: 68 of 84 with model UnivariateMotif for Validation 2\n",
      "68 - UnivariateMotif with avg smape 81.03: \n",
      "Model Number: 69 of 84 with model ARDL for Validation 2\n",
      "69 - ARDL with avg smape 46.98: \n",
      "Model Number: 70 of 84 with model ARDL for Validation 2\n",
      "70 - ARDL with avg smape 46.98: \n",
      "Model Number: 71 of 84 with model MetricMotif for Validation 2\n",
      "71 - MetricMotif with avg smape 50.55: \n",
      "Model Number: 72 of 84 with model MetricMotif for Validation 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\decomposition\\_fastica.py:708: FutureWarning: Starting in v1.3, whiten=True should be specified as whiten='arbitrary-variance' (its current behaviour). This behavior is deprecated in 1.1 and will raise ValueError in 1.3.\n",
      "  return self._fit_transform(X, compute_sources=True)\n",
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\linear_model\\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.22635e-24): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72 - MetricMotif with avg smape 49.8: \n",
      "Model Number: 73 of 84 with model MetricMotif for Validation 2\n",
      "73 - MetricMotif with avg smape 56.12: \n",
      "Model Number: 74 of 84 with model MetricMotif for Validation 2\n",
      "74 - MetricMotif with avg smape 49.87: \n",
      "Model Number: 75 of 84 with model LastValueNaive for Validation 2\n",
      "75 - LastValueNaive with avg smape 83.81: \n",
      "Model Number: 76 of 84 with model NVAR for Validation 2\n",
      "76 - NVAR with avg smape 154.22: \n",
      "Model Number: 77 of 84 with model UnivariateMotif for Validation 2\n",
      "77 - UnivariateMotif with avg smape 86.01: \n",
      "Model Number: 78 of 84 with model Theta for Validation 2\n",
      "78 - Theta with avg smape 128.29: \n",
      "Model Number: 79 of 84 with model Theta for Validation 2\n",
      "79 - Theta with avg smape 128.29: \n",
      "Model Number: 80 of 84 with model Theta for Validation 2\n",
      "80 - Theta with avg smape 127.98: \n",
      "Model Number: 81 of 84 with model NVAR for Validation 2\n",
      "Template Eval Error: Exception('Transformer StandardScaler failed on inverse') in model 81 in generation 0: NVAR\n",
      "Model Number: 82 of 84 with model NVAR for Validation 2\n",
      "82 - NVAR with avg smape 41.69: \n",
      "Model Number: 83 of 84 with model MultivariateRegression for Validation 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\pandas\\core\\internals\\blocks.py:351: RuntimeWarning: overflow encountered in exp\n",
      "  result = func(self.values, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83 - MultivariateRegression with avg smape 38.86: \n",
      "Model Number: 84 of 84 with model MultivariateRegression for Validation 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84 - MultivariateRegression with avg smape 38.86: \n",
      "Validation Round: 3\n",
      "Model Number: 1 of 84 with model NVAR for Validation 3\n",
      "📈 1 - NVAR with avg smape 70.74: \n",
      "Model Number: 2 of 84 with model ConstantNaive for Validation 3\n",
      "2 - ConstantNaive with avg smape 164.79: \n",
      "Model Number: 3 of 84 with model ConstantNaive for Validation 3\n",
      "3 - ConstantNaive with avg smape 91.96: \n",
      "Model Number: 4 of 84 with model ConstantNaive for Validation 3\n",
      "4 - ConstantNaive with avg smape 91.96: \n",
      "Model Number: 5 of 84 with model ConstantNaive for Validation 3\n",
      "5 - ConstantNaive with avg smape 91.96: \n",
      "Model Number: 6 of 84 with model ARIMA for Validation 3\n",
      "6 - ARIMA with avg smape 87.33: \n",
      "Model Number: 7 of 84 with model ConstantNaive for Validation 3\n",
      "7 - ConstantNaive with avg smape 90.62: \n",
      "Model Number: 8 of 84 with model GLM for Validation 3\n",
      "8 - GLM with avg smape 107.38: \n",
      "Model Number: 9 of 84 with model GLS for Validation 3\n",
      "9 - GLS with avg smape 90.62: \n",
      "Model Number: 10 of 84 with model LastValueNaive for Validation 3\n",
      "📈 10 - LastValueNaive with avg smape 24.39: \n",
      "Model Number: 11 of 84 with model AverageValueNaive for Validation 3\n",
      "11 - AverageValueNaive with avg smape 91.91: \n",
      "Model Number: 12 of 84 with model AverageValueNaive for Validation 3\n",
      "12 - AverageValueNaive with avg smape 91.91: \n",
      "Model Number: 13 of 84 with model UnobservedComponents for Validation 3\n",
      "13 - UnobservedComponents with avg smape 90.62: \n",
      "Model Number: 14 of 84 with model ETS for Validation 3\n",
      "ETS error ValueError('Cannot compute initial seasonals using heuristic method with less than two full seasonal cycles in the data.')\n",
      "ETS failed on NET_SALES with ValueError('Cannot compute initial seasonals using heuristic method with less than two full seasonal cycles in the data.')\n",
      "14 - ETS with avg smape 91.96: \n",
      "Model Number: 15 of 84 with model ETS for Validation 3\n",
      "15 - ETS with avg smape 65.63: \n",
      "Model Number: 16 of 84 with model ETS for Validation 3\n",
      "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
      "ETS failed on NET_SALES with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
      "16 - ETS with avg smape 91.96: \n",
      "Model Number: 17 of 84 with model ETS for Validation 3\n",
      "ETS error ValueError('Cannot compute initial seasonals using heuristic method with less than two full seasonal cycles in the data.')\n",
      "ETS failed on NET_SALES with ValueError('Cannot compute initial seasonals using heuristic method with less than two full seasonal cycles in the data.')\n",
      "17 - ETS with avg smape 90.62: \n",
      "Model Number: 18 of 84 with model GLS for Validation 3\n",
      "18 - GLS with avg smape 90.62: \n",
      "Model Number: 19 of 84 with model GLS for Validation 3\n",
      "19 - GLS with avg smape 90.62: \n",
      "Model Number: 20 of 84 with model AverageValueNaive for Validation 3\n",
      "20 - AverageValueNaive with avg smape 126.42: \n",
      "Model Number: 21 of 84 with model AverageValueNaive for Validation 3\n",
      "21 - AverageValueNaive with avg smape 126.42: \n",
      "Model Number: 22 of 84 with model DatepartRegression for Validation 3\n",
      "22 - DatepartRegression with avg smape 86.47: \n",
      "Model Number: 23 of 84 with model DatepartRegression for Validation 3\n",
      "23 - DatepartRegression with avg smape 86.47: \n",
      "Model Number: 24 of 84 with model UnobservedComponents for Validation 3\n",
      "24 - UnobservedComponents with avg smape 99.08: \n",
      "Model Number: 25 of 84 with model GLS for Validation 3\n",
      "25 - GLS with avg smape 125.07: \n",
      "Model Number: 26 of 84 with model GLS for Validation 3\n",
      "26 - GLS with avg smape 126.51: \n",
      "Model Number: 27 of 84 with model SeasonalNaive for Validation 3\n",
      "27 - SeasonalNaive with avg smape 113.44: \n",
      "Model Number: 28 of 84 with model UnobservedComponents for Validation 3\n",
      "28 - UnobservedComponents with avg smape 83.04: \n",
      "Model Number: 29 of 84 with model ARIMA for Validation 3\n",
      "29 - ARIMA with avg smape 90.62: \n",
      "Model Number: 30 of 84 with model AverageValueNaive for Validation 3\n",
      "30 - AverageValueNaive with avg smape 85.67: \n",
      "Model Number: 31 of 84 with model UnobservedComponents for Validation 3\n",
      "31 - UnobservedComponents with avg smape 137.23: \n",
      "Model Number: 32 of 84 with model UnobservedComponents for Validation 3\n",
      "32 - UnobservedComponents with avg smape 137.23: \n",
      "Model Number: 33 of 84 with model DatepartRegression for Validation 3\n",
      "33 - DatepartRegression with avg smape 90.97: \n",
      "Model Number: 34 of 84 with model SeasonalNaive for Validation 3\n",
      "Template Eval Error: Exception('Transformer RegressionFilter failed on fit') in model 34 in generation 0: SeasonalNaive\n",
      "Model Number: 35 of 84 with model GLM for Validation 3\n",
      "Template Eval Error: Exception('Transformer RegressionFilter failed on fit') in model 35 in generation 0: GLM\n",
      "Model Number: 36 of 84 with model ARIMA for Validation 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\linear_model\\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.9706e-24): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36 - ARIMA with avg smape 79.86: \n",
      "Model Number: 37 of 84 with model ETS for Validation 3\n",
      "Template Eval Error: Exception('Transformer RegressionFilter failed on fit') in model 37 in generation 0: ETS\n",
      "Model Number: 38 of 84 with model ARDL for Validation 3\n",
      "38 - ARDL with avg smape 53.38: \n",
      "Model Number: 39 of 84 with model SectionalMotif for Validation 3\n",
      "Template Eval Error: ValueError('kth(=5) out of bounds (2)') in model 39 in generation 0: SectionalMotif\n",
      "Model Number: 40 of 84 with model SeasonalNaive for Validation 3\n",
      "40 - SeasonalNaive with avg smape 117.86: \n",
      "Model Number: 41 of 84 with model GLM for Validation 3\n",
      "41 - GLM with avg smape 76.21: \n",
      "Model Number: 42 of 84 with model GLM for Validation 3\n",
      "42 - GLM with avg smape 83.56: \n",
      "Model Number: 43 of 84 with model SeasonalNaive for Validation 3\n",
      "43 - SeasonalNaive with avg smape 96.09: \n",
      "Model Number: 44 of 84 with model SeasonalNaive for Validation 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\decomposition\\_fastica.py:708: FutureWarning: Starting in v1.3, whiten=True should be specified as whiten='arbitrary-variance' (its current behaviour). This behavior is deprecated in 1.1 and will raise ValueError in 1.3.\n",
      "  return self._fit_transform(X, compute_sources=True)\n",
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\decomposition\\_fastica.py:708: FutureWarning: Starting in v1.3, whiten=True should be specified as whiten='arbitrary-variance' (its current behaviour). This behavior is deprecated in 1.1 and will raise ValueError in 1.3.\n",
      "  return self._fit_transform(X, compute_sources=True)\n",
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\decomposition\\_fastica.py:708: FutureWarning: Starting in v1.3, whiten=True should be specified as whiten='arbitrary-variance' (its current behaviour). This behavior is deprecated in 1.1 and will raise ValueError in 1.3.\n",
      "  return self._fit_transform(X, compute_sources=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44 - SeasonalNaive with avg smape 96.66: \n",
      "Model Number: 45 of 84 with model GLM for Validation 3\n",
      "45 - GLM with avg smape 85.78: \n",
      "Model Number: 46 of 84 with model SectionalMotif for Validation 3\n",
      "Template Eval Error: ValueError('kth(=3) out of bounds (2)') in model 46 in generation 0: SectionalMotif\n",
      "Model Number: 47 of 84 with model SectionalMotif for Validation 3\n",
      "Template Eval Error: ValueError('kth(=3) out of bounds (2)') in model 47 in generation 0: SectionalMotif\n",
      "Model Number: 48 of 84 with model MetricMotif for Validation 3\n",
      "Template Eval Error: Exception('Transformer RegressionFilter failed on fit') in model 48 in generation 0: MetricMotif\n",
      "Model Number: 49 of 84 with model SectionalMotif for Validation 3\n",
      "49 - SectionalMotif with avg smape 94.27: \n",
      "Model Number: 50 of 84 with model ARDL for Validation 3\n",
      "50 - ARDL with avg smape 71.42: \n",
      "Model Number: 51 of 84 with model UnivariateRegression for Validation 3\n",
      "51 - UnivariateRegression with avg smape 84.29: \n",
      "Model Number: 52 of 84 with model UnivariateRegression for Validation 3\n",
      "📈 52 - UnivariateRegression with avg smape 22.47: \n",
      "Model Number: 53 of 84 with model NVAR for Validation 3\n",
      "53 - NVAR with avg smape 29.47: \n",
      "Model Number: 54 of 84 with model LastValueNaive for Validation 3\n",
      "54 - LastValueNaive with avg smape 34.17: \n",
      "Model Number: 55 of 84 with model LastValueNaive for Validation 3\n",
      "55 - LastValueNaive with avg smape 33.92: \n",
      "Model Number: 56 of 84 with model LastValueNaive for Validation 3\n",
      "56 - LastValueNaive with avg smape 49.96: \n",
      "Model Number: 57 of 84 with model UnivariateRegression for Validation 3\n",
      "57 - UnivariateRegression with avg smape 56.79: \n",
      "Model Number: 58 of 84 with model SectionalMotif for Validation 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\autots\\tools\\probabilistic.py:67: RuntimeWarning: invalid value encountered in divide\n",
      "  (prior_mu / prior_sigma**2) + ((n * data_mu) / prior_sigma**2)\n",
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\autots\\tools\\probabilistic.py:68: RuntimeWarning: divide by zero encountered in divide\n",
      "  ) / ((1 / prior_sigma**2) + (n / prior_sigma**2))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58 - SectionalMotif with avg smape 100.23: \n",
      "Model Number: 59 of 84 with model UnivariateRegression for Validation 3\n",
      "59 - UnivariateRegression with avg smape 133.69: \n",
      "Model Number: 60 of 84 with model ARIMA for Validation 3\n",
      "60 - ARIMA with avg smape 31.42: \n",
      "Model Number: 61 of 84 with model UnivariateRegression for Validation 3\n",
      "61 - UnivariateRegression with avg smape 106.81: \n",
      "Model Number: 62 of 84 with model DatepartRegression for Validation 3\n",
      "62 - DatepartRegression with avg smape 54.94: \n",
      "Model Number: 63 of 84 with model ARDL for Validation 3\n",
      "63 - ARDL with avg smape 36.64: \n",
      "Model Number: 64 of 84 with model MultivariateMotif for Validation 3\n",
      "64 - MultivariateMotif with avg smape 104.6: \n",
      "Model Number: 65 of 84 with model MultivariateMotif for Validation 3\n",
      "65 - MultivariateMotif with avg smape 104.62: \n",
      "Model Number: 66 of 84 with model ARIMA for Validation 3\n",
      "66 - ARIMA with avg smape 72.99: \n",
      "Model Number: 67 of 84 with model DatepartRegression for Validation 3\n",
      "📈 67 - DatepartRegression with avg smape 20.06: \n",
      "Model Number: 68 of 84 with model UnivariateMotif for Validation 3\n",
      "68 - UnivariateMotif with avg smape 75.64: \n",
      "Model Number: 69 of 84 with model ARDL for Validation 3\n",
      "69 - ARDL with avg smape 64.9: \n",
      "Model Number: 70 of 84 with model ARDL for Validation 3\n",
      "70 - ARDL with avg smape 64.9: \n",
      "Model Number: 71 of 84 with model MetricMotif for Validation 3\n",
      "Template Eval Error: Exception('Transformer RegressionFilter failed on fit') in model 71 in generation 0: MetricMotif\n",
      "Model Number: 72 of 84 with model MetricMotif for Validation 3\n",
      "72 - MetricMotif with avg smape 41.0: \n",
      "Model Number: 73 of 84 with model MetricMotif for Validation 3\n",
      "73 - MetricMotif with avg smape 87.96: \n",
      "Model Number: 74 of 84 with model MetricMotif for Validation 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\decomposition\\_fastica.py:708: FutureWarning: Starting in v1.3, whiten=True should be specified as whiten='arbitrary-variance' (its current behaviour). This behavior is deprecated in 1.1 and will raise ValueError in 1.3.\n",
      "  return self._fit_transform(X, compute_sources=True)\n",
      "c:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\sklearn\\linear_model\\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.9706e-24): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74 - MetricMotif with avg smape 86.58: \n",
      "Model Number: 75 of 84 with model LastValueNaive for Validation 3\n",
      "75 - LastValueNaive with avg smape 44.77: \n",
      "Model Number: 76 of 84 with model NVAR for Validation 3\n",
      "76 - NVAR with avg smape 101.5: \n",
      "Model Number: 77 of 84 with model UnivariateMotif for Validation 3\n",
      "77 - UnivariateMotif with avg smape 116.65: \n",
      "Model Number: 78 of 84 with model Theta for Validation 3\n",
      "78 - Theta with avg smape 145.45: \n",
      "Model Number: 79 of 84 with model Theta for Validation 3\n",
      "79 - Theta with avg smape 145.45: \n",
      "Model Number: 80 of 84 with model Theta for Validation 3\n",
      "80 - Theta with avg smape 145.29: \n",
      "Model Number: 81 of 84 with model NVAR for Validation 3\n",
      "81 - NVAR with avg smape 82.41: \n",
      "Model Number: 82 of 84 with model NVAR for Validation 3\n",
      "82 - NVAR with avg smape 20.43: \n",
      "Model Number: 83 of 84 with model MultivariateRegression for Validation 3\n",
      "Template Eval Error: Exception('Transformer RegressionFilter failed on fit') in model 83 in generation 0: MultivariateRegression\n",
      "Model Number: 84 of 84 with model MultivariateRegression for Validation 3\n",
      "Template Eval Error: Exception('Transformer RegressionFilter failed on fit') in model 84 in generation 0: MultivariateRegression\n",
      "TotalRuntime missing in 5!\n",
      "Validation Round: 1\n",
      "TotalRuntime missing in 0!\n",
      "Validation Round: 2\n",
      "TotalRuntime missing in 0!\n",
      "Validation Round: 3\n",
      "TotalRuntime missing in 0!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██▏       | 3/14 [08:48<32:19, 176.32s/it]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "future_regressor and X index failed to align",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 49\u001b[0m\n\u001b[0;32m     39\u001b[0m model \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mfit(\n\u001b[0;32m     40\u001b[0m     df_subset_trim,\n\u001b[0;32m     41\u001b[0m     future_regressor\u001b[39m=\u001b[39mdf_subset_train,\n\u001b[0;32m     42\u001b[0m     date_col\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mMONTH\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m     43\u001b[0m     value_col\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mNET_SALES\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m     44\u001b[0m )\n\u001b[0;32m     46\u001b[0m \u001b[39m# print(model)\u001b[39;00m\n\u001b[0;32m     47\u001b[0m \n\u001b[0;32m     48\u001b[0m \u001b[39m# create prediction\u001b[39;00m\n\u001b[1;32m---> 49\u001b[0m prediction \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mpredict(future_regressor\u001b[39m=\u001b[39;49mdf_subset_fcast, forecast_length\u001b[39m=\u001b[39;49mfh)\n\u001b[0;32m     51\u001b[0m \u001b[39m# temp fcast dataframe\u001b[39;00m\n\u001b[0;32m     52\u001b[0m temp_fcasts \u001b[39m=\u001b[39m prediction\u001b[39m.\u001b[39mforecast\n",
      "File \u001b[1;32mc:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\autots\\evaluator\\auto_ts.py:2199\u001b[0m, in \u001b[0;36mAutoTS.predict\u001b[1;34m(self, forecast_length, prediction_interval, future_regressor, hierarchy, just_point_forecast, fail_on_forecast_nan, verbose)\u001b[0m\n\u001b[0;32m   2197\u001b[0m     \u001b[39mreturn\u001b[39;00m forecast_objects\n\u001b[0;32m   2198\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 2199\u001b[0m     df_forecast \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_predict(\n\u001b[0;32m   2200\u001b[0m         forecast_length\u001b[39m=\u001b[39;49mforecast_length,\n\u001b[0;32m   2201\u001b[0m         prediction_interval\u001b[39m=\u001b[39;49mprediction_interval,\n\u001b[0;32m   2202\u001b[0m         future_regressor\u001b[39m=\u001b[39;49mfuture_regressor,\n\u001b[0;32m   2203\u001b[0m         fail_on_forecast_nan\u001b[39m=\u001b[39;49mfail_on_forecast_nan,\n\u001b[0;32m   2204\u001b[0m         verbose\u001b[39m=\u001b[39;49mverbose,\n\u001b[0;32m   2205\u001b[0m     )\n\u001b[0;32m   2206\u001b[0m     \u001b[39mif\u001b[39;00m just_point_forecast:\n\u001b[0;32m   2207\u001b[0m         \u001b[39mreturn\u001b[39;00m df_forecast\u001b[39m.\u001b[39mforecast\n",
      "File \u001b[1;32mc:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\autots\\evaluator\\auto_ts.py:2074\u001b[0m, in \u001b[0;36mAutoTS._predict\u001b[1;34m(self, forecast_length, prediction_interval, future_regressor, fail_on_forecast_nan, verbose, model_name, model_params, model_transformation_params, df_wide_numeric, future_regressor_train, refit)\u001b[0m\n\u001b[0;32m   2072\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   2073\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mfit_data(use_data, future_regressor\u001b[39m=\u001b[39muse_regr_train)\n\u001b[1;32m-> 2074\u001b[0m     df_forecast \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel\u001b[39m.\u001b[39;49mpredict(\n\u001b[0;32m   2075\u001b[0m         forecast_length, future_regressor\u001b[39m=\u001b[39;49mfuture_regressor\n\u001b[0;32m   2076\u001b[0m     )\n\u001b[0;32m   2077\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   2078\u001b[0m     df_forecast \u001b[39m=\u001b[39m model_forecast(\n\u001b[0;32m   2079\u001b[0m         model_name\u001b[39m=\u001b[39muse_model,\n\u001b[0;32m   2080\u001b[0m         model_param_dict\u001b[39m=\u001b[39muse_params,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2099\u001b[0m         return_model\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[0;32m   2100\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\autots\\evaluator\\auto_model.py:765\u001b[0m, in \u001b[0;36mModelPrediction.predict\u001b[1;34m(self, forecast_length, future_regressor)\u001b[0m\n\u001b[0;32m    763\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fit_complete:\n\u001b[0;32m    764\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mModel not yet fit.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m--> 765\u001b[0m df_forecast \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel\u001b[39m.\u001b[39;49mpredict(\n\u001b[0;32m    766\u001b[0m     forecast_length\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mforecast_length, future_regressor\u001b[39m=\u001b[39;49mfuture_regressor\n\u001b[0;32m    767\u001b[0m )\n\u001b[0;32m    769\u001b[0m \u001b[39m# THIS CHECKS POINT FORECAST FOR NULLS BUT NOT UPPER/LOWER FORECASTS\u001b[39;00m\n\u001b[0;32m    770\u001b[0m \u001b[39m# can maybe remove this eventually and just keep the later one\u001b[39;00m\n\u001b[0;32m    771\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfail_on_forecast_nan:\n",
      "File \u001b[1;32mc:\\Users\\crudek\\AppData\\Local\\anaconda3\\envs\\newpycaret\\lib\\site-packages\\autots\\models\\sklearn.py:2047\u001b[0m, in \u001b[0;36mDatepartRegression.predict\u001b[1;34m(self, forecast_length, future_regressor, just_point_forecast, df)\u001b[0m\n\u001b[0;32m   2045\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mX_pred \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mconcat([\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mX_pred, future_regressor], axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m   2046\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mX_pred\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m] \u001b[39m>\u001b[39m index\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]:\n\u001b[1;32m-> 2047\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mfuture_regressor and X index failed to align\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   2048\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mX_pred\u001b[39m.\u001b[39mcolumns \u001b[39m=\u001b[39m [\u001b[39mstr\u001b[39m(xc) \u001b[39mfor\u001b[39;00m xc \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mX_pred\u001b[39m.\u001b[39mcolumns]\n\u001b[0;32m   2050\u001b[0m forecast \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(\n\u001b[0;32m   2051\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mpredict(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mX_pred\u001b[39m.\u001b[39mastype(\u001b[39mfloat\u001b[39m)),\n\u001b[0;32m   2052\u001b[0m     index\u001b[39m=\u001b[39mindex,\n\u001b[0;32m   2053\u001b[0m     columns\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumn_names,\n\u001b[0;32m   2054\u001b[0m )\n",
      "\u001b[1;31mValueError\u001b[0m: future_regressor and X index failed to align"
     ]
    }
   ],
   "source": [
    "### Time Series Loop w/ Regressors ###\n",
    "\n",
    "# Create empty dataframes\n",
    "all_predictions = pd.DataFrame()\n",
    "\n",
    "# list of each dep-ent\n",
    "de_list = df_d_regress1['DEP_ENT'].unique()\n",
    "\n",
    "for i in tqdm(de_list):\n",
    "\n",
    "    df_subset = df_d_regress1[df_d_regress1['DEP_ENT'] == i]\n",
    "    df_subset_trim = df_subset[df_subset['MONTH'] <= end_of_data]\n",
    "    df_subset_trim = df_subset_trim[['MONTH', 'NET_SALES']]\n",
    "\n",
    "    # split the train and original df\n",
    "\n",
    "    # train\n",
    "    df_subset_train = df_subset[df_subset['MONTH'] <= end_of_data]\n",
    "    df_subset_train = df_subset_train[[\"MONTH\", \"COVID\", \"AMZN\"]]\n",
    "    df_subset_train['COVID'] = df_subset_train['COVID'].apply(str)\n",
    "    df_subset_train['AMZN'] = df_subset_train['AMZN'].apply(str)\n",
    "    #df_subset_trim.reset_index()\n",
    "\n",
    "    # for future forecast\n",
    "    df_subset_fcast = df_subset[df_subset['MONTH'] > end_of_data]\n",
    "    df_subset_fcast = df_subset_fcast[[\"MONTH\", \"COVID\", \"AMZN\"]]\n",
    "    df_subset_fcast['COVID'] = df_subset_fcast['COVID'].apply(str)\n",
    "    df_subset_fcast['AMZN'] = df_subset_fcast['AMZN'].apply(str)\n",
    "    #df_subset_trim.reset_index()\n",
    "\n",
    "    # model\n",
    "    model = AutoTS(\n",
    "        forecast_length=fh,\n",
    "        frequency='infer',\n",
    "        # prediction_interval=0.95,\n",
    "        # ensemble='simple',\n",
    "        # models_mode='deep',\n",
    "        # model_list = 'univariate', # or could do a list like ['ARIMA','ETS']\n",
    "        max_generations=3,\n",
    "        num_validations=3,\n",
    "        no_negatives=True,\n",
    "        n_jobs='auto'\n",
    "    )\n",
    "\n",
    "    model = model.fit(\n",
    "        df_subset_trim,\n",
    "        future_regressor=df_subset_train,\n",
    "        date_col='MONTH',\n",
    "        value_col='NET_SALES',\n",
    "    )\n",
    "\n",
    "    # print(model)\n",
    "\n",
    "    # create prediction\n",
    "    prediction = model.predict(future_regressor=df_subset_fcast, forecast_length=fh)\n",
    "\n",
    "    # temp fcast dataframe\n",
    "    temp_fcasts = prediction.forecast\n",
    "\n",
    "    # make index, date, a column\n",
    "    temp_fcasts_ni = temp_fcasts.reset_index()\n",
    "\n",
    "    # rename\n",
    "    temp_fcasts_ni.rename(columns={'index': 'MONTH'}, inplace=True)\n",
    "\n",
    "    temp_fcasts_ni['DEP_ENT'] = i  # add dep\n",
    "\n",
    "    # append to master dataframe\n",
    "    all_predictions = all_predictions.append(temp_fcasts_ni)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MONTH</th>\n",
       "      <th>COVID</th>\n",
       "      <th>AMZN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>372</th>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373</th>\n",
       "      <td>2023-02-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374</th>\n",
       "      <td>2023-03-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375</th>\n",
       "      <td>2023-04-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376</th>\n",
       "      <td>2023-05-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377</th>\n",
       "      <td>2023-06-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378</th>\n",
       "      <td>2023-07-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379</th>\n",
       "      <td>2023-08-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380</th>\n",
       "      <td>2023-09-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381</th>\n",
       "      <td>2023-10-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382</th>\n",
       "      <td>2023-11-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383</th>\n",
       "      <td>2023-12-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         MONTH COVID  AMZN\n",
       "372 2023-01-01     0     0\n",
       "373 2023-02-01     0     0\n",
       "374 2023-03-01     0     0\n",
       "375 2023-04-01     0     0\n",
       "376 2023-05-01     0     0\n",
       "377 2023-06-01     0     0\n",
       "378 2023-07-01     0     0\n",
       "379 2023-08-01     0     0\n",
       "380 2023-09-01     0     0\n",
       "381 2023-10-01     0     0\n",
       "382 2023-11-01     0     0\n",
       "383 2023-12-01     0     0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_subset_fcast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>MONTH</th>\n",
       "      <th>COVID</th>\n",
       "      <th>AMZN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>372</td>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>373</td>\n",
       "      <td>2023-02-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>374</td>\n",
       "      <td>2023-03-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>375</td>\n",
       "      <td>2023-04-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>376</td>\n",
       "      <td>2023-05-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>377</td>\n",
       "      <td>2023-06-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>378</td>\n",
       "      <td>2023-07-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>379</td>\n",
       "      <td>2023-08-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>380</td>\n",
       "      <td>2023-09-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>381</td>\n",
       "      <td>2023-10-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>382</td>\n",
       "      <td>2023-11-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>383</td>\n",
       "      <td>2023-12-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    index      MONTH COVID  AMZN\n",
       "0     372 2023-01-01     0     0\n",
       "1     373 2023-02-01     0     0\n",
       "2     374 2023-03-01     0     0\n",
       "3     375 2023-04-01     0     0\n",
       "4     376 2023-05-01     0     0\n",
       "5     377 2023-06-01     0     0\n",
       "6     378 2023-07-01     0     0\n",
       "7     379 2023-08-01     0     0\n",
       "8     380 2023-09-01     0     0\n",
       "9     381 2023-10-01     0     0\n",
       "10    382 2023-11-01     0     0\n",
       "11    383 2023-12-01     0     0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_subset_fcast.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>MONTH</th>\n",
       "      <th>NET_SALES</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>288</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>39129.602940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>289</td>\n",
       "      <td>2016-02-01</td>\n",
       "      <td>46143.840813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>290</td>\n",
       "      <td>2016-03-01</td>\n",
       "      <td>36359.259808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>291</td>\n",
       "      <td>2016-04-01</td>\n",
       "      <td>27159.842641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>292</td>\n",
       "      <td>2016-05-01</td>\n",
       "      <td>36951.860410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>367</td>\n",
       "      <td>2022-08-01</td>\n",
       "      <td>219711.287423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>368</td>\n",
       "      <td>2022-09-01</td>\n",
       "      <td>362698.991751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>369</td>\n",
       "      <td>2022-10-01</td>\n",
       "      <td>110217.050523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>370</td>\n",
       "      <td>2022-11-01</td>\n",
       "      <td>442799.632353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>371</td>\n",
       "      <td>2022-12-01</td>\n",
       "      <td>221944.756223</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>84 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    index      MONTH      NET_SALES\n",
       "0     288 2016-01-01   39129.602940\n",
       "1     289 2016-02-01   46143.840813\n",
       "2     290 2016-03-01   36359.259808\n",
       "3     291 2016-04-01   27159.842641\n",
       "4     292 2016-05-01   36951.860410\n",
       "..    ...        ...            ...\n",
       "79    367 2022-08-01  219711.287423\n",
       "80    368 2022-09-01  362698.991751\n",
       "81    369 2022-10-01  110217.050523\n",
       "82    370 2022-11-01  442799.632353\n",
       "83    371 2022-12-01  221944.756223\n",
       "\n",
       "[84 rows x 3 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_subset_trim.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### AFTER THE LOOP ###\n",
    "\n",
    "# rename index col\n",
    "all_predictions.rename(columns={'index': 'MONTH', 'NET_SALES': 'PRED'}, inplace=True)\n",
    "\n",
    "# initial sales pull\n",
    "sales = df_initial\n",
    "# select cols\n",
    "sales = sales[[\"DEP_ENT\", \"MONTH\", \"NET_SALES\"]]\n",
    "# only include sales data for the full months we have\n",
    "first_of_month = datetime.today().replace(day=1).date()\n",
    "sales = sales[sales['MONTH'] < pd.to_datetime(first_of_month)]\n",
    "\n",
    "# combine prediction data and original sales data\n",
    "merged = pd.merge(all_predictions, sales, how='left', on=['DEP_ENT', 'MONTH'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (py.warnings._showwarnmsg) - C:\\Users\\crudek\\AppData\\Local\\Temp\\ipykernel_12204\\3534014428.py:8: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  budg = pd.read_sql_query(query.read(),conn)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### BUDGET ###\n",
    "\n",
    "# Establish a connection to Snowflake\n",
    "conn = snowflake.connector.connect(**connection_params)\n",
    "\n",
    "with open('budget_query.sql', 'r') as query:\n",
    "    # connection == the connection to your database, in your case prob_db\n",
    "    budg = pd.read_sql_query(query.read(), conn)\n",
    "\n",
    "# Close the connection\n",
    "conn.close()\n",
    "\n",
    "# convert month to datetime\n",
    "budg[\"MONTH\"] = pd.to_datetime(budg[\"MONTH\"])\n",
    "# select cols\n",
    "budg = budg[[\"MONTH\", \"BUDGET_AMOUNT\", \"DEP_ENT\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine prediction/sales data with budget data\n",
    "merged2 = pd.merge(merged, budg, how='left', on=['DEP_ENT', 'MONTH'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write csv\n",
    "merged2.to_csv('auto_tsr_results.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "newpycaret",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
