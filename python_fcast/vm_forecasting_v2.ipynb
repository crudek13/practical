{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vitamix Forecasting Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global\n",
    "    * Data Load and Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Packages\n",
    "import snowflake.connector\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# import the time seris module from pycaret\n",
    "#from pycaret.time_series import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# copy and paste in to a new chunk, enter credentials and run to save in environment. Then delete chunk\n",
    "%env snowflakeuser=<your_snowflake_username>\n",
    "%env snowflakepass=<your_snowflake_password>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\crudek\\AppData\\Local\\Temp\\ipykernel_18760\\2851543061.py:9: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql_query(query, conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   DEP_ENT       MONTH   NET_SALES  BUDGET_AMOUNT      FORECAST\n",
      "0  210_155  2023-07-01  2817972.34      5004554.0  3.885478e+06\n",
      "1  210_155  2023-08-01         NaN      5812184.0  3.431112e+06\n",
      "2  210_155  2023-09-01         NaN      5786571.0  4.134850e+06\n",
      "3  210_155  2023-10-01         NaN      5239358.0  3.793092e+06\n",
      "4  210_155  2023-11-01         NaN      7036356.0  5.865456e+06\n"
     ]
    }
   ],
   "source": [
    "# Query Snowflake\n",
    "\n",
    "def snowflake_to_pandas(connection_params, query):\n",
    "    try:\n",
    "        # Establish a connection to Snowflake\n",
    "        conn = snowflake.connector.connect(**connection_params)\n",
    "\n",
    "        # Execute the SQL query and fetch the results into a DataFrame\n",
    "        df = pd.read_sql_query(query, conn)\n",
    "\n",
    "        # Close the connection\n",
    "        conn.close()\n",
    "\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return None\n",
    "\n",
    "# Snowflake connection parameters\n",
    "connection_params = {\n",
    "    \"user\": os.environ['snowflakeuser'],\n",
    "    \"password\": os.environ['snowflakepass'],\n",
    "    \"account\": \"zib52348.us-east-1\",\n",
    "    \"role\": \"ACCOUNTADMIN\",\n",
    "    \"warehouse\": \"REPORTING\",\n",
    "    \"database\": \"ANALYTICS\",\n",
    "    \"schema\": \"FORECASTING\",\n",
    "}\n",
    "\n",
    "# SQL command \n",
    "query = 'SELECT * FROM \"ANALYTICS\".\"FORECASTING\".\"sales_fcast_combined_v\"'\n",
    "\n",
    "# Call the function to retrieve the data into a Pandas DataFrame\n",
    "result_df = snowflake_to_pandas(connection_params, query)\n",
    "\n",
    "if result_df is not None:\n",
    "    print(result_df.head())  # Display the first few rows of the DataFrame\n",
    "else:\n",
    "    print(\"Failed to retrieve data from Snowflake.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Data prep ###\n",
    "\n",
    "result_df[\"MONTH\"] = pd.to_datetime(result_df[\"MONTH\"]) # convert month field to date\n",
    "df_all = result_df[result_df['MONTH'] <= pd.Timestamp(2023,6,1)] # we have data through July '23 when we are training these models. Some random months will have data that we want to remove (* Want to test without July though)\n",
    "df_all = df_all[[\"DEP_ENT\", \"MONTH\", \"NET_SALES\"]] # select fields of interest\n",
    "df_all = df_all.sort_values(['DEP_ENT', 'MONTH']) # reorder dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n",
      "-----\n",
      "DEP_ENT\n",
      "160_155    90\n",
      "170_155    90\n",
      "200_155    90\n",
      "200_310    90\n",
      "210_155    90\n",
      "210_165    90\n",
      "210_310    90\n",
      "220_155    90\n",
      "220_310    84\n",
      "240_155    90\n",
      "250_155    90\n",
      "250_165    56\n",
      "250_310    90\n",
      "260_155    53\n",
      "dtype: int64\n",
      "-----\n",
      "DEP_ENT      0\n",
      "MONTH        0\n",
      "NET_SALES    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "### Spot checks ###\n",
    "\n",
    "# check the unique time_series. 14 different department-entity combinations\n",
    "print(df_all['DEP_ENT'].nunique())\n",
    "print(\"-----\")\n",
    "\n",
    "# check how many months for each dep-ent. 3 dep-ent do not have a full 91 months of data\n",
    "print(df_all.groupby(['DEP_ENT']).size())\n",
    "print(\"-----\")\n",
    "\n",
    "# check for nulls. No nulls\n",
    "print(df_all.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataset to test for one department\n",
    "df_200_155 = df_all[(df_all.DEP_ENT == \"200_155\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1\n",
    "# Time Series Forecasting with PyCaret Regression\n",
    "\n",
    "Pycaret 3.04 regression documentation: https://pycaret.readthedocs.io/en/stable/api/regression.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Series  Year  Month   NET_SALES\n",
      "976      73  2022      1  1985988.92\n",
      "977      74  2022      2  2328955.97\n",
      "978      75  2022      3  2240477.51\n",
      "979      76  2022      4  2394403.39\n",
      "980      77  2022      5  2275736.56\n",
      "-----\n",
      "(72, 4) (18, 4)\n"
     ]
    }
   ],
   "source": [
    "### Regression data preparation ###\n",
    "\n",
    "# extract month and year from dates\n",
    "df_200_155['Month'] = [i.month for i in df_200_155['MONTH']]\n",
    "df_200_155['Year'] = [i.year for i in df_200_155['MONTH']]\n",
    "\n",
    "# create a sequence of numbers\n",
    "df_200_155['Series'] = np.arange(1,len(df_200_155)+1)\n",
    "\n",
    "# trim\n",
    "df_200_155_trim = df_200_155[['Series', 'Year', 'Month', 'NET_SALES']] \n",
    "\n",
    "# ## Testing and Training datsets. This is need to determine best model. We can't include the whole dataset or we will overfit\n",
    "# train_200_155 = df_200_155[(df_200_155.Series <= round(len(df_200_155.index) * .8))] # ~80% for training\n",
    "# test_200_155 = df_200_155[(df_200_155.Series > round(len(df_200_155.index) * .8))] # ~20% for testing\n",
    "\n",
    "# # drop unnecessary columns and re-arrange\n",
    "# train_200_155 = train_200_155[['Series', 'Year', 'Month', 'NET_SALES']] \n",
    "# test_200_155 = test_200_155[['Series', 'Year', 'Month', 'NET_SALES']] \n",
    "\n",
    "# # review\n",
    "# print(test_200_155.head())\n",
    "# print(\"-----\")\n",
    "# # check shape\n",
    "# print(train_200_155.shape, test_200_155.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_7a269_row8_col1 {\n",
       "  background-color: lightgreen;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_7a269\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_7a269_level0_col0\" class=\"col_heading level0 col0\" >Description</th>\n",
       "      <th id=\"T_7a269_level0_col1\" class=\"col_heading level0 col1\" >Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_7a269_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_7a269_row0_col0\" class=\"data row0 col0\" >Session id</td>\n",
       "      <td id=\"T_7a269_row0_col1\" class=\"data row0 col1\" >123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7a269_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_7a269_row1_col0\" class=\"data row1 col0\" >Target</td>\n",
       "      <td id=\"T_7a269_row1_col1\" class=\"data row1 col1\" >NET_SALES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7a269_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_7a269_row2_col0\" class=\"data row2 col0\" >Target type</td>\n",
       "      <td id=\"T_7a269_row2_col1\" class=\"data row2 col1\" >Regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7a269_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_7a269_row3_col0\" class=\"data row3 col0\" >Original data shape</td>\n",
       "      <td id=\"T_7a269_row3_col1\" class=\"data row3 col1\" >(90, 4)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7a269_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_7a269_row4_col0\" class=\"data row4 col0\" >Transformed data shape</td>\n",
       "      <td id=\"T_7a269_row4_col1\" class=\"data row4 col1\" >(90, 4)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7a269_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_7a269_row5_col0\" class=\"data row5 col0\" >Transformed train set shape</td>\n",
       "      <td id=\"T_7a269_row5_col1\" class=\"data row5 col1\" >(62, 4)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7a269_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_7a269_row6_col0\" class=\"data row6 col0\" >Transformed test set shape</td>\n",
       "      <td id=\"T_7a269_row6_col1\" class=\"data row6 col1\" >(28, 4)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7a269_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_7a269_row7_col0\" class=\"data row7 col0\" >Numeric features</td>\n",
       "      <td id=\"T_7a269_row7_col1\" class=\"data row7 col1\" >3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7a269_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_7a269_row8_col0\" class=\"data row8 col0\" >Preprocess</td>\n",
       "      <td id=\"T_7a269_row8_col1\" class=\"data row8 col1\" >True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7a269_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_7a269_row9_col0\" class=\"data row9 col0\" >Imputation type</td>\n",
       "      <td id=\"T_7a269_row9_col1\" class=\"data row9 col1\" >simple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7a269_level0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
       "      <td id=\"T_7a269_row10_col0\" class=\"data row10 col0\" >Numeric imputation</td>\n",
       "      <td id=\"T_7a269_row10_col1\" class=\"data row10 col1\" >mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7a269_level0_row11\" class=\"row_heading level0 row11\" >11</th>\n",
       "      <td id=\"T_7a269_row11_col0\" class=\"data row11 col0\" >Categorical imputation</td>\n",
       "      <td id=\"T_7a269_row11_col1\" class=\"data row11 col1\" >mode</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7a269_level0_row12\" class=\"row_heading level0 row12\" >12</th>\n",
       "      <td id=\"T_7a269_row12_col0\" class=\"data row12 col0\" >Fold Generator</td>\n",
       "      <td id=\"T_7a269_row12_col1\" class=\"data row12 col1\" >KFold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7a269_level0_row13\" class=\"row_heading level0 row13\" >13</th>\n",
       "      <td id=\"T_7a269_row13_col0\" class=\"data row13 col0\" >Fold Number</td>\n",
       "      <td id=\"T_7a269_row13_col1\" class=\"data row13 col1\" >10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7a269_level0_row14\" class=\"row_heading level0 row14\" >14</th>\n",
       "      <td id=\"T_7a269_row14_col0\" class=\"data row14 col0\" >CPU Jobs</td>\n",
       "      <td id=\"T_7a269_row14_col1\" class=\"data row14 col1\" >-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7a269_level0_row15\" class=\"row_heading level0 row15\" >15</th>\n",
       "      <td id=\"T_7a269_row15_col0\" class=\"data row15 col0\" >Use GPU</td>\n",
       "      <td id=\"T_7a269_row15_col1\" class=\"data row15 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7a269_level0_row16\" class=\"row_heading level0 row16\" >16</th>\n",
       "      <td id=\"T_7a269_row16_col0\" class=\"data row16 col0\" >Log Experiment</td>\n",
       "      <td id=\"T_7a269_row16_col1\" class=\"data row16 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7a269_level0_row17\" class=\"row_heading level0 row17\" >17</th>\n",
       "      <td id=\"T_7a269_row17_col0\" class=\"data row17 col0\" >Experiment Name</td>\n",
       "      <td id=\"T_7a269_row17_col1\" class=\"data row17 col1\" >reg-default-name</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7a269_level0_row18\" class=\"row_heading level0 row18\" >18</th>\n",
       "      <td id=\"T_7a269_row18_col0\" class=\"data row18 col0\" >USI</td>\n",
       "      <td id=\"T_7a269_row18_col1\" class=\"data row18 col1\" >6092</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1fec0c63700>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### Regression Functional API\n",
    "\n",
    "# import the regression module from pycaret   \n",
    "from pycaret.regression import *\n",
    "\n",
    "# initialize setup**\n",
    "s = setup(data = df_200_155_trim, target = 'NET_SALES', session_id = 123)\n",
    "\n",
    "\n",
    "### Modeling steps ###\n",
    "\n",
    "# model training and selection\n",
    "regress_best = compare_models(sort = 'R2')\n",
    "\n",
    "# evaluate trained model\n",
    "evaluate_model(regress_best)\n",
    "\n",
    "# predict on hold-out/test set\n",
    "regress_pred_holdout = predict_model(regress_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "### New data to predict ###\n",
    "\n",
    "# max date from original dataset\n",
    "max_timestamp = df_200_155['MONTH'].max()\n",
    "\n",
    "# create dataframe for future dates, in this case the rest of 2023\n",
    "next_dates = [max_timestamp.replace(day=1) + pd.DateOffset(months=i) for i in range(1, 7)] # Need to change range based on how many periods ahead you want to predict\n",
    "new_dates_df = pd.DataFrame({'MONTH': next_dates})\n",
    "new_dates_df[\"MONTH\"] = pd.to_datetime(new_dates_df[\"MONTH\"]) \n",
    "\n",
    "# extract month and year from dates\n",
    "new_dates_df['Month'] = [i.month for i in new_dates_df['MONTH']]\n",
    "new_dates_df['Year'] = [i.year for i in new_dates_df['MONTH']]\n",
    "\n",
    "# create a sequence of numbers\n",
    "new_dates_df['Series'] = np.arange(1,len(new_dates_df)+1)\n",
    "\n",
    "# select cols\n",
    "new_dates_df = new_dates_df[['Series', 'Year', 'Month']] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# predict on new data\n",
    "predictions = predict_model(regress_best, data = new_dates_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "newpycaret",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
